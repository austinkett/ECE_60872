diff --git a/numpy/core/src/umath/loops.c.src b/numpy/core/src/umath/loops.c.src
index 0d9806f5d6a..9b90b67be38 100644
--- a/numpy/core/src/umath/loops.c.src
+++ b/numpy/core/src/umath/loops.c.src
@@ -772,6 +772,7 @@ BOOL__ones_like(char **args, npy_intp *dimensions, npy_intp *steps, void *NPY_UN
  *         npy_long, npy_ulong, npy_longlong, npy_ulonglong#
  * #ftype = npy_float, npy_float, npy_float, npy_float, npy_double, npy_double,
  *          npy_double, npy_double, npy_double, npy_double#
+ * #issigned = 1, 0, 1, 0, 1, 0, 1, 0, 1, 0#
  */
 
 #define @TYPE@_floor_divide @TYPE@_divide
@@ -824,15 +825,15 @@ NPY_NO_EXPORT NPY_GCC_OPT_3 void
 
 /**begin repeat1
  * Arithmetic
- * #kind = add, subtract, multiply, bitwise_and, bitwise_or, bitwise_xor,
- *          left_shift, right_shift#
- * #OP = +, -,*, &, |, ^, <<, >>#
+ * #kind = add, subtract, multiply, bitwise_and, bitwise_or, bitwise_xor#
+ * #OP = +, -,*, &, |, ^#
  */
 
 NPY_NO_EXPORT NPY_GCC_OPT_3 void
-@TYPE@_@kind@(char **args, npy_intp *dimensions, npy_intp *steps, void *NPY_UNUSED(func))
+@TYPE@_@kind@(char **args, npy_intp *dimensions, npy_intp *steps,
+              void *NPY_UNUSED(func))
 {
-    if(IS_BINARY_REDUCE) {
+    if (IS_BINARY_REDUCE) {
         BINARY_REDUCE_LOOP(@type@) {
             io1 @OP@= *(@type@ *)ip2;
         }
@@ -845,6 +846,109 @@ NPY_NO_EXPORT NPY_GCC_OPT_3 void
 
 /**end repeat1**/
 
+/*
+ * Arithmetic bit shift operations.
+ *
+ * Intel hardware masks bit shift values, so large shifts wrap around
+ * and can produce surprising results. The special handling ensures that
+ * behavior is independent of compiler or hardware.
+ * TODO: We could implement consistent behavior for negative shifts,
+ *       which is undefined in C.
+ */
+
+#define LEFT_SHIFT_OP                               \
+    do {                                            \
+        if (NPY_LIKELY(in2 < sizeof(@type@) * 8)) { \
+            *out = in1 << in2;                      \
+        }                                           \
+        else {                                      \
+            *out = 0;                               \
+        }                                           \
+    } while (0)
+
+
+NPY_NO_EXPORT NPY_GCC_OPT_3 void
+@TYPE@_left_shift(char **args, npy_intp *dimensions, npy_intp *steps,
+                  void *NPY_UNUSED(func))
+{
+    if (IS_BINARY_REDUCE) {
+        BINARY_REDUCE_LOOP(@type@) {
+            @type@ ip2_val = *(@type@ *)ip2;
+
+            if (NPY_LIKELY(ip2_val < sizeof(@type@) * 8)) {
+                io1 <<= ip2_val;
+            }
+            else {
+                io1 = 0;
+            }
+        }
+        *((@type@ *)iop1) = io1;
+    }
+    else {
+        BINARY_LOOP_FAST(@type@, @type@, LEFT_SHIFT_OP);
+    }
+}
+
+#undef LEFT_SHIFT_OP
+
+#define RIGHT_SHIFT_OP_SIGNED                       \
+    do {                                            \
+        if (NPY_LIKELY(in2 < sizeof(@type@) * 8)) { \
+            *out = in1 >> in2;                      \
+        }                                           \
+        else if (in1 < 0) {                         \
+            *out = -1;                              \
+        }                                           \
+        else {                                      \
+            *out = 0;                               \
+        }                                           \
+    } while (0)
+
+#define RIGHT_SHIFT_OP_UNSIGNED                     \
+    do {                                            \
+        if (NPY_LIKELY(in2 < sizeof(@type@) * 8)) { \
+            *out = in1 >> in2;                      \
+        }                                           \
+        else {                                      \
+            *out = 0;                               \
+        }                                           \
+    } while (0)
+
+NPY_NO_EXPORT NPY_GCC_OPT_3 void
+@TYPE@_right_shift(char **args, npy_intp *dimensions, npy_intp *steps,
+                   void *NPY_UNUSED(func))
+{
+    if (IS_BINARY_REDUCE) {
+        BINARY_REDUCE_LOOP(@type@) {
+            @type@ ip2_val = *(@type@ *)ip2;
+
+            if (NPY_LIKELY(ip2_val < sizeof(@type@) * 8)) {
+                io1 >>= ip2_val;
+            }
+#if @issigned@
+            else if (io1 < 0) {
+                io1 = -1;
+            }
+#endif
+            else {
+                io1 = 0;
+            }
+        }
+        *((@type@ *)iop1) = io1;
+    }
+    else {
+#if @issigned@
+        BINARY_LOOP_FAST(@type@, @type@, RIGHT_SHIFT_OP_SIGNED);
+#else
+        BINARY_LOOP_FAST(@type@, @type@, RIGHT_SHIFT_OP_UNSIGNED);
+#endif
+    }
+}
+
+#undef RIGHT_SHIFT_OP_SIGNED
+#undef RIGHT_SHIFT_OP_UNSIGNED
+
+
 /**begin repeat1
  * #kind = equal, not_equal, greater, greater_equal, less, less_equal,
  *         logical_and, logical_or#
diff --git a/numpy/core/src/umath/scalarmath.c.src b/numpy/core/src/umath/scalarmath.c.src
index c651383eb17..84dc8e0f7eb 100644
--- a/numpy/core/src/umath/scalarmath.c.src
+++ b/numpy/core/src/umath/scalarmath.c.src
@@ -245,25 +245,58 @@ static void
 /**end repeat**/
 
 
-
-/* QUESTION:  Should we check for overflow / underflow in (l,r)shift? */
-
 /**begin repeat
  * #name = byte, ubyte, short, ushort, int, uint,
  *         long, ulong, longlong, ulonglong#
  * #type = npy_byte, npy_ubyte, npy_short, npy_ushort, npy_int, npy_uint,
  *         npy_long, npy_ulong, npy_longlong, npy_ulonglong#
+ * #issigned = 1, 0, 1, 0, 1, 0, 1, 0, 1, 0#
  */
 
 /**begin repeat1
- * #oper = and, xor, or, lshift, rshift#
- * #op = &, ^, |, <<, >>#
+ * #oper = and, xor, or#
+ * #op = &, ^, |#
  */
 
 #define @name@_ctype_@oper@(arg1, arg2, out) *(out) = (arg1) @op@ (arg2)
 
 /**end repeat1**/
 
+#define @name@_ctype_lshift(arg1, arg2, out)           \
+    do {                                               \
+        if (NPY_LIKELY((arg2) < sizeof(@type@) * 8)) { \
+            *(out) = (arg1) << (arg2);                 \
+        }                                              \
+        else {                                         \
+            *(out) = 0;                                \
+        }                                              \
+    } while (0)
+
+#if @issigned@
+    #define @name@_ctype_rshift(arg1, arg2, out)           \
+        do {                                               \
+            if (NPY_LIKELY((arg2) < sizeof(@type@) * 8)) { \
+                *(out) = (arg1) >> (arg2);                 \
+            }                                              \
+            else if ((arg1) < 0) {                         \
+                *(out) = -1;                               \
+            }                                              \
+            else {                                         \
+                *(out) = 0;                                \
+            }                                              \
+        } while (0)
+#else
+    #define @name@_ctype_rshift(arg1, arg2, out)           \
+        do {                                               \
+            if (NPY_LIKELY((arg2) < sizeof(@type@) * 8)) { \
+                *(out) = (arg1) >> (arg2);                 \
+            }                                              \
+            else {                                         \
+                *(out) = 0;                                \
+            }                                              \
+        } while (0)
+#endif
+
 /**end repeat**/
 
 /**begin repeat
@@ -575,7 +608,7 @@ static void
  * 1) Convert the types to the common type if both are scalars (0 return)
  * 2) If both are not scalars use ufunc machinery (-2 return)
  * 3) If both are scalars but cannot be cast to the right type
- * return NotImplmented (-1 return)
+ * return NotImplemented (-1 return)
  *
  * 4) Perform the function on the C-type.
  * 5) If an error condition occurred, check to see
diff --git a/numpy/core/tests/test_scalarmath.py b/numpy/core/tests/test_scalarmath.py
index b8f4388b16b..52c9d3bc63f 100644
--- a/numpy/core/tests/test_scalarmath.py
+++ b/numpy/core/tests/test_scalarmath.py
@@ -525,5 +525,37 @@ def test_numpy_abs(self):
         self._test_abs_func(np.abs)
 
 
+class TestBitShifts(TestCase):
+
+    def test_left_shift(self):
+        # gh-2449
+        for dt in np.typecodes['AllInteger']:
+            arr = np.array([5, -5], dtype=dt)
+            scl_pos, scl_neg = arr
+            for shift in np.array([arr.dtype.itemsize * 8], dtype=dt):
+                res_pos = scl_pos << shift
+                res_neg = scl_neg << shift
+                assert_equal(res_pos, 0)
+                assert_equal(res_neg, 0)
+                # Result on scalars should be the same as on arrays
+                assert_array_equal(arr << shift, [res_pos, res_neg])
+
+    def test_right_shift(self):
+        # gh-2449
+        for dt in np.typecodes['AllInteger']:
+            arr = np.array([5, -5], dtype=dt)
+            scl_pos, scl_neg = arr
+            for shift in np.array([arr.dtype.itemsize * 8], dtype=dt):
+                res_pos = scl_pos >> shift
+                res_neg = scl_neg >> shift
+                assert_equal(res_pos, 0)
+                if dt in np.typecodes['UnsignedInteger']:
+                    assert_equal(res_neg, 0)
+                else:
+                    assert_equal(res_neg, -1)
+                # Result on scalars should be the same as on arrays
+                assert_array_equal(arr >> shift, [res_pos, res_neg], dt)
+
+
 if __name__ == "__main__":
     run_module_suite()
