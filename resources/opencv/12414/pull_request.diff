diff --git a/.github/ISSUE_TEMPLATE.md b/.github/ISSUE_TEMPLATE.md
index e72c70d8c3d..f6b5b9f5969 100644
--- a/.github/ISSUE_TEMPLATE.md
+++ b/.github/ISSUE_TEMPLATE.md
@@ -2,6 +2,14 @@
 If you have a question rather than reporting a bug please go to http://answers.opencv.org where you get much faster responses.
 If you need further assistance please read [How To Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute).
 
+Please:
+
+* Read the documentation to test with the latest developer build.
+* Check if other person has already created the same issue to avoid duplicates. You can comment on it if there already is an issue.
+* Try to be as detailed as possible in your report.
+* Report only one problem per created issue.
+
+
 This is a template helping you to create an issue which can be processed as quickly as possible. This is the bug reporting section for the OpenCV library.
 -->
 
@@ -27,4 +35,4 @@ This is a template helping you to create an issue which can be processed as quic
     // C++ code example
     ```
  or attach as .txt or .zip file
--->
\ No newline at end of file
+-->
diff --git a/3rdparty/ffmpeg/ffmpeg.cmake b/3rdparty/ffmpeg/ffmpeg.cmake
index cfa8ff40275..5414b8f29e0 100644
--- a/3rdparty/ffmpeg/ffmpeg.cmake
+++ b/3rdparty/ffmpeg/ffmpeg.cmake
@@ -1,8 +1,8 @@
-# Binaries branch name: ffmpeg/3.4_20180608
-# Binaries were created for OpenCV: f5ddbbf65937d8f44e481e4ee1082961821f5c62
-ocv_update(FFMPEG_BINARIES_COMMIT "8041bd6f5ad37045c258904ba3030bb3442e3911")
-ocv_update(FFMPEG_FILE_HASH_BIN32 "fa5a2a4e2f37defcb95bde8ed145c2b3")
-ocv_update(FFMPEG_FILE_HASH_BIN64 "2cc08fc4fef8199fe80e0f126684834f")
+# Binaries branch name: ffmpeg/master_20180220
+# Binaries were created for OpenCV: 9819ebc0954c2df62943ebbd5936d325e5dc89e1
+ocv_update(FFMPEG_BINARIES_COMMIT "0a0e88972a7ea97708378d0488a65f83e7cc5e69")
+ocv_update(FFMPEG_FILE_HASH_BIN32 "b8120c07962d591e2e9071a1bf566fd0")
+ocv_update(FFMPEG_FILE_HASH_BIN64 "dc9c50e7b05482acc25d6ce0ac61bf1d")
 ocv_update(FFMPEG_FILE_HASH_CMAKE "3b90f67f4b429e77d3da36698cef700c")
 
 function(download_win_ffmpeg script_var)
diff --git a/3rdparty/openvx/hal/openvx_hal.cpp b/3rdparty/openvx/hal/openvx_hal.cpp
index 53a2711d527..191816488bc 100644
--- a/3rdparty/openvx/hal/openvx_hal.cpp
+++ b/3rdparty/openvx/hal/openvx_hal.cpp
@@ -431,7 +431,7 @@ int ovx_hal_warpAffine(int atype, const uchar *a, size_t astep, int aw, int ah,
     return CV_HAL_ERROR_OK;
 }
 
-int ovx_hal_warpPerspectve(int atype, const uchar *a, size_t astep, int aw, int ah, uchar *b, size_t bstep, int bw, int bh, const double M[9], int interpolation, int borderType, const double borderValue[4])
+int ovx_hal_warpPerspective(int atype, const uchar *a, size_t astep, int aw, int ah, uchar *b, size_t bstep, int bw, int bh, const double M[9], int interpolation, int borderType, const double borderValue[4])
 {
     if (skipSmallImages<VX_KERNEL_WARP_PERSPECTIVE>(aw, ah))
         return CV_HAL_ERROR_NOT_IMPLEMENTED;
diff --git a/3rdparty/openvx/hal/openvx_hal.hpp b/3rdparty/openvx/hal/openvx_hal.hpp
index c94cde3158a..98bb4dc43e6 100644
--- a/3rdparty/openvx/hal/openvx_hal.hpp
+++ b/3rdparty/openvx/hal/openvx_hal.hpp
@@ -27,7 +27,7 @@ int ovx_hal_mul(const T *a, size_t astep, const T *b, size_t bstep, T *c, size_t
 int ovx_hal_merge8u(const uchar **src_data, uchar *dst_data, int len, int cn);
 int ovx_hal_resize(int atype, const uchar *a, size_t astep, int aw, int ah, uchar *b, size_t bstep, int bw, int bh, double inv_scale_x, double inv_scale_y, int interpolation);
 int ovx_hal_warpAffine(int atype, const uchar *a, size_t astep, int aw, int ah, uchar *b, size_t bstep, int bw, int bh, const double M[6], int interpolation, int borderType, const double borderValue[4]);
-int ovx_hal_warpPerspectve(int atype, const uchar *a, size_t astep, int aw, int ah, uchar *b, size_t bstep, int bw, int bh, const double M[9], int interpolation, int borderType, const double borderValue[4]);
+int ovx_hal_warpPerspective(int atype, const uchar *a, size_t astep, int aw, int ah, uchar *b, size_t bstep, int bw, int bh, const double M[9], int interpolation, int borderType, const double borderValue[4]);
 
 struct cvhalFilter2D;
 int ovx_hal_filterInit(cvhalFilter2D **filter_context, uchar *kernel_data, size_t kernel_step, int kernel_type, int kernel_width, int kernel_height,
@@ -97,7 +97,7 @@ int ovx_hal_integral(int depth, int sdepth, int, const uchar * a, size_t astep,
 //#undef cv_hal_warpAffine
 //#define cv_hal_warpAffine ovx_hal_warpAffine
 //#undef cv_hal_warpPerspective
-//#define cv_hal_warpPerspective ovx_hal_warpPerspectve
+//#define cv_hal_warpPerspective ovx_hal_warpPerspective
 
 #undef cv_hal_filterInit
 #define cv_hal_filterInit ovx_hal_filterInit
diff --git a/CMakeLists.txt b/CMakeLists.txt
index c7c76ecf35f..190fbc091f6 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -149,7 +149,6 @@ endif()
 # ----------------------------------------------------------------------------
 # Detect compiler and target platform architecture
 # ----------------------------------------------------------------------------
-OCV_OPTION(ENABLE_CXX11 "Enable C++11 compilation mode" "${OPENCV_CXX11}")
 include(cmake/OpenCVDetectCXXCompiler.cmake)
 ocv_cmake_hook(POST_DETECT_COMPILER)
 
@@ -253,8 +252,8 @@ OCV_OPTION(WITH_WIN32UI        "Build with Win32 UI Backend support"         ON
 OCV_OPTION(WITH_QUICKTIME      "Use QuickTime for Video I/O"                 OFF  IF APPLE )
 OCV_OPTION(WITH_QTKIT          "Use QTKit Video I/O backend"                 OFF  IF APPLE )
 OCV_OPTION(WITH_TBB            "Include Intel TBB support"                   OFF  IF (NOT IOS AND NOT WINRT) )
+OCV_OPTION(WITH_HPX            "Include Ste||ar Group HPX support"           OFF)
 OCV_OPTION(WITH_OPENMP         "Include OpenMP support"                      OFF)
-OCV_OPTION(WITH_CSTRIPES       "Include C= support"                          OFF  IF (WIN32 AND NOT WINRT)  )
 OCV_OPTION(WITH_PTHREADS_PF    "Use pthreads-based parallel_for"             ON   IF (NOT WIN32 OR MINGW) )
 OCV_OPTION(WITH_TIFF           "Include TIFF support"                        ON   IF (NOT IOS) )
 OCV_OPTION(WITH_UNICAP         "Include Unicap support (GPL)"                OFF  IF (UNIX AND NOT APPLE AND NOT ANDROID) )
@@ -271,6 +270,7 @@ OCV_OPTION(WITH_OPENCLAMDFFT   "Include AMD OpenCL FFT library support"      ON
 OCV_OPTION(WITH_OPENCLAMDBLAS  "Include AMD OpenCL BLAS library support"     ON   IF (NOT ANDROID AND NOT IOS AND NOT WINRT) )
 OCV_OPTION(WITH_DIRECTX        "Include DirectX support"                     ON   IF (WIN32 AND NOT WINRT) )
 OCV_OPTION(WITH_INTELPERC      "Include Intel Perceptual Computing support"  OFF  IF (WIN32 AND NOT WINRT) )
+OCV_OPTION(WITH_LIBREALSENSE   "Include Intel librealsense support"          OFF  IF (NOT WITH_INTELPERC) )
 OCV_OPTION(WITH_MATLAB         "Include Matlab support"                      ON   IF (NOT ANDROID AND NOT IOS AND NOT WINRT))
 OCV_OPTION(WITH_VA             "Include VA support"                          OFF  IF (UNIX AND NOT ANDROID) )
 OCV_OPTION(WITH_VA_INTEL       "Include Intel VA-API/OpenCL support"         OFF  IF (UNIX AND NOT ANDROID) )
@@ -283,6 +283,7 @@ OCV_OPTION(WITH_PROTOBUF       "Enable libprotobuf"                          ON
 OCV_OPTION(WITH_IMGCODEC_HDR   "Include HDR support"                         ON)
 OCV_OPTION(WITH_IMGCODEC_SUNRASTER "Include SUNRASTER support"               ON)
 OCV_OPTION(WITH_IMGCODEC_PXM   "Include PNM (PBM,PGM,PPM) and PAM formats support" ON)
+OCV_OPTION(WITH_IMGCODEC_PFM   "Include PFM formats support"                 ON)
 
 # OpenCV build components
 # ===================================================
@@ -1015,9 +1016,6 @@ string(STRIP "${OPENCV_COMPILER_STR}" OPENCV_COMPILER_STR)
 status("")
 status("  C/C++:")
 status("    Built as dynamic libs?:" BUILD_SHARED_LIBS THEN YES ELSE NO)
-if(ENABLE_CXX11 OR HAVE_CXX11)
-status("    C++11:" HAVE_CXX11 THEN YES ELSE NO)
-endif()
 status("    C++ Compiler:"           ${OPENCV_COMPILER_STR})
 status("    C++ flags (Release):"    ${CMAKE_CXX_FLAGS} ${CMAKE_CXX_FLAGS_RELEASE})
 status("    C++ flags (Debug):"      ${CMAKE_CXX_FLAGS} ${CMAKE_CXX_FLAGS_DEBUG})
@@ -1231,6 +1229,10 @@ if(WITH_IMGCODEC_PXM OR DEFINED HAVE_IMGCODEC_PXM)
   status("    PXM:" HAVE_IMGCODEC_PXM THEN "YES" ELSE "NO")
 endif()
 
+if(WITH_IMGCODEC_PFM OR DEFINED HAVE_IMGCODEC_PFM)
+  status("    PFM:" HAVE_IMGCODEC_PFM THEN "YES" ELSE "NO")
+endif()
+
 # ========================== VIDEO IO ==========================
 status("")
 status("  Video I/O:")
@@ -1352,7 +1354,7 @@ endif()
 # Order is similar to CV_PARALLEL_FRAMEWORK in core/src/parallel.cpp
 ocv_build_features_string(parallel_status EXCLUSIVE
   IF HAVE_TBB THEN "TBB (ver ${TBB_VERSION_MAJOR}.${TBB_VERSION_MINOR} interface ${TBB_INTERFACE_VERSION})"
-  IF HAVE_CSTRIPES THEN "C="
+  IF HAVE_HPX THEN "HPX"
   IF HAVE_OPENMP THEN "OpenMP"
   IF HAVE_GCD THEN "GCD"
   IF WINRT OR HAVE_CONCURRENCY THEN "Concurrency"
diff --git a/README.md b/README.md
index a3933c74041..ee5ba680db0 100644
--- a/README.md
+++ b/README.md
@@ -2,8 +2,8 @@
 
 ### Resources
 
-* Homepage: <http://opencv.org>
-* Docs: <http://docs.opencv.org/master/>
+* Homepage: <https://opencv.org>
+* Docs: <https://docs.opencv.org/master/>
 * Q&A forum: <http://answers.opencv.org>
 * Issue tracking: <https://github.com/opencv/opencv/issues>
 
diff --git a/cmake/OpenCVDetectCStripes.cmake b/cmake/OpenCVDetectCStripes.cmake
deleted file mode 100644
index dce52d92b1c..00000000000
--- a/cmake/OpenCVDetectCStripes.cmake
+++ /dev/null
@@ -1,11 +0,0 @@
-if(WIN32)
-    find_path( CSTRIPES_LIB_DIR
-               NAMES "C=.lib"
-               DOC "The path to C= lib and dll")
-    if(CSTRIPES_LIB_DIR)
-        ocv_include_directories("${CSTRIPES_LIB_DIR}/..")
-        link_directories("${CSTRIPES_LIB_DIR}")
-        set(OPENCV_LINKER_LIBS ${OPENCV_LINKER_LIBS} "C=")
-        set(HAVE_CSTRIPES 1)
-    endif()
-endif()
diff --git a/cmake/OpenCVDetectCUDA.cmake b/cmake/OpenCVDetectCUDA.cmake
index 76e57c8fc99..27bf79bd8ee 100644
--- a/cmake/OpenCVDetectCUDA.cmake
+++ b/cmake/OpenCVDetectCUDA.cmake
@@ -70,6 +70,12 @@ if(CUDA_FOUND)
     unset(CUDA_ARCH_PTX CACHE)
   endif()
 
+  SET(DETECT_ARCHS_COMMAND "${CUDA_NVCC_EXECUTABLE}" ${CUDA_NVCC_FLAGS} "${OpenCV_SOURCE_DIR}/cmake/checks/OpenCVDetectCudaArch.cu" "--run")
+  if(WIN32 AND CMAKE_LINKER) #Workaround for VS cl.exe not being in the env. path
+    get_filename_component(host_compiler_bindir ${CMAKE_LINKER} DIRECTORY)
+    SET(DETECT_ARCHS_COMMAND ${DETECT_ARCHS_COMMAND} "-ccbin" "${host_compiler_bindir}")
+  endif()
+
   set(__cuda_arch_ptx "")
   if(CUDA_GENERATION STREQUAL "Fermi")
     set(__cuda_arch_bin "2.0")
@@ -82,10 +88,11 @@ if(CUDA_FOUND)
   elseif(CUDA_GENERATION STREQUAL "Volta")
     set(__cuda_arch_bin "7.0")
   elseif(CUDA_GENERATION STREQUAL "Auto")
-    execute_process( COMMAND "${CUDA_NVCC_EXECUTABLE}" ${CUDA_NVCC_FLAGS} "${OpenCV_SOURCE_DIR}/cmake/checks/OpenCVDetectCudaArch.cu" "--run"
+    execute_process( COMMAND ${DETECT_ARCHS_COMMAND}
                      WORKING_DIRECTORY "${CMAKE_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/CMakeTmp/"
                      RESULT_VARIABLE _nvcc_res OUTPUT_VARIABLE _nvcc_out
                      ERROR_QUIET OUTPUT_STRIP_TRAILING_WHITESPACE)
+    string(REGEX REPLACE ".*\n" "" _nvcc_out "${_nvcc_out}") #Strip leading warning messages, if any
     if(NOT _nvcc_res EQUAL 0)
       message(STATUS "Automatic detection of CUDA generation failed. Going to build for all known architectures.")
     else()
@@ -99,10 +106,11 @@ if(CUDA_FOUND)
       set(__cuda_arch_bin "3.2")
       set(__cuda_arch_ptx "")
     elseif(AARCH64)
-      execute_process( COMMAND "${CUDA_NVCC_EXECUTABLE}" ${CUDA_NVCC_FLAGS} "${OpenCV_SOURCE_DIR}/cmake/checks/OpenCVDetectCudaArch.cu" "--run"
+      execute_process( COMMAND ${DETECT_ARCHS_COMMAND}
                        WORKING_DIRECTORY "${CMAKE_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/CMakeTmp/"
                        RESULT_VARIABLE _nvcc_res OUTPUT_VARIABLE _nvcc_out
                        ERROR_QUIET OUTPUT_STRIP_TRAILING_WHITESPACE)
+      string(REGEX REPLACE ".*\n" "" _nvcc_out "${_nvcc_out}") #Strip leading warning messages, if any
       if(NOT _nvcc_res EQUAL 0)
         message(STATUS "Automatic detection of CUDA generation failed. Going to build for all known architectures.")
         set(__cuda_arch_bin "5.3 6.2 7.0")
@@ -240,7 +248,7 @@ if(CUDA_FOUND)
     endif()
 
     if(UNIX OR APPLE)
-      set(CUDA_NVCC_FLAGS ${CUDA_NVCC_FLAGS} -Xcompiler -fPIC)
+      set(CUDA_NVCC_FLAGS ${CUDA_NVCC_FLAGS} -Xcompiler -fPIC --std=c++11)
     endif()
     if(APPLE)
       set(CUDA_NVCC_FLAGS ${CUDA_NVCC_FLAGS} -Xcompiler -fno-finite-math-only)
diff --git a/cmake/OpenCVDetectCXXCompiler.cmake b/cmake/OpenCVDetectCXXCompiler.cmake
index 8c9ff0345a3..04a1f48134e 100644
--- a/cmake/OpenCVDetectCXXCompiler.cmake
+++ b/cmake/OpenCVDetectCXXCompiler.cmake
@@ -166,14 +166,11 @@ if(CMAKE_VERSION VERSION_LESS "3.1")
   endforeach()
 endif()
 
-if(ENABLE_CXX11)
-  #cmake_minimum_required(VERSION 3.1.0 FATAL_ERROR)
-  set(CMAKE_CXX_STANDARD 11)
-  set(CMAKE_CXX_STANDARD_REQUIRED TRUE)
-  set(CMAKE_CXX_EXTENSIONS OFF) # use -std=c++11 instead of -std=gnu++11
-  if(CMAKE_CXX11_COMPILE_FEATURES)
-    set(HAVE_CXX11 ON)
-  endif()
+set(CMAKE_CXX_STANDARD 11)
+set(CMAKE_CXX_STANDARD_REQUIRED TRUE)
+set(CMAKE_CXX_EXTENSIONS OFF) # use -std=c++11 instead of -std=gnu++11
+if(CMAKE_CXX11_COMPILE_FEATURES)
+  set(HAVE_CXX11 ON)
 endif()
 if(NOT HAVE_CXX11)
   ocv_check_compiler_flag(CXX "" HAVE_CXX11 "${OpenCV_SOURCE_DIR}/cmake/checks/cxx11.cpp")
@@ -185,3 +182,6 @@ if(NOT HAVE_CXX11)
     endif()
   endif()
 endif()
+if(NOT HAVE_CXX11)
+  message(FATAL_ERROR "OpenCV 4.x requires C++11")
+endif()
diff --git a/cmake/OpenCVDetectVTK.cmake b/cmake/OpenCVDetectVTK.cmake
index f16077755a7..702069b80be 100644
--- a/cmake/OpenCVDetectVTK.cmake
+++ b/cmake/OpenCVDetectVTK.cmake
@@ -52,5 +52,18 @@ if(HAVE_QT AND ${VTK_VERSION} VERSION_GREATER "6.0.0" AND NOT ${VTK_QT_VERSION}
   endif()
 endif()
 
+try_compile(VTK_COMPILE_STATUS
+    "${OpenCV_BINARY_DIR}"
+    "${OpenCV_SOURCE_DIR}/cmake/checks/vtk_test.cpp"
+    CMAKE_FLAGS "-DINCLUDE_DIRECTORIES:STRING=${VTK_INCLUDE_DIRS}"
+    LINK_LIBRARIES ${VTK_LIBRARIES}
+    OUTPUT_VARIABLE OUTPUT
+)
+
+if(NOT ${VTK_COMPILE_STATUS})
+  message(STATUS "VTK support is disabled. Compilation of the sample code has failed.")
+  return()
+endif()
+
 set(HAVE_VTK ON)
 message(STATUS "Found VTK ${VTK_VERSION} (${VTK_USE_FILE})")
diff --git a/cmake/OpenCVFindLibRealsense.cmake b/cmake/OpenCVFindLibRealsense.cmake
new file mode 100644
index 00000000000..32cff063f31
--- /dev/null
+++ b/cmake/OpenCVFindLibRealsense.cmake
@@ -0,0 +1,15 @@
+# Main variables:
+# LIBREALSENSE_LIBRARIES and LIBREALSENSE_INCLUDE to link Intel librealsense modules
+# HAVE_LIBREALSENSE for conditional compilation OpenCV with/without librealsense
+
+find_path(LIBREALSENSE_INCLUDE_DIR "librealsense2/rs.hpp" PATHS "$ENV{LIBREALSENSE_INCLUDE}" DOC "Path to librealsense interface headers")
+find_library(LIBREALSENSE_LIBRARIES "realsense2" PATHS "$ENV{LIBREALSENSE_LIB}" DOC "Path to librealsense interface libraries")
+
+if(LIBREALSENSE_INCLUDE_DIR AND LIBREALSENSE_LIBRARIES)
+    set(HAVE_LIBREALSENSE TRUE)
+else()
+    set(HAVE_LIBREALSENSE FALSE)
+    message( WARNING, " librealsense include directory (set by LIBREALSENSE_INCLUDE_DIR variable) is not found or does not have librealsense include files." )
+endif() #if(LIBREALSENSE_INCLUDE_DIR AND LIBREALSENSE_LIBRARIES)
+
+mark_as_advanced(FORCE LIBREALSENSE_LIBRARIES LIBREALSENSE_INCLUDE_DIR)
\ No newline at end of file
diff --git a/cmake/OpenCVFindLibsGrfmt.cmake b/cmake/OpenCVFindLibsGrfmt.cmake
index 9f18e2bf627..91afcc4f12f 100644
--- a/cmake/OpenCVFindLibsGrfmt.cmake
+++ b/cmake/OpenCVFindLibsGrfmt.cmake
@@ -268,3 +268,8 @@ if(WITH_IMGCODEC_PXM)
 elseif(DEFINED WITH_IMGCODEC_PXM)
   set(HAVE_IMGCODEC_PXM OFF)
 endif()
+if(WITH_IMGCODEC_PFM)
+  set(HAVE_IMGCODEC_PFM ON)
+elseif(DEFINED WITH_IMGCODEC_PFM)
+  set(HAVE_IMGCODEC_PFM OFF)
+endif()
\ No newline at end of file
diff --git a/cmake/OpenCVFindLibsPerf.cmake b/cmake/OpenCVFindLibsPerf.cmake
index 4dfd7aab4b6..651200dfeca 100644
--- a/cmake/OpenCVFindLibsPerf.cmake
+++ b/cmake/OpenCVFindLibsPerf.cmake
@@ -7,6 +7,13 @@ if(WITH_TBB)
   include("${OpenCV_SOURCE_DIR}/cmake/OpenCVDetectTBB.cmake")
 endif(WITH_TBB)
 
+# --- HPX ---
+if(WITH_HPX)
+  find_package(HPX REQUIRED)
+  ocv_include_directories(${HPX_INCLUDE_DIRS})
+  set(HAVE_HPX TRUE)
+endif(WITH_HPX)
+
 # --- IPP ---
 if(WITH_IPP)
   include("${OpenCV_SOURCE_DIR}/cmake/OpenCVFindIPP.cmake")
@@ -104,22 +111,15 @@ if(WITH_CLP)
   endif()
 endif(WITH_CLP)
 
-# --- C= ---
-if(WITH_CSTRIPES AND NOT HAVE_TBB)
-  include("${OpenCV_SOURCE_DIR}/cmake/OpenCVDetectCStripes.cmake")
-else()
-  set(HAVE_CSTRIPES 0)
-endif()
-
 # --- GCD ---
-if(APPLE AND NOT HAVE_TBB AND NOT HAVE_CSTRIPES)
+if(APPLE AND NOT HAVE_TBB)
   set(HAVE_GCD 1)
 else()
   set(HAVE_GCD 0)
 endif()
 
 # --- Concurrency ---
-if(MSVC AND NOT HAVE_TBB AND NOT HAVE_CSTRIPES)
+if(MSVC AND NOT HAVE_TBB)
   set(_fname "${CMAKE_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/CMakeTmp/concurrencytest.cpp")
   file(WRITE "${_fname}" "#if _MSC_VER < 1600\n#error\n#endif\nint main() { return 0; }\n")
   try_compile(HAVE_CONCURRENCY "${CMAKE_BINARY_DIR}" "${_fname}")
diff --git a/cmake/OpenCVFindLibsVideo.cmake b/cmake/OpenCVFindLibsVideo.cmake
index b9d15c38b86..fb1b92ec5f6 100644
--- a/cmake/OpenCVFindLibsVideo.cmake
+++ b/cmake/OpenCVFindLibsVideo.cmake
@@ -310,6 +310,11 @@ if(APPLE)
   endif()
 endif(APPLE)
 
+# --- Intel librealsense ---
+if(WITH_LIBREALSENSE)
+  include("${OpenCV_SOURCE_DIR}/cmake/OpenCVFindLibRealsense.cmake")
+endif(WITH_LIBREALSENSE)
+
 # --- Intel Perceptual Computing SDK ---
 if(WITH_INTELPERC)
   include("${OpenCV_SOURCE_DIR}/cmake/OpenCVFindIntelPerCSDK.cmake")
diff --git a/cmake/OpenCVGenAndroidMK.cmake b/cmake/OpenCVGenAndroidMK.cmake
index 832ed675339..ebf25d72a66 100644
--- a/cmake/OpenCVGenAndroidMK.cmake
+++ b/cmake/OpenCVGenAndroidMK.cmake
@@ -48,7 +48,7 @@ if(ANDROID)
   string(REPLACE "opencv_" "" OPENCV_MODULES_CONFIGMAKE "${OPENCV_MODULES_CONFIGMAKE}")
 
   if(BUILD_FAT_JAVA_LIB)
-    set(OPENCV_LIBS_CONFIGMAKE java3)
+    set(OPENCV_LIBS_CONFIGMAKE java4)
   else()
     set(OPENCV_LIBS_CONFIGMAKE "${OPENCV_MODULES_CONFIGMAKE}")
   endif()
diff --git a/cmake/OpenCVMinDepVersions.cmake b/cmake/OpenCVMinDepVersions.cmake
index d2c5b7c27fd..f08fa577343 100644
--- a/cmake/OpenCVMinDepVersions.cmake
+++ b/cmake/OpenCVMinDepVersions.cmake
@@ -1,4 +1,4 @@
-set(MIN_VER_CMAKE 2.8.12.2)
+set(MIN_VER_CMAKE 3.5.1)
 set(MIN_VER_CUDA 6.5)
 set(MIN_VER_PYTHON2 2.6)
 set(MIN_VER_PYTHON3 3.2)
diff --git a/cmake/OpenCVModule.cmake b/cmake/OpenCVModule.cmake
index 54f100d3cf7..7c81b0c6f7f 100644
--- a/cmake/OpenCVModule.cmake
+++ b/cmake/OpenCVModule.cmake
@@ -1135,6 +1135,11 @@ function(ocv_add_perf_tests)
       ocv_target_link_libraries(${the_target} LINK_PRIVATE ${perf_deps} ${OPENCV_MODULE_${the_module}_DEPS} ${OPENCV_LINKER_LIBS} ${OPENCV_PERF_${the_module}_DEPS})
       add_dependencies(opencv_perf_tests ${the_target})
 
+      if(HAVE_HPX)
+        message("Linking HPX to Perf test of module ${name}")
+        ocv_target_link_libraries(${the_target} LINK_PRIVATE "${HPX_LIBRARIES}")
+      endif()
+
       set_target_properties(${the_target} PROPERTIES LABELS "${OPENCV_MODULE_${the_module}_LABEL};PerfTest")
       set_source_files_properties(${OPENCV_PERF_${the_module}_SOURCES} ${${the_target}_pch}
         PROPERTIES LABELS "${OPENCV_MODULE_${the_module}_LABEL};PerfTest")
@@ -1220,6 +1225,11 @@ function(ocv_add_accuracy_tests)
       ocv_target_link_libraries(${the_target} LINK_PRIVATE ${test_deps} ${OPENCV_MODULE_${the_module}_DEPS} ${OPENCV_LINKER_LIBS} ${OPENCV_TEST_${the_module}_DEPS})
       add_dependencies(opencv_tests ${the_target})
 
+      if(HAVE_HPX)
+        message("Linking HPX to Perf test of module ${name}")
+        ocv_target_link_libraries(${the_target} LINK_PRIVATE "${HPX_LIBRARIES}")
+      endif()
+
       set_target_properties(${the_target} PROPERTIES LABELS "${OPENCV_MODULE_${the_module}_LABEL};AccuracyTest")
       set_source_files_properties(${OPENCV_TEST_${the_module}_SOURCES} ${${the_target}_pch}
         PROPERTIES LABELS "${OPENCV_MODULE_${the_module}_LABEL};AccuracyTest")
diff --git a/cmake/checks/OpenCVDetectCudaArch.cu b/cmake/checks/OpenCVDetectCudaArch.cu
index 9d7086cf248..70ca9755307 100644
--- a/cmake/checks/OpenCVDetectCudaArch.cu
+++ b/cmake/checks/OpenCVDetectCudaArch.cu
@@ -1,14 +1,25 @@
-#include <stdio.h>
+#include <iostream>
+#include <sstream>
+#include <list>
+
 int main()
 {
+    std::ostringstream arch;
+    std::list<std::string> archs;
+
     int count = 0;
-    if (cudaSuccess != cudaGetDeviceCount(&count)){return -1;}
-    if (count == 0) {return -1;}
+    if (cudaSuccess != cudaGetDeviceCount(&count)){ return -1; }
+    if (count == 0) { return -1; }
     for (int device = 0; device < count; ++device)
     {
         cudaDeviceProp prop;
-        if (cudaSuccess != cudaGetDeviceProperties(&prop, device)){ continue;}
-        printf("%d.%d ", prop.major, prop.minor);
+        if (cudaSuccess != cudaGetDeviceProperties(&prop, device)){ continue; }
+        arch << prop.major << "." << prop.minor;
+        archs.push_back(arch.str());
+        arch.str("");
     }
+    archs.unique(); #Some devices might have the same arch
+    for (std::list<std::string>::iterator it=archs.begin(); it!=archs.end(); ++it)
+        std::cout << *it << " ";
     return 0;
 }
diff --git a/cmake/checks/vtk_test.cpp b/cmake/checks/vtk_test.cpp
new file mode 100644
index 00000000000..2096133e5fa
--- /dev/null
+++ b/cmake/checks/vtk_test.cpp
@@ -0,0 +1,9 @@
+#include <vtkSmartPointer.h>
+#include <vtkTransform.h>
+#include <vtkMath.h>
+
+int main()
+{
+  vtkSmartPointer<vtkTransform> transform = vtkSmartPointer<vtkTransform>::New();
+  return 0;
+}
diff --git a/cmake/templates/cvconfig.h.in b/cmake/templates/cvconfig.h.in
index c661a20abda..ce779934ce2 100644
--- a/cmake/templates/cvconfig.h.in
+++ b/cmake/templates/cvconfig.h.in
@@ -46,9 +46,6 @@
 /* Cocoa API */
 #cmakedefine HAVE_COCOA
 
-/* C= */
-#cmakedefine HAVE_CSTRIPES
-
 /* NVIDIA CUDA Basic Linear Algebra Subprograms (BLAS) API*/
 #cmakedefine HAVE_CUBLAS
 
@@ -150,6 +147,9 @@
 /* OpenNI library */
 #cmakedefine HAVE_OPENNI2
 
+/* librealsense library */
+#cmakedefine HAVE_LIBREALSENSE
+
 /* PNG codec */
 #cmakedefine HAVE_PNG
 
@@ -174,6 +174,9 @@
 /* Intel Threading Building Blocks */
 #cmakedefine HAVE_TBB
 
+/* Ste||ar Group High Performance ParallelX */
+#cmakedefine HAVE_HPX
+
 /* TIFF codec */
 #cmakedefine HAVE_TIFF
 
diff --git a/doc/Doxyfile.in b/doc/Doxyfile.in
index 1ac09c4351e..ff6c18e34d3 100644
--- a/doc/Doxyfile.in
+++ b/doc/Doxyfile.in
@@ -241,6 +241,9 @@ PREDEFINED             = __cplusplus=1 \
                          CV_PROP_RW= \
                          CV_WRAP= \
                          CV_WRAP_AS(x)= \
+                         CV_WRAP_MAPPABLE(x)= \
+                         CV_WRAP_PHANTOM(x)= \
+                         CV_WRAP_DEFAULT(x)= \
                          CV_CDECL= \
                          CV_Func = \
                          CV_DO_PRAGMA(x)= \
diff --git a/doc/py_tutorials/py_bindings/py_bindings_basics/py_bindings_basics.markdown b/doc/py_tutorials/py_bindings/py_bindings_basics/py_bindings_basics.markdown
index 4f48ae7799d..8b10f27047d 100644
--- a/doc/py_tutorials/py_bindings/py_bindings_basics/py_bindings_basics.markdown
+++ b/doc/py_tutorials/py_bindings/py_bindings_basics/py_bindings_basics.markdown
@@ -20,20 +20,20 @@ A simple example on extending C++ functions to Python can be found in official P
 documentation[1]. So extending all functions in OpenCV to Python by writing their wrapper functions
 manually is a time-consuming task. So OpenCV does it in a more intelligent way. OpenCV generates
 these wrapper functions automatically from the C++ headers using some Python scripts which are
-located in modules/python/src2. We will look into what they do.
+located in `modules/python/src2`. We will look into what they do.
 
-First, modules/python/CMakeFiles.txt is a CMake script which checks the modules to be extended to
+First, `modules/python/CMakeFiles.txt` is a CMake script which checks the modules to be extended to
 Python. It will automatically check all the modules to be extended and grab their header files.
 These header files contain list of all classes, functions, constants etc. for that particular
 modules.
 
-Second, these header files are passed to a Python script, modules/python/src2/gen2.py. This is the
-Python bindings generator script. It calls another Python script modules/python/src2/hdr_parser.py.
+Second, these header files are passed to a Python script, `modules/python/src2/gen2.py`. This is the
+Python bindings generator script. It calls another Python script `modules/python/src2/hdr_parser.py`.
 This is the header parser script. This header parser splits the complete header file into small
 Python lists. So these lists contain all details about a particular function, class etc. For
 example, a function will be parsed to get a list containing function name, return type, input
-arguments, argument types etc. Final list contains details of all the functions, structs, classes
-etc. in that header file.
+arguments, argument types etc. Final list contains details of all the functions, enums, structs,
+classes etc. in that header file.
 
 But header parser doesn't parse all the functions/classes in the header file. The developer has to
 specify which functions should be exported to Python. For that, there are certain macros added to
@@ -44,15 +44,15 @@ macros will be given in next session.
 
 So header parser returns a final big list of parsed functions. Our generator script (gen2.py) will
 create wrapper functions for all the functions/classes/enums/structs parsed by header parser (You
-can find these header files during compilation in the build/modules/python/ folder as
+can find these header files during compilation in the `build/modules/python/` folder as
 pyopencv_generated_\*.h files). But there may be some basic OpenCV datatypes like Mat, Vec4i,
 Size. They need to be extended manually. For example, a Mat type should be extended to Numpy array,
 Size should be extended to a tuple of two integers etc. Similarly, there may be some complex
 structs/classes/functions etc. which need to be extended manually. All such manual wrapper functions
-are placed in modules/python/src2/cv2.cpp.
+are placed in `modules/python/src2/cv2.cpp`.
 
 So now only thing left is the compilation of these wrapper files which gives us **cv2** module. So
-when you call a function, say res = equalizeHist(img1,img2) in Python, you pass two numpy arrays and
+when you call a function, say `res = equalizeHist(img1,img2)` in Python, you pass two numpy arrays and
 you expect another numpy array as the output. So these numpy arrays are converted to cv::Mat and
 then calls the equalizeHist() function in C++. Final result, res will be converted back into a Numpy
 array. So in short, almost all operations are done in C++ which gives us almost same speed as that
@@ -67,19 +67,19 @@ Header parser parse the header files based on some wrapper macros added to funct
 Enumeration constants don't need any wrapper macros. They are automatically wrapped. But remaining
 functions, classes etc. need wrapper macros.
 
-Functions are extended using CV_EXPORTS_W macro. An example is shown below.
+Functions are extended using `CV_EXPORTS_W` macro. An example is shown below.
 @code{.cpp}
 CV_EXPORTS_W void equalizeHist( InputArray src, OutputArray dst );
 @endcode
 Header parser can understand the input and output arguments from keywords like
 InputArray, OutputArray etc. But sometimes, we may need to hardcode inputs and outputs. For that,
-macros like CV_OUT, CV_IN_OUT etc. are used.
+macros like `CV_OUT`, `CV_IN_OUT` etc. are used.
 @code{.cpp}
 CV_EXPORTS_W void minEnclosingCircle( InputArray points,
                                      CV_OUT Point2f& center, CV_OUT float& radius );
 @endcode
-For large classes also, CV_EXPORTS_W is used. To extend class methods, CV_WRAP is used.
-Similarly, CV_PROP is used for class fields.
+For large classes also, `CV_EXPORTS_W` is used. To extend class methods, `CV_WRAP` is used.
+Similarly, `CV_PROP` is used for class fields.
 @code{.cpp}
 class CV_EXPORTS_W CLAHE : public Algorithm
 {
@@ -90,9 +90,9 @@ public:
     CV_WRAP virtual double getClipLimit() const = 0;
 }
 @endcode
-Overloaded functions can be extended using CV_EXPORTS_AS. But we need to pass a new name so that
+Overloaded functions can be extended using `CV_EXPORTS_AS`. But we need to pass a new name so that
 each function will be called by that name in Python. Take the case of integral function below. Three
-functions are available, so each one is named with a suffix in Python. Similarly CV_WRAP_AS can be
+functions are available, so each one is named with a suffix in Python. Similarly `CV_WRAP_AS` can be
 used to wrap overloaded methods.
 @code{.cpp}
 //! computes the integral image
@@ -107,9 +107,9 @@ CV_EXPORTS_AS(integral3) void integral( InputArray src, OutputArray sum,
                                         OutputArray sqsum, OutputArray tilted,
                                         int sdepth = -1, int sqdepth = -1 );
 @endcode
-Small classes/structs are extended using CV_EXPORTS_W_SIMPLE. These structs are passed by value
-to C++ functions. Examples are KeyPoint, Match etc. Their methods are extended by CV_WRAP and
-fields are extended by CV_PROP_RW.
+Small classes/structs are extended using `CV_EXPORTS_W_SIMPLE`. These structs are passed by value
+to C++ functions. Examples are `KeyPoint`, `Match` etc. Their methods are extended by `CV_WRAP` and
+fields are extended by `CV_PROP_RW`.
 @code{.cpp}
 class CV_EXPORTS_W_SIMPLE DMatch
 {
@@ -125,8 +125,8 @@ public:
     CV_PROP_RW float distance;
 };
 @endcode
-Some other small classes/structs can be exported using CV_EXPORTS_W_MAP where it is exported to a
-Python native dictionary. Moments() is an example of it.
+Some other small classes/structs can be exported using `CV_EXPORTS_W_MAP` where it is exported to a
+Python native dictionary. `Moments()` is an example of it.
 @code{.cpp}
 class CV_EXPORTS_W_MAP Moments
 {
@@ -142,6 +142,41 @@ public:
 So these are the major extension macros available in OpenCV. Typically, a developer has to put
 proper macros in their appropriate positions. Rest is done by generator scripts. Sometimes, there
 may be an exceptional cases where generator scripts cannot create the wrappers. Such functions need
-to be handled manually, to do this write your own pyopencv_*.hpp extending headers and put them into
+to be handled manually, to do this write your own `pyopencv_*.hpp` extending headers and put them into
 misc/python subdirectory of your module. But most of the time, a code written according to OpenCV
-coding guidelines will be automatically wrapped by generator scripts.
\ No newline at end of file
+coding guidelines will be automatically wrapped by generator scripts.
+
+More advanced cases involves providing Python with additional features that does not exist
+in the C++ interface such as extra methods, type mappings, or to provide default arguments.
+We will take `UMat` datatype as an example of such cases later on.
+First, to provide Python-specific methods, `CV_WRAP_PHANTOM` is utilized in a similar manner to
+`CV_WRAP`, except that it takes the method header as its argument, and you would need to provide
+the method body in your own `pyopencv_*.hpp` extension. `UMat::queue()` and `UMat::context()` are
+an example of such phantom methods that does not exist in C++ interface, but are needed to handle
+OpenCL functionalities at the Python side.
+Second, if an already-existing datatype(s) is mappable to your class, it is highly preferable to
+indicate such capacity using `CV_WRAP_MAPPABLE` with the source type as its argument,
+rather than crafting your own binding function(s). This is the case of `UMat` which maps from `Mat`.
+Finally, if a default argument is needed, but it is not provided in the native C++ interface,
+you can provide it for Python side as the argument of `CV_WRAP_DEFAULT`. As per the `UMat::getMat`
+example below:
+@code{.cpp}
+class CV_EXPORTS_W UMat
+{
+public:
+    //! Mat is mappable to UMat.
+    // You would need to provide `static bool cv_mappable_to(const Ptr<Mat>& src, Ptr<UMat>& dst)`
+    CV_WRAP_MAPPABLE(Ptr<Mat>);
+
+    /! returns the OpenCL queue used by OpenCV UMat.
+    // You would need to provide the method body in the binder code
+    CV_WRAP_PHANTOM(static void* queue());
+
+    //! returns the OpenCL context used by OpenCV UMat
+    // You would need to provide the method body in the binder code
+    CV_WRAP_PHANTOM(static void* context());
+
+    //! The wrapped method become equvalent to `get(int flags = ACCESS_RW)`
+    CV_WRAP_AS(get) Mat getMat(int flags CV_WRAP_DEFAULT(ACCESS_RW)) const;
+};
+@endcode
diff --git a/doc/py_tutorials/py_ml/py_svm/py_svm_opencv/py_svm_opencv.markdown b/doc/py_tutorials/py_ml/py_svm/py_svm_opencv/py_svm_opencv.markdown
index a9502996f63..dd034e9afaa 100644
--- a/doc/py_tutorials/py_ml/py_svm/py_svm_opencv/py_svm_opencv.markdown
+++ b/doc/py_tutorials/py_ml/py_svm/py_svm_opencv/py_svm_opencv.markdown
@@ -36,7 +36,7 @@ gives us a feature vector containing 64 values. This is the feature vector we us
 
 Finally, as in the previous case, we start by splitting our big dataset into individual cells. For
 every digit, 250 cells are reserved for training data and remaining 250 data is reserved for
-testing. Full code is given below, you also can download it from [here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/ml/py_svm_opencv/hogsvm.py):
+testing. Full code is given below, you also can download it from [here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/ml/py_svm_opencv/hogsvm.py):
 
 @include samples/python/tutorial_code/ml/py_svm_opencv/hogsvm.py
 
diff --git a/doc/tutorials/calib3d/camera_calibration/camera_calibration.markdown b/doc/tutorials/calib3d/camera_calibration/camera_calibration.markdown
index 6ce791cd0a6..a7a7dd727eb 100644
--- a/doc/tutorials/calib3d/camera_calibration/camera_calibration.markdown
+++ b/doc/tutorials/calib3d/camera_calibration/camera_calibration.markdown
@@ -77,13 +77,13 @@ Source code
 
 You may also find the source code in the `samples/cpp/tutorial_code/calib3d/camera_calibration/`
 folder of the OpenCV source library or [download it from here
-](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/calib3d/camera_calibration/camera_calibration.cpp). The program has a
+](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/calib3d/camera_calibration/camera_calibration.cpp). The program has a
 single argument: the name of its configuration file. If none is given then it will try to open the
 one named "default.xml". [Here's a sample configuration file
-](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/calib3d/camera_calibration/in_VID5.xml) in XML format. In the
+](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/calib3d/camera_calibration/in_VID5.xml) in XML format. In the
 configuration file you may choose to use camera as an input, a video file or an image list. If you
 opt for the last one, you will need to create a configuration file where you enumerate the images to
-use. Here's [an example of this ](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/calib3d/camera_calibration/VID5.xml).
+use. Here's [an example of this ](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/calib3d/camera_calibration/VID5.xml).
 The important part to remember is that the images need to be specified using the absolute path or
 the relative one from your application's working directory. You may find all this in the samples
 directory mentioned above.
diff --git a/doc/tutorials/core/adding_images/adding_images.markdown b/doc/tutorials/core/adding_images/adding_images.markdown
index 0da6d2d33e0..c8776325a37 100644
--- a/doc/tutorials/core/adding_images/adding_images.markdown
+++ b/doc/tutorials/core/adding_images/adding_images.markdown
@@ -33,19 +33,19 @@ Source Code
 
 @add_toggle_cpp
 Download the source code from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/core/AddingImages/AddingImages.cpp).
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/core/AddingImages/AddingImages.cpp).
 @include cpp/tutorial_code/core/AddingImages/AddingImages.cpp
 @end_toggle
 
 @add_toggle_java
 Download the source code from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/java/tutorial_code/core/AddingImages/AddingImages.java).
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/java/tutorial_code/core/AddingImages/AddingImages.java).
 @include java/tutorial_code/core/AddingImages/AddingImages.java
 @end_toggle
 
 @add_toggle_python
 Download the source code from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/python/tutorial_code/core/AddingImages/adding_images.py).
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/python/tutorial_code/core/AddingImages/adding_images.py).
 @include python/tutorial_code/core/AddingImages/adding_images.py
 @end_toggle
 
@@ -69,7 +69,7 @@ We need two source images (\f$f_{0}(x)\f$ and \f$f_{1}(x)\f$). So, we load them
 @snippet python/tutorial_code/core/AddingImages/adding_images.py load
 @end_toggle
 
-We used the following images: [LinuxLogo.jpg](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/data/LinuxLogo.jpg) and [WindowsLogo.jpg](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/data/WindowsLogo.jpg)
+We used the following images: [LinuxLogo.jpg](https://raw.githubusercontent.com/opencv/opencv/master/samples/data/LinuxLogo.jpg) and [WindowsLogo.jpg](https://raw.githubusercontent.com/opencv/opencv/master/samples/data/WindowsLogo.jpg)
 
 @warning Since we are *adding* *src1* and *src2*, they both have to be of the same size
 (width and height) and type.
diff --git a/doc/tutorials/core/basic_linear_transform/basic_linear_transform.markdown b/doc/tutorials/core/basic_linear_transform/basic_linear_transform.markdown
index 803de71acbb..7b5a82aa33f 100644
--- a/doc/tutorials/core/basic_linear_transform/basic_linear_transform.markdown
+++ b/doc/tutorials/core/basic_linear_transform/basic_linear_transform.markdown
@@ -58,7 +58,7 @@ Code
 
 @add_toggle_cpp
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/ImgProc/BasicLinearTransforms.cpp)
+    [here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/ImgProc/BasicLinearTransforms.cpp)
 
 -   The following code performs the operation \f$g(i,j) = \alpha \cdot f(i,j) + \beta\f$ :
     @include samples/cpp/tutorial_code/ImgProc/BasicLinearTransforms.cpp
@@ -66,7 +66,7 @@ Code
 
 @add_toggle_java
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/ImgProc/changing_contrast_brightness_image/BasicLinearTransformsDemo.java)
+    [here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/ImgProc/changing_contrast_brightness_image/BasicLinearTransformsDemo.java)
 
 -   The following code performs the operation \f$g(i,j) = \alpha \cdot f(i,j) + \beta\f$ :
     @include samples/java/tutorial_code/ImgProc/changing_contrast_brightness_image/BasicLinearTransformsDemo.java
@@ -74,7 +74,7 @@ Code
 
 @add_toggle_python
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/imgProc/changing_contrast_brightness_image/BasicLinearTransforms.py)
+    [here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/imgProc/changing_contrast_brightness_image/BasicLinearTransforms.py)
 
 -   The following code performs the operation \f$g(i,j) = \alpha \cdot f(i,j) + \beta\f$ :
     @include samples/python/tutorial_code/imgProc/changing_contrast_brightness_image/BasicLinearTransforms.py
@@ -284,15 +284,15 @@ and are not intended to be used as a replacement of a raster graphics editor!**
 ### Code
 
 @add_toggle_cpp
-Code for the tutorial is [here](https://github.com/opencv/opencv/blob/3.4/samples/cpp/tutorial_code/ImgProc/changing_contrast_brightness_image/changing_contrast_brightness_image.cpp).
+Code for the tutorial is [here](https://github.com/opencv/opencv/blob/master/samples/cpp/tutorial_code/ImgProc/changing_contrast_brightness_image/changing_contrast_brightness_image.cpp).
 @end_toggle
 
 @add_toggle_java
-Code for the tutorial is [here](https://github.com/opencv/opencv/blob/3.4/samples/java/tutorial_code/ImgProc/changing_contrast_brightness_image/ChangingContrastBrightnessImageDemo.java).
+Code for the tutorial is [here](https://github.com/opencv/opencv/blob/master/samples/java/tutorial_code/ImgProc/changing_contrast_brightness_image/ChangingContrastBrightnessImageDemo.java).
 @end_toggle
 
 @add_toggle_python
-Code for the tutorial is [here](https://github.com/opencv/opencv/blob/3.4/samples/python/tutorial_code/imgProc/changing_contrast_brightness_image/changing_contrast_brightness_image.py).
+Code for the tutorial is [here](https://github.com/opencv/opencv/blob/master/samples/python/tutorial_code/imgProc/changing_contrast_brightness_image/changing_contrast_brightness_image.py).
 @end_toggle
 
 Code for the gamma correction:
diff --git a/doc/tutorials/core/discrete_fourier_transform/discrete_fourier_transform.markdown b/doc/tutorials/core/discrete_fourier_transform/discrete_fourier_transform.markdown
index ca485a92930..53ef27258d1 100644
--- a/doc/tutorials/core/discrete_fourier_transform/discrete_fourier_transform.markdown
+++ b/doc/tutorials/core/discrete_fourier_transform/discrete_fourier_transform.markdown
@@ -19,7 +19,7 @@ Source code
 
 @add_toggle_cpp
 You can [download this from here
-](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/core/discrete_fourier_transform/discrete_fourier_transform.cpp) or
+](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/core/discrete_fourier_transform/discrete_fourier_transform.cpp) or
 find it in the
 `samples/cpp/tutorial_code/core/discrete_fourier_transform/discrete_fourier_transform.cpp` of the
 OpenCV source code library.
@@ -27,7 +27,7 @@ OpenCV source code library.
 
 @add_toggle_java
 You can [download this from here
-](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/java/tutorial_code/core/discrete_fourier_transform/DiscreteFourierTransform.java) or
+](https://raw.githubusercontent.com/opencv/opencv/master/samples/java/tutorial_code/core/discrete_fourier_transform/DiscreteFourierTransform.java) or
 find it in the
 `samples/java/tutorial_code/core/discrete_fourier_transform/DiscreteFourierTransform.java` of the
 OpenCV source code library.
@@ -35,7 +35,7 @@ OpenCV source code library.
 
 @add_toggle_python
 You can [download this from here
-](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/python/tutorial_code/core/discrete_fourier_transform/discrete_fourier_transform.py) or
+](https://raw.githubusercontent.com/opencv/opencv/master/samples/python/tutorial_code/core/discrete_fourier_transform/discrete_fourier_transform.py) or
 find it in the
 `samples/python/tutorial_code/core/discrete_fourier_transform/discrete_fourier_transform.py` of the
 OpenCV source code library.
@@ -222,7 +222,7 @@ An application idea would be to determine the geometrical orientation present in
 example, let us find out if a text is horizontal or not? Looking at some text you'll notice that the
 text lines sort of form also horizontal lines and the letters form sort of vertical lines. These two
 main components of a text snippet may be also seen in case of the Fourier transform. Let us use
-[this horizontal ](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/data/imageTextN.png) and [this rotated](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/data/imageTextR.png)
+[this horizontal ](https://raw.githubusercontent.com/opencv/opencv/master/samples/data/imageTextN.png) and [this rotated](https://raw.githubusercontent.com/opencv/opencv/master/samples/data/imageTextR.png)
 image about a text.
 
 In case of the horizontal text:
diff --git a/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown b/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown
index 7b91af75a3e..97cdc3c35f1 100644
--- a/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown
+++ b/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown
@@ -19,7 +19,7 @@ Source code
 -----------
 
 You can [download this from here
-](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/core/file_input_output/file_input_output.cpp) or find it in the
+](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/core/file_input_output/file_input_output.cpp) or find it in the
 `samples/cpp/tutorial_code/core/file_input_output/file_input_output.cpp` of the OpenCV source code
 library.
 
diff --git a/doc/tutorials/core/how_to_scan_images/how_to_scan_images.markdown b/doc/tutorials/core/how_to_scan_images/how_to_scan_images.markdown
index a4b7af63757..c85503773b0 100644
--- a/doc/tutorials/core/how_to_scan_images/how_to_scan_images.markdown
+++ b/doc/tutorials/core/how_to_scan_images/how_to_scan_images.markdown
@@ -54,7 +54,7 @@ three major ways of going through an image pixel by pixel. To make things a litt
 will make the scanning for each image using all of these methods, and print out how long it took.
 
 You can download the full source code [here
-](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/core/how_to_scan_images/how_to_scan_images.cpp) or look it up in
+](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/core/how_to_scan_images/how_to_scan_images.cpp) or look it up in
 the samples directory of OpenCV at the cpp tutorial code for the core section. Its basic usage is:
 @code{.bash}
 how_to_scan_images imageName.jpg intValueToReduce [G]
diff --git a/doc/tutorials/core/how_to_use_OpenCV_parallel_for_/how_to_use_OpenCV_parallel_for_.markdown b/doc/tutorials/core/how_to_use_OpenCV_parallel_for_/how_to_use_OpenCV_parallel_for_.markdown
index 3f5f556d35d..fb876dad3b5 100644
--- a/doc/tutorials/core/how_to_use_OpenCV_parallel_for_/how_to_use_OpenCV_parallel_for_.markdown
+++ b/doc/tutorials/core/how_to_use_OpenCV_parallel_for_/how_to_use_OpenCV_parallel_for_.markdown
@@ -9,7 +9,7 @@ Goal
 The goal of this tutorial is to show you how to use the OpenCV `parallel_for_` framework to easily
 parallelize your code. To illustrate the concept, we will write a program to draw a Mandelbrot set
 exploiting almost all the CPU load available.
-The full tutorial code is [here](https://github.com/opencv/opencv/blob/3.4/samples/cpp/tutorial_code/core/how_to_use_OpenCV_parallel_for_/how_to_use_OpenCV_parallel_for_.cpp).
+The full tutorial code is [here](https://github.com/opencv/opencv/blob/master/samples/cpp/tutorial_code/core/how_to_use_OpenCV_parallel_for_/how_to_use_OpenCV_parallel_for_.cpp).
 If you want more information about multithreading, you will have to refer to a reference book or course as this tutorial is intended
 to remain simple.
 
@@ -177,7 +177,7 @@ C++ 11 standard allows to simplify the parallel implementation by get rid of the
 Results
 -----------
 
-You can find the full tutorial code [here](https://github.com/opencv/opencv/blob/3.4/samples/cpp/tutorial_code/core/how_to_use_OpenCV_parallel_for_/how_to_use_OpenCV_parallel_for_.cpp).
+You can find the full tutorial code [here](https://github.com/opencv/opencv/blob/master/samples/cpp/tutorial_code/core/how_to_use_OpenCV_parallel_for_/how_to_use_OpenCV_parallel_for_.cpp).
 The performance of the parallel implementation depends of the type of CPU you have. For instance, on 4 cores / 8 threads
 CPU, you can expect a speed-up of around 6.9X. There are many factors to explain why we do not achieve a speed-up of almost 8X.
 Main reasons should be mostly due to:
diff --git a/doc/tutorials/core/how_to_use_ippa_conversion/how_to_use_ippa_conversion.markdown b/doc/tutorials/core/how_to_use_ippa_conversion/how_to_use_ippa_conversion.markdown
index e5e0e4a1eb5..4bc56fa7339 100644
--- a/doc/tutorials/core/how_to_use_ippa_conversion/how_to_use_ippa_conversion.markdown
+++ b/doc/tutorials/core/how_to_use_ippa_conversion/how_to_use_ippa_conversion.markdown
@@ -19,7 +19,7 @@ Code
 
 You may also find the source code in the
 `samples/cpp/tutorial_code/core/ippasync/ippasync_sample.cpp` file of the OpenCV source library or
-download it from [here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/core/ippasync/ippasync_sample.cpp).
+download it from [here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/core/ippasync/ippasync_sample.cpp).
 
 @include cpp/tutorial_code/core/ippasync/ippasync_sample.cpp
 
diff --git a/doc/tutorials/core/interoperability_with_OpenCV_1/interoperability_with_OpenCV_1.markdown b/doc/tutorials/core/interoperability_with_OpenCV_1/interoperability_with_OpenCV_1.markdown
index 0e2b45cea59..8895415164c 100644
--- a/doc/tutorials/core/interoperability_with_OpenCV_1/interoperability_with_OpenCV_1.markdown
+++ b/doc/tutorials/core/interoperability_with_OpenCV_1/interoperability_with_OpenCV_1.markdown
@@ -88,7 +88,7 @@ L = Mat(pI);
 A case study
 ------------
 
-Now that you have the basics done [here's](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/core/interoperability_with_OpenCV_1/interoperability_with_OpenCV_1.cpp)
+Now that you have the basics done [here's](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/core/interoperability_with_OpenCV_1/interoperability_with_OpenCV_1.cpp)
 an example that mixes the usage of the C interface with the C++ one. You will also find it in the
 sample directory of the OpenCV source code library at the
 `samples/cpp/tutorial_code/core/interoperability_with_OpenCV_1/interoperability_with_OpenCV_1.cpp` .
@@ -135,7 +135,7 @@ output:
 
 You may observe a runtime instance of this on the [YouTube
 here](https://www.youtube.com/watch?v=qckm-zvo31w) and you can [download the source code from here
-](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/core/interoperability_with_OpenCV_1/interoperability_with_OpenCV_1.cpp)
+](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/core/interoperability_with_OpenCV_1/interoperability_with_OpenCV_1.cpp)
 or find it in the
 `samples/cpp/tutorial_code/core/interoperability_with_OpenCV_1/interoperability_with_OpenCV_1.cpp`
 of the OpenCV source code library.
diff --git a/doc/tutorials/core/mat-mask-operations/mat_mask_operations.markdown b/doc/tutorials/core/mat-mask-operations/mat_mask_operations.markdown
index bd74267f547..8e1febebffc 100644
--- a/doc/tutorials/core/mat-mask-operations/mat_mask_operations.markdown
+++ b/doc/tutorials/core/mat-mask-operations/mat_mask_operations.markdown
@@ -33,7 +33,7 @@ Code
 
 @add_toggle_cpp
 You can download this source code from [here
-](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/core/mat_mask_operations/mat_mask_operations.cpp) or look in the
+](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/core/mat_mask_operations/mat_mask_operations.cpp) or look in the
 OpenCV source code libraries sample directory at
 `samples/cpp/tutorial_code/core/mat_mask_operations/mat_mask_operations.cpp`.
 @include samples/cpp/tutorial_code/core/mat_mask_operations/mat_mask_operations.cpp
@@ -41,7 +41,7 @@ OpenCV source code libraries sample directory at
 
 @add_toggle_java
 You can download this source code from [here
-](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/java/tutorial_code/core/mat_mask_operations/MatMaskOperations.java) or look in the
+](https://raw.githubusercontent.com/opencv/opencv/master/samples/java/tutorial_code/core/mat_mask_operations/MatMaskOperations.java) or look in the
 OpenCV source code libraries sample directory at
 `samples/java/tutorial_code/core/mat_mask_operations/MatMaskOperations.java`.
 @include samples/java/tutorial_code/core/mat_mask_operations/MatMaskOperations.java
@@ -49,7 +49,7 @@ OpenCV source code libraries sample directory at
 
 @add_toggle_python
 You can download this source code from [here
-](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/python/tutorial_code/core/mat_mask_operations/mat_mask_operations.py) or look in the
+](https://raw.githubusercontent.com/opencv/opencv/master/samples/python/tutorial_code/core/mat_mask_operations/mat_mask_operations.py) or look in the
 OpenCV source code libraries sample directory at
 `samples/python/tutorial_code/core/mat_mask_operations/mat_mask_operations.py`.
 @include samples/python/tutorial_code/core/mat_mask_operations/mat_mask_operations.py
diff --git a/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown b/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown
index 882b7a4a0bb..314921fe3b5 100644
--- a/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown
+++ b/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown
@@ -262,7 +262,7 @@ OpenCV offers support for output of other common OpenCV data structures too via
     ![](images/MatBasicContainerOut15.png)
 
 Most of the samples here have been included in a small console application. You can download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/core/mat_the_basic_image_container/mat_the_basic_image_container.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/core/mat_the_basic_image_container/mat_the_basic_image_container.cpp)
 or in the core section of the cpp samples.
 
 You can also find a quick video demonstration of this on
diff --git a/doc/tutorials/dnn/dnn_custom_layers/dnn_custom_layers.md b/doc/tutorials/dnn/dnn_custom_layers/dnn_custom_layers.md
index 0486b31e14c..f367946620c 100644
--- a/doc/tutorials/dnn/dnn_custom_layers/dnn_custom_layers.md
+++ b/doc/tutorials/dnn/dnn_custom_layers/dnn_custom_layers.md
@@ -216,7 +216,7 @@ a centric one.
 @snippet dnn/edge_detection.py Register
 
 That's it! We've replaced an implemented OpenCV's layer to a custom one.
-You may find a full script in the [source code](https://github.com/opencv/opencv/tree/3.4/samples/dnn/edge_detection.py).
+You may find a full script in the [source code](https://github.com/opencv/opencv/tree/master/samples/dnn/edge_detection.py).
 
 <table border="0">
 <tr>
diff --git a/doc/tutorials/dnn/dnn_googlenet/dnn_googlenet.markdown b/doc/tutorials/dnn/dnn_googlenet/dnn_googlenet.markdown
index 1f26c37035b..50946b1ba45 100644
--- a/doc/tutorials/dnn/dnn_googlenet/dnn_googlenet.markdown
+++ b/doc/tutorials/dnn/dnn_googlenet/dnn_googlenet.markdown
@@ -13,7 +13,7 @@ We will demonstrate results of this example on the following picture.
 Source Code
 -----------
 
-We will be using snippets from the example application, that can be downloaded [here](https://github.com/opencv/opencv/blob/3.4/samples/dnn/classification.cpp).
+We will be using snippets from the example application, that can be downloaded [here](https://github.com/opencv/opencv/blob/master/samples/dnn/classification.cpp).
 
 @include dnn/classification.cpp
 
@@ -25,7 +25,7 @@ Explanation
    [bvlc_googlenet.caffemodel](http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel)
 
    Also you need file with names of [ILSVRC2012](http://image-net.org/challenges/LSVRC/2012/browse-synsets) classes:
-   [classification_classes_ILSVRC2012.txt](https://github.com/opencv/opencv/tree/3.4/samples/dnn/classification_classes_ILSVRC2012.txt).
+   [classification_classes_ILSVRC2012.txt](https://github.com/opencv/opencv/tree/master/samples/dnn/classification_classes_ILSVRC2012.txt).
 
    Put these files into working dir of this program example.
 
diff --git a/doc/tutorials/dnn/dnn_halide/dnn_halide.markdown b/doc/tutorials/dnn/dnn_halide/dnn_halide.markdown
index 7271d08b689..fe82f05816d 100644
--- a/doc/tutorials/dnn/dnn_halide/dnn_halide.markdown
+++ b/doc/tutorials/dnn/dnn_halide/dnn_halide.markdown
@@ -68,8 +68,6 @@ MSBuild.exe /m:4 /t:Build /p:Configuration=Release .\\ALL_BUILD.vcxproj
 ## Build OpenCV with Halide backend
 When you build OpenCV add the following configuration flags:
 
-- `ENABLE_CXX11` - enable C++11 standard
-
 - `WITH_HALIDE` - enable Halide linkage
 
 - `HALIDE_ROOT_DIR` - path to Halide build directory
diff --git a/doc/tutorials/dnn/dnn_yolo/dnn_yolo.markdown b/doc/tutorials/dnn/dnn_yolo/dnn_yolo.markdown
index 76bf0edd250..968b3faacaa 100644
--- a/doc/tutorials/dnn/dnn_yolo/dnn_yolo.markdown
+++ b/doc/tutorials/dnn/dnn_yolo/dnn_yolo.markdown
@@ -19,8 +19,8 @@ Source Code
 -----------
 
 Use a universal sample for object detection models written
-[in C++](https://github.com/opencv/opencv/blob/3.4/samples/dnn/object_detection.cpp) and
-[in Python](https://github.com/opencv/opencv/blob/3.4/samples/dnn/object_detection.py) languages
+[in C++](https://github.com/opencv/opencv/blob/master/samples/dnn/object_detection.cpp) and
+[in Python](https://github.com/opencv/opencv/blob/master/samples/dnn/object_detection.py) languages
 
 Usage examples
 --------------
diff --git a/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown b/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown
index d0f772439bc..b2350f84c48 100644
--- a/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown
+++ b/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown
@@ -32,7 +32,7 @@ You can find the images (*graf1.png*, *graf3.png*) and homography (*H1to3p.xml*)
 
 @add_toggle_cpp
 -   **Downloadable code**: Click
-    [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/features2D/AKAZE_match.cpp)
+    [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/features2D/AKAZE_match.cpp)
 
 -   **Code at glance:**
     @include samples/cpp/tutorial_code/features2D/AKAZE_match.cpp
@@ -40,7 +40,7 @@ You can find the images (*graf1.png*, *graf3.png*) and homography (*H1to3p.xml*)
 
 @add_toggle_java
 -   **Downloadable code**: Click
-    [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/java/tutorial_code/features2D/akaze_matching/AKAZEMatchDemo.java)
+    [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/java/tutorial_code/features2D/akaze_matching/AKAZEMatchDemo.java)
 
 -   **Code at glance:**
     @include samples/java/tutorial_code/features2D/akaze_matching/AKAZEMatchDemo.java
@@ -48,7 +48,7 @@ You can find the images (*graf1.png*, *graf3.png*) and homography (*H1to3p.xml*)
 
 @add_toggle_python
 -   **Downloadable code**: Click
-    [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/python/tutorial_code/features2D/akaze_matching/AKAZE_match.py)
+    [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/python/tutorial_code/features2D/akaze_matching/AKAZE_match.py)
 
 -   **Code at glance:**
     @include samples/python/tutorial_code/features2D/akaze_matching/AKAZE_match.py
diff --git a/doc/tutorials/features2d/feature_description/feature_description.markdown b/doc/tutorials/features2d/feature_description/feature_description.markdown
index 01ec0de90ed..ec3cd0e4c54 100644
--- a/doc/tutorials/features2d/feature_description/feature_description.markdown
+++ b/doc/tutorials/features2d/feature_description/feature_description.markdown
@@ -24,19 +24,19 @@ Code
 
 @add_toggle_cpp
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/features2D/feature_description/SURF_matching_Demo.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/features2D/feature_description/SURF_matching_Demo.cpp)
 @include samples/cpp/tutorial_code/features2D/feature_description/SURF_matching_Demo.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/features2D/feature_description/SURFMatchingDemo.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/features2D/feature_description/SURFMatchingDemo.java)
 @include samples/java/tutorial_code/features2D/feature_description/SURFMatchingDemo.java
 @end_toggle
 
 @add_toggle_python
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/features2D/feature_description/SURF_matching_Demo.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/features2D/feature_description/SURF_matching_Demo.py)
 @include samples/python/tutorial_code/features2D/feature_description/SURF_matching_Demo.py
 @end_toggle
 
diff --git a/doc/tutorials/features2d/feature_detection/feature_detection.markdown b/doc/tutorials/features2d/feature_detection/feature_detection.markdown
index bb2658633bd..d0996512ef4 100644
--- a/doc/tutorials/features2d/feature_detection/feature_detection.markdown
+++ b/doc/tutorials/features2d/feature_detection/feature_detection.markdown
@@ -22,19 +22,19 @@ Code
 
 @add_toggle_cpp
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/features2D/feature_detection/SURF_detection_Demo.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/features2D/feature_detection/SURF_detection_Demo.cpp)
 @include samples/cpp/tutorial_code/features2D/feature_detection/SURF_detection_Demo.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/features2D/feature_detection/SURFDetectionDemo.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/features2D/feature_detection/SURFDetectionDemo.java)
 @include samples/java/tutorial_code/features2D/feature_detection/SURFDetectionDemo.java
 @end_toggle
 
 @add_toggle_python
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/features2D/feature_detection/SURF_detection_Demo.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/features2D/feature_detection/SURF_detection_Demo.py)
 @include samples/python/tutorial_code/features2D/feature_detection/SURF_detection_Demo.py
 @end_toggle
 
diff --git a/doc/tutorials/features2d/feature_flann_matcher/feature_flann_matcher.markdown b/doc/tutorials/features2d/feature_flann_matcher/feature_flann_matcher.markdown
index de04f635045..e7f865c3cef 100644
--- a/doc/tutorials/features2d/feature_flann_matcher/feature_flann_matcher.markdown
+++ b/doc/tutorials/features2d/feature_flann_matcher/feature_flann_matcher.markdown
@@ -45,19 +45,19 @@ Code
 
 @add_toggle_cpp
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/features2D/feature_flann_matcher/SURF_FLANN_matching_Demo.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/features2D/feature_flann_matcher/SURF_FLANN_matching_Demo.cpp)
 @include samples/cpp/tutorial_code/features2D/feature_flann_matcher/SURF_FLANN_matching_Demo.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/features2D/feature_flann_matcher/SURFFLANNMatchingDemo.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/features2D/feature_flann_matcher/SURFFLANNMatchingDemo.java)
 @include samples/java/tutorial_code/features2D/feature_flann_matcher/SURFFLANNMatchingDemo.java
 @end_toggle
 
 @add_toggle_python
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/features2D/feature_flann_matcher/SURF_FLANN_matching_Demo.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/features2D/feature_flann_matcher/SURF_FLANN_matching_Demo.py)
 @include samples/python/tutorial_code/features2D/feature_flann_matcher/SURF_FLANN_matching_Demo.py
 @end_toggle
 
diff --git a/doc/tutorials/features2d/feature_homography/feature_homography.markdown b/doc/tutorials/features2d/feature_homography/feature_homography.markdown
index 908f2c69a14..c4f0c00e551 100644
--- a/doc/tutorials/features2d/feature_homography/feature_homography.markdown
+++ b/doc/tutorials/features2d/feature_homography/feature_homography.markdown
@@ -20,19 +20,19 @@ Code
 
 @add_toggle_cpp
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/features2D/feature_homography/SURF_FLANN_matching_homography_Demo.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/features2D/feature_homography/SURF_FLANN_matching_homography_Demo.cpp)
 @include samples/cpp/tutorial_code/features2D/feature_homography/SURF_FLANN_matching_homography_Demo.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/features2D/feature_homography/SURFFLANNMatchingHomographyDemo.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/features2D/feature_homography/SURFFLANNMatchingHomographyDemo.java)
 @include samples/java/tutorial_code/features2D/feature_homography/SURFFLANNMatchingHomographyDemo.java
 @end_toggle
 
 @add_toggle_python
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/features2D/feature_homography/SURF_FLANN_matching_homography_Demo.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/features2D/feature_homography/SURF_FLANN_matching_homography_Demo.py)
 @include samples/python/tutorial_code/features2D/feature_homography/SURF_FLANN_matching_homography_Demo.py
 @end_toggle
 
diff --git a/doc/tutorials/features2d/homography/homography.markdown b/doc/tutorials/features2d/homography/homography.markdown
index 1fc8a9e3c48..020017f023e 100644
--- a/doc/tutorials/features2d/homography/homography.markdown
+++ b/doc/tutorials/features2d/homography/homography.markdown
@@ -12,8 +12,8 @@ For detailed explanations about the theory, please refer to a computer vision co
 *   An Invitation to 3-D Vision: From Images to Geometric Models, @cite Ma:2003:IVI
 *   Computer Vision: Algorithms and Applications, @cite RS10
 
-The tutorial code can be found [here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/features2D/Homography).
-The images used in this tutorial can be found [here](https://github.com/opencv/opencv/tree/3.4/samples/data) (`left*.jpg`).
+The tutorial code can be found [here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/features2D/Homography).
+The images used in this tutorial can be found [here](https://github.com/opencv/opencv/tree/master/samples/data) (`left*.jpg`).
 
 Basic theory {#tutorial_homography_Basic_theory}
 ------------
diff --git a/doc/tutorials/features2d/trackingmotion/corner_subpixels/corner_subpixels.markdown b/doc/tutorials/features2d/trackingmotion/corner_subpixels/corner_subpixels.markdown
index 514fd332c07..82b33dd2561 100644
--- a/doc/tutorials/features2d/trackingmotion/corner_subpixels/corner_subpixels.markdown
+++ b/doc/tutorials/features2d/trackingmotion/corner_subpixels/corner_subpixels.markdown
@@ -17,19 +17,19 @@ Code
 
 @add_toggle_cpp
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/TrackingMotion/cornerSubPix_Demo.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/TrackingMotion/cornerSubPix_Demo.cpp)
 @include samples/cpp/tutorial_code/TrackingMotion/cornerSubPix_Demo.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/TrackingMotion/corner_subpixels/CornerSubPixDemo.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/TrackingMotion/corner_subpixels/CornerSubPixDemo.java)
 @include samples/java/tutorial_code/TrackingMotion/corner_subpixels/CornerSubPixDemo.java
 @end_toggle
 
 @add_toggle_python
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/TrackingMotion/corner_subpixels/cornerSubPix_Demo.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/TrackingMotion/corner_subpixels/cornerSubPix_Demo.py)
 @include samples/python/tutorial_code/TrackingMotion/corner_subpixels/cornerSubPix_Demo.py
 @end_toggle
 
diff --git a/doc/tutorials/features2d/trackingmotion/generic_corner_detector/generic_corner_detector.markdown b/doc/tutorials/features2d/trackingmotion/generic_corner_detector/generic_corner_detector.markdown
index aded0d1c98c..f10d3efe4e0 100644
--- a/doc/tutorials/features2d/trackingmotion/generic_corner_detector/generic_corner_detector.markdown
+++ b/doc/tutorials/features2d/trackingmotion/generic_corner_detector/generic_corner_detector.markdown
@@ -21,21 +21,21 @@ Code
 
 @add_toggle_cpp
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/TrackingMotion/cornerDetector_Demo.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/TrackingMotion/cornerDetector_Demo.cpp)
 
 @include samples/cpp/tutorial_code/TrackingMotion/cornerDetector_Demo.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/TrackingMotion/generic_corner_detector/CornerDetectorDemo.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/TrackingMotion/generic_corner_detector/CornerDetectorDemo.java)
 
 @include samples/java/tutorial_code/TrackingMotion/generic_corner_detector/CornerDetectorDemo.java
 @end_toggle
 
 @add_toggle_python
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/TrackingMotion/generic_corner_detector/cornerDetector_Demo.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/TrackingMotion/generic_corner_detector/cornerDetector_Demo.py)
 
 @include samples/python/tutorial_code/TrackingMotion/generic_corner_detector/cornerDetector_Demo.py
 @end_toggle
diff --git a/doc/tutorials/features2d/trackingmotion/good_features_to_track/good_features_to_track.markdown b/doc/tutorials/features2d/trackingmotion/good_features_to_track/good_features_to_track.markdown
index 1c5c7029cf2..70d25ab9e21 100644
--- a/doc/tutorials/features2d/trackingmotion/good_features_to_track/good_features_to_track.markdown
+++ b/doc/tutorials/features2d/trackingmotion/good_features_to_track/good_features_to_track.markdown
@@ -16,19 +16,19 @@ Code
 
 @add_toggle_cpp
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/TrackingMotion/goodFeaturesToTrack_Demo.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/TrackingMotion/goodFeaturesToTrack_Demo.cpp)
 @include samples/cpp/tutorial_code/TrackingMotion/goodFeaturesToTrack_Demo.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/TrackingMotion/good_features_to_track/GoodFeaturesToTrackDemo.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/TrackingMotion/good_features_to_track/GoodFeaturesToTrackDemo.java)
 @include samples/java/tutorial_code/TrackingMotion/good_features_to_track/GoodFeaturesToTrackDemo.java
 @end_toggle
 
 @add_toggle_python
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/TrackingMotion/good_features_to_track/goodFeaturesToTrack_Demo.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/TrackingMotion/good_features_to_track/goodFeaturesToTrack_Demo.py)
 @include samples/python/tutorial_code/TrackingMotion/good_features_to_track/goodFeaturesToTrack_Demo.py
 @end_toggle
 
diff --git a/doc/tutorials/features2d/trackingmotion/harris_detector/harris_detector.markdown b/doc/tutorials/features2d/trackingmotion/harris_detector/harris_detector.markdown
index a59a2ad3af5..bbf4fdbd5be 100644
--- a/doc/tutorials/features2d/trackingmotion/harris_detector/harris_detector.markdown
+++ b/doc/tutorials/features2d/trackingmotion/harris_detector/harris_detector.markdown
@@ -120,19 +120,19 @@ Code
 
 @add_toggle_cpp
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/TrackingMotion/cornerHarris_Demo.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/TrackingMotion/cornerHarris_Demo.cpp)
 @include samples/cpp/tutorial_code/TrackingMotion/cornerHarris_Demo.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/TrackingMotion/harris_detector/CornerHarrisDemo.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/TrackingMotion/harris_detector/CornerHarrisDemo.java)
 @include samples/java/tutorial_code/TrackingMotion/harris_detector/CornerHarrisDemo.java
 @end_toggle
 
 @add_toggle_python
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/TrackingMotion/harris_detector/cornerHarris_Demo.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/TrackingMotion/harris_detector/cornerHarris_Demo.py)
 @include samples/python/tutorial_code/TrackingMotion/harris_detector/cornerHarris_Demo.py
 @end_toggle
 
diff --git a/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown b/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown
index 1ef0e743119..9452bc38d79 100644
--- a/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown
+++ b/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown
@@ -24,7 +24,7 @@ The source code
 
 You may also find the source code and the video file in the
 `samples/cpp/tutorial_code/gpu/gpu-basics-similarity/gpu-basics-similarity` directory of the OpenCV
-source library or download it from [here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/gpu/gpu-basics-similarity/gpu-basics-similarity.cpp).
+source library or download it from [here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/gpu/gpu-basics-similarity/gpu-basics-similarity.cpp).
 The full source code is quite long (due to the controlling of the application via the command line
 arguments and performance measurement). Therefore, to avoid cluttering up these sections with those
 you'll find here only the functions itself.
diff --git a/doc/tutorials/highgui/trackbar/trackbar.markdown b/doc/tutorials/highgui/trackbar/trackbar.markdown
index 0613d7d5e87..d6700d63871 100644
--- a/doc/tutorials/highgui/trackbar/trackbar.markdown
+++ b/doc/tutorials/highgui/trackbar/trackbar.markdown
@@ -27,19 +27,19 @@ Let's modify the program made in the tutorial @ref tutorial_adding_images. We wi
 
 @add_toggle_cpp
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/HighGUI/AddingImagesTrackbar.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/HighGUI/AddingImagesTrackbar.cpp)
 @include cpp/tutorial_code/HighGUI/AddingImagesTrackbar.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/highgui/trackbar/AddingImagesTrackbar.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/highgui/trackbar/AddingImagesTrackbar.java)
 @include java/tutorial_code/highgui/trackbar/AddingImagesTrackbar.java
 @end_toggle
 
 @add_toggle_python
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/highgui/trackbar/AddingImagesTrackbar.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/highgui/trackbar/AddingImagesTrackbar.py)
 @include python/tutorial_code/highgui/trackbar/AddingImagesTrackbar.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown b/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown
index 70543cf14f3..77c44219f9b 100644
--- a/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown
+++ b/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown
@@ -81,19 +81,19 @@ Code
 
 @add_toggle_cpp
 -   This code is in your OpenCV sample folder. Otherwise you can grab it from
-    [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/ImgProc/basic_drawing/Drawing_1.cpp)
+    [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/ImgProc/basic_drawing/Drawing_1.cpp)
     @include samples/cpp/tutorial_code/ImgProc/basic_drawing/Drawing_1.cpp
 @end_toggle
 
 @add_toggle_java
 -   This code is in your OpenCV sample folder. Otherwise you can grab it from
-    [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/java/tutorial_code/ImgProc/BasicGeometricDrawing/BasicGeometricDrawing.java)
+    [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/java/tutorial_code/ImgProc/BasicGeometricDrawing/BasicGeometricDrawing.java)
     @include samples/java/tutorial_code/ImgProc/BasicGeometricDrawing/BasicGeometricDrawing.java
 @end_toggle
 
 @add_toggle_python
 -   This code is in your OpenCV sample folder. Otherwise you can grab it from
-    [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/python/tutorial_code/imgProc/BasicGeometricDrawing/basic_geometric_drawing.py)
+    [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/python/tutorial_code/imgProc/BasicGeometricDrawing/basic_geometric_drawing.py)
     @include samples/python/tutorial_code/imgProc/BasicGeometricDrawing/basic_geometric_drawing.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/erosion_dilatation/erosion_dilatation.markdown b/doc/tutorials/imgproc/erosion_dilatation/erosion_dilatation.markdown
index ddb7d9e8f5a..a5c6695f919 100644
--- a/doc/tutorials/imgproc/erosion_dilatation/erosion_dilatation.markdown
+++ b/doc/tutorials/imgproc/erosion_dilatation/erosion_dilatation.markdown
@@ -65,19 +65,19 @@ Code
 
 @add_toggle_cpp
 This tutorial's code is shown below. You can also download it
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/ImgProc/Morphology_1.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/ImgProc/Morphology_1.cpp)
 @include samples/cpp/tutorial_code/ImgProc/Morphology_1.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial's code is shown below. You can also download it
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/ImgProc/erosion_dilatation/MorphologyDemo1.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/ImgProc/erosion_dilatation/MorphologyDemo1.java)
 @include samples/java/tutorial_code/ImgProc/erosion_dilatation/MorphologyDemo1.java
 @end_toggle
 
 @add_toggle_python
 This tutorial's code is shown below. You can also download it
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/imgProc/erosion_dilatation/morphology_1.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/imgProc/erosion_dilatation/morphology_1.py)
 @include samples/python/tutorial_code/imgProc/erosion_dilatation/morphology_1.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/gausian_median_blur_bilateral_filter/gausian_median_blur_bilateral_filter.markdown b/doc/tutorials/imgproc/gausian_median_blur_bilateral_filter/gausian_median_blur_bilateral_filter.markdown
index 92dd1d5ed75..1bfb5f1f27f 100644
--- a/doc/tutorials/imgproc/gausian_median_blur_bilateral_filter/gausian_median_blur_bilateral_filter.markdown
+++ b/doc/tutorials/imgproc/gausian_median_blur_bilateral_filter/gausian_median_blur_bilateral_filter.markdown
@@ -98,7 +98,7 @@ Code
 
 @add_toggle_cpp
 -   **Downloadable code**: Click
-    [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/ImgProc/Smoothing/Smoothing.cpp)
+    [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/ImgProc/Smoothing/Smoothing.cpp)
 
 -   **Code at glance:**
     @include samples/cpp/tutorial_code/ImgProc/Smoothing/Smoothing.cpp
@@ -106,7 +106,7 @@ Code
 
 @add_toggle_java
 -   **Downloadable code**: Click
-    [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/java/tutorial_code/ImgProc/Smoothing/Smoothing.java)
+    [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/java/tutorial_code/ImgProc/Smoothing/Smoothing.java)
 
 -   **Code at glance:**
     @include samples/java/tutorial_code/ImgProc/Smoothing/Smoothing.java
@@ -114,7 +114,7 @@ Code
 
 @add_toggle_python
 -   **Downloadable code**: Click
-    [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/python/tutorial_code/imgProc/Smoothing/smoothing.py)
+    [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/python/tutorial_code/imgProc/Smoothing/smoothing.py)
 
 -   **Code at glance:**
     @include samples/python/tutorial_code/imgProc/Smoothing/smoothing.py
@@ -221,7 +221,7 @@ already known by now.
 Results
 -------
 
--   The code opens an image (in this case [lena.jpg](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/data/lena.jpg))
+-   The code opens an image (in this case [lena.jpg](https://raw.githubusercontent.com/opencv/opencv/master/samples/data/lena.jpg))
     and display it under the effects of the 4 filters explained.
 -   Here is a snapshot of the image smoothed using *medianBlur*:
 
diff --git a/doc/tutorials/imgproc/histograms/back_projection/back_projection.markdown b/doc/tutorials/imgproc/histograms/back_projection/back_projection.markdown
index cae547bd950..61baca9bf1d 100644
--- a/doc/tutorials/imgproc/histograms/back_projection/back_projection.markdown
+++ b/doc/tutorials/imgproc/histograms/back_projection/back_projection.markdown
@@ -74,13 +74,13 @@ Code
 @add_toggle_cpp
 -   **Downloadable code**:
     -   Click
-        [here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/Histograms_Matching/calcBackProject_Demo1.cpp)
+        [here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/Histograms_Matching/calcBackProject_Demo1.cpp)
         for the basic version (explained in this tutorial).
     -   For stuff slightly fancier (using H-S histograms and floodFill to define a mask for the
         skin area) you can check the [improved
-        demo](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/Histograms_Matching/calcBackProject_Demo2.cpp)
+        demo](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/Histograms_Matching/calcBackProject_Demo2.cpp)
     -   ...or you can always check out the classical
-        [camshiftdemo](https://github.com/opencv/opencv/tree/3.4/samples/cpp/camshiftdemo.cpp)
+        [camshiftdemo](https://github.com/opencv/opencv/tree/master/samples/cpp/camshiftdemo.cpp)
         in samples.
 
 -   **Code at glance:**
@@ -90,13 +90,13 @@ Code
 @add_toggle_java
 -   **Downloadable code**:
     -   Click
-        [here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/Histograms_Matching/back_projection/CalcBackProjectDemo1.java)
+        [here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/Histograms_Matching/back_projection/CalcBackProjectDemo1.java)
         for the basic version (explained in this tutorial).
     -   For stuff slightly fancier (using H-S histograms and floodFill to define a mask for the
         skin area) you can check the [improved
-        demo](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/Histograms_Matching/back_projection/CalcBackProjectDemo2.java)
+        demo](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/Histograms_Matching/back_projection/CalcBackProjectDemo2.java)
     -   ...or you can always check out the classical
-        [camshiftdemo](https://github.com/opencv/opencv/tree/3.4/samples/cpp/camshiftdemo.cpp)
+        [camshiftdemo](https://github.com/opencv/opencv/tree/master/samples/cpp/camshiftdemo.cpp)
         in samples.
 
 -   **Code at glance:**
@@ -106,13 +106,13 @@ Code
 @add_toggle_python
 -   **Downloadable code**:
     -   Click
-        [here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/Histograms_Matching/back_projection/calcBackProject_Demo1.py)
+        [here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/Histograms_Matching/back_projection/calcBackProject_Demo1.py)
         for the basic version (explained in this tutorial).
     -   For stuff slightly fancier (using H-S histograms and floodFill to define a mask for the
         skin area) you can check the [improved
-        demo](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/Histograms_Matching/back_projection/calcBackProject_Demo2.py)
+        demo](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/Histograms_Matching/back_projection/calcBackProject_Demo2.py)
     -   ...or you can always check out the classical
-        [camshiftdemo](https://github.com/opencv/opencv/tree/3.4/samples/cpp/camshiftdemo.cpp)
+        [camshiftdemo](https://github.com/opencv/opencv/tree/master/samples/cpp/camshiftdemo.cpp)
         in samples.
 
 -   **Code at glance:**
diff --git a/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown b/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown
index 471887c59ac..0623ba12f2d 100644
--- a/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown
+++ b/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown
@@ -72,7 +72,7 @@ Code
 
 @add_toggle_cpp
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/Histograms_Matching/calcHist_Demo.cpp)
+    [here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/Histograms_Matching/calcHist_Demo.cpp)
 
 -   **Code at glance:**
     @include samples/cpp/tutorial_code/Histograms_Matching/calcHist_Demo.cpp
@@ -80,7 +80,7 @@ Code
 
 @add_toggle_java
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/Histograms_Matching/histogram_calculation/CalcHistDemo.java)
+    [here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/Histograms_Matching/histogram_calculation/CalcHistDemo.java)
 
 -   **Code at glance:**
     @include samples/java/tutorial_code/Histograms_Matching/histogram_calculation/CalcHistDemo.java
@@ -88,7 +88,7 @@ Code
 
 @add_toggle_python
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/Histograms_Matching/histogram_calculation/calcHist_Demo.py)
+    [here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/Histograms_Matching/histogram_calculation/calcHist_Demo.py)
 
 -   **Code at glance:**
     @include samples/python/tutorial_code/Histograms_Matching/histogram_calculation/calcHist_Demo.py
diff --git a/doc/tutorials/imgproc/histograms/histogram_comparison/histogram_comparison.markdown b/doc/tutorials/imgproc/histograms/histogram_comparison/histogram_comparison.markdown
index d243511be87..8b7bf78377a 100644
--- a/doc/tutorials/imgproc/histograms/histogram_comparison/histogram_comparison.markdown
+++ b/doc/tutorials/imgproc/histograms/histogram_comparison/histogram_comparison.markdown
@@ -49,7 +49,7 @@ Code
 
 @add_toggle_cpp
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/Histograms_Matching/compareHist_Demo.cpp)
+    [here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/Histograms_Matching/compareHist_Demo.cpp)
 
 -   **Code at glance:**
     @include samples/cpp/tutorial_code/Histograms_Matching/compareHist_Demo.cpp
@@ -57,7 +57,7 @@ Code
 
 @add_toggle_java
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/Histograms_Matching/histogram_comparison/CompareHistDemo.java)
+    [here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/Histograms_Matching/histogram_comparison/CompareHistDemo.java)
 
 -   **Code at glance:**
     @include samples/java/tutorial_code/Histograms_Matching/histogram_comparison/CompareHistDemo.java
@@ -65,7 +65,7 @@ Code
 
 @add_toggle_python
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/Histograms_Matching/histogram_comparison/compareHist_Demo.py)
+    [here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/Histograms_Matching/histogram_comparison/compareHist_Demo.py)
 
 -   **Code at glance:**
     @include samples/python/tutorial_code/Histograms_Matching/histogram_comparison/compareHist_Demo.py
diff --git a/doc/tutorials/imgproc/histograms/histogram_equalization/histogram_equalization.markdown b/doc/tutorials/imgproc/histograms/histogram_equalization/histogram_equalization.markdown
index 2add8bade40..271c6d13472 100644
--- a/doc/tutorials/imgproc/histograms/histogram_equalization/histogram_equalization.markdown
+++ b/doc/tutorials/imgproc/histograms/histogram_equalization/histogram_equalization.markdown
@@ -67,7 +67,7 @@ Code
 
 @add_toggle_cpp
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/Histograms_Matching/EqualizeHist_Demo.cpp)
+    [here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/Histograms_Matching/EqualizeHist_Demo.cpp)
 
 -   **Code at glance:**
     @include samples/cpp/tutorial_code/Histograms_Matching/EqualizeHist_Demo.cpp
@@ -75,7 +75,7 @@ Code
 
 @add_toggle_java
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/Histograms_Matching/histogram_equalization/EqualizeHistDemo.java)
+    [here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/Histograms_Matching/histogram_equalization/EqualizeHistDemo.java)
 
 -   **Code at glance:**
     @include samples/java/tutorial_code/Histograms_Matching/histogram_equalization/EqualizeHistDemo.java
@@ -83,7 +83,7 @@ Code
 
 @add_toggle_python
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/Histograms_Matching/histogram_equalization/EqualizeHist_Demo.py)
+    [here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/Histograms_Matching/histogram_equalization/EqualizeHist_Demo.py)
 
 -   **Code at glance:**
     @include samples/python/tutorial_code/Histograms_Matching/histogram_equalization/EqualizeHist_Demo.py
diff --git a/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown b/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown
index c5f22330cfb..1189923a98b 100644
--- a/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown
+++ b/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown
@@ -130,7 +130,7 @@ Code
 @add_toggle_cpp
 
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/Histograms_Matching/MatchTemplate_Demo.cpp)
+    [here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/Histograms_Matching/MatchTemplate_Demo.cpp)
 -   **Code at glance:**
     @include samples/cpp/tutorial_code/Histograms_Matching/MatchTemplate_Demo.cpp
 
@@ -139,7 +139,7 @@ Code
 @add_toggle_java
 
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/ImgProc/tutorial_template_matching/MatchTemplateDemo.java)
+    [here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/ImgProc/tutorial_template_matching/MatchTemplateDemo.java)
 -   **Code at glance:**
     @include samples/java/tutorial_code/ImgProc/tutorial_template_matching/MatchTemplateDemo.java
 
@@ -148,7 +148,7 @@ Code
 @add_toggle_python
 
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/imgProc/match_template/match_template.py)
+    [here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/imgProc/match_template/match_template.py)
 -   **Code at glance:**
     @include samples/python/tutorial_code/imgProc/match_template/match_template.py
 
diff --git a/doc/tutorials/imgproc/hitOrMiss/hitOrMiss.markdown b/doc/tutorials/imgproc/hitOrMiss/hitOrMiss.markdown
index efb1f232db3..c55f09296f5 100644
--- a/doc/tutorials/imgproc/hitOrMiss/hitOrMiss.markdown
+++ b/doc/tutorials/imgproc/hitOrMiss/hitOrMiss.markdown
@@ -48,19 +48,19 @@ The code corresponding to the previous example is shown below.
 
 @add_toggle_cpp
 You can also download it from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/ImgProc/HitMiss/HitMiss.cpp)
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/ImgProc/HitMiss/HitMiss.cpp)
 @include samples/cpp/tutorial_code/ImgProc/HitMiss/HitMiss.cpp
 @end_toggle
 
 @add_toggle_java
 You can also download it from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/java/tutorial_code/ImgProc/HitMiss/HitMiss.java)
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/java/tutorial_code/ImgProc/HitMiss/HitMiss.java)
 @include samples/java/tutorial_code/ImgProc/HitMiss/HitMiss.java
 @end_toggle
 
 @add_toggle_python
 You can also download it from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/python/tutorial_code/imgProc/HitMiss/hit_miss.py)
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/python/tutorial_code/imgProc/HitMiss/hit_miss.py)
 @include samples/python/tutorial_code/imgProc/HitMiss/hit_miss.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/imgtrans/canny_detector/canny_detector.markdown b/doc/tutorials/imgproc/imgtrans/canny_detector/canny_detector.markdown
index 5ef2b7e6299..01bf6f862d6 100644
--- a/doc/tutorials/imgproc/imgtrans/canny_detector/canny_detector.markdown
+++ b/doc/tutorials/imgproc/imgtrans/canny_detector/canny_detector.markdown
@@ -71,19 +71,19 @@ Code
 
 @add_toggle_cpp
 -   The tutorial code's is shown lines below. You can also download it from
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/ImgTrans/CannyDetector_Demo.cpp)
+    [here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/ImgTrans/CannyDetector_Demo.cpp)
     @include samples/cpp/tutorial_code/ImgTrans/CannyDetector_Demo.cpp
 @end_toggle
 
 @add_toggle_java
 -   The tutorial code's is shown lines below. You can also download it from
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/ImgTrans/canny_detector/CannyDetectorDemo.java)
+    [here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/ImgTrans/canny_detector/CannyDetectorDemo.java)
     @include samples/java/tutorial_code/ImgTrans/canny_detector/CannyDetectorDemo.java
 @end_toggle
 
 @add_toggle_python
 -   The tutorial code's is shown lines below. You can also download it from
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/ImgTrans/canny_detector/CannyDetector_Demo.py)
+    [here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/ImgTrans/canny_detector/CannyDetector_Demo.py)
     @include samples/python/tutorial_code/ImgTrans/canny_detector/CannyDetector_Demo.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/imgtrans/copyMakeBorder/copyMakeBorder.markdown b/doc/tutorials/imgproc/imgtrans/copyMakeBorder/copyMakeBorder.markdown
index aba46bdab34..8a4bbc0702b 100644
--- a/doc/tutorials/imgproc/imgtrans/copyMakeBorder/copyMakeBorder.markdown
+++ b/doc/tutorials/imgproc/imgtrans/copyMakeBorder/copyMakeBorder.markdown
@@ -52,19 +52,19 @@ The tutorial code's is shown lines below.
 
 @add_toggle_cpp
 You can also download it from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/ImgTrans/copyMakeBorder_demo.cpp)
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/ImgTrans/copyMakeBorder_demo.cpp)
 @include samples/cpp/tutorial_code/ImgTrans/copyMakeBorder_demo.cpp
 @end_toggle
 
 @add_toggle_java
 You can also download it from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/java/tutorial_code/ImgTrans/MakeBorder/CopyMakeBorder.java)
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/java/tutorial_code/ImgTrans/MakeBorder/CopyMakeBorder.java)
 @include samples/java/tutorial_code/ImgTrans/MakeBorder/CopyMakeBorder.java
 @end_toggle
 
 @add_toggle_python
 You can also download it from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/python/tutorial_code/ImgTrans/MakeBorder/copy_make_border.py)
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/python/tutorial_code/ImgTrans/MakeBorder/copy_make_border.py)
 @include samples/python/tutorial_code/ImgTrans/MakeBorder/copy_make_border.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/imgtrans/distance_transformation/distance_transform.markdown b/doc/tutorials/imgproc/imgtrans/distance_transformation/distance_transform.markdown
index 18995b1e2d0..a5afffdbb19 100644
--- a/doc/tutorials/imgproc/imgtrans/distance_transformation/distance_transform.markdown
+++ b/doc/tutorials/imgproc/imgtrans/distance_transformation/distance_transform.markdown
@@ -21,19 +21,19 @@ Code
 
 @add_toggle_cpp
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/ImgTrans/imageSegmentation.cpp).
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/ImgTrans/imageSegmentation.cpp).
 @include samples/cpp/tutorial_code/ImgTrans/imageSegmentation.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/ImgTrans/distance_transformation/ImageSegmentationDemo.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/ImgTrans/distance_transformation/ImageSegmentationDemo.java)
 @include samples/java/tutorial_code/ImgTrans/distance_transformation/ImageSegmentationDemo.java
 @end_toggle
 
 @add_toggle_python
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/ImgTrans/distance_transformation/imageSegmentation.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/ImgTrans/distance_transformation/imageSegmentation.py)
 @include samples/python/tutorial_code/ImgTrans/distance_transformation/imageSegmentation.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/imgtrans/filter_2d/filter_2d.markdown b/doc/tutorials/imgproc/imgtrans/filter_2d/filter_2d.markdown
index 3dea827a4b0..454f745177e 100644
--- a/doc/tutorials/imgproc/imgtrans/filter_2d/filter_2d.markdown
+++ b/doc/tutorials/imgproc/imgtrans/filter_2d/filter_2d.markdown
@@ -68,19 +68,19 @@ The tutorial code's is shown in the lines below.
 
 @add_toggle_cpp
 You can also download it from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/ImgTrans/filter2D_demo.cpp)
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/ImgTrans/filter2D_demo.cpp)
 @include cpp/tutorial_code/ImgTrans/filter2D_demo.cpp
 @end_toggle
 
 @add_toggle_java
 You can also download it from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/java/tutorial_code/ImgTrans/Filter2D/Filter2D_Demo.java)
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/java/tutorial_code/ImgTrans/Filter2D/Filter2D_Demo.java)
 @include java/tutorial_code/ImgTrans/Filter2D/Filter2D_Demo.java
 @end_toggle
 
 @add_toggle_python
 You can also download it from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/python/tutorial_code/ImgTrans/Filter2D/filter2D.py)
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/python/tutorial_code/ImgTrans/Filter2D/filter2D.py)
 @include python/tutorial_code/ImgTrans/Filter2D/filter2D.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/imgtrans/hough_circle/hough_circle.markdown b/doc/tutorials/imgproc/imgtrans/hough_circle/hough_circle.markdown
index c4a9989e2b6..fe2f88be155 100644
--- a/doc/tutorials/imgproc/imgtrans/hough_circle/hough_circle.markdown
+++ b/doc/tutorials/imgproc/imgtrans/hough_circle/hough_circle.markdown
@@ -44,28 +44,28 @@ Code
 
 @add_toggle_cpp
 The sample code that we will explain can be downloaded from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/ImgTrans/houghcircles.cpp).
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/ImgTrans/houghcircles.cpp).
 A slightly fancier version (which shows trackbars for changing the threshold values) can be found
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/ImgTrans/HoughCircle_Demo.cpp).
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/ImgTrans/HoughCircle_Demo.cpp).
 @include samples/cpp/tutorial_code/ImgTrans/houghcircles.cpp
 @end_toggle
 
 @add_toggle_java
 The sample code that we will explain can be downloaded from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/java/tutorial_code/ImgTrans/HoughCircle/HoughCircles.java).
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/java/tutorial_code/ImgTrans/HoughCircle/HoughCircles.java).
 @include samples/java/tutorial_code/ImgTrans/HoughCircle/HoughCircles.java
 @end_toggle
 
 @add_toggle_python
 The sample code that we will explain can be downloaded from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/python/tutorial_code/ImgTrans/HoughCircle/hough_circle.py).
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/python/tutorial_code/ImgTrans/HoughCircle/hough_circle.py).
 @include samples/python/tutorial_code/ImgTrans/HoughCircle/hough_circle.py
 @end_toggle
 
 Explanation
 -----------
 
-The image we used can be found [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/data/smarties.png)
+The image we used can be found [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/data/smarties.png)
 
 ####  Load an image:
 
diff --git a/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown b/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown
index d9687e2a1d8..8b24d87a2df 100644
--- a/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown
+++ b/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown
@@ -100,22 +100,22 @@ Code
 
 @add_toggle_cpp
 The sample code that we will explain can be downloaded from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/ImgTrans/houghlines.cpp).
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/ImgTrans/houghlines.cpp).
 A slightly fancier version (which shows both Hough standard and probabilistic
 with trackbars for changing the threshold values) can be found
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/ImgTrans/HoughLines_Demo.cpp).
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/ImgTrans/HoughLines_Demo.cpp).
 @include samples/cpp/tutorial_code/ImgTrans/houghlines.cpp
 @end_toggle
 
 @add_toggle_java
 The sample code that we will explain can be downloaded from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/java/tutorial_code/ImgTrans/HoughLine/HoughLines.java).
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/java/tutorial_code/ImgTrans/HoughLine/HoughLines.java).
 @include samples/java/tutorial_code/ImgTrans/HoughLine/HoughLines.java
 @end_toggle
 
 @add_toggle_python
 The sample code that we will explain can be downloaded from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/python/tutorial_code/ImgTrans/HoughLine/hough_lines.py).
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/python/tutorial_code/ImgTrans/HoughLine/hough_lines.py).
 @include samples/python/tutorial_code/ImgTrans/HoughLine/hough_lines.py
 @end_toggle
 
@@ -271,7 +271,7 @@ Result
     section. It still implements the same stuff as above, only adding the Trackbar for the
     Threshold.
 
-Using an input image such as a [sudoku image](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/data/sudoku.png).
+Using an input image such as a [sudoku image](https://raw.githubusercontent.com/opencv/opencv/master/samples/data/sudoku.png).
 We get the following result by using the Standard Hough Line Transform:
 ![](images/hough_lines_result1.png)
 And by using the Probabilistic Hough Line Transform:
diff --git a/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown b/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown
index 1ca525b5c6d..63aed356b25 100644
--- a/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown
+++ b/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown
@@ -55,19 +55,19 @@ Code
 
 @add_toggle_cpp
 -#  The tutorial code's is shown lines below. You can also download it from
-    [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/ImgTrans/Laplace_Demo.cpp)
+    [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/ImgTrans/Laplace_Demo.cpp)
     @include samples/cpp/tutorial_code/ImgTrans/Laplace_Demo.cpp
 @end_toggle
 
 @add_toggle_java
 -#  The tutorial code's is shown lines below. You can also download it from
-    [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/java/tutorial_code/ImgTrans/LaPlace/LaplaceDemo.java)
+    [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/java/tutorial_code/ImgTrans/LaPlace/LaplaceDemo.java)
     @include samples/java/tutorial_code/ImgTrans/LaPlace/LaplaceDemo.java
 @end_toggle
 
 @add_toggle_python
 -#  The tutorial code's is shown lines below. You can also download it from
-    [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/python/tutorial_code/ImgTrans/LaPlace/laplace_demo.py)
+    [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/python/tutorial_code/ImgTrans/LaPlace/laplace_demo.py)
     @include samples/python/tutorial_code/ImgTrans/LaPlace/laplace_demo.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/imgtrans/remap/remap.markdown b/doc/tutorials/imgproc/imgtrans/remap/remap.markdown
index ac2b8791711..58c79c60393 100644
--- a/doc/tutorials/imgproc/imgtrans/remap/remap.markdown
+++ b/doc/tutorials/imgproc/imgtrans/remap/remap.markdown
@@ -56,19 +56,19 @@ Code
 
 @add_toggle_cpp
 -   The tutorial code's is shown lines below. You can also download it from
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/ImgTrans/Remap_Demo.cpp)
+    [here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/ImgTrans/Remap_Demo.cpp)
     @include samples/cpp/tutorial_code/ImgTrans/Remap_Demo.cpp
 @end_toggle
 
 @add_toggle_java
 -   The tutorial code's is shown lines below. You can also download it from
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/ImgTrans/remap/RemapDemo.java)
+    [here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/ImgTrans/remap/RemapDemo.java)
     @include samples/java/tutorial_code/ImgTrans/remap/RemapDemo.java
 @end_toggle
 
 @add_toggle_python
 -   The tutorial code's is shown lines below. You can also download it from
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/ImgTrans/remap/Remap_Demo.py)
+    [here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/ImgTrans/remap/Remap_Demo.py)
     @include samples/python/tutorial_code/ImgTrans/remap/Remap_Demo.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/imgtrans/sobel_derivatives/sobel_derivatives.markdown b/doc/tutorials/imgproc/imgtrans/sobel_derivatives/sobel_derivatives.markdown
index cf335ee8f23..f8725d2a12f 100644
--- a/doc/tutorials/imgproc/imgtrans/sobel_derivatives/sobel_derivatives.markdown
+++ b/doc/tutorials/imgproc/imgtrans/sobel_derivatives/sobel_derivatives.markdown
@@ -114,19 +114,19 @@ Code
 
 @add_toggle_cpp
 You can also download it from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/ImgTrans/Sobel_Demo.cpp)
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/ImgTrans/Sobel_Demo.cpp)
 @include samples/cpp/tutorial_code/ImgTrans/Sobel_Demo.cpp
 @end_toggle
 
 @add_toggle_java
 You can also download it from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/java/tutorial_code/ImgTrans/SobelDemo/SobelDemo.java)
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/java/tutorial_code/ImgTrans/SobelDemo/SobelDemo.java)
 @include samples/java/tutorial_code/ImgTrans/SobelDemo/SobelDemo.java
 @end_toggle
 
 @add_toggle_python
 You can also download it from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/python/tutorial_code/ImgTrans/SobelDemo/sobel_demo.py)
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/python/tutorial_code/ImgTrans/SobelDemo/sobel_demo.py)
 @include samples/python/tutorial_code/ImgTrans/SobelDemo/sobel_demo.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/imgtrans/warp_affine/warp_affine.markdown b/doc/tutorials/imgproc/imgtrans/warp_affine/warp_affine.markdown
index dab4e953fb8..b5023ad03e3 100644
--- a/doc/tutorials/imgproc/imgtrans/warp_affine/warp_affine.markdown
+++ b/doc/tutorials/imgproc/imgtrans/warp_affine/warp_affine.markdown
@@ -93,19 +93,19 @@ Code
 
 @add_toggle_cpp
 -   The tutorial's code is shown below. You can also download it
-    [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/ImgProc/Smoothing/Smoothing.cpp)
+    [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/ImgProc/Smoothing/Smoothing.cpp)
     @include samples/cpp/tutorial_code/ImgTrans/Geometric_Transforms_Demo.cpp
 @end_toggle
 
 @add_toggle_java
 -   The tutorial's code is shown below. You can also download it
-    [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/ImgProc/Smoothing/Smoothing.cpp)
+    [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/ImgProc/Smoothing/Smoothing.cpp)
     @include samples/java/tutorial_code/ImgTrans/warp_affine/GeometricTransformsDemo.java
 @end_toggle
 
 @add_toggle_python
 -   The tutorial's code is shown below. You can also download it
-    [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/python/tutorial_code/ImgTrans/warp_affine/Geometric_Transforms_Demo.py)
+    [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/python/tutorial_code/ImgTrans/warp_affine/Geometric_Transforms_Demo.py)
     @include samples/python/tutorial_code/ImgTrans/warp_affine/Geometric_Transforms_Demo.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/morph_lines_detection/morph_lines_detection.md b/doc/tutorials/imgproc/morph_lines_detection/morph_lines_detection.md
index cf0e79755a0..4b0d3fae60c 100644
--- a/doc/tutorials/imgproc/morph_lines_detection/morph_lines_detection.md
+++ b/doc/tutorials/imgproc/morph_lines_detection/morph_lines_detection.md
@@ -54,24 +54,24 @@ Code
 This tutorial code's is shown lines below.
 
 @add_toggle_cpp
-You can also download it from [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/ImgProc/morph_lines_detection/Morphology_3.cpp).
+You can also download it from [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/ImgProc/morph_lines_detection/Morphology_3.cpp).
 @include samples/cpp/tutorial_code/ImgProc/morph_lines_detection/Morphology_3.cpp
 @end_toggle
 
 @add_toggle_java
-You can also download it from [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/java/tutorial_code/ImgProc/morph_lines_detection/Morphology_3.java).
+You can also download it from [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/java/tutorial_code/ImgProc/morph_lines_detection/Morphology_3.java).
 @include samples/java/tutorial_code/ImgProc/morph_lines_detection/Morphology_3.java
 @end_toggle
 
 @add_toggle_python
-You can also download it from [here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/python/tutorial_code/imgProc/morph_lines_detection/morph_lines_detection.py).
+You can also download it from [here](https://raw.githubusercontent.com/opencv/opencv/master/samples/python/tutorial_code/imgProc/morph_lines_detection/morph_lines_detection.py).
 @include samples/python/tutorial_code/imgProc/morph_lines_detection/morph_lines_detection.py
 @end_toggle
 
 Explanation / Result
 --------------------
 
-Get image from [here](https://raw.githubusercontent.com/opencv/opencv/3.4/doc/tutorials/imgproc/morph_lines_detection/images/src.png) .
+Get image from [here](https://raw.githubusercontent.com/opencv/opencv/master/doc/tutorials/imgproc/morph_lines_detection/images/src.png) .
 
 #### Load Image
 
diff --git a/doc/tutorials/imgproc/opening_closing_hats/opening_closing_hats.markdown b/doc/tutorials/imgproc/opening_closing_hats/opening_closing_hats.markdown
index ab1ba87e1fd..e918c65ce77 100644
--- a/doc/tutorials/imgproc/opening_closing_hats/opening_closing_hats.markdown
+++ b/doc/tutorials/imgproc/opening_closing_hats/opening_closing_hats.markdown
@@ -84,19 +84,19 @@ Code
 
 @add_toggle_cpp
 This tutorial's code is shown below. You can also download it
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/ImgProc/Morphology_2.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/ImgProc/Morphology_2.cpp)
 @include cpp/tutorial_code/ImgProc/Morphology_2.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial's code is shown below. You can also download it
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/ImgProc/opening_closing_hats/MorphologyDemo2.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/ImgProc/opening_closing_hats/MorphologyDemo2.java)
 @include java/tutorial_code/ImgProc/opening_closing_hats/MorphologyDemo2.java
 @end_toggle
 
 @add_toggle_python
 This tutorial's code is shown below. You can also download it
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/imgProc/opening_closing_hats/morphology_2.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/imgProc/opening_closing_hats/morphology_2.py)
 @include python/tutorial_code/imgProc/opening_closing_hats/morphology_2.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/pyramids/pyramids.markdown b/doc/tutorials/imgproc/pyramids/pyramids.markdown
index 9b507e604ea..b832b22fb88 100644
--- a/doc/tutorials/imgproc/pyramids/pyramids.markdown
+++ b/doc/tutorials/imgproc/pyramids/pyramids.markdown
@@ -72,19 +72,19 @@ This tutorial code's is shown lines below.
 
 @add_toggle_cpp
 You can also download it from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/cpp/tutorial_code/ImgProc/Pyramids/Pyramids.cpp)
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/cpp/tutorial_code/ImgProc/Pyramids/Pyramids.cpp)
 @include samples/cpp/tutorial_code/ImgProc/Pyramids/Pyramids.cpp
 @end_toggle
 
 @add_toggle_java
 You can also download it from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/java/tutorial_code/ImgProc/Pyramids/Pyramids.java)
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/java/tutorial_code/ImgProc/Pyramids/Pyramids.java)
 @include samples/java/tutorial_code/ImgProc/Pyramids/Pyramids.java
 @end_toggle
 
 @add_toggle_python
 You can also download it from
-[here](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/python/tutorial_code/imgProc/Pyramids/pyramids.py)
+[here](https://raw.githubusercontent.com/opencv/opencv/master/samples/python/tutorial_code/imgProc/Pyramids/pyramids.py)
 @include samples/python/tutorial_code/imgProc/Pyramids/pyramids.py
 @end_toggle
 
@@ -184,7 +184,7 @@ Otherwise, an error will be shown.
 Results
 -------
 
--   The program calls by default an image [chicky_512.png](https://raw.githubusercontent.com/opencv/opencv/3.4/samples/data/chicky_512.png)
+-   The program calls by default an image [chicky_512.png](https://raw.githubusercontent.com/opencv/opencv/master/samples/data/chicky_512.png)
     that comes in the `samples/data` folder. Notice that this image is \f$512 \times 512\f$,
     hence a downsample won't generate any error (\f$512 = 2^{9}\f$). The original image is shown below:
 
diff --git a/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown b/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown
index 48db64464b1..d6194dfd3f3 100644
--- a/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown
+++ b/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown
@@ -20,19 +20,19 @@ Code
 
 @add_toggle_cpp
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/ShapeDescriptors/generalContours_demo1.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/ShapeDescriptors/generalContours_demo1.cpp)
 @include samples/cpp/tutorial_code/ShapeDescriptors/generalContours_demo1.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/ShapeDescriptors/bounding_rects_circles/GeneralContoursDemo1.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/ShapeDescriptors/bounding_rects_circles/GeneralContoursDemo1.java)
 @include samples/java/tutorial_code/ShapeDescriptors/bounding_rects_circles/GeneralContoursDemo1.java
 @end_toggle
 
 @add_toggle_python
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/ShapeDescriptors/bounding_rects_circles/generalContours_demo1.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/ShapeDescriptors/bounding_rects_circles/generalContours_demo1.py)
 @include samples/python/tutorial_code/ShapeDescriptors/bounding_rects_circles/generalContours_demo1.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/shapedescriptors/bounding_rotated_ellipses/bounding_rotated_ellipses.markdown b/doc/tutorials/imgproc/shapedescriptors/bounding_rotated_ellipses/bounding_rotated_ellipses.markdown
index bf53f14a9b4..a4c29b2fdef 100644
--- a/doc/tutorials/imgproc/shapedescriptors/bounding_rotated_ellipses/bounding_rotated_ellipses.markdown
+++ b/doc/tutorials/imgproc/shapedescriptors/bounding_rotated_ellipses/bounding_rotated_ellipses.markdown
@@ -20,19 +20,19 @@ Code
 
 @add_toggle_cpp
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/ShapeDescriptors/generalContours_demo2.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/ShapeDescriptors/generalContours_demo2.cpp)
 @include samples/cpp/tutorial_code/ShapeDescriptors/generalContours_demo2.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/ShapeDescriptors/bounding_rotated_ellipses/GeneralContoursDemo2.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/ShapeDescriptors/bounding_rotated_ellipses/GeneralContoursDemo2.java)
 @include samples/java/tutorial_code/ShapeDescriptors/bounding_rotated_ellipses/GeneralContoursDemo2.java
 @end_toggle
 
 @add_toggle_python
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/ShapeDescriptors/bounding_rotated_ellipses/generalContours_demo2.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/ShapeDescriptors/bounding_rotated_ellipses/generalContours_demo2.py)
 @include samples/python/tutorial_code/ShapeDescriptors/bounding_rotated_ellipses/generalContours_demo2.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/shapedescriptors/find_contours/find_contours.markdown b/doc/tutorials/imgproc/shapedescriptors/find_contours/find_contours.markdown
index 340143a7943..b8aa6d898f2 100644
--- a/doc/tutorials/imgproc/shapedescriptors/find_contours/find_contours.markdown
+++ b/doc/tutorials/imgproc/shapedescriptors/find_contours/find_contours.markdown
@@ -20,19 +20,19 @@ Code
 
 @add_toggle_cpp
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/ShapeDescriptors/findContours_demo.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/ShapeDescriptors/findContours_demo.cpp)
 @include samples/cpp/tutorial_code/ShapeDescriptors/findContours_demo.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/ShapeDescriptors/find_contours/FindContoursDemo.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/ShapeDescriptors/find_contours/FindContoursDemo.java)
 @include samples/java/tutorial_code/ShapeDescriptors/find_contours/FindContoursDemo.java
 @end_toggle
 
 @add_toggle_python
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/ShapeDescriptors/find_contours/findContours_demo.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/ShapeDescriptors/find_contours/findContours_demo.py)
 @include samples/python/tutorial_code/ShapeDescriptors/find_contours/findContours_demo.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/shapedescriptors/hull/hull.markdown b/doc/tutorials/imgproc/shapedescriptors/hull/hull.markdown
index e1eda3565bb..e40934e6e2d 100644
--- a/doc/tutorials/imgproc/shapedescriptors/hull/hull.markdown
+++ b/doc/tutorials/imgproc/shapedescriptors/hull/hull.markdown
@@ -19,19 +19,19 @@ Code
 
 @add_toggle_cpp
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/ShapeDescriptors/hull_demo.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/ShapeDescriptors/hull_demo.cpp)
 @include samples/cpp/tutorial_code/ShapeDescriptors/hull_demo.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/ShapeDescriptors/hull/HullDemo.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/ShapeDescriptors/hull/HullDemo.java)
 @include samples/java/tutorial_code/ShapeDescriptors/hull/HullDemo.java
 @end_toggle
 
 @add_toggle_python
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/ShapeDescriptors/hull/hull_demo.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/ShapeDescriptors/hull/hull_demo.py)
 @include samples/python/tutorial_code/ShapeDescriptors/hull/hull_demo.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/shapedescriptors/moments/moments.markdown b/doc/tutorials/imgproc/shapedescriptors/moments/moments.markdown
index 2e3daba6856..683568ab0cc 100644
--- a/doc/tutorials/imgproc/shapedescriptors/moments/moments.markdown
+++ b/doc/tutorials/imgproc/shapedescriptors/moments/moments.markdown
@@ -21,19 +21,19 @@ Code
 
 @add_toggle_cpp
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/ShapeDescriptors/moments_demo.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/ShapeDescriptors/moments_demo.cpp)
 @include samples/cpp/tutorial_code/ShapeDescriptors/moments_demo.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/ShapeDescriptors/moments/MomentsDemo.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/ShapeDescriptors/moments/MomentsDemo.java)
 @include samples/java/tutorial_code/ShapeDescriptors/moments/MomentsDemo.java
 @end_toggle
 
 @add_toggle_python
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/ShapeDescriptors/moments/moments_demo.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/ShapeDescriptors/moments/moments_demo.py)
 @include samples/python/tutorial_code/ShapeDescriptors/moments/moments_demo.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/shapedescriptors/point_polygon_test/point_polygon_test.markdown b/doc/tutorials/imgproc/shapedescriptors/point_polygon_test/point_polygon_test.markdown
index 0ac2ab768a1..2e02fb8815a 100644
--- a/doc/tutorials/imgproc/shapedescriptors/point_polygon_test/point_polygon_test.markdown
+++ b/doc/tutorials/imgproc/shapedescriptors/point_polygon_test/point_polygon_test.markdown
@@ -19,19 +19,19 @@ Code
 
 @add_toggle_cpp
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/ShapeDescriptors/pointPolygonTest_demo.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/ShapeDescriptors/pointPolygonTest_demo.cpp)
 @include samples/cpp/tutorial_code/ShapeDescriptors/pointPolygonTest_demo.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/ShapeDescriptors/point_polygon_test/PointPolygonTestDemo.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/ShapeDescriptors/point_polygon_test/PointPolygonTestDemo.java)
 @include samples/java/tutorial_code/ShapeDescriptors/point_polygon_test/PointPolygonTestDemo.java
 @end_toggle
 
 @add_toggle_python
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/ShapeDescriptors/point_polygon_test/pointPolygonTest_demo.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/ShapeDescriptors/point_polygon_test/pointPolygonTest_demo.py)
 @include samples/python/tutorial_code/ShapeDescriptors/point_polygon_test/pointPolygonTest_demo.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/threshold/threshold.markdown b/doc/tutorials/imgproc/threshold/threshold.markdown
index b5a25e3aee8..a452d14042e 100644
--- a/doc/tutorials/imgproc/threshold/threshold.markdown
+++ b/doc/tutorials/imgproc/threshold/threshold.markdown
@@ -101,19 +101,19 @@ Code
 
 @add_toggle_cpp
 The tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/ImgProc/Threshold.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/ImgProc/Threshold.cpp)
 @include samples/cpp/tutorial_code/ImgProc/Threshold.cpp
 @end_toggle
 
 @add_toggle_java
 The tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/ImgProc/threshold/Threshold.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/ImgProc/threshold/Threshold.java)
 @include samples/java/tutorial_code/ImgProc/threshold/Threshold.java
 @end_toggle
 
 @add_toggle_python
 The tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/imgProc/threshold/threshold.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/imgProc/threshold/threshold.py)
 @include samples/python/tutorial_code/imgProc/threshold/threshold.py
 @end_toggle
 
diff --git a/doc/tutorials/imgproc/threshold_inRange/threshold_inRange.markdown b/doc/tutorials/imgproc/threshold_inRange/threshold_inRange.markdown
index 3b63b07231f..0995b9758c2 100644
--- a/doc/tutorials/imgproc/threshold_inRange/threshold_inRange.markdown
+++ b/doc/tutorials/imgproc/threshold_inRange/threshold_inRange.markdown
@@ -43,19 +43,19 @@ Code
 
 @add_toggle_cpp
 The tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/ImgProc/Threshold_inRange.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/ImgProc/Threshold_inRange.cpp)
 @include samples/cpp/tutorial_code/ImgProc/Threshold_inRange.cpp
 @end_toggle
 
 @add_toggle_java
 The tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/ImgProc/threshold_inRange/ThresholdInRange.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/ImgProc/threshold_inRange/ThresholdInRange.java)
 @include samples/java/tutorial_code/ImgProc/threshold_inRange/ThresholdInRange.java
 @end_toggle
 
 @add_toggle_python
 The tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/imgProc/threshold_inRange/threshold_inRange.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/imgProc/threshold_inRange/threshold_inRange.py)
 @include samples/python/tutorial_code/imgProc/threshold_inRange/threshold_inRange.py
 @end_toggle
 
diff --git a/doc/tutorials/introduction/android_binary_package/O4A_SDK.markdown b/doc/tutorials/introduction/android_binary_package/O4A_SDK.markdown
index cb61f6dd94e..57600c03c6f 100644
--- a/doc/tutorials/introduction/android_binary_package/O4A_SDK.markdown
+++ b/doc/tutorials/introduction/android_binary_package/O4A_SDK.markdown
@@ -19,18 +19,6 @@ If you encounter any error after thoroughly following these steps, feel free to
 [OpenCV4Android](https://groups.google.com/group/android-opencv/) discussion group or OpenCV [Q&A
 forum](http://answers.opencv.org). We'll do our best to help you out.
 
-Tegra Android Development Pack users
-------------------------------------
-
-You may have used [Tegra Android Development
-Pack](http://developer.nvidia.com/tegra-android-development-pack) (**TADP**) released by **NVIDIA**
-for Android development environment setup.
-
-Beside Android development tools the TADP 2.0 includes OpenCV4Android SDK, so it can be already
-installed in your system and you can skip to @ref tutorial_O4A_SDK_samples "samples" section of this tutorial.
-
-More details regarding TADP can be found in the @ref tutorial_android_dev_intro guide.
-
 General info
 ------------
 
diff --git a/doc/tutorials/introduction/android_binary_package/android_dev_intro.markdown b/doc/tutorials/introduction/android_binary_package/android_dev_intro.markdown
index 5d43b229d69..a6140819260 100644
--- a/doc/tutorials/introduction/android_binary_package/android_dev_intro.markdown
+++ b/doc/tutorials/introduction/android_binary_package/android_dev_intro.markdown
@@ -31,31 +31,6 @@ key topis:
 -#  OpenCV development will certainly require some knowledge of the [Android
     Camera](http://developer.android.com/guide/topics/media/camera.html) specifics.
 
-Quick environment setup for Android development
------------------------------------------------
-
-If you are making a clean environment install, then you can try [Tegra Android Development
-Pack](https://developer.nvidia.com/tegra-android-development-pack) (**TADP**) released by
-**NVIDIA**.
-
-@note Starting the *version 2.0* the TADP package includes *OpenCV for Tegra* SDK that is a regular
-*OpenCV4Android SDK* extended with Tegra-specific stuff. When unpacked, TADP will cover all of the
-environment setup automatically and you can skip the rest of the guide.
-
-If you are a beginner in Android development then we also recommend you to start with TADP.
-
-@note *NVIDIA*'s Tegra Android Development Pack includes some special features for *NVIDIA*s [Tegra
-platform](http://www.nvidia.com/object/tegra-3-processor.html)
-but its use is not limited to *Tegra* devices only. \* You need at least *1.6 Gb* free
-disk space for the install.
-
--   TADP will download Android SDK platforms and Android NDK from Google's server, so Internet
-    connection is required for the installation.
--   TADP may ask you to flash your development kit at the end of installation process. Just skip
-    this step if you have no [Tegra Development Kit](http://developer.nvidia.com/mobile/tegra-hardware-sales-inquiries).
--   (UNIX) TADP will ask you for *root* in the middle of installation, so you need to be a member of
-    *sudo* group.
-
 Manual environment setup for Android development
 ------------------------------------------------
 
diff --git a/doc/tutorials/introduction/android_binary_package/android_ocl_intro.markdown b/doc/tutorials/introduction/android_binary_package/android_ocl_intro.markdown
index 4bd1bc64456..b41f91b241b 100644
--- a/doc/tutorials/introduction/android_binary_package/android_ocl_intro.markdown
+++ b/doc/tutorials/introduction/android_binary_package/android_ocl_intro.markdown
@@ -17,7 +17,7 @@ If you need help with anything of the above, you may refer to our @ref tutorial_
 This tutorial also assumes you have an Android operated device with OpenCL enabled.
 
 The related source code is located within OpenCV samples at
-[opencv/samples/android/tutorial-4-opencl](https://github.com/opencv/opencv/tree/3.4/samples/android/tutorial-4-opencl/) directory.
+[opencv/samples/android/tutorial-4-opencl](https://github.com/opencv/opencv/tree/master/samples/android/tutorial-4-opencl/) directory.
 
 Preface
 -------
@@ -144,7 +144,7 @@ Here is a simple Java wrapper for our JNI stuff:
 public class NativeGLRenderer {
     static
     {
-        System.loadLibrary("opencv_java3"); // comment this when using OpenCV Manager
+        System.loadLibrary("opencv_java4"); // comment this when using OpenCV Manager
         System.loadLibrary("JNIrender");
     }
 
@@ -244,7 +244,7 @@ As you can see, inheritors for `Camera` and `Camera2` APIs should implement the
 @endcode
 
 Let's leave the details of their implementation beyond of this tutorial, please refer the
-[source code](https://github.com/opencv/opencv/tree/3.4/samples/android/tutorial-4-opencl/) to see them.
+[source code](https://github.com/opencv/opencv/tree/master/samples/android/tutorial-4-opencl/) to see them.
 
 Preview Frames modification
 ---------------------------
@@ -383,7 +383,7 @@ Unfortunately `UMat` keeps OpenCL _buffer_ internally, that can't be wrapped ove
   path/to/cmake.exe -GNinja -DCMAKE_MAKE_PROGRAM="path/to/ninja.exe" -DCMAKE_TOOLCHAIN_FILE=path/to/opencv/platforms/android/android.toolchain.cmake -DANDROID_ABI="armeabi-v7a with NEON" -DCMAKE_BUILD_WITH_INSTALL_RPATH=ON path/to/opencv
   path/to/ninja.exe install/strip
   @endcode
-  To use your own modified `libopencv_java3.so` you have to keep inside your APK, not to use OpenCV Manager and load it manually via `System.loadLibrary("opencv_java3")`.
+  To use your own modified `libopencv_java4.so` you have to keep inside your APK, not to use OpenCV Manager and load it manually via `System.loadLibrary("opencv_java4")`.
 
 Performance notes
 -----------------
diff --git a/doc/tutorials/introduction/display_image/display_image.markdown b/doc/tutorials/introduction/display_image/display_image.markdown
index 60b6c4c3b56..ba550580b67 100644
--- a/doc/tutorials/introduction/display_image/display_image.markdown
+++ b/doc/tutorials/introduction/display_image/display_image.markdown
@@ -14,7 +14,7 @@ Source Code
 -----------
 
 Download the source code from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/introduction/display_image/display_image.cpp).
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/introduction/display_image/display_image.cpp).
 
 @include cpp/tutorial_code/introduction/display_image/display_image.cpp
 
diff --git a/doc/tutorials/introduction/windows_visual_studio_opencv/windows_visual_studio_opencv.markdown b/doc/tutorials/introduction/windows_visual_studio_opencv/windows_visual_studio_opencv.markdown
index caf7e57f98f..e8ef112b028 100644
--- a/doc/tutorials/introduction/windows_visual_studio_opencv/windows_visual_studio_opencv.markdown
+++ b/doc/tutorials/introduction/windows_visual_studio_opencv/windows_visual_studio_opencv.markdown
@@ -194,7 +194,7 @@ Test it!
 --------
 
 Now to try this out download our little test [source code
-](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/introduction/windows_visual_studio_opencv/introduction_windows_vs.cpp)
+](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/introduction/windows_visual_studio_opencv/introduction_windows_vs.cpp)
 or get it from the sample code folder of the OpenCV sources. Add this to your project and build it.
 Here's its content:
 
@@ -210,7 +210,7 @@ the *IDE* the console window will not close once finished. It will wait for a ke
 This is important to remember when you code inside the code open and save commands. Your resources
 will be saved ( and queried for at opening!!!) relatively to your working directory. This is unless
 you give a full, explicit path as a parameter for the I/O functions. In the code above we open [this
-OpenCV logo](https://github.com/opencv/opencv/tree/3.4/samples/data/opencv-logo.png). Before starting up the application,
+OpenCV logo](https://github.com/opencv/opencv/tree/master/samples/data/opencv-logo.png). Before starting up the application,
 make sure you place
 the image file in your current working directory. Modify the image file name inside the code to try
 it out on other images too. Run it and voil :
diff --git a/doc/tutorials/ml/introduction_to_pca/introduction_to_pca.markdown b/doc/tutorials/ml/introduction_to_pca/introduction_to_pca.markdown
index fe712a5f7f7..63ab1eeb1a5 100644
--- a/doc/tutorials/ml/introduction_to_pca/introduction_to_pca.markdown
+++ b/doc/tutorials/ml/introduction_to_pca/introduction_to_pca.markdown
@@ -93,7 +93,7 @@ Source Code
 
 @add_toggle_cpp
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/ml/introduction_to_pca/introduction_to_pca.cpp)
+    [here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/ml/introduction_to_pca/introduction_to_pca.cpp)
 
 -   **Code at glance:**
     @include samples/cpp/tutorial_code/ml/introduction_to_pca/introduction_to_pca.cpp
@@ -101,7 +101,7 @@ Source Code
 
 @add_toggle_java
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/ml/introduction_to_pca/IntroductionToPCADemo.java)
+    [here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/ml/introduction_to_pca/IntroductionToPCADemo.java)
 
 -   **Code at glance:**
     @include samples/java/tutorial_code/ml/introduction_to_pca/IntroductionToPCADemo.java
@@ -109,13 +109,13 @@ Source Code
 
 @add_toggle_python
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/ml/introduction_to_pca/introduction_to_pca.py)
+    [here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/ml/introduction_to_pca/introduction_to_pca.py)
 
 -   **Code at glance:**
     @include samples/python/tutorial_code/ml/introduction_to_pca/introduction_to_pca.py
 @end_toggle
 
-@note Another example using PCA for dimensionality reduction while maintaining an amount of variance can be found at [opencv_source_code/samples/cpp/pca.cpp](https://github.com/opencv/opencv/tree/3.4/samples/cpp/pca.cpp)
+@note Another example using PCA for dimensionality reduction while maintaining an amount of variance can be found at [opencv_source_code/samples/cpp/pca.cpp](https://github.com/opencv/opencv/tree/master/samples/cpp/pca.cpp)
 
 Explanation
 -----------
diff --git a/doc/tutorials/ml/introduction_to_svm/introduction_to_svm.markdown b/doc/tutorials/ml/introduction_to_svm/introduction_to_svm.markdown
index 5039285df42..f1a2261e37c 100644
--- a/doc/tutorials/ml/introduction_to_svm/introduction_to_svm.markdown
+++ b/doc/tutorials/ml/introduction_to_svm/introduction_to_svm.markdown
@@ -98,7 +98,7 @@ Source Code
 
 @add_toggle_cpp
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/ml/introduction_to_svm/introduction_to_svm.cpp)
+    [here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/ml/introduction_to_svm/introduction_to_svm.cpp)
 
 -   **Code at glance:**
     @include samples/cpp/tutorial_code/ml/introduction_to_svm/introduction_to_svm.cpp
@@ -106,7 +106,7 @@ Source Code
 
 @add_toggle_java
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/ml/introduction_to_svm/IntroductionToSVMDemo.java)
+    [here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/ml/introduction_to_svm/IntroductionToSVMDemo.java)
 
 -   **Code at glance:**
     @include samples/java/tutorial_code/ml/introduction_to_svm/IntroductionToSVMDemo.java
@@ -114,7 +114,7 @@ Source Code
 
 @add_toggle_python
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/ml/introduction_to_svm/introduction_to_svm.py)
+    [here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/ml/introduction_to_svm/introduction_to_svm.py)
 
 -   **Code at glance:**
     @include samples/python/tutorial_code/ml/introduction_to_svm/introduction_to_svm.py
diff --git a/doc/tutorials/ml/non_linear_svms/non_linear_svms.markdown b/doc/tutorials/ml/non_linear_svms/non_linear_svms.markdown
index 9212911b1a1..e03c75b62f7 100644
--- a/doc/tutorials/ml/non_linear_svms/non_linear_svms.markdown
+++ b/doc/tutorials/ml/non_linear_svms/non_linear_svms.markdown
@@ -87,14 +87,14 @@ Source Code
 -----------
 
 You may also find the source code in `samples/cpp/tutorial_code/ml/non_linear_svms` folder of the OpenCV source library or
-[download it from here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/ml/non_linear_svms/non_linear_svms.cpp).
+[download it from here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/ml/non_linear_svms/non_linear_svms.cpp).
 
 @note The following code has been implemented with OpenCV 3.0 classes and functions. An equivalent version of the code
 using OpenCV 2.4 can be found in [this page.](http://docs.opencv.org/2.4/doc/tutorials/ml/non_linear_svms/non_linear_svms.html#nonlinearsvms)
 
 @add_toggle_cpp
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/ml/non_linear_svms/non_linear_svms.cpp)
+    [here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/ml/non_linear_svms/non_linear_svms.cpp)
 
 -   **Code at glance:**
     @include samples/cpp/tutorial_code/ml/non_linear_svms/non_linear_svms.cpp
@@ -102,7 +102,7 @@ using OpenCV 2.4 can be found in [this page.](http://docs.opencv.org/2.4/doc/tut
 
 @add_toggle_java
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/ml/non_linear_svms/NonLinearSVMsDemo.java)
+    [here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/ml/non_linear_svms/NonLinearSVMsDemo.java)
 
 -   **Code at glance:**
     @include samples/java/tutorial_code/ml/non_linear_svms/NonLinearSVMsDemo.java
@@ -110,7 +110,7 @@ using OpenCV 2.4 can be found in [this page.](http://docs.opencv.org/2.4/doc/tut
 
 @add_toggle_python
 -   **Downloadable code**: Click
-    [here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/ml/non_linear_svms/non_linear_svms.py)
+    [here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/ml/non_linear_svms/non_linear_svms.py)
 
 -   **Code at glance:**
     @include samples/python/tutorial_code/ml/non_linear_svms/non_linear_svms.py
diff --git a/doc/tutorials/objdetect/cascade_classifier/cascade_classifier.markdown b/doc/tutorials/objdetect/cascade_classifier/cascade_classifier.markdown
index 3c7bf6b90c7..c2f7851a7b4 100644
--- a/doc/tutorials/objdetect/cascade_classifier/cascade_classifier.markdown
+++ b/doc/tutorials/objdetect/cascade_classifier/cascade_classifier.markdown
@@ -19,19 +19,19 @@ Code
 
 @add_toggle_cpp
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/objectDetection/objectDetection.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/objectDetection/objectDetection.cpp)
 @include samples/cpp/tutorial_code/objectDetection/objectDetection.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/objectDetection/cascade_classifier/ObjectDetectionDemo.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/objectDetection/cascade_classifier/ObjectDetectionDemo.java)
 @include samples/java/tutorial_code/objectDetection/cascade_classifier/ObjectDetectionDemo.java
 @end_toggle
 
 @add_toggle_python
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/objectDetection/cascade_classifier/objectDetection.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/objectDetection/cascade_classifier/objectDetection.py)
 @include samples/python/tutorial_code/objectDetection/cascade_classifier/objectDetection.py
 @end_toggle
 
diff --git a/doc/tutorials/objdetect/traincascade.markdown b/doc/tutorials/objdetect/traincascade.markdown
index 167e34fe60b..0dd4e41f466 100644
--- a/doc/tutorials/objdetect/traincascade.markdown
+++ b/doc/tutorials/objdetect/traincascade.markdown
@@ -6,7 +6,7 @@ Introduction
 
 Working with a boosted cascade of weak classifiers includes two major stages: the training and the detection stage. The detection stage using either HAAR or LBP based models, is described in the @ref tutorial_cascade_classifier "object detection tutorial". This documentation gives an overview of the functionality needed to train your own boosted cascade of weak classifiers. The current guide will walk through all the different stages: collecting training data, preparation of the training data and executing the actual model training.
 
-To support this tutorial, several official OpenCV applications will be used: [opencv_createsamples](https://github.com/opencv/opencv/tree/3.4/apps/createsamples), [opencv_annotation](https://github.com/opencv/opencv/tree/3.4/apps/annotation), [opencv_traincascade](https://github.com/opencv/opencv/tree/3.4/apps/traincascade) and [opencv_visualisation](https://github.com/opencv/opencv/tree/3.4/apps/visualisation).
+To support this tutorial, several official OpenCV applications will be used: [opencv_createsamples](https://github.com/opencv/opencv/tree/master/apps/createsamples), [opencv_annotation](https://github.com/opencv/opencv/tree/master/apps/annotation), [opencv_traincascade](https://github.com/opencv/opencv/tree/master/apps/traincascade) and [opencv_visualisation](https://github.com/opencv/opencv/tree/master/apps/visualisation).
 
 ### Important notes
 
diff --git a/doc/tutorials/photo/hdr_imaging/hdr_imaging.markdown b/doc/tutorials/photo/hdr_imaging/hdr_imaging.markdown
index b26c8f48775..b8e8b3094b1 100644
--- a/doc/tutorials/photo/hdr_imaging/hdr_imaging.markdown
+++ b/doc/tutorials/photo/hdr_imaging/hdr_imaging.markdown
@@ -33,19 +33,19 @@ Source Code
 
 @add_toggle_cpp
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/photo/hdr_imaging/hdr_imaging.cpp)
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/photo/hdr_imaging/hdr_imaging.cpp)
 @include samples/cpp/tutorial_code/photo/hdr_imaging/hdr_imaging.cpp
 @end_toggle
 
 @add_toggle_java
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/java/tutorial_code/photo/hdr_imaging/HDRImagingDemo.java)
+[here](https://github.com/opencv/opencv/tree/master/samples/java/tutorial_code/photo/hdr_imaging/HDRImagingDemo.java)
 @include samples/java/tutorial_code/photo/hdr_imaging/HDRImagingDemo.java
 @end_toggle
 
 @add_toggle_python
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/python/tutorial_code/photo/hdr_imaging/hdr_imaging.py)
+[here](https://github.com/opencv/opencv/tree/master/samples/python/tutorial_code/photo/hdr_imaging/hdr_imaging.py)
 @include samples/python/tutorial_code/photo/hdr_imaging/hdr_imaging.py
 @end_toggle
 
@@ -53,7 +53,7 @@ Sample images
 -------------
 
 Data directory that contains images, exposure times and `list.txt` file can be downloaded from
-[here](https://github.com/opencv/opencv_extra/tree/3.4/testdata/cv/hdr/exposures).
+[here](https://github.com/opencv/opencv_extra/tree/master/testdata/cv/hdr/exposures).
 
 Explanation
 -----------
diff --git a/doc/tutorials/stitching/stitcher/stitcher.markdown b/doc/tutorials/stitching/stitcher/stitcher.markdown
index f0e7731e519..1d4f27bdb95 100644
--- a/doc/tutorials/stitching/stitcher/stitcher.markdown
+++ b/doc/tutorials/stitching/stitcher/stitcher.markdown
@@ -15,7 +15,7 @@ Code
 ----
 
 This tutorial code's is shown lines below. You can also download it from
-[here](https://github.com/opencv/opencv/tree/3.4/samples/cpp/samples/cpp/stitching.cpp).
+[here](https://github.com/opencv/opencv/tree/master/samples/cpp/samples/cpp/stitching.cpp).
 
 @include samples/cpp/stitching.cpp
 
@@ -101,5 +101,5 @@ See also
 
 If you want to study internals of the stitching pipeline or you want to experiment with detailed
 configuration see
-[stitching_detailed.cpp](https://github.com/opencv/opencv/tree/3.4/samples/cpp/stitching_detailed.cpp)
+[stitching_detailed.cpp](https://github.com/opencv/opencv/tree/master/samples/cpp/stitching_detailed.cpp)
 in `opencv/samples/cpp` folder.
diff --git a/doc/tutorials/video/background_subtraction/background_subtraction.markdown b/doc/tutorials/video/background_subtraction/background_subtraction.markdown
index f914379f3ed..ed8bd843350 100644
--- a/doc/tutorials/video/background_subtraction/background_subtraction.markdown
+++ b/doc/tutorials/video/background_subtraction/background_subtraction.markdown
@@ -43,7 +43,7 @@ file or a sequence of images.
 We will use @ref cv::BackgroundSubtractorMOG2 in this sample, to generate the foreground mask.
 
 The results as well as the input data are shown on the screen.
-The source file can be downloaded [here ](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/video/bg_sub.cpp).
+The source file can be downloaded [here ](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/video/bg_sub.cpp).
 
 @include samples/cpp/tutorial_code/video/bg_sub.cpp
 
diff --git a/doc/tutorials/videoio/intelperc.markdown b/doc/tutorials/videoio/intelperc.markdown
index 932d78bd100..a36511a9782 100644
--- a/doc/tutorials/videoio/intelperc.markdown
+++ b/doc/tutorials/videoio/intelperc.markdown
@@ -78,5 +78,5 @@ there are two flags that should be used to set/get property of the needed genera
     flag value is assumed by default if neither of the two possible values of the property is set.
 
 For more information please refer to the example of usage
-[intelperc_capture.cpp](https://github.com/opencv/opencv/tree/3.4/samples/cpp/intelperc_capture.cpp)
+[intelperc_capture.cpp](https://github.com/opencv/opencv/tree/master/samples/cpp/intelperc_capture.cpp)
 in opencv/samples/cpp folder.
diff --git a/doc/tutorials/videoio/kinect_openni.markdown b/doc/tutorials/videoio/kinect_openni.markdown
index e8b7ad5b082..97fbd7ed2b8 100644
--- a/doc/tutorials/videoio/kinect_openni.markdown
+++ b/doc/tutorials/videoio/kinect_openni.markdown
@@ -134,5 +134,5 @@ property. The following properties of cameras available through OpenNI interface
     -   CAP_OPENNI_DEPTH_GENERATOR_REGISTRATION = CAP_OPENNI_DEPTH_GENERATOR + CAP_PROP_OPENNI_REGISTRATION
 
 For more information please refer to the example of usage
-[openni_capture.cpp](https://github.com/opencv/opencv/tree/3.4/samples/cpp/openni_capture.cpp) in
+[openni_capture.cpp](https://github.com/opencv/opencv/tree/master/samples/cpp/openni_capture.cpp) in
 opencv/samples/cpp folder.
diff --git a/doc/tutorials/videoio/video-input-psnr-ssim/video_input_psnr_ssim.markdown b/doc/tutorials/videoio/video-input-psnr-ssim/video_input_psnr_ssim.markdown
index a07736f88d7..c2a2304a98f 100644
--- a/doc/tutorials/videoio/video-input-psnr-ssim/video_input_psnr_ssim.markdown
+++ b/doc/tutorials/videoio/video-input-psnr-ssim/video_input_psnr_ssim.markdown
@@ -20,8 +20,8 @@ As a test case where to show off these using OpenCV I've created a small program
 video files and performs a similarity check between them. This is something you could use to check
 just how well a new video compressing algorithms works. Let there be a reference (original) video
 like [this small Megamind clip
-](https://github.com/opencv/opencv/tree/3.4/samples/data/Megamind.avi) and [a compressed
-version of it ](https://github.com/opencv/opencv/tree/3.4/samples/data/Megamind_bugy.avi).
+](https://github.com/opencv/opencv/tree/master/samples/data/Megamind.avi) and [a compressed
+version of it ](https://github.com/opencv/opencv/tree/master/samples/data/Megamind_bugy.avi).
 You may also find the source code and these video file in the
 `samples/data` folder of the OpenCV source library.
 
diff --git a/doc/tutorials/videoio/video-write/video_write.markdown b/doc/tutorials/videoio/video-write/video_write.markdown
index dff53c1f87e..9781a7075d0 100644
--- a/doc/tutorials/videoio/video-write/video_write.markdown
+++ b/doc/tutorials/videoio/video-write/video_write.markdown
@@ -31,7 +31,7 @@ The source code
 
 You may also find the source code and these video file in the
 `samples/cpp/tutorial_code/videoio/video-write/` folder of the OpenCV source library or [download it
-from here ](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/videoio/video-write/video-write.cpp).
+from here ](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/videoio/video-write/video-write.cpp).
 
 @include cpp/tutorial_code/videoio/video-write/video-write.cpp
 
diff --git a/doc/tutorials/viz/creating_widgets/creating_widgets.markdown b/doc/tutorials/viz/creating_widgets/creating_widgets.markdown
index 3023e9b2d81..4e4f6e5aed1 100644
--- a/doc/tutorials/viz/creating_widgets/creating_widgets.markdown
+++ b/doc/tutorials/viz/creating_widgets/creating_widgets.markdown
@@ -12,7 +12,7 @@ In this tutorial you will learn how to
 Code
 ----
 
-You can download the code from [here ](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/viz/creating_widgets.cpp).
+You can download the code from [here ](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/viz/creating_widgets.cpp).
 @include samples/cpp/tutorial_code/viz/creating_widgets.cpp
 
 Explanation
diff --git a/doc/tutorials/viz/histo3D/histo3D.markdown b/doc/tutorials/viz/histo3D/histo3D.markdown
index 10e9996aa43..fdf174cedd6 100644
--- a/doc/tutorials/viz/histo3D/histo3D.markdown
+++ b/doc/tutorials/viz/histo3D/histo3D.markdown
@@ -12,7 +12,7 @@ In this tutorial you will learn how to
 Code
 ----
 
-You can download the code from [here ](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/viz/histo3D.cpp).
+You can download the code from [here ](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/viz/histo3D.cpp).
 @include samples/cpp/tutorial_code/viz/histo3D.cpp
 
 Explanation
diff --git a/doc/tutorials/viz/launching_viz/launching_viz.markdown b/doc/tutorials/viz/launching_viz/launching_viz.markdown
index 6a02b9b7ade..d4ec97d49e4 100644
--- a/doc/tutorials/viz/launching_viz/launching_viz.markdown
+++ b/doc/tutorials/viz/launching_viz/launching_viz.markdown
@@ -14,7 +14,7 @@ In this tutorial you will learn how to
 Code
 ----
 
-You can download the code from [here ](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/viz/launching_viz.cpp).
+You can download the code from [here ](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/viz/launching_viz.cpp).
 @include samples/cpp/tutorial_code/viz/launching_viz.cpp
 
 Explanation
diff --git a/doc/tutorials/viz/transformations/transformations.markdown b/doc/tutorials/viz/transformations/transformations.markdown
index c10b90bd661..512ce80bdb6 100644
--- a/doc/tutorials/viz/transformations/transformations.markdown
+++ b/doc/tutorials/viz/transformations/transformations.markdown
@@ -13,7 +13,7 @@ In this tutorial you will learn how to
 Code
 ----
 
-You can download the code from [here ](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/viz/transformations.cpp).
+You can download the code from [here ](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/viz/transformations.cpp).
 @include samples/cpp/tutorial_code/viz/transformations.cpp
 
 Explanation
diff --git a/doc/tutorials/viz/widget_pose/widget_pose.markdown b/doc/tutorials/viz/widget_pose/widget_pose.markdown
index ea3b93e778a..382ae985565 100644
--- a/doc/tutorials/viz/widget_pose/widget_pose.markdown
+++ b/doc/tutorials/viz/widget_pose/widget_pose.markdown
@@ -13,7 +13,7 @@ In this tutorial you will learn how to
 Code
 ----
 
-You can download the code from [here ](https://github.com/opencv/opencv/tree/3.4/samples/cpp/tutorial_code/viz/widget_pose.cpp).
+You can download the code from [here ](https://github.com/opencv/opencv/tree/master/samples/cpp/tutorial_code/viz/widget_pose.cpp).
 @include samples/cpp/tutorial_code/viz/widget_pose.cpp
 
 Explanation
diff --git a/modules/calib3d/include/opencv2/calib3d.hpp b/modules/calib3d/include/opencv2/calib3d.hpp
index efec7333324..be5fc86f192 100644
--- a/modules/calib3d/include/opencv2/calib3d.hpp
+++ b/modules/calib3d/include/opencv2/calib3d.hpp
@@ -881,16 +881,15 @@ struct CV_EXPORTS_W_SIMPLE CirclesGridFinderParameters
       SYMMETRIC_GRID, ASYMMETRIC_GRID
     };
     GridType gridType;
-};
-
-struct CV_EXPORTS_W_SIMPLE CirclesGridFinderParameters2 : public CirclesGridFinderParameters
-{
-    CV_WRAP CirclesGridFinderParameters2();
 
     CV_PROP_RW float squareSize; //!< Distance between two adjacent points. Used by CALIB_CB_CLUSTERING.
     CV_PROP_RW float maxRectifiedDistance; //!< Max deviation from predicion. Used by CALIB_CB_CLUSTERING.
 };
 
+#ifndef DISABLE_OPENCV_3_COMPATIBILITY
+typedef CirclesGridFinderParameters CirclesGridFinderParameters2;
+#endif
+
 /** @brief Finds centers in the grid of circles.
 
 @param image grid view of input circles; it must be an 8-bit grayscale or color image.
@@ -926,13 +925,7 @@ the board to make the detection more robust in various environments.
 CV_EXPORTS_W bool findCirclesGrid( InputArray image, Size patternSize,
                                    OutputArray centers, int flags,
                                    const Ptr<FeatureDetector> &blobDetector,
-                                   CirclesGridFinderParameters parameters);
-
-/** @overload */
-CV_EXPORTS_W bool findCirclesGrid2( InputArray image, Size patternSize,
-                                   OutputArray centers, int flags,
-                                   const Ptr<FeatureDetector> &blobDetector,
-                                   CirclesGridFinderParameters2 parameters);
+                                   const CirclesGridFinderParameters& parameters);
 
 /** @overload */
 CV_EXPORTS_W bool findCirclesGrid( InputArray image, Size patternSize,
@@ -2451,8 +2444,4 @@ optimization. It stays at the center or at a different location specified when C
 
 } //end namespace cv
 
-#ifndef DISABLE_OPENCV_24_COMPATIBILITY
-#include "opencv2/calib3d/calib3d_c.h"
-#endif
-
 #endif
diff --git a/modules/calib3d/misc/java/gen_dict.json b/modules/calib3d/misc/java/gen_dict.json
index 4658096730e..3e690944878 100644
--- a/modules/calib3d/misc/java/gen_dict.json
+++ b/modules/calib3d/misc/java/gen_dict.json
@@ -1,7 +1,6 @@
 {
     "class_ignore_list": [
-        "CirclesGridFinderParameters",
-        "CirclesGridFinderParameters2"
+        "CirclesGridFinderParameters"
     ],
     "missing_consts" : {
         "Calib3d": {
diff --git a/modules/calib3d/perf/perf_main.cpp b/modules/calib3d/perf/perf_main.cpp
index a8dddb81d9c..54c334da138 100644
--- a/modules/calib3d/perf/perf_main.cpp
+++ b/modules/calib3d/perf/perf_main.cpp
@@ -1,3 +1,7 @@
 #include "perf_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_PERF_TEST_MAIN(calib3d)
diff --git a/modules/calib3d/src/calibinit.cpp b/modules/calib3d/src/calibinit.cpp
index c2180d73ad4..9297bd35b12 100644
--- a/modules/calib3d/src/calibinit.cpp
+++ b/modules/calib3d/src/calibinit.cpp
@@ -2179,22 +2179,14 @@ static int quiet_error(int /*status*/, const char* /*func_name*/,
     return 0;
 }
 
-bool findCirclesGrid(InputArray image, Size patternSize,
-                     OutputArray centers, int flags,
-                     const Ptr<FeatureDetector> &blobDetector,
-                     CirclesGridFinderParameters parameters)
-{
-    CirclesGridFinderParameters2 parameters2;
-    *((CirclesGridFinderParameters*)&parameters2) = parameters;
-    return cv::findCirclesGrid2(image, patternSize, centers, flags, blobDetector, parameters2);
-}
-
-bool findCirclesGrid2(InputArray _image, Size patternSize,
-                      OutputArray _centers, int flags, const Ptr<FeatureDetector> &blobDetector,
-                      CirclesGridFinderParameters2 parameters)
+bool findCirclesGrid( InputArray _image, Size patternSize,
+                          OutputArray _centers, int flags, const Ptr<FeatureDetector> &blobDetector,
+                          const CirclesGridFinderParameters& parameters_)
 {
     CV_INSTRUMENT_REGION()
 
+    CirclesGridFinderParameters parameters = parameters_; // parameters.gridType is amended below
+
     bool isAsymmetricGrid = (flags & CALIB_CB_ASYMMETRIC_GRID) ? true : false;
     bool isSymmetricGrid  = (flags & CALIB_CB_SYMMETRIC_GRID ) ? true : false;
     CV_Assert(isAsymmetricGrid ^ isSymmetricGrid);
@@ -2286,7 +2278,7 @@ bool findCirclesGrid2(InputArray _image, Size patternSize,
 bool findCirclesGrid(InputArray _image, Size patternSize,
                      OutputArray _centers, int flags, const Ptr<FeatureDetector> &blobDetector)
 {
-    return cv::findCirclesGrid2(_image, patternSize, _centers, flags, blobDetector, CirclesGridFinderParameters2());
+    return cv::findCirclesGrid(_image, patternSize, _centers, flags, blobDetector, CirclesGridFinderParameters());
 }
 
 } // namespace
diff --git a/modules/calib3d/src/circlesgrid.cpp b/modules/calib3d/src/circlesgrid.cpp
index 2d1a817629c..01824ae7d79 100644
--- a/modules/calib3d/src/circlesgrid.cpp
+++ b/modules/calib3d/src/circlesgrid.cpp
@@ -69,10 +69,6 @@ void drawPoints(const std::vector<Point2f> &points, Mat &outImage, int radius =
 
 void CirclesGridClusterFinder::hierarchicalClustering(const std::vector<Point2f> &points, const Size &patternSz, std::vector<Point2f> &patternPoints)
 {
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    if(tegra::useTegra() && tegra::hierarchicalClustering(points, patternSz, patternPoints))
-        return;
-#endif
     int j, n = (int)points.size();
     size_t pn = static_cast<size_t>(patternSz.area());
 
@@ -565,13 +561,9 @@ CirclesGridFinderParameters::CirclesGridFinderParameters()
 
   minRNGEdgeSwitchDist = 5.f;
   gridType = SYMMETRIC_GRID;
-}
 
-CirclesGridFinderParameters2::CirclesGridFinderParameters2()
-: CirclesGridFinderParameters()
-{
-    squareSize = 1.0f;
-    maxRectifiedDistance = squareSize/2.0f;
+  squareSize = 1.0f;
+  maxRectifiedDistance = squareSize/2.0f;
 }
 
 CirclesGridFinder::CirclesGridFinder(Size _patternSize, const std::vector<Point2f> &testKeypoints,
diff --git a/modules/calib3d/src/circlesgrid.hpp b/modules/calib3d/src/circlesgrid.hpp
index ad0f916eede..9ddc7d552c4 100644
--- a/modules/calib3d/src/circlesgrid.hpp
+++ b/modules/calib3d/src/circlesgrid.hpp
@@ -49,14 +49,12 @@
 #include <numeric>
 #include <map>
 
-#include "precomp.hpp"
-
 class CirclesGridClusterFinder
 {
     CirclesGridClusterFinder& operator=(const CirclesGridClusterFinder&);
     CirclesGridClusterFinder(const CirclesGridClusterFinder&);
 public:
-  CirclesGridClusterFinder(const cv::CirclesGridFinderParameters2 &parameters)
+  CirclesGridClusterFinder(const cv::CirclesGridFinderParameters &parameters)
   {
     isAsymmetricGrid = parameters.gridType == cv::CirclesGridFinderParameters::ASYMMETRIC_GRID;
     squareSize = parameters.squareSize;
diff --git a/modules/calib3d/src/precomp.hpp b/modules/calib3d/src/precomp.hpp
index 329692eb010..23355991a7b 100644
--- a/modules/calib3d/src/precomp.hpp
+++ b/modules/calib3d/src/precomp.hpp
@@ -53,11 +53,7 @@
 
 #include "opencv2/core/ocl.hpp"
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-#include "opencv2/calib3d/calib3d_tegra.hpp"
-#else
 #define GET_OPTIMIZED(func) (func)
-#endif
 
 
 namespace cv
diff --git a/modules/calib3d/test/test_affine3d_estimator.cpp b/modules/calib3d/test/test_affine3d_estimator.cpp
index 9c3821bbc4b..42e10a0e77a 100644
--- a/modules/calib3d/test/test_affine3d_estimator.cpp
+++ b/modules/calib3d/test/test_affine3d_estimator.cpp
@@ -138,13 +138,8 @@ bool CV_Affine3D_EstTest::testNPoints()
     std::transform(fpts.ptr<Point3f>(), fpts.ptr<Point3f>() + n, tpts.ptr<Point3f>(), WrapAff(aff));
 
     /* adding noise*/
-#ifdef CV_CXX11
     std::transform(tpts.ptr<Point3f>() + m, tpts.ptr<Point3f>() + n, tpts.ptr<Point3f>() + m,
         [=] (const Point3f& pt) -> Point3f { return Noise(noise_level)(pt + shift_outl); });
-#else
-    std::transform(tpts.ptr<Point3f>() + m, tpts.ptr<Point3f>() + n, tpts.ptr<Point3f>() + m, std::bind2nd(std::plus<Point3f>(), shift_outl));
-    std::transform(tpts.ptr<Point3f>() + m, tpts.ptr<Point3f>() + n, tpts.ptr<Point3f>() + m, Noise(noise_level));
-#endif
 
     Mat aff_est;
     vector<uchar> outl;
diff --git a/modules/calib3d/test/test_main.cpp b/modules/calib3d/test/test_main.cpp
index a6fc332d4ae..faa8d0e2e2e 100644
--- a/modules/calib3d/test/test_main.cpp
+++ b/modules/calib3d/test/test_main.cpp
@@ -3,4 +3,8 @@
 // of this distribution and at http://opencv.org/license.html.
 #include "test_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_TEST_MAIN("")
diff --git a/modules/core/CMakeLists.txt b/modules/core/CMakeLists.txt
index fa72e716582..73acbdd0223 100644
--- a/modules/core/CMakeLists.txt
+++ b/modules/core/CMakeLists.txt
@@ -77,6 +77,10 @@ ocv_target_link_libraries(${the_module} LINK_PRIVATE
     "${OPENCV_HAL_LINKER_LIBS}"
 )
 
+if(HAVE_HPX)
+  ocv_target_link_libraries(${the_module} LINK_PRIVATE "${HPX_LIBRARIES}")
+endif()
+
 if(HAVE_CUDA)
   ocv_target_compile_definitions(${the_module} PUBLIC OPENCV_TRAITS_ENABLE_DEPRECATED)
 endif()
diff --git a/modules/core/doc/cuda.markdown b/modules/core/doc/cuda.markdown
index 19b2dfc2d63..ea85007a34d 100644
--- a/modules/core/doc/cuda.markdown
+++ b/modules/core/doc/cuda.markdown
@@ -82,4 +82,4 @@ Block Matching algorithm has been successfully parallelized using the following
 3.  Merge the results into a single disparity map.
 
 With this algorithm, a dual GPU gave a 180% performance increase comparing to the single Fermi GPU.
-For a source code example, see <https://github.com/opencv/opencv/tree/3.4/samples/gpu/>.
+For a source code example, see <https://github.com/opencv/opencv/tree/master/samples/gpu/>.
diff --git a/modules/core/include/opencv2/core.hpp b/modules/core/include/opencv2/core.hpp
index 4d8f3b56d2d..2abcb98672b 100644
--- a/modules/core/include/opencv2/core.hpp
+++ b/modules/core/include/opencv2/core.hpp
@@ -144,7 +144,7 @@ It is possible to alternate error processing by using #redirectError().
 @param exc the exception raisen.
 @deprecated drop this version
  */
-CV_EXPORTS void error( const Exception& exc );
+CV_EXPORTS CV_NORETURN void error(const Exception& exc);
 
 enum SortFlags { SORT_EVERY_ROW    = 0, //!< each matrix row is sorted independently
                  SORT_EVERY_COLUMN = 1, //!< each matrix column is sorted
@@ -211,27 +211,6 @@ enum KmeansFlags {
     KMEANS_USE_INITIAL_LABELS = 1
 };
 
-//! type of line
-enum LineTypes {
-    FILLED  = -1,
-    LINE_4  = 4, //!< 4-connected line
-    LINE_8  = 8, //!< 8-connected line
-    LINE_AA = 16 //!< antialiased line
-};
-
-//! Only a subset of Hershey fonts <https://en.wikipedia.org/wiki/Hershey_fonts> are supported
-enum HersheyFonts {
-    FONT_HERSHEY_SIMPLEX        = 0, //!< normal size sans-serif font
-    FONT_HERSHEY_PLAIN          = 1, //!< small size sans-serif font
-    FONT_HERSHEY_DUPLEX         = 2, //!< normal size sans-serif font (more complex than FONT_HERSHEY_SIMPLEX)
-    FONT_HERSHEY_COMPLEX        = 3, //!< normal size serif font
-    FONT_HERSHEY_TRIPLEX        = 4, //!< normal size serif font (more complex than FONT_HERSHEY_COMPLEX)
-    FONT_HERSHEY_COMPLEX_SMALL  = 5, //!< smaller version of FONT_HERSHEY_COMPLEX
-    FONT_HERSHEY_SCRIPT_SIMPLEX = 6, //!< hand-writing style font
-    FONT_HERSHEY_SCRIPT_COMPLEX = 7, //!< more complex variant of FONT_HERSHEY_SCRIPT_SIMPLEX
-    FONT_ITALIC                 = 16 //!< flag for italic font
-};
-
 enum ReduceTypes { REDUCE_SUM = 0, //!< the output is the sum of all rows/columns of the matrix.
                    REDUCE_AVG = 1, //!< the output is the mean vector of all rows/columns of the matrix.
                    REDUCE_MAX = 2, //!< the output is the maximum (column/row-wise) of all rows/columns of the matrix.
@@ -602,7 +581,7 @@ or
     // access pixel coordinates
     Point pnt = locations[i];
 @endcode
-@param src single-channel array (type CV_8UC1)
+@param src single-channel array
 @param idx the output array, type of cv::Mat or std::vector<Point>, corresponding to non-zero indices in the input
 */
 CV_EXPORTS_W void findNonZero( InputArray src, OutputArray idx );
@@ -702,7 +681,8 @@ CV_EXPORTS double norm( const SparseMat& src, int normType );
 
 /** @brief Computes the Peak Signal-to-Noise Ratio (PSNR) image quality metric.
 
-This function calculates the Peak Signal-to-Noise Ratio (PSNR) image quality metric in decibels (dB), between two input arrays src1 and src2. Arrays must have depth CV_8U.
+This function calculates the Peak Signal-to-Noise Ratio (PSNR) image quality metric in decibels (dB),
+between two input arrays src1 and src2. The arrays must have the same type.
 
 The PSNR is calculated as follows:
 
@@ -710,13 +690,15 @@ The PSNR is calculated as follows:
 \texttt{PSNR} = 10 \cdot \log_{10}{\left( \frac{R^2}{MSE} \right) }
 \f]
 
-where R is the maximum integer value of depth CV_8U (255) and MSE is the mean squared error between the two arrays.
+where R is the maximum integer value of depth (e.g. 255 in the case of CV_8U data)
+and MSE is the mean squared error between the two arrays.
 
 @param src1 first input array.
 @param src2 second input array of the same size as src1.
+@param R the maximum pixel value (255 by default)
 
   */
-CV_EXPORTS_W double PSNR(InputArray src1, InputArray src2);
+CV_EXPORTS_W double PSNR(InputArray src1, InputArray src2, double R=255.);
 
 /** @brief naive nearest neighbor finder
 
@@ -2603,7 +2585,6 @@ class CV_EXPORTS LDA
     static Mat subspaceReconstruct(InputArray W, InputArray mean, InputArray src);
 
 protected:
-    bool _dataAsRow; // unused, but needed for 3.0 ABI compatibility.
     int _num_components;
     Mat _eigenvectors;
     Mat _eigenvalues;
diff --git a/modules/core/include/opencv2/core/base.hpp b/modules/core/include/opencv2/core/base.hpp
index 389fa65705b..24f92b5413f 100644
--- a/modules/core/include/opencv2/core/base.hpp
+++ b/modules/core/include/opencv2/core/base.hpp
@@ -373,32 +373,7 @@ It is possible to alternate error processing by using redirectError().
 @param _line - line number in the source file where the error has occurred
 @see CV_Error, CV_Error_, CV_Assert, CV_DbgAssert
  */
-CV_EXPORTS void error(int _code, const String& _err, const char* _func, const char* _file, int _line);
-
-#ifdef __GNUC__
-# if defined __clang__ || defined __APPLE__
-#   pragma GCC diagnostic push
-#   pragma GCC diagnostic ignored "-Winvalid-noreturn"
-# endif
-#endif
-
-/** same as cv::error, but does not return */
-CV_INLINE CV_NORETURN void errorNoReturn(int _code, const String& _err, const char* _func, const char* _file, int _line)
-{
-    error(_code, _err, _func, _file, _line);
-#ifdef __GNUC__
-# if !defined __clang__ && !defined __APPLE__
-    // this suppresses this warning: "noreturn" function does return [enabled by default]
-    __builtin_trap();
-    // or use infinite loop: for (;;) {}
-# endif
-#endif
-}
-#ifdef __GNUC__
-# if defined __clang__ || defined __APPLE__
-#   pragma GCC diagnostic pop
-# endif
-#endif
+CV_EXPORTS CV_NORETURN void error(int _code, const String& _err, const char* _func, const char* _file, int _line);
 
 #if defined __GNUC__
 #define CV_Func __func__
@@ -452,37 +427,19 @@ configurations while CV_DbgAssert is only retained in the Debug configuration.
 */
 #define CV_Assert( expr ) do { if(!!(expr)) ; else cv::error( cv::Error::StsAssert, #expr, CV_Func, __FILE__, __LINE__ ); } while(0)
 
-//! @cond IGNORED
-#define CV__ErrorNoReturn( code, msg ) cv::errorNoReturn( code, msg, CV_Func, __FILE__, __LINE__ )
-#define CV__ErrorNoReturn_( code, args ) cv::errorNoReturn( code, cv::format args, CV_Func, __FILE__, __LINE__ )
-#ifdef __OPENCV_BUILD
-#undef CV_Error
-#define CV_Error CV__ErrorNoReturn
-#undef CV_Error_
-#define CV_Error_ CV__ErrorNoReturn_
-#undef CV_Assert
-#define CV_Assert( expr ) do { if(!!(expr)) ; else cv::errorNoReturn( cv::Error::StsAssert, #expr, CV_Func, __FILE__, __LINE__ ); } while(0)
-#else
-// backward compatibility
-#define CV_ErrorNoReturn CV__ErrorNoReturn
-#define CV_ErrorNoReturn_ CV__ErrorNoReturn_
-#endif
-//! @endcond
-
 #endif // CV_STATIC_ANALYSIS
 
 //! @cond IGNORED
-
-#if defined OPENCV_FORCE_MULTIARG_ASSERT_CHECK && defined CV_STATIC_ANALYSIS
-#warning "OPENCV_FORCE_MULTIARG_ASSERT_CHECK can't be used with CV_STATIC_ANALYSIS"
-#undef OPENCV_FORCE_MULTIARG_ASSERT_CHECK
+#if !defined(__OPENCV_BUILD)  // TODO: backward compatibility only
+#ifndef CV_ErrorNoReturn
+#define CV_ErrorNoReturn CV_Error
+#endif
+#ifndef CV_ErrorNoReturn_
+#define CV_ErrorNoReturn_ CV_Error_
+#endif
 #endif
 
-#ifdef OPENCV_FORCE_MULTIARG_ASSERT_CHECK
-#define CV_Assert_1( expr ) do { if(!!(expr)) ; else cv::error( cv::Error::StsAssert, #expr, CV_Func, __FILE__, __LINE__ ); } while(0)
-#else
 #define CV_Assert_1 CV_Assert
-#endif
 #define CV_Assert_2( expr1, expr2 ) CV_Assert_1(expr1); CV_Assert_1(expr2)
 #define CV_Assert_3( expr1, expr2, expr3 ) CV_Assert_2(expr1, expr2); CV_Assert_1(expr3)
 #define CV_Assert_4( expr1, expr2, expr3, expr4 ) CV_Assert_3(expr1, expr2, expr3); CV_Assert_1(expr4)
@@ -495,10 +452,6 @@ configurations while CV_DbgAssert is only retained in the Debug configuration.
 
 #define CV_Assert_N(...) do { __CV_CAT(CV_Assert_, __CV_VA_NUM_ARGS(__VA_ARGS__)) (__VA_ARGS__); } while(0)
 
-#ifdef OPENCV_FORCE_MULTIARG_ASSERT_CHECK
-#undef CV_Assert
-#define CV_Assert CV_Assert_N
-#endif
 //! @endcond
 
 #if defined _DEBUG || defined CV_STATIC_ANALYSIS
@@ -751,11 +704,7 @@ namespace cudev
 
 namespace ipp
 {
-#if OPENCV_ABI_COMPATIBILITY > 300
 CV_EXPORTS   unsigned long long getIppFeatures();
-#else
-CV_EXPORTS   int getIppFeatures();
-#endif
 CV_EXPORTS   void setIppStatus(int status, const char * const funcname = NULL, const char * const filename = NULL,
                              int line = 0);
 CV_EXPORTS   int getIppStatus();
diff --git a/modules/core/include/opencv2/core/cuda.hpp b/modules/core/include/opencv2/core/cuda.hpp
index 820aba71ecb..4863a656745 100644
--- a/modules/core/include/opencv2/core/cuda.hpp
+++ b/modules/core/include/opencv2/core/cuda.hpp
@@ -102,10 +102,10 @@ streams.
 
 @sa Mat
  */
-class CV_EXPORTS GpuMat
+class CV_EXPORTS_W GpuMat
 {
 public:
-    class CV_EXPORTS Allocator
+    class CV_EXPORTS_W Allocator
     {
     public:
         virtual ~Allocator() {}
@@ -116,33 +116,33 @@ class CV_EXPORTS GpuMat
     };
 
     //! default allocator
-    static Allocator* defaultAllocator();
-    static void setDefaultAllocator(Allocator* allocator);
+    CV_WRAP static GpuMat::Allocator* defaultAllocator();
+    CV_WRAP static void setDefaultAllocator(GpuMat::Allocator* allocator);
 
     //! default constructor
-    explicit GpuMat(Allocator* allocator = defaultAllocator());
+    CV_WRAP explicit GpuMat(GpuMat::Allocator* allocator = GpuMat::defaultAllocator());
 
     //! constructs GpuMat of the specified size and type
-    GpuMat(int rows, int cols, int type, Allocator* allocator = defaultAllocator());
-    GpuMat(Size size, int type, Allocator* allocator = defaultAllocator());
+    CV_WRAP GpuMat(int rows, int cols, int type, GpuMat::Allocator* allocator = GpuMat::defaultAllocator());
+    CV_WRAP GpuMat(Size size, int type, GpuMat::Allocator* allocator = GpuMat::defaultAllocator());
 
     //! constucts GpuMat and fills it with the specified value _s
-    GpuMat(int rows, int cols, int type, Scalar s, Allocator* allocator = defaultAllocator());
-    GpuMat(Size size, int type, Scalar s, Allocator* allocator = defaultAllocator());
+    CV_WRAP GpuMat(int rows, int cols, int type, Scalar s, GpuMat::Allocator* allocator = GpuMat::defaultAllocator());
+    CV_WRAP GpuMat(Size size, int type, Scalar s, GpuMat::Allocator* allocator = GpuMat::defaultAllocator());
 
     //! copy constructor
-    GpuMat(const GpuMat& m);
+    CV_WRAP GpuMat(const GpuMat& m);
 
     //! constructor for GpuMat headers pointing to user-allocated data
-    GpuMat(int rows, int cols, int type, void* data, size_t step = Mat::AUTO_STEP);
-    GpuMat(Size size, int type, void* data, size_t step = Mat::AUTO_STEP);
+    CV_WRAP GpuMat(int rows, int cols, int type, void* data, size_t step = Mat::AUTO_STEP);
+    CV_WRAP GpuMat(Size size, int type, void* data, size_t step = Mat::AUTO_STEP);
 
     //! creates a GpuMat header for a part of the bigger matrix
-    GpuMat(const GpuMat& m, Range rowRange, Range colRange);
-    GpuMat(const GpuMat& m, Rect roi);
+    CV_WRAP GpuMat(const GpuMat& m, Range rowRange, Range colRange);
+    CV_WRAP GpuMat(const GpuMat& m, Rect roi);
 
     //! builds GpuMat from host memory (Blocking call)
-    explicit GpuMat(InputArray arr, Allocator* allocator = defaultAllocator());
+    CV_WRAP explicit GpuMat(InputArray arr, GpuMat::Allocator* allocator = GpuMat::defaultAllocator());
 
     //! destructor - calls release()
     ~GpuMat();
@@ -151,21 +151,21 @@ class CV_EXPORTS GpuMat
     GpuMat& operator =(const GpuMat& m);
 
     //! allocates new GpuMat data unless the GpuMat already has specified size and type
-    void create(int rows, int cols, int type);
-    void create(Size size, int type);
+    CV_WRAP void create(int rows, int cols, int type);
+    CV_WRAP void create(Size size, int type);
 
     //! decreases reference counter, deallocate the data when reference counter reaches 0
     void release();
 
     //! swaps with other smart pointer
-    void swap(GpuMat& mat);
+    CV_WRAP void swap(GpuMat& mat);
 
     /** @brief Performs data upload to GpuMat (Blocking call)
 
     This function copies data from host memory to device memory. As being a blocking call, it is
     guaranteed that the copy operation is finished when this function returns.
     */
-    void upload(InputArray arr);
+    CV_WRAP void upload(InputArray arr);
 
     /** @brief Performs data upload to GpuMat (Non-Blocking call)
 
@@ -175,14 +175,14 @@ class CV_EXPORTS GpuMat
     The copy operation may be overlapped with operations in other non-default streams if \p stream is
     not the default stream and \p dst is HostMem allocated with HostMem::PAGE_LOCKED option.
     */
-    void upload(InputArray arr, Stream& stream);
+    CV_WRAP void upload(InputArray arr, Stream& stream);
 
     /** @brief Performs data download from GpuMat (Blocking call)
 
     This function copies data from device memory to host memory. As being a blocking call, it is
     guaranteed that the copy operation is finished when this function returns.
     */
-    void download(OutputArray dst) const;
+    CV_WRAP void download(OutputArray dst) const;
 
     /** @brief Performs data download from GpuMat (Non-Blocking call)
 
@@ -192,51 +192,51 @@ class CV_EXPORTS GpuMat
     The copy operation may be overlapped with operations in other non-default streams if \p stream is
     not the default stream and \p dst is HostMem allocated with HostMem::PAGE_LOCKED option.
     */
-    void download(OutputArray dst, Stream& stream) const;
+    CV_WRAP void download(OutputArray dst, Stream& stream) const;
 
     //! returns deep copy of the GpuMat, i.e. the data is copied
-    GpuMat clone() const;
+    CV_WRAP GpuMat clone() const;
 
     //! copies the GpuMat content to device memory (Blocking call)
-    void copyTo(OutputArray dst) const;
+    CV_WRAP void copyTo(OutputArray dst) const;
 
     //! copies the GpuMat content to device memory (Non-Blocking call)
-    void copyTo(OutputArray dst, Stream& stream) const;
+    CV_WRAP void copyTo(OutputArray dst, Stream& stream) const;
 
     //! copies those GpuMat elements to "m" that are marked with non-zero mask elements (Blocking call)
-    void copyTo(OutputArray dst, InputArray mask) const;
+    CV_WRAP void copyTo(OutputArray dst, InputArray mask) const;
 
     //! copies those GpuMat elements to "m" that are marked with non-zero mask elements (Non-Blocking call)
-    void copyTo(OutputArray dst, InputArray mask, Stream& stream) const;
+    CV_WRAP void copyTo(OutputArray dst, InputArray mask, Stream& stream) const;
 
     //! sets some of the GpuMat elements to s (Blocking call)
-    GpuMat& setTo(Scalar s);
+    CV_WRAP GpuMat& setTo(Scalar s);
 
     //! sets some of the GpuMat elements to s (Non-Blocking call)
-    GpuMat& setTo(Scalar s, Stream& stream);
+    CV_WRAP GpuMat& setTo(Scalar s, Stream& stream);
 
     //! sets some of the GpuMat elements to s, according to the mask (Blocking call)
-    GpuMat& setTo(Scalar s, InputArray mask);
+    CV_WRAP GpuMat& setTo(Scalar s, InputArray mask);
 
     //! sets some of the GpuMat elements to s, according to the mask (Non-Blocking call)
-    GpuMat& setTo(Scalar s, InputArray mask, Stream& stream);
+    CV_WRAP GpuMat& setTo(Scalar s, InputArray mask, Stream& stream);
 
     //! converts GpuMat to another datatype (Blocking call)
-    void convertTo(OutputArray dst, int rtype) const;
+    CV_WRAP void convertTo(OutputArray dst, int rtype) const;
 
     //! converts GpuMat to another datatype (Non-Blocking call)
-    void convertTo(OutputArray dst, int rtype, Stream& stream) const;
+    CV_WRAP void convertTo(OutputArray dst, int rtype, Stream& stream) const;
 
     //! converts GpuMat to another datatype with scaling (Blocking call)
-    void convertTo(OutputArray dst, int rtype, double alpha, double beta = 0.0) const;
+    CV_WRAP void convertTo(OutputArray dst, int rtype, double alpha, double beta = 0.0) const;
 
     //! converts GpuMat to another datatype with scaling (Non-Blocking call)
-    void convertTo(OutputArray dst, int rtype, double alpha, Stream& stream) const;
+    CV_WRAP void convertTo(OutputArray dst, int rtype, double alpha, Stream& stream) const;
 
     //! converts GpuMat to another datatype with scaling (Non-Blocking call)
-    void convertTo(OutputArray dst, int rtype, double alpha, double beta, Stream& stream) const;
+    CV_WRAP void convertTo(OutputArray dst, int rtype, double alpha, double beta, Stream& stream) const;
 
-    void assignTo(GpuMat& m, int type=-1) const;
+    CV_WRAP void assignTo(GpuMat& m, int type = -1) const;
 
     //! returns pointer to y-th row
     uchar* ptr(int y = 0);
@@ -250,18 +250,18 @@ class CV_EXPORTS GpuMat
     template <typename _Tp> operator PtrStep<_Tp>() const;
 
     //! returns a new GpuMat header for the specified row
-    GpuMat row(int y) const;
+    CV_WRAP GpuMat row(int y) const;
 
     //! returns a new GpuMat header for the specified column
-    GpuMat col(int x) const;
+    CV_WRAP GpuMat col(int x) const;
 
     //! ... for the specified row span
-    GpuMat rowRange(int startrow, int endrow) const;
-    GpuMat rowRange(Range r) const;
+    CV_WRAP GpuMat rowRange(int startrow, int endrow) const;
+    CV_WRAP GpuMat rowRange(Range r) const;
 
     //! ... for the specified column span
-    GpuMat colRange(int startcol, int endcol) const;
-    GpuMat colRange(Range r) const;
+    CV_WRAP GpuMat colRange(int startcol, int endcol) const;
+    CV_WRAP GpuMat colRange(Range r) const;
 
     //! extracts a rectangular sub-GpuMat (this is a generalized form of row, rowRange etc.)
     GpuMat operator ()(Range rowRange, Range colRange) const;
@@ -269,44 +269,44 @@ class CV_EXPORTS GpuMat
 
     //! creates alternative GpuMat header for the same data, with different
     //! number of channels and/or different number of rows
-    GpuMat reshape(int cn, int rows = 0) const;
+    CV_WRAP GpuMat reshape(int cn, int rows = 0) const;
 
     //! locates GpuMat header within a parent GpuMat
-    void locateROI(Size& wholeSize, Point& ofs) const;
+    CV_WRAP void locateROI(Size& wholeSize, Point& ofs) const;
 
     //! moves/resizes the current GpuMat ROI inside the parent GpuMat
-    GpuMat& adjustROI(int dtop, int dbottom, int dleft, int dright);
+    CV_WRAP GpuMat& adjustROI(int dtop, int dbottom, int dleft, int dright);
 
     //! returns true iff the GpuMat data is continuous
     //! (i.e. when there are no gaps between successive rows)
-    bool isContinuous() const;
+    CV_WRAP bool isContinuous() const;
 
     //! returns element size in bytes
-    size_t elemSize() const;
+    CV_WRAP size_t elemSize() const;
 
     //! returns the size of element channel in bytes
-    size_t elemSize1() const;
+    CV_WRAP size_t elemSize1() const;
 
     //! returns element type
-    int type() const;
+    CV_WRAP int type() const;
 
     //! returns element type
-    int depth() const;
+    CV_WRAP int depth() const;
 
     //! returns number of channels
-    int channels() const;
+    CV_WRAP int channels() const;
 
     //! returns step/elemSize1()
-    size_t step1() const;
+    CV_WRAP size_t step1() const;
 
     //! returns GpuMat size : width == number of columns, height == number of rows
-    Size size() const;
+    CV_WRAP Size size() const;
 
     //! returns true if GpuMat data is NULL
-    bool empty() const;
+    CV_WRAP bool empty() const;
 
     //! internal use method: updates the continuity flag
-    void updateContinuityFlag();
+    CV_WRAP void updateContinuityFlag();
 
     /*! includes several bit-fields:
     - the magic signature
@@ -320,7 +320,7 @@ class CV_EXPORTS GpuMat
     int rows, cols;
 
     //! a distance between successive rows in bytes; includes the gap if any
-    size_t step;
+    CV_PROP size_t step;
 
     //! pointer to the data
     uchar* data;
@@ -348,7 +348,7 @@ class CV_EXPORTS GpuMat
 Matrix is called continuous if its elements are stored continuously, that is, without gaps at the
 end of each row.
  */
-CV_EXPORTS void createContinuous(int rows, int cols, int type, OutputArray arr);
+CV_EXPORTS_W void createContinuous(int rows, int cols, int type, OutputArray arr);
 
 /** @brief Ensures that the size of a matrix is big enough and the matrix has a proper type.
 
@@ -359,7 +359,7 @@ CV_EXPORTS void createContinuous(int rows, int cols, int type, OutputArray arr);
 
 The function does not reallocate memory if the matrix has proper attributes already.
  */
-CV_EXPORTS void ensureSizeIsEnough(int rows, int cols, int type, OutputArray arr);
+CV_EXPORTS_W void ensureSizeIsEnough(int rows, int cols, int type, OutputArray arr);
 
 /** @brief BufferPool for use with CUDA streams
 
@@ -478,7 +478,7 @@ and the corresponding memory is automatically returned to the pool for later usa
     }
 @endcode
  */
-class CV_EXPORTS BufferPool
+class CV_EXPORTS_W BufferPool
 {
 public:
 
@@ -486,21 +486,21 @@ class CV_EXPORTS BufferPool
     explicit BufferPool(Stream& stream);
 
     //! Allocates a new GpuMat of given size and type.
-    GpuMat getBuffer(int rows, int cols, int type);
+    CV_WRAP GpuMat getBuffer(int rows, int cols, int type);
 
     //! Allocates a new GpuMat of given size and type.
-    GpuMat getBuffer(Size size, int type) { return getBuffer(size.height, size.width, type); }
+    CV_WRAP GpuMat getBuffer(Size size, int type) { return getBuffer(size.height, size.width, type); }
 
     //! Returns the allocator associated with the stream.
-    Ptr<GpuMat::Allocator> getAllocator() const { return allocator_; }
+    CV_WRAP Ptr<GpuMat::Allocator> getAllocator() const { return allocator_; }
 
 private:
     Ptr<GpuMat::Allocator> allocator_;
 };
 
 //! BufferPool management (must be called before Stream creation)
-CV_EXPORTS void setBufferPoolUsage(bool on);
-CV_EXPORTS void setBufferPoolConfig(int deviceId, size_t stackSize, int stackCount);
+CV_EXPORTS_W void setBufferPoolUsage(bool on);
+CV_EXPORTS_W void setBufferPoolConfig(int deviceId, size_t stackSize, int stackCount);
 
 //===================================================================================
 // HostMem
@@ -521,46 +521,46 @@ Its interface is also Mat-like but with additional memory type parameters.
 @note Allocation size of such memory types is usually limited. For more details, see *CUDA 2.2
 Pinned Memory APIs* document or *CUDA C Programming Guide*.
  */
-class CV_EXPORTS HostMem
+class CV_EXPORTS_W HostMem
 {
 public:
     enum AllocType { PAGE_LOCKED = 1, SHARED = 2, WRITE_COMBINED = 4 };
 
-    static MatAllocator* getAllocator(AllocType alloc_type = PAGE_LOCKED);
+    static MatAllocator* getAllocator(HostMem::AllocType alloc_type = HostMem::AllocType::PAGE_LOCKED);
 
-    explicit HostMem(AllocType alloc_type = PAGE_LOCKED);
+    CV_WRAP explicit HostMem(HostMem::AllocType alloc_type = HostMem::AllocType::PAGE_LOCKED);
 
     HostMem(const HostMem& m);
 
-    HostMem(int rows, int cols, int type, AllocType alloc_type = PAGE_LOCKED);
-    HostMem(Size size, int type, AllocType alloc_type = PAGE_LOCKED);
+    CV_WRAP HostMem(int rows, int cols, int type, HostMem::AllocType alloc_type = HostMem::AllocType::PAGE_LOCKED);
+    CV_WRAP HostMem(Size size, int type, HostMem::AllocType alloc_type = HostMem::AllocType::PAGE_LOCKED);
 
     //! creates from host memory with coping data
-    explicit HostMem(InputArray arr, AllocType alloc_type = PAGE_LOCKED);
+    CV_WRAP explicit HostMem(InputArray arr, HostMem::AllocType alloc_type = HostMem::AllocType::PAGE_LOCKED);
 
     ~HostMem();
 
     HostMem& operator =(const HostMem& m);
 
     //! swaps with other smart pointer
-    void swap(HostMem& b);
+    CV_WRAP void swap(HostMem& b);
 
     //! returns deep copy of the matrix, i.e. the data is copied
-    HostMem clone() const;
+    CV_WRAP HostMem clone() const;
 
     //! allocates new matrix data unless the matrix already has specified size and type.
-    void create(int rows, int cols, int type);
+    CV_WRAP void create(int rows, int cols, int type);
     void create(Size size, int type);
 
     //! creates alternative HostMem header for the same data, with different
     //! number of channels and/or different number of rows
-    HostMem reshape(int cn, int rows = 0) const;
+    CV_WRAP HostMem reshape(int cn, int rows = 0) const;
 
     //! decrements reference counter and released memory if needed.
     void release();
 
     //! returns matrix header with disabled reference counting for HostMem data.
-    Mat createMatHeader() const;
+    CV_WRAP Mat createMatHeader() const;
 
     /** @brief Maps CPU memory to GPU address space and creates the cuda::GpuMat header without reference counting
     for it.
@@ -572,20 +572,20 @@ class CV_EXPORTS HostMem
     GpuMat createGpuMatHeader() const;
 
     // Please see cv::Mat for descriptions
-    bool isContinuous() const;
-    size_t elemSize() const;
-    size_t elemSize1() const;
-    int type() const;
-    int depth() const;
-    int channels() const;
-    size_t step1() const;
-    Size size() const;
-    bool empty() const;
+    CV_WRAP bool isContinuous() const;
+    CV_WRAP size_t elemSize() const;
+    CV_WRAP size_t elemSize1() const;
+    CV_WRAP int type() const;
+    CV_WRAP int depth() const;
+    CV_WRAP int channels() const;
+    CV_WRAP size_t step1() const;
+    CV_WRAP Size size() const;
+    CV_WRAP bool empty() const;
 
     // Please see cv::Mat for descriptions
     int flags;
     int rows, cols;
-    size_t step;
+    CV_PROP size_t step;
 
     uchar* data;
     int* refcount;
@@ -600,13 +600,13 @@ class CV_EXPORTS HostMem
 
 @param m Input matrix.
  */
-CV_EXPORTS void registerPageLocked(Mat& m);
+CV_EXPORTS_W void registerPageLocked(Mat& m);
 
 /** @brief Unmaps the memory of matrix and makes it pageable again.
 
 @param m Input matrix.
  */
-CV_EXPORTS void unregisterPageLocked(Mat& m);
+CV_EXPORTS_W void unregisterPageLocked(Mat& m);
 
 //===================================================================================
 // Stream
@@ -639,7 +639,7 @@ void thread2()
 @note By default all CUDA routines are launched in Stream::Null() object, if the stream is not specified by user.
 In multi-threading environment the stream objects must be passed explicitly (see previous note).
  */
-class CV_EXPORTS Stream
+class CV_EXPORTS_W Stream
 {
     typedef void (Stream::*bool_type)() const;
     void this_type_does_not_support_comparisons() const {}
@@ -648,22 +648,22 @@ class CV_EXPORTS Stream
     typedef void (*StreamCallback)(int status, void* userData);
 
     //! creates a new asynchronous stream
-    Stream();
+    CV_WRAP Stream();
 
     //! creates a new asynchronous stream with custom allocator
-    Stream(const Ptr<GpuMat::Allocator>& allocator);
+    CV_WRAP Stream(const Ptr<GpuMat::Allocator>& allocator);
 
     /** @brief Returns true if the current stream queue is finished. Otherwise, it returns false.
     */
-    bool queryIfComplete() const;
+    CV_WRAP bool queryIfComplete() const;
 
     /** @brief Blocks the current CPU thread until all operations in the stream are complete.
     */
-    void waitForCompletion();
+    CV_WRAP void waitForCompletion();
 
     /** @brief Makes a compute stream wait on an event.
     */
-    void waitEvent(const Event& event);
+    CV_WRAP void waitEvent(const Event& event);
 
     /** @brief Adds a callback to be called on the host after all currently enqueued items in the stream have
     completed.
@@ -676,7 +676,7 @@ class CV_EXPORTS Stream
     void enqueueHostCallback(StreamCallback callback, void* userData);
 
     //! return Stream object for default CUDA stream
-    static Stream& Null();
+    CV_WRAP static Stream& Null();
 
     //! returns true if stream object is not default (!= 0)
     operator bool_type() const;
@@ -692,7 +692,7 @@ class CV_EXPORTS Stream
     friend class DefaultDeviceInitializer;
 };
 
-class CV_EXPORTS Event
+class CV_EXPORTS_W Event
 {
 public:
     enum CreateFlags
@@ -703,19 +703,19 @@ class CV_EXPORTS Event
         INTERPROCESS   = 0x04   /**< Event is suitable for interprocess use. DisableTiming must be set */
     };
 
-    explicit Event(CreateFlags flags = DEFAULT);
+    CV_WRAP explicit Event(Event::CreateFlags flags = Event::CreateFlags::DEFAULT);
 
     //! records an event
-    void record(Stream& stream = Stream::Null());
+    CV_WRAP void record(Stream& stream = Stream::Null());
 
     //! queries an event's status
-    bool queryIfComplete() const;
+    CV_WRAP bool queryIfComplete() const;
 
     //! waits for an event to complete
-    void waitForCompletion();
+    CV_WRAP void waitForCompletion();
 
     //! computes the elapsed time between events
-    static float elapsedTime(const Event& start, const Event& end);
+    CV_WRAP static float elapsedTime(const Event& start, const Event& end);
 
     class Impl;
 
@@ -741,7 +741,7 @@ Use this function before any other CUDA functions calls. If OpenCV is compiled w
 this function returns 0. If the CUDA driver is not installed, or is incompatible, this function
 returns -1.
  */
-CV_EXPORTS int getCudaEnabledDeviceCount();
+CV_EXPORTS_W int getCudaEnabledDeviceCount();
 
 /** @brief Sets a device and initializes it for the current thread.
 
@@ -749,18 +749,18 @@ CV_EXPORTS int getCudaEnabledDeviceCount();
 
 If the call of this function is omitted, a default device is initialized at the fist CUDA usage.
  */
-CV_EXPORTS void setDevice(int device);
+CV_EXPORTS_W void setDevice(int device);
 
 /** @brief Returns the current device index set by cuda::setDevice or initialized by default.
  */
-CV_EXPORTS int getDevice();
+CV_EXPORTS_W int getDevice();
 
 /** @brief Explicitly destroys and cleans up all resources associated with the current device in the current
 process.
 
 Any subsequent API call to this device will reinitialize the device.
  */
-CV_EXPORTS void resetDevice();
+CV_EXPORTS_W void resetDevice();
 
 /** @brief Enumeration providing CUDA computing features.
  */
@@ -793,7 +793,7 @@ built for.
 According to the CUDA C Programming Guide Version 3.2: "PTX code produced for some specific compute
 capability can always be compiled to binary code of greater or equal compute capability".
  */
-class CV_EXPORTS TargetArchs
+class CV_EXPORTS_W TargetArchs
 {
 public:
     /** @brief The following method checks whether the module was built with the support of the given feature:
@@ -808,23 +808,23 @@ class CV_EXPORTS TargetArchs
     @param major Major compute capability version.
     @param minor Minor compute capability version.
      */
-    static bool has(int major, int minor);
-    static bool hasPtx(int major, int minor);
-    static bool hasBin(int major, int minor);
-
-    static bool hasEqualOrLessPtx(int major, int minor);
-    static bool hasEqualOrGreater(int major, int minor);
-    static bool hasEqualOrGreaterPtx(int major, int minor);
-    static bool hasEqualOrGreaterBin(int major, int minor);
+    CV_WRAP static bool has(int major, int minor);
+    CV_WRAP static bool hasPtx(int major, int minor);
+    CV_WRAP static bool hasBin(int major, int minor);
+
+    CV_WRAP static bool hasEqualOrLessPtx(int major, int minor);
+    CV_WRAP static bool hasEqualOrGreater(int major, int minor);
+    CV_WRAP static bool hasEqualOrGreaterPtx(int major, int minor);
+    CV_WRAP static bool hasEqualOrGreaterBin(int major, int minor);
 };
 
 /** @brief Class providing functionality for querying the specified GPU properties.
  */
-class CV_EXPORTS DeviceInfo
+class CV_EXPORTS_W DeviceInfo
 {
 public:
     //! creates DeviceInfo object for the current GPU
-    DeviceInfo();
+    CV_WRAP DeviceInfo();
 
     /** @brief The constructors.
 
@@ -833,68 +833,68 @@ class CV_EXPORTS DeviceInfo
     Constructs the DeviceInfo object for the specified device. If device_id parameter is missed, it
     constructs an object for the current device.
      */
-    DeviceInfo(int device_id);
+    CV_WRAP DeviceInfo(int device_id);
 
     /** @brief Returns system index of the CUDA device starting with 0.
     */
-    int deviceID() const;
+    CV_WRAP int deviceID() const;
 
     //! ASCII string identifying device
     const char* name() const;
 
     //! global memory available on device in bytes
-    size_t totalGlobalMem() const;
+    CV_WRAP size_t totalGlobalMem() const;
 
     //! shared memory available per block in bytes
-    size_t sharedMemPerBlock() const;
+    CV_WRAP size_t sharedMemPerBlock() const;
 
     //! 32-bit registers available per block
-    int regsPerBlock() const;
+    CV_WRAP int regsPerBlock() const;
 
     //! warp size in threads
-    int warpSize() const;
+    CV_WRAP int warpSize() const;
 
     //! maximum pitch in bytes allowed by memory copies
-    size_t memPitch() const;
+    CV_WRAP size_t memPitch() const;
 
     //! maximum number of threads per block
-    int maxThreadsPerBlock() const;
+    CV_WRAP int maxThreadsPerBlock() const;
 
     //! maximum size of each dimension of a block
-    Vec3i maxThreadsDim() const;
+    CV_WRAP Vec3i maxThreadsDim() const;
 
     //! maximum size of each dimension of a grid
-    Vec3i maxGridSize() const;
+    CV_WRAP Vec3i maxGridSize() const;
 
     //! clock frequency in kilohertz
-    int clockRate() const;
+    CV_WRAP int clockRate() const;
 
     //! constant memory available on device in bytes
-    size_t totalConstMem() const;
+    CV_WRAP size_t totalConstMem() const;
 
     //! major compute capability
-    int majorVersion() const;
+    CV_WRAP int majorVersion() const;
 
     //! minor compute capability
-    int minorVersion() const;
+    CV_WRAP int minorVersion() const;
 
     //! alignment requirement for textures
-    size_t textureAlignment() const;
+    CV_WRAP size_t textureAlignment() const;
 
     //! pitch alignment requirement for texture references bound to pitched memory
-    size_t texturePitchAlignment() const;
+    CV_WRAP size_t texturePitchAlignment() const;
 
     //! number of multiprocessors on device
-    int multiProcessorCount() const;
+    CV_WRAP int multiProcessorCount() const;
 
     //! specified whether there is a run time limit on kernels
-    bool kernelExecTimeoutEnabled() const;
+    CV_WRAP bool kernelExecTimeoutEnabled() const;
 
     //! device is integrated as opposed to discrete
-    bool integrated() const;
+    CV_WRAP bool integrated() const;
 
     //! device can map host memory with cudaHostAlloc/cudaHostGetDevicePointer
-    bool canMapHostMemory() const;
+    CV_WRAP bool canMapHostMemory() const;
 
     enum ComputeMode
     {
@@ -905,108 +905,108 @@ class CV_EXPORTS DeviceInfo
     };
 
     //! compute mode
-    ComputeMode computeMode() const;
+    CV_WRAP DeviceInfo::ComputeMode computeMode() const;
 
     //! maximum 1D texture size
-    int maxTexture1D() const;
+    CV_WRAP int maxTexture1D() const;
 
     //! maximum 1D mipmapped texture size
-    int maxTexture1DMipmap() const;
+    CV_WRAP int maxTexture1DMipmap() const;
 
     //! maximum size for 1D textures bound to linear memory
-    int maxTexture1DLinear() const;
+    CV_WRAP int maxTexture1DLinear() const;
 
     //! maximum 2D texture dimensions
-    Vec2i maxTexture2D() const;
+    CV_WRAP Vec2i maxTexture2D() const;
 
     //! maximum 2D mipmapped texture dimensions
-    Vec2i maxTexture2DMipmap() const;
+    CV_WRAP Vec2i maxTexture2DMipmap() const;
 
     //! maximum dimensions (width, height, pitch) for 2D textures bound to pitched memory
-    Vec3i maxTexture2DLinear() const;
+    CV_WRAP Vec3i maxTexture2DLinear() const;
 
     //! maximum 2D texture dimensions if texture gather operations have to be performed
-    Vec2i maxTexture2DGather() const;
+    CV_WRAP Vec2i maxTexture2DGather() const;
 
     //! maximum 3D texture dimensions
-    Vec3i maxTexture3D() const;
+    CV_WRAP Vec3i maxTexture3D() const;
 
     //! maximum Cubemap texture dimensions
-    int maxTextureCubemap() const;
+    CV_WRAP int maxTextureCubemap() const;
 
     //! maximum 1D layered texture dimensions
-    Vec2i maxTexture1DLayered() const;
+    CV_WRAP Vec2i maxTexture1DLayered() const;
 
     //! maximum 2D layered texture dimensions
-    Vec3i maxTexture2DLayered() const;
+    CV_WRAP Vec3i maxTexture2DLayered() const;
 
     //! maximum Cubemap layered texture dimensions
-    Vec2i maxTextureCubemapLayered() const;
+    CV_WRAP Vec2i maxTextureCubemapLayered() const;
 
     //! maximum 1D surface size
-    int maxSurface1D() const;
+    CV_WRAP int maxSurface1D() const;
 
     //! maximum 2D surface dimensions
-    Vec2i maxSurface2D() const;
+    CV_WRAP Vec2i maxSurface2D() const;
 
     //! maximum 3D surface dimensions
-    Vec3i maxSurface3D() const;
+    CV_WRAP Vec3i maxSurface3D() const;
 
     //! maximum 1D layered surface dimensions
-    Vec2i maxSurface1DLayered() const;
+    CV_WRAP Vec2i maxSurface1DLayered() const;
 
     //! maximum 2D layered surface dimensions
-    Vec3i maxSurface2DLayered() const;
+    CV_WRAP Vec3i maxSurface2DLayered() const;
 
     //! maximum Cubemap surface dimensions
-    int maxSurfaceCubemap() const;
+    CV_WRAP int maxSurfaceCubemap() const;
 
     //! maximum Cubemap layered surface dimensions
-    Vec2i maxSurfaceCubemapLayered() const;
+    CV_WRAP Vec2i maxSurfaceCubemapLayered() const;
 
     //! alignment requirements for surfaces
-    size_t surfaceAlignment() const;
+    CV_WRAP size_t surfaceAlignment() const;
 
     //! device can possibly execute multiple kernels concurrently
-    bool concurrentKernels() const;
+    CV_WRAP bool concurrentKernels() const;
 
     //! device has ECC support enabled
-    bool ECCEnabled() const;
+    CV_WRAP bool ECCEnabled() const;
 
     //! PCI bus ID of the device
-    int pciBusID() const;
+    CV_WRAP int pciBusID() const;
 
     //! PCI device ID of the device
-    int pciDeviceID() const;
+    CV_WRAP int pciDeviceID() const;
 
     //! PCI domain ID of the device
-    int pciDomainID() const;
+    CV_WRAP int pciDomainID() const;
 
     //! true if device is a Tesla device using TCC driver, false otherwise
-    bool tccDriver() const;
+    CV_WRAP bool tccDriver() const;
 
     //! number of asynchronous engines
-    int asyncEngineCount() const;
+    CV_WRAP int asyncEngineCount() const;
 
     //! device shares a unified address space with the host
-    bool unifiedAddressing() const;
+    CV_WRAP bool unifiedAddressing() const;
 
     //! peak memory clock frequency in kilohertz
-    int memoryClockRate() const;
+    CV_WRAP int memoryClockRate() const;
 
     //! global memory bus width in bits
-    int memoryBusWidth() const;
+    CV_WRAP int memoryBusWidth() const;
 
     //! size of L2 cache in bytes
-    int l2CacheSize() const;
+    CV_WRAP int l2CacheSize() const;
 
     //! maximum resident threads per multiprocessor
-    int maxThreadsPerMultiProcessor() const;
+    CV_WRAP int maxThreadsPerMultiProcessor() const;
 
     //! gets free and total device memory
-    void queryMemory(size_t& totalMemory, size_t& freeMemory) const;
-    size_t freeMemory() const;
-    size_t totalMemory() const;
+    CV_WRAP void queryMemory(size_t& totalMemory, size_t& freeMemory) const;
+    CV_WRAP size_t freeMemory() const;
+    CV_WRAP size_t totalMemory() const;
 
     /** @brief Provides information on CUDA feature support.
 
@@ -1021,14 +1021,14 @@ class CV_EXPORTS DeviceInfo
     This function returns true if the CUDA module can be run on the specified device. Otherwise, it
     returns false .
      */
-    bool isCompatible() const;
+    CV_WRAP bool isCompatible() const;
 
 private:
     int device_id_;
 };
 
-CV_EXPORTS void printCudaDeviceInfo(int device);
-CV_EXPORTS void printShortCudaDeviceInfo(int device);
+CV_EXPORTS_W void printCudaDeviceInfo(int device);
+CV_EXPORTS_W void printShortCudaDeviceInfo(int device);
 
 /** @brief Converts an array to half precision floating number.
 
diff --git a/modules/core/include/opencv2/core/cuda/functional.hpp b/modules/core/include/opencv2/core/cuda/functional.hpp
index b28f7a5e0ee..7f404dece5c 100644
--- a/modules/core/include/opencv2/core/cuda/functional.hpp
+++ b/modules/core/include/opencv2/core/cuda/functional.hpp
@@ -58,7 +58,6 @@
 namespace cv { namespace cuda { namespace device
 {
     // Function Objects
-#ifdef CV_CXX11
     template<typename Argument, typename Result> struct unary_function
     {
         typedef Argument argument_type;
@@ -70,10 +69,6 @@ namespace cv { namespace cuda { namespace device
         typedef Argument2 second_argument_type;
         typedef Result result_type;
     };
-#else
-    template<typename Argument, typename Result> struct unary_function : public std::unary_function<Argument, Result> {};
-    template<typename Argument1, typename Argument2, typename Result> struct binary_function : public std::binary_function<Argument1, Argument2, Result> {};
-#endif
 
     // Arithmetic Operations
     template <typename T> struct plus : binary_function<T, T, T>
diff --git a/modules/core/include/opencv2/core/cuda/vec_math.hpp b/modules/core/include/opencv2/core/cuda/vec_math.hpp
index 9085b92397d..80b13036818 100644
--- a/modules/core/include/opencv2/core/cuda/vec_math.hpp
+++ b/modules/core/include/opencv2/core/cuda/vec_math.hpp
@@ -199,14 +199,7 @@ CV_CUDEV_IMPLEMENT_VEC_UNARY_OP(~, uint, uint)
         return VecTraits<output_type ## 4>::make(func (a.x), func (a.y), func (a.z), func (a.w)); \
     }
 
-CV_CUDEV_IMPLEMENT_VEC_UNARY_FUNC(abs, /*::abs*/, uchar, uchar)
-CV_CUDEV_IMPLEMENT_VEC_UNARY_FUNC(abs, ::abs, char, char)
-CV_CUDEV_IMPLEMENT_VEC_UNARY_FUNC(abs, /*::abs*/, ushort, ushort)
-CV_CUDEV_IMPLEMENT_VEC_UNARY_FUNC(abs, ::abs, short, short)
-CV_CUDEV_IMPLEMENT_VEC_UNARY_FUNC(abs, ::abs, int, int)
-CV_CUDEV_IMPLEMENT_VEC_UNARY_FUNC(abs, /*::abs*/, uint, uint)
 CV_CUDEV_IMPLEMENT_VEC_UNARY_FUNC(abs, ::fabsf, float, float)
-CV_CUDEV_IMPLEMENT_VEC_UNARY_FUNC(abs, ::fabs, double, double)
 
 CV_CUDEV_IMPLEMENT_VEC_UNARY_FUNC(sqrt, ::sqrtf, uchar, float)
 CV_CUDEV_IMPLEMENT_VEC_UNARY_FUNC(sqrt, ::sqrtf, char, float)
diff --git a/modules/core/include/opencv2/core/cvdef.h b/modules/core/include/opencv2/core/cvdef.h
index 56403b31914..659f59bbf9e 100644
--- a/modules/core/include/opencv2/core/cvdef.h
+++ b/modules/core/include/opencv2/core/cvdef.h
@@ -253,10 +253,10 @@ typedef union Cv64suf
 }
 Cv64suf;
 
-#define OPENCV_ABI_COMPATIBILITY 300
+#define OPENCV_ABI_COMPATIBILITY 400
 
 #ifdef __OPENCV_BUILD
-#  define DISABLE_OPENCV_24_COMPATIBILITY
+#  define DISABLE_OPENCV_3_COMPATIBILITY
 #  define OPENCV_DISABLE_DEPRECATED_COMPATIBILITY
 #endif
 
@@ -307,6 +307,9 @@ Cv64suf;
 #define CV_PROP_RW
 #define CV_WRAP
 #define CV_WRAP_AS(synonym)
+#define CV_WRAP_MAPPABLE(mappable)
+#define CV_WRAP_PHANTOM(phantom_header)
+#define CV_WRAP_DEFAULT(val)
 
 /****************************************************************************************\
 *                                  Matrix type (Mat)                                     *
@@ -444,66 +447,30 @@ Cv64suf;
 #    undef CV_CXX11
 #  endif
 #endif
-
-
-/****************************************************************************************\
-*                                    C++ Move semantics                                  *
-\****************************************************************************************/
-
-#ifndef CV_CXX_MOVE_SEMANTICS
-#  if __cplusplus >= 201103L || defined(__GXX_EXPERIMENTAL_CXX0X__) || (defined(_MSC_VER) && _MSC_VER >= 1600)
-#    define CV_CXX_MOVE_SEMANTICS 1
-#  elif defined(__clang)
-#    if __has_feature(cxx_rvalue_references)
-#      define CV_CXX_MOVE_SEMANTICS 1
-#    endif
-#  endif
-#else
-#  if CV_CXX_MOVE_SEMANTICS == 0
-#    undef CV_CXX_MOVE_SEMANTICS
-#  endif
-#endif
-
-/****************************************************************************************\
-*                                    C++11 std::array                                    *
-\****************************************************************************************/
-
-#ifndef CV_CXX_STD_ARRAY
-#  if __cplusplus >= 201103L || (defined(_MSC_VER) && _MSC_VER >= 1900/*MSVS 2015*/)
-#    define CV_CXX_STD_ARRAY 1
-#    include <array>
-#  endif
-#else
-#  if CV_CXX_STD_ARRAY == 0
-#    undef CV_CXX_STD_ARRAY
-#  endif
+#ifndef CV_CXX11
+#  error "OpenCV 4.x+ requires enabled C++11 support"
 #endif
 
-
-/****************************************************************************************\
-*                                 C++11 override / final                                 *
-\****************************************************************************************/
-
+#define CV_CXX_MOVE_SEMANTICS 1
+#define CV_CXX_STD_ARRAY 1
+#include <array>
 #ifndef CV_OVERRIDE
-#  ifdef CV_CXX11
-#    define CV_OVERRIDE override
-#  endif
+#  define CV_OVERRIDE override
 #endif
-#ifndef CV_OVERRIDE
-#  define CV_OVERRIDE
+#ifndef CV_FINAL
+#  define CV_FINAL final
 #endif
 
-#ifndef CV_FINAL
-#  ifdef CV_CXX11
-#    define CV_FINAL final
+#ifndef CV_NOEXCEPT
+#  if __cplusplus >= 201103L || (defined(_MSC_VER) && _MSC_VER >= 1900/*MSVS 2015*/)
+#    define CV_NOEXCEPT noexcept
 #  endif
 #endif
-#ifndef CV_FINAL
-#  define CV_FINAL
+#ifndef CV_NOEXCEPT
+#  define CV_NOEXCEPT
 #endif
 
 
-
 // Integer types portatibility
 #ifdef OPENCV_STDINT_HEADER
 #include OPENCV_STDINT_HEADER
diff --git a/modules/core/include/opencv2/core/cvstd.hpp b/modules/core/include/opencv2/core/cvstd.hpp
index 0a3f553ab89..69846f7ab6a 100644
--- a/modules/core/include/opencv2/core/cvstd.hpp
+++ b/modules/core/include/opencv2/core/cvstd.hpp
@@ -281,10 +281,7 @@ struct Ptr
     @note It is often easier to use makePtr instead.
      */
     template<typename Y>
-#ifdef DISABLE_OPENCV_24_COMPATIBILITY
-    explicit
-#endif
-    Ptr(Y* p);
+    explicit Ptr(Y* p);
 
     /** @overload
     @param d Deleter to use for the owned pointer.
@@ -389,10 +386,8 @@ struct Ptr
     template<typename Y>
     Ptr<Y> dynamicCast() const;
 
-#ifdef CV_CXX_MOVE_SEMANTICS
     Ptr(Ptr&& o);
     Ptr& operator = (Ptr&& o);
-#endif
 
 private:
     detail::PtrOwner* owner;
@@ -455,586 +450,44 @@ Ptr<T> makePtr(const A1& a1, const A2& a2, const A3& a3, const A4& a4, const A5&
 
 class CV_EXPORTS FileNode; //for string constructor from FileNode
 
-class CV_EXPORTS String
-{
-public:
-    typedef char value_type;
-    typedef char& reference;
-    typedef const char& const_reference;
-    typedef char* pointer;
-    typedef const char* const_pointer;
-    typedef ptrdiff_t difference_type;
-    typedef size_t size_type;
-    typedef char* iterator;
-    typedef const char* const_iterator;
-
-    static const size_t npos = size_t(-1);
-
-    String();
-    String(const String& str);
-    String(const String& str, size_t pos, size_t len = npos);
-    String(const char* s);
-    String(const char* s, size_t n);
-    String(size_t n, char c);
-    String(const char* first, const char* last);
-    template<typename Iterator> String(Iterator first, Iterator last);
-    explicit String(const FileNode& fn);
-    ~String();
-
-    String& operator=(const String& str);
-    String& operator=(const char* s);
-    String& operator=(char c);
-
-    String& operator+=(const String& str);
-    String& operator+=(const char* s);
-    String& operator+=(char c);
-
-    size_t size() const;
-    size_t length() const;
-
-    char operator[](size_t idx) const;
-    char operator[](int idx) const;
-
-    const char* begin() const;
-    const char* end() const;
-
-    const char* c_str() const;
-
-    bool empty() const;
-    void clear();
-
-    int compare(const char* s) const;
-    int compare(const String& str) const;
-
-    void swap(String& str);
-    String substr(size_t pos = 0, size_t len = npos) const;
-
-    size_t find(const char* s, size_t pos, size_t n) const;
-    size_t find(char c, size_t pos = 0) const;
-    size_t find(const String& str, size_t pos = 0) const;
-    size_t find(const char* s, size_t pos = 0) const;
-
-    size_t rfind(const char* s, size_t pos, size_t n) const;
-    size_t rfind(char c, size_t pos = npos) const;
-    size_t rfind(const String& str, size_t pos = npos) const;
-    size_t rfind(const char* s, size_t pos = npos) const;
-
-    size_t find_first_of(const char* s, size_t pos, size_t n) const;
-    size_t find_first_of(char c, size_t pos = 0) const;
-    size_t find_first_of(const String& str, size_t pos = 0) const;
-    size_t find_first_of(const char* s, size_t pos = 0) const;
-
-    size_t find_last_of(const char* s, size_t pos, size_t n) const;
-    size_t find_last_of(char c, size_t pos = npos) const;
-    size_t find_last_of(const String& str, size_t pos = npos) const;
-    size_t find_last_of(const char* s, size_t pos = npos) const;
-
-    friend String operator+ (const String& lhs, const String& rhs);
-    friend String operator+ (const String& lhs, const char*   rhs);
-    friend String operator+ (const char*   lhs, const String& rhs);
-    friend String operator+ (const String& lhs, char          rhs);
-    friend String operator+ (char          lhs, const String& rhs);
-
-    String toLowerCase() const;
-
-    String(const std::string& str);
-    String(const std::string& str, size_t pos, size_t len = npos);
-    String& operator=(const std::string& str);
-    String& operator+=(const std::string& str);
-    operator std::string() const;
+typedef std::string String;
 
-    friend String operator+ (const String& lhs, const std::string& rhs);
-    friend String operator+ (const std::string& lhs, const String& rhs);
-
-private:
-    char*  cstr_;
-    size_t len_;
-
-    char* allocate(size_t len); // len without trailing 0
-    void deallocate();
-
-    String(int); // disabled and invalid. Catch invalid usages like, commandLineParser.has(0) problem
-};
-
-//! @} core_basic
-
-////////////////////////// cv::String implementation /////////////////////////
+#ifndef OPENCV_DISABLE_STRING_LOWER_UPPER_CONVERSIONS
 
 //! @cond IGNORED
-
-inline
-String::String()
-    : cstr_(0), len_(0)
-{}
-
-inline
-String::String(const String& str)
-    : cstr_(str.cstr_), len_(str.len_)
-{
-    if (cstr_)
-        CV_XADD(((int*)cstr_)-1, 1);
-}
-
-inline
-String::String(const String& str, size_t pos, size_t len)
-    : cstr_(0), len_(0)
-{
-    pos = min(pos, str.len_);
-    len = min(str.len_ - pos, len);
-    if (!len) return;
-    if (len == str.len_)
-    {
-        CV_XADD(((int*)str.cstr_)-1, 1);
-        cstr_ = str.cstr_;
-        len_ = str.len_;
-        return;
-    }
-    memcpy(allocate(len), str.cstr_ + pos, len);
-}
-
-inline
-String::String(const char* s)
-    : cstr_(0), len_(0)
-{
-    if (!s) return;
-    size_t len = strlen(s);
-    if (!len) return;
-    memcpy(allocate(len), s, len);
-}
-
-inline
-String::String(const char* s, size_t n)
-    : cstr_(0), len_(0)
-{
-    if (!n) return;
-    if (!s) return;
-    memcpy(allocate(n), s, n);
-}
-
-inline
-String::String(size_t n, char c)
-    : cstr_(0), len_(0)
-{
-    if (!n) return;
-    memset(allocate(n), c, n);
-}
-
-inline
-String::String(const char* first, const char* last)
-    : cstr_(0), len_(0)
-{
-    size_t len = (size_t)(last - first);
-    if (!len) return;
-    memcpy(allocate(len), first, len);
-}
-
-template<typename Iterator> inline
-String::String(Iterator first, Iterator last)
-    : cstr_(0), len_(0)
-{
-    size_t len = (size_t)(last - first);
-    if (!len) return;
-    char* str = allocate(len);
-    while (first != last)
-    {
-        *str++ = *first;
-        ++first;
-    }
-}
-
-inline
-String::~String()
-{
-    deallocate();
-}
-
-inline
-String& String::operator=(const String& str)
-{
-    if (&str == this) return *this;
-
-    deallocate();
-    if (str.cstr_) CV_XADD(((int*)str.cstr_)-1, 1);
-    cstr_ = str.cstr_;
-    len_ = str.len_;
-    return *this;
-}
-
-inline
-String& String::operator=(const char* s)
-{
-    deallocate();
-    if (!s) return *this;
-    size_t len = strlen(s);
-    if (len) memcpy(allocate(len), s, len);
-    return *this;
-}
-
-inline
-String& String::operator=(char c)
-{
-    deallocate();
-    allocate(1)[0] = c;
-    return *this;
-}
-
-inline
-String& String::operator+=(const String& str)
-{
-    *this = *this + str;
-    return *this;
-}
-
-inline
-String& String::operator+=(const char* s)
+namespace details {
+// std::tolower is int->int
+static inline char char_tolower(char ch)
 {
-    *this = *this + s;
-    return *this;
+    return (char)std::tolower((int)ch);
 }
-
-inline
-String& String::operator+=(char c)
+// std::toupper is int->int
+static inline char char_toupper(char ch)
 {
-    *this = *this + c;
-    return *this;
+    return (char)std::toupper((int)ch);
 }
-
-inline
-size_t String::size() const
-{
-    return len_;
-}
-
-inline
-size_t String::length() const
-{
-    return len_;
-}
-
-inline
-char String::operator[](size_t idx) const
-{
-    return cstr_[idx];
-}
-
-inline
-char String::operator[](int idx) const
-{
-    return cstr_[idx];
-}
-
-inline
-const char* String::begin() const
-{
-    return cstr_;
-}
-
-inline
-const char* String::end() const
-{
-    return len_ ? cstr_ + len_ : NULL;
-}
-
-inline
-bool String::empty() const
-{
-    return len_ == 0;
-}
-
-inline
-const char* String::c_str() const
-{
-    return cstr_ ? cstr_ : "";
-}
-
-inline
-void String::swap(String& str)
-{
-    cv::swap(cstr_, str.cstr_);
-    cv::swap(len_, str.len_);
-}
-
-inline
-void String::clear()
-{
-    deallocate();
-}
-
-inline
-int String::compare(const char* s) const
-{
-    if (cstr_ == s) return 0;
-    return strcmp(c_str(), s);
-}
-
-inline
-int String::compare(const String& str) const
-{
-    if (cstr_ == str.cstr_) return 0;
-    return strcmp(c_str(), str.c_str());
-}
-
-inline
-String String::substr(size_t pos, size_t len) const
-{
-    return String(*this, pos, len);
-}
-
-inline
-size_t String::find(const char* s, size_t pos, size_t n) const
-{
-    if (n == 0 || pos + n > len_) return npos;
-    const char* lmax = cstr_ + len_ - n;
-    for (const char* i = cstr_ + pos; i <= lmax; ++i)
-    {
-        size_t j = 0;
-        while (j < n && s[j] == i[j]) ++j;
-        if (j == n) return (size_t)(i - cstr_);
-    }
-    return npos;
-}
-
-inline
-size_t String::find(char c, size_t pos) const
-{
-    return find(&c, pos, 1);
-}
-
-inline
-size_t String::find(const String& str, size_t pos) const
-{
-    return find(str.c_str(), pos, str.len_);
-}
-
-inline
-size_t String::find(const char* s, size_t pos) const
-{
-    if (pos >= len_ || !s[0]) return npos;
-    const char* lmax = cstr_ + len_;
-    for (const char* i = cstr_ + pos; i < lmax; ++i)
-    {
-        size_t j = 0;
-        while (s[j] && s[j] == i[j])
-        {   if(i + j >= lmax) return npos;
-            ++j;
-        }
-        if (!s[j]) return (size_t)(i - cstr_);
-    }
-    return npos;
-}
-
-inline
-size_t String::rfind(const char* s, size_t pos, size_t n) const
-{
-    if (n > len_) return npos;
-    if (pos > len_ - n) pos = len_ - n;
-    for (const char* i = cstr_ + pos; i >= cstr_; --i)
-    {
-        size_t j = 0;
-        while (j < n && s[j] == i[j]) ++j;
-        if (j == n) return (size_t)(i - cstr_);
-    }
-    return npos;
-}
-
-inline
-size_t String::rfind(char c, size_t pos) const
-{
-    return rfind(&c, pos, 1);
-}
-
-inline
-size_t String::rfind(const String& str, size_t pos) const
-{
-    return rfind(str.c_str(), pos, str.len_);
-}
-
-inline
-size_t String::rfind(const char* s, size_t pos) const
-{
-    return rfind(s, pos, strlen(s));
-}
-
-inline
-size_t String::find_first_of(const char* s, size_t pos, size_t n) const
-{
-    if (n == 0 || pos + n > len_) return npos;
-    const char* lmax = cstr_ + len_;
-    for (const char* i = cstr_ + pos; i < lmax; ++i)
-    {
-        for (size_t j = 0; j < n; ++j)
-            if (s[j] == *i)
-                return (size_t)(i - cstr_);
-    }
-    return npos;
-}
-
-inline
-size_t String::find_first_of(char c, size_t pos) const
-{
-    return find_first_of(&c, pos, 1);
-}
-
-inline
-size_t String::find_first_of(const String& str, size_t pos) const
-{
-    return find_first_of(str.c_str(), pos, str.len_);
-}
-
-inline
-size_t String::find_first_of(const char* s, size_t pos) const
-{
-    if (len_ == 0) return npos;
-    if (pos >= len_ || !s[0]) return npos;
-    const char* lmax = cstr_ + len_;
-    for (const char* i = cstr_ + pos; i < lmax; ++i)
-    {
-        for (size_t j = 0; s[j]; ++j)
-            if (s[j] == *i)
-                return (size_t)(i - cstr_);
-    }
-    return npos;
-}
-
-inline
-size_t String::find_last_of(const char* s, size_t pos, size_t n) const
-{
-    if (len_ == 0) return npos;
-    if (pos >= len_) pos = len_ - 1;
-    for (const char* i = cstr_ + pos; i >= cstr_; --i)
-    {
-        for (size_t j = 0; j < n; ++j)
-            if (s[j] == *i)
-                return (size_t)(i - cstr_);
-    }
-    return npos;
-}
-
-inline
-size_t String::find_last_of(char c, size_t pos) const
-{
-    return find_last_of(&c, pos, 1);
-}
-
-inline
-size_t String::find_last_of(const String& str, size_t pos) const
-{
-    return find_last_of(str.c_str(), pos, str.len_);
-}
-
-inline
-size_t String::find_last_of(const char* s, size_t pos) const
-{
-    if (len_ == 0) return npos;
-    if (pos >= len_) pos = len_ - 1;
-    for (const char* i = cstr_ + pos; i >= cstr_; --i)
-    {
-        for (size_t j = 0; s[j]; ++j)
-            if (s[j] == *i)
-                return (size_t)(i - cstr_);
-    }
-    return npos;
-}
-
-inline
-String String::toLowerCase() const
-{
-    if (!cstr_)
-        return String();
-    String res(cstr_, len_);
-    for (size_t i = 0; i < len_; ++i)
-        res.cstr_[i] = (char) ::tolower(cstr_[i]);
-
-    return res;
-}
-
+} // namespace details
 //! @endcond
 
-// ************************* cv::String non-member functions *************************
-
-//! @relates cv::String
-//! @{
-
-inline
-String operator + (const String& lhs, const String& rhs)
-{
-    String s;
-    s.allocate(lhs.len_ + rhs.len_);
-    if (lhs.len_) memcpy(s.cstr_, lhs.cstr_, lhs.len_);
-    if (rhs.len_) memcpy(s.cstr_ + lhs.len_, rhs.cstr_, rhs.len_);
-    return s;
-}
-
-inline
-String operator + (const String& lhs, const char* rhs)
-{
-    String s;
-    size_t rhslen = strlen(rhs);
-    s.allocate(lhs.len_ + rhslen);
-    if (lhs.len_) memcpy(s.cstr_, lhs.cstr_, lhs.len_);
-    if (rhslen) memcpy(s.cstr_ + lhs.len_, rhs, rhslen);
-    return s;
-}
-
-inline
-String operator + (const char* lhs, const String& rhs)
-{
-    String s;
-    size_t lhslen = strlen(lhs);
-    s.allocate(lhslen + rhs.len_);
-    if (lhslen) memcpy(s.cstr_, lhs, lhslen);
-    if (rhs.len_) memcpy(s.cstr_ + lhslen, rhs.cstr_, rhs.len_);
-    return s;
-}
-
-inline
-String operator + (const String& lhs, char rhs)
+static inline std::string toLowerCase(const std::string& str)
 {
-    String s;
-    s.allocate(lhs.len_ + 1);
-    if (lhs.len_) memcpy(s.cstr_, lhs.cstr_, lhs.len_);
-    s.cstr_[lhs.len_] = rhs;
-    return s;
+    std::string result(str);
+    std::transform(result.begin(), result.end(), result.begin(), details::char_tolower);
+    return result;
 }
 
-inline
-String operator + (char lhs, const String& rhs)
+static inline std::string toUpperCase(const std::string& str)
 {
-    String s;
-    s.allocate(rhs.len_ + 1);
-    s.cstr_[0] = lhs;
-    if (rhs.len_) memcpy(s.cstr_ + 1, rhs.cstr_, rhs.len_);
-    return s;
+    std::string result(str);
+    std::transform(result.begin(), result.end(), result.begin(), details::char_toupper);
+    return result;
 }
 
-static inline bool operator== (const String& lhs, const String& rhs) { return 0 == lhs.compare(rhs); }
-static inline bool operator== (const char*   lhs, const String& rhs) { return 0 == rhs.compare(lhs); }
-static inline bool operator== (const String& lhs, const char*   rhs) { return 0 == lhs.compare(rhs); }
-static inline bool operator!= (const String& lhs, const String& rhs) { return 0 != lhs.compare(rhs); }
-static inline bool operator!= (const char*   lhs, const String& rhs) { return 0 != rhs.compare(lhs); }
-static inline bool operator!= (const String& lhs, const char*   rhs) { return 0 != lhs.compare(rhs); }
-static inline bool operator<  (const String& lhs, const String& rhs) { return lhs.compare(rhs) <  0; }
-static inline bool operator<  (const char*   lhs, const String& rhs) { return rhs.compare(lhs) >  0; }
-static inline bool operator<  (const String& lhs, const char*   rhs) { return lhs.compare(rhs) <  0; }
-static inline bool operator<= (const String& lhs, const String& rhs) { return lhs.compare(rhs) <= 0; }
-static inline bool operator<= (const char*   lhs, const String& rhs) { return rhs.compare(lhs) >= 0; }
-static inline bool operator<= (const String& lhs, const char*   rhs) { return lhs.compare(rhs) <= 0; }
-static inline bool operator>  (const String& lhs, const String& rhs) { return lhs.compare(rhs) >  0; }
-static inline bool operator>  (const char*   lhs, const String& rhs) { return rhs.compare(lhs) <  0; }
-static inline bool operator>  (const String& lhs, const char*   rhs) { return lhs.compare(rhs) >  0; }
-static inline bool operator>= (const String& lhs, const String& rhs) { return lhs.compare(rhs) >= 0; }
-static inline bool operator>= (const char*   lhs, const String& rhs) { return rhs.compare(lhs) <= 0; }
-static inline bool operator>= (const String& lhs, const char*   rhs) { return lhs.compare(rhs) >= 0; }
-
-//! @} relates cv::String
+#endif // OPENCV_DISABLE_STRING_LOWER_UPPER_CONVERSIONS
 
+//! @} core_basic
 } // cv
 
-namespace std
-{
-    static inline void swap(cv::String& a, cv::String& b) { a.swap(b); }
-}
-
 #include "opencv2/core/ptr.inl.hpp"
 
 #endif //OPENCV_CORE_CVSTD_HPP
diff --git a/modules/core/include/opencv2/core/cvstd.inl.hpp b/modules/core/include/opencv2/core/cvstd.inl.hpp
index ed37cacb300..5df48abb63b 100644
--- a/modules/core/include/opencv2/core/cvstd.inl.hpp
+++ b/modules/core/include/opencv2/core/cvstd.inl.hpp
@@ -73,69 +73,6 @@ template<typename _Tp> class DataType< std::complex<_Tp> >
     typedef Vec<channel_type, channels> vec_type;
 };
 
-inline
-String::String(const std::string& str)
-    : cstr_(0), len_(0)
-{
-    size_t len = str.size();
-    if (len) memcpy(allocate(len), str.c_str(), len);
-}
-
-inline
-String::String(const std::string& str, size_t pos, size_t len)
-    : cstr_(0), len_(0)
-{
-    size_t strlen = str.size();
-    pos = min(pos, strlen);
-    len = min(strlen - pos, len);
-    if (!len) return;
-    memcpy(allocate(len), str.c_str() + pos, len);
-}
-
-inline
-String& String::operator = (const std::string& str)
-{
-    deallocate();
-    size_t len = str.size();
-    if (len) memcpy(allocate(len), str.c_str(), len);
-    return *this;
-}
-
-inline
-String& String::operator += (const std::string& str)
-{
-    *this = *this + str;
-    return *this;
-}
-
-inline
-String::operator std::string() const
-{
-    return std::string(cstr_, len_);
-}
-
-inline
-String operator + (const String& lhs, const std::string& rhs)
-{
-    String s;
-    size_t rhslen = rhs.size();
-    s.allocate(lhs.len_ + rhslen);
-    if (lhs.len_) memcpy(s.cstr_, lhs.cstr_, lhs.len_);
-    if (rhslen) memcpy(s.cstr_ + lhs.len_, rhs.c_str(), rhslen);
-    return s;
-}
-
-inline
-String operator + (const std::string& lhs, const String& rhs)
-{
-    String s;
-    size_t lhslen = lhs.size();
-    s.allocate(lhslen + rhs.len_);
-    if (lhslen) memcpy(s.cstr_, lhs.c_str(), lhslen);
-    if (rhs.len_) memcpy(s.cstr_ + lhslen, rhs.cstr_, rhs.len_);
-    return s;
-}
-
 inline
 FileNode::operator std::string() const
 {
diff --git a/modules/core/include/opencv2/core/fast_math.hpp b/modules/core/include/opencv2/core/fast_math.hpp
index 7858d40492e..6ff31c2017a 100644
--- a/modules/core/include/opencv2/core/fast_math.hpp
+++ b/modules/core/include/opencv2/core/fast_math.hpp
@@ -70,10 +70,6 @@
 #  endif
 #endif
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-#  include "tegra_round.hpp"
-#endif
-
 #if defined __GNUC__ && defined __arm__ && (defined __ARM_PCS_VFP || defined __ARM_VFPV3__ || defined __ARM_NEON__) && !defined __SOFTFP__ && !defined(__CUDACC__)
     // 1. general scheme
     #define ARM_ROUND(_value, _asm_string) \
@@ -112,9 +108,6 @@ cvRound( double value )
         fistp t;
     }
     return t;
-#elif ((defined _MSC_VER && defined _M_ARM) || defined CV_ICC || \
-        defined __GNUC__) && defined HAVE_TEGRA_OPTIMIZATION
-    TEGRA_ROUND_DBL(value);
 #elif defined CV_ICC || defined __GNUC__
 # if defined ARM_ROUND_DBL
     ARM_ROUND_DBL(value);
@@ -200,9 +193,6 @@ CV_INLINE int cvRound(float value)
         fistp t;
     }
     return t;
-#elif ((defined _MSC_VER && defined _M_ARM) || defined CV_ICC || \
-        defined __GNUC__) && defined HAVE_TEGRA_OPTIMIZATION
-    TEGRA_ROUND_FLT(value);
 #elif defined CV_ICC || defined __GNUC__
 # if defined ARM_ROUND_FLT
     ARM_ROUND_FLT(value);
diff --git a/modules/core/include/opencv2/core/mat.hpp b/modules/core/include/opencv2/core/mat.hpp
index a7d30218572..1884abd66c0 100644
--- a/modules/core/include/opencv2/core/mat.hpp
+++ b/modules/core/include/opencv2/core/mat.hpp
@@ -53,9 +53,7 @@
 
 #include "opencv2/core/bufferpool.hpp"
 
-#ifdef CV_CXX11
 #include <type_traits>
-#endif
 
 namespace cv
 {
@@ -185,7 +183,7 @@ class CV_EXPORTS _InputArray
     template<typename _Tp> _InputArray(const std::vector<_Tp>& vec);
     _InputArray(const std::vector<bool>& vec);
     template<typename _Tp> _InputArray(const std::vector<std::vector<_Tp> >& vec);
-    _InputArray(const std::vector<std::vector<bool> >&);
+    _InputArray(const std::vector<std::vector<bool> >&) = delete;  // not supported
     template<typename _Tp> _InputArray(const std::vector<Mat_<_Tp> >& vec);
     template<typename _Tp> _InputArray(const _Tp* vec, int n);
     template<typename _Tp, int m, int n> _InputArray(const Matx<_Tp, m, n>& matx);
@@ -198,10 +196,8 @@ class CV_EXPORTS _InputArray
     _InputArray(const UMat& um);
     _InputArray(const std::vector<UMat>& umv);
 
-#ifdef CV_CXX_STD_ARRAY
     template<typename _Tp, std::size_t _Nm> _InputArray(const std::array<_Tp, _Nm>& arr);
     template<std::size_t _Nm> _InputArray(const std::array<Mat, _Nm>& arr);
-#endif
 
     Mat getMat(int idx=-1) const;
     Mat getMat_(int idx=-1) const;
@@ -306,9 +302,9 @@ class CV_EXPORTS _OutputArray : public _InputArray
     _OutputArray(cuda::HostMem& cuda_mem);
     template<typename _Tp> _OutputArray(cudev::GpuMat_<_Tp>& m);
     template<typename _Tp> _OutputArray(std::vector<_Tp>& vec);
-    _OutputArray(std::vector<bool>& vec);
+    _OutputArray(std::vector<bool>& vec) = delete;  // not supported
     template<typename _Tp> _OutputArray(std::vector<std::vector<_Tp> >& vec);
-    _OutputArray(std::vector<std::vector<bool> >&);
+    _OutputArray(std::vector<std::vector<bool> >&) = delete;  // not supported
     template<typename _Tp> _OutputArray(std::vector<Mat_<_Tp> >& vec);
     template<typename _Tp> _OutputArray(Mat_<_Tp>& m);
     template<typename _Tp> _OutputArray(_Tp* vec, int n);
@@ -376,7 +372,7 @@ class CV_EXPORTS _InputOutputArray : public _OutputArray
     _InputOutputArray(cuda::HostMem& cuda_mem);
     template<typename _Tp> _InputOutputArray(cudev::GpuMat_<_Tp>& m);
     template<typename _Tp> _InputOutputArray(std::vector<_Tp>& vec);
-    _InputOutputArray(std::vector<bool>& vec);
+    _InputOutputArray(std::vector<bool>& vec) = delete;  // not supported
     template<typename _Tp> _InputOutputArray(std::vector<std::vector<_Tp> >& vec);
     template<typename _Tp> _InputOutputArray(std::vector<Mat_<_Tp> >& vec);
     template<typename _Tp> _InputOutputArray(Mat_<_Tp>& m);
@@ -986,7 +982,6 @@ class CV_EXPORTS Mat
     */
     template<typename _Tp> explicit Mat(const std::vector<_Tp>& vec, bool copyData=false);
 
-#ifdef CV_CXX11
     /** @overload
     */
     template<typename _Tp, typename = typename std::enable_if<std::is_arithmetic<_Tp>::value>::type>
@@ -995,7 +990,6 @@ class CV_EXPORTS Mat
     /** @overload
     */
     template<typename _Tp> explicit Mat(const std::initializer_list<int> sizes, const std::initializer_list<_Tp> list);
-#endif
 
 #ifdef CV_CXX_STD_ARRAY
     /** @overload
@@ -2062,10 +2056,8 @@ class CV_EXPORTS Mat
     /** @overload */
     template<typename _Tp, typename Functor> void forEach(const Functor& operation) const;
 
-#ifdef CV_CXX_MOVE_SEMANTICS
     Mat(Mat&& m);
     Mat& operator = (Mat&& m);
-#endif
 
     enum { MAGIC_VAL  = 0x42FF0000, AUTO_STEP = 0, CONTINUOUS_FLAG = CV_MAT_CONT_FLAG, SUBMATRIX_FLAG = CV_SUBMAT_FLAG };
     enum { MAGIC_MASK = 0xFFFF0000, TYPE_MASK = 0x00000FFF, DEPTH_MASK = 7 };
@@ -2219,10 +2211,8 @@ template<typename _Tp> class Mat_ : public Mat
     explicit Mat_(const Point3_<typename DataType<_Tp>::channel_type>& pt, bool copyData=true);
     explicit Mat_(const MatCommaInitializer_<_Tp>& commaInitializer);
 
-#ifdef CV_CXX11
     Mat_(std::initializer_list<_Tp> values);
     explicit Mat_(const std::initializer_list<int> sizes, const std::initializer_list<_Tp> values);
-#endif
 
 #ifdef CV_CXX_STD_ARRAY
     template <std::size_t _Nm> explicit Mat_(const std::array<_Tp, _Nm>& arr, bool copyData=false);
@@ -2334,7 +2324,6 @@ template<typename _Tp> class Mat_ : public Mat
     //! conversion to Matx
     template<int m, int n> operator Matx<typename DataType<_Tp>::channel_type, m, n>() const;
 
-#ifdef CV_CXX_MOVE_SEMANTICS
     Mat_(Mat_&& m);
     Mat_& operator = (Mat_&& m);
 
@@ -2342,7 +2331,6 @@ template<typename _Tp> class Mat_ : public Mat
     Mat_& operator = (Mat&& m);
 
     Mat_(MatExpr&& e);
-#endif
 };
 
 typedef Mat_<uchar> Mat1b;
@@ -2539,10 +2527,8 @@ class CV_EXPORTS UMat
     //! returns N if the matrix is 1-channel (N x ptdim) or ptdim-channel (1 x N) or (N x 1); negative number otherwise
     int checkVector(int elemChannels, int depth=-1, bool requireContinuous=true) const;
 
-#ifdef CV_CXX_MOVE_SEMANTICS
     UMat(UMat&& m);
     UMat& operator = (UMat&& m);
-#endif
 
     /*! Returns the OpenCL buffer handle on which UMat operates on.
         The UMat instance should be kept alive during the use of the handle to prevent the buffer to be
diff --git a/modules/core/include/opencv2/core/mat.inl.hpp b/modules/core/include/opencv2/core/mat.inl.hpp
index 2e9b57ecceb..609f4bd57b3 100644
--- a/modules/core/include/opencv2/core/mat.inl.hpp
+++ b/modules/core/include/opencv2/core/mat.inl.hpp
@@ -84,7 +84,6 @@ template<typename _Tp> inline
 _InputArray::_InputArray(const std::vector<_Tp>& vec)
 { init(FIXED_TYPE + STD_VECTOR + traits::Type<_Tp>::value + ACCESS_READ, &vec); }
 
-#ifdef CV_CXX_STD_ARRAY
 template<typename _Tp, std::size_t _Nm> inline
 _InputArray::_InputArray(const std::array<_Tp, _Nm>& arr)
 { init(FIXED_TYPE + FIXED_SIZE + STD_ARRAY + traits::Type<_Tp>::value + ACCESS_READ, arr.data(), Size(1, _Nm)); }
@@ -92,7 +91,6 @@ _InputArray::_InputArray(const std::array<_Tp, _Nm>& arr)
 template<std::size_t _Nm> inline
 _InputArray::_InputArray(const std::array<Mat, _Nm>& arr)
 { init(STD_ARRAY_MAT + ACCESS_READ, arr.data(), Size(1, _Nm)); }
-#endif
 
 inline
 _InputArray::_InputArray(const std::vector<bool>& vec)
@@ -102,10 +100,6 @@ template<typename _Tp> inline
 _InputArray::_InputArray(const std::vector<std::vector<_Tp> >& vec)
 { init(FIXED_TYPE + STD_VECTOR_VECTOR + traits::Type<_Tp>::value + ACCESS_READ, &vec); }
 
-inline
-_InputArray::_InputArray(const std::vector<std::vector<bool> >&)
-{ CV_Error(Error::StsUnsupportedFormat, "std::vector<std::vector<bool> > is not supported!\n"); }
-
 template<typename _Tp> inline
 _InputArray::_InputArray(const std::vector<Mat_<_Tp> >& vec)
 { init(FIXED_TYPE + STD_VECTOR_MAT + traits::Type<_Tp>::value + ACCESS_READ, &vec); }
@@ -173,7 +167,6 @@ template<typename _Tp> inline
 _OutputArray::_OutputArray(std::vector<_Tp>& vec)
 { init(FIXED_TYPE + STD_VECTOR + traits::Type<_Tp>::value + ACCESS_WRITE, &vec); }
 
-#ifdef CV_CXX_STD_ARRAY
 template<typename _Tp, std::size_t _Nm> inline
 _OutputArray::_OutputArray(std::array<_Tp, _Nm>& arr)
 { init(FIXED_TYPE + FIXED_SIZE + STD_ARRAY + traits::Type<_Tp>::value + ACCESS_WRITE, arr.data(), Size(1, _Nm)); }
@@ -181,20 +174,11 @@ _OutputArray::_OutputArray(std::array<_Tp, _Nm>& arr)
 template<std::size_t _Nm> inline
 _OutputArray::_OutputArray(std::array<Mat, _Nm>& arr)
 { init(STD_ARRAY_MAT + ACCESS_WRITE, arr.data(), Size(1, _Nm)); }
-#endif
-
-inline
-_OutputArray::_OutputArray(std::vector<bool>&)
-{ CV_Error(Error::StsUnsupportedFormat, "std::vector<bool> cannot be an output array\n"); }
 
 template<typename _Tp> inline
 _OutputArray::_OutputArray(std::vector<std::vector<_Tp> >& vec)
 { init(FIXED_TYPE + STD_VECTOR_VECTOR + traits::Type<_Tp>::value + ACCESS_WRITE, &vec); }
 
-inline
-_OutputArray::_OutputArray(std::vector<std::vector<bool> >&)
-{ CV_Error(Error::StsUnsupportedFormat, "std::vector<std::vector<bool> > cannot be an output array\n"); }
-
 template<typename _Tp> inline
 _OutputArray::_OutputArray(std::vector<Mat_<_Tp> >& vec)
 { init(FIXED_TYPE + STD_VECTOR_MAT + traits::Type<_Tp>::value + ACCESS_WRITE, &vec); }
@@ -215,7 +199,6 @@ template<typename _Tp> inline
 _OutputArray::_OutputArray(const std::vector<_Tp>& vec)
 { init(FIXED_TYPE + FIXED_SIZE + STD_VECTOR + traits::Type<_Tp>::value + ACCESS_WRITE, &vec); }
 
-#ifdef CV_CXX_STD_ARRAY
 template<typename _Tp, std::size_t _Nm> inline
 _OutputArray::_OutputArray(const std::array<_Tp, _Nm>& arr)
 { init(FIXED_TYPE + FIXED_SIZE + STD_ARRAY + traits::Type<_Tp>::value + ACCESS_WRITE, arr.data(), Size(1, _Nm)); }
@@ -223,7 +206,6 @@ _OutputArray::_OutputArray(const std::array<_Tp, _Nm>& arr)
 template<std::size_t _Nm> inline
 _OutputArray::_OutputArray(const std::array<Mat, _Nm>& arr)
 { init(FIXED_SIZE + STD_ARRAY_MAT + ACCESS_WRITE, arr.data(), Size(1, _Nm)); }
-#endif
 
 template<typename _Tp> inline
 _OutputArray::_OutputArray(const std::vector<std::vector<_Tp> >& vec)
@@ -292,7 +274,6 @@ template<typename _Tp> inline
 _InputOutputArray::_InputOutputArray(std::vector<_Tp>& vec)
 { init(FIXED_TYPE + STD_VECTOR + traits::Type<_Tp>::value + ACCESS_RW, &vec); }
 
-#ifdef CV_CXX_STD_ARRAY
 template<typename _Tp, std::size_t _Nm> inline
 _InputOutputArray::_InputOutputArray(std::array<_Tp, _Nm>& arr)
 { init(FIXED_TYPE + FIXED_SIZE + STD_ARRAY + traits::Type<_Tp>::value + ACCESS_RW, arr.data(), Size(1, _Nm)); }
@@ -300,10 +281,6 @@ _InputOutputArray::_InputOutputArray(std::array<_Tp, _Nm>& arr)
 template<std::size_t _Nm> inline
 _InputOutputArray::_InputOutputArray(std::array<Mat, _Nm>& arr)
 { init(STD_ARRAY_MAT + ACCESS_RW, arr.data(), Size(1, _Nm)); }
-#endif
-
-inline _InputOutputArray::_InputOutputArray(std::vector<bool>&)
-{ CV_Error(Error::StsUnsupportedFormat, "std::vector<bool> cannot be an input/output array\n"); }
 
 template<typename _Tp> inline
 _InputOutputArray::_InputOutputArray(std::vector<std::vector<_Tp> >& vec)
@@ -329,7 +306,6 @@ template<typename _Tp> inline
 _InputOutputArray::_InputOutputArray(const std::vector<_Tp>& vec)
 { init(FIXED_TYPE + FIXED_SIZE + STD_VECTOR + traits::Type<_Tp>::value + ACCESS_RW, &vec); }
 
-#ifdef CV_CXX_STD_ARRAY
 template<typename _Tp, std::size_t _Nm> inline
 _InputOutputArray::_InputOutputArray(const std::array<_Tp, _Nm>& arr)
 { init(FIXED_TYPE + FIXED_SIZE + STD_ARRAY + traits::Type<_Tp>::value + ACCESS_RW, arr.data(), Size(1, _Nm)); }
@@ -337,7 +313,6 @@ _InputOutputArray::_InputOutputArray(const std::array<_Tp, _Nm>& arr)
 template<std::size_t _Nm> inline
 _InputOutputArray::_InputOutputArray(const std::array<Mat, _Nm>& arr)
 { init(FIXED_SIZE + STD_ARRAY_MAT + ACCESS_RW, arr.data(), Size(1, _Nm)); }
-#endif
 
 template<typename _Tp> inline
 _InputOutputArray::_InputOutputArray(const std::vector<std::vector<_Tp> >& vec)
@@ -568,7 +543,6 @@ Mat::Mat(const std::vector<_Tp>& vec, bool copyData)
         Mat((int)vec.size(), 1, traits::Type<_Tp>::value, (uchar*)&vec[0]).copyTo(*this);
 }
 
-#ifdef CV_CXX11
 template<typename _Tp, typename> inline
 Mat::Mat(const std::initializer_list<_Tp> list)
     : Mat()
@@ -588,9 +562,7 @@ Mat::Mat(const std::initializer_list<int> sizes, const std::initializer_list<_Tp
     CV_Assert(size_total == list.size());
     Mat((int)sizes.size(), (int*)sizes.begin(), traits::Type<_Tp>::value, (uchar*)list.begin()).copyTo(*this);
 }
-#endif
 
-#ifdef CV_CXX_STD_ARRAY
 template<typename _Tp, std::size_t _Nm> inline
 Mat::Mat(const std::array<_Tp, _Nm>& arr, bool copyData)
     : flags(MAGIC_VAL | traits::Type<_Tp>::value | CV_MAT_CONT_FLAG), dims(2), rows((int)arr.size()),
@@ -607,7 +579,6 @@ Mat::Mat(const std::array<_Tp, _Nm>& arr, bool copyData)
     else
         Mat((int)arr.size(), 1, traits::Type<_Tp>::value, (uchar*)arr.data()).copyTo(*this);
 }
-#endif
 
 template<typename _Tp, int n> inline
 Mat::Mat(const Vec<_Tp, n>& vec, bool copyData)
@@ -948,7 +919,7 @@ _Tp* Mat::ptr(int y)
 template<typename _Tp> inline
 const _Tp* Mat::ptr(int y) const
 {
-    CV_DbgAssert( y == 0 || (data && dims >= 1 && data && (unsigned)y < (unsigned)size.p[0]) );
+    CV_DbgAssert( y == 0 || (data && dims >= 1 && (unsigned)y < (unsigned)size.p[0]) );
     return (const _Tp*)(data + step.p[0] * y);
 }
 
@@ -1259,7 +1230,6 @@ Mat::operator std::vector<_Tp>() const
     return v;
 }
 
-#ifdef CV_CXX_STD_ARRAY
 template<typename _Tp, std::size_t _Nm> inline
 Mat::operator std::array<_Tp, _Nm>() const
 {
@@ -1267,7 +1237,6 @@ Mat::operator std::array<_Tp, _Nm>() const
     copyTo(v);
     return v;
 }
-#endif
 
 template<typename _Tp, int n> inline
 Mat::operator Vec<_Tp, n>() const
@@ -1335,8 +1304,6 @@ void Mat::push_back(const std::vector<_Tp>& v)
     push_back(Mat(v));
 }
 
-#ifdef CV_CXX_MOVE_SEMANTICS
-
 inline
 Mat::Mat(Mat&& m)
     : flags(m.flags), dims(m.dims), rows(m.rows), cols(m.cols), data(m.data),
@@ -1398,8 +1365,6 @@ Mat& Mat::operator = (Mat&& m)
     return *this;
 }
 
-#endif
-
 
 ///////////////////////////// MatSize ////////////////////////////
 
@@ -1644,7 +1609,6 @@ Mat_<_Tp>::Mat_(const std::vector<_Tp>& vec, bool copyData)
     : Mat(vec, copyData)
 {}
 
-#ifdef CV_CXX11
 template<typename _Tp> inline
 Mat_<_Tp>::Mat_(std::initializer_list<_Tp> list)
     : Mat(list)
@@ -1654,14 +1618,11 @@ template<typename _Tp> inline
 Mat_<_Tp>::Mat_(const std::initializer_list<int> sizes, std::initializer_list<_Tp> list)
     : Mat(sizes, list)
 {}
-#endif
 
-#ifdef CV_CXX_STD_ARRAY
 template<typename _Tp> template<std::size_t _Nm> inline
 Mat_<_Tp>::Mat_(const std::array<_Tp, _Nm>& arr, bool copyData)
     : Mat(arr, copyData)
 {}
-#endif
 
 template<typename _Tp> inline
 Mat_<_Tp>& Mat_<_Tp>::operator = (const Mat& m)
@@ -1949,7 +1910,6 @@ Mat_<_Tp>::operator std::vector<_Tp>() const
     return v;
 }
 
-#ifdef CV_CXX_STD_ARRAY
 template<typename _Tp> template<std::size_t _Nm> inline
 Mat_<_Tp>::operator std::array<_Tp, _Nm>() const
 {
@@ -1957,7 +1917,6 @@ Mat_<_Tp>::operator std::array<_Tp, _Nm>() const
     copyTo(a);
     return a;
 }
-#endif
 
 template<typename _Tp> template<int n> inline
 Mat_<_Tp>::operator Vec<typename DataType<_Tp>::channel_type, n>() const
@@ -2021,8 +1980,6 @@ void Mat_<_Tp>::forEach(const Functor& operation) const {
     Mat::forEach<_Tp, Functor>(operation);
 }
 
-#ifdef CV_CXX_MOVE_SEMANTICS
-
 template<typename _Tp> inline
 Mat_<_Tp>::Mat_(Mat_&& m)
     : Mat(m)
@@ -2070,7 +2027,6 @@ Mat_<_Tp>::Mat_(MatExpr&& e)
     *this = Mat(e);
 }
 
-#endif
 
 ///////////////////////////// SparseMat /////////////////////////////
 
@@ -3843,8 +3799,6 @@ size_t UMat::total() const
     return p;
 }
 
-#ifdef CV_CXX_MOVE_SEMANTICS
-
 inline
 UMat::UMat(UMat&& m)
 : flags(m.flags), dims(m.dims), rows(m.rows), cols(m.cols), allocator(m.allocator),
@@ -3905,8 +3859,6 @@ UMat& UMat::operator = (UMat&& m)
     return *this;
 }
 
-#endif
-
 
 inline bool UMatData::hostCopyObsolete() const { return (flags & HOST_COPY_OBSOLETE) != 0; }
 inline bool UMatData::deviceCopyObsolete() const { return (flags & DEVICE_COPY_OBSOLETE) != 0; }
diff --git a/modules/core/include/opencv2/core/matx.hpp b/modules/core/include/opencv2/core/matx.hpp
index bf3f046276a..82de1f88d83 100644
--- a/modules/core/include/opencv2/core/matx.hpp
+++ b/modules/core/include/opencv2/core/matx.hpp
@@ -53,9 +53,7 @@
 #include "opencv2/core/traits.hpp"
 #include "opencv2/core/saturate.hpp"
 
-#ifdef CV_CXX11
 #include <initializer_list>
-#endif
 
 namespace cv
 {
@@ -142,9 +140,7 @@ template<typename _Tp, int m, int n> class Matx
          _Tp v12, _Tp v13, _Tp v14, _Tp v15); //!< 1x16, 4x4 or 16x1 matrix
     explicit Matx(const _Tp* vals); //!< initialize from a plain array
 
-#ifdef CV_CXX11
     Matx(std::initializer_list<_Tp>); //!< initialize from an initializer list
-#endif
 
     static Matx all(_Tp alpha);
     static Matx zeros();
@@ -362,9 +358,7 @@ template<typename _Tp, int cn> class Vec : public Matx<_Tp, cn, 1>
     Vec(_Tp v0, _Tp v1, _Tp v2, _Tp v3, _Tp v4, _Tp v5, _Tp v6, _Tp v7, _Tp v8, _Tp v9, _Tp v10, _Tp v11, _Tp v12, _Tp v13); //!< 14-element vector constructor
     explicit Vec(const _Tp* values);
 
-#ifdef CV_CXX11
     Vec(std::initializer_list<_Tp>);
-#endif
 
     Vec(const Vec<_Tp, cn>& v);
 
@@ -666,7 +660,6 @@ Matx<_Tp, m, n>::Matx(const _Tp* values)
     for( int i = 0; i < channels; i++ ) val[i] = values[i];
 }
 
-#ifdef CV_CXX11
 template<typename _Tp, int m, int n> inline
 Matx<_Tp, m, n>::Matx(std::initializer_list<_Tp> list)
 {
@@ -677,7 +670,6 @@ Matx<_Tp, m, n>::Matx(std::initializer_list<_Tp> list)
         val[i++] = elem;
     }
 }
-#endif
 
 template<typename _Tp, int m, int n> inline
 Matx<_Tp, m, n> Matx<_Tp, m, n>::all(_Tp alpha)
@@ -1020,11 +1012,9 @@ template<typename _Tp, int cn> inline
 Vec<_Tp, cn>::Vec(const _Tp* values)
     : Matx<_Tp, cn, 1>(values) {}
 
-#ifdef CV_CXX11
 template<typename _Tp, int cn> inline
 Vec<_Tp, cn>::Vec(std::initializer_list<_Tp> list)
     : Matx<_Tp, cn, 1>(list) {}
-#endif
 
 template<typename _Tp, int cn> inline
 Vec<_Tp, cn>::Vec(const Vec<_Tp, cn>& m)
diff --git a/modules/core/include/opencv2/core/persistence.hpp b/modules/core/include/opencv2/core/persistence.hpp
index a82235b7c3f..790dde83f6c 100644
--- a/modules/core/include/opencv2/core/persistence.hpp
+++ b/modules/core/include/opencv2/core/persistence.hpp
@@ -444,7 +444,9 @@ class CV_EXPORTS_W FileStorage
     /// @overload
     CV_WRAP void write(const String& name, const String& val);
     /// @overload
-    CV_WRAP void write(const String& name, InputArray val);
+    CV_WRAP void write(const String& name, const Mat& val);
+    /// @overload
+    CV_WRAP void write(const String& name, const std::vector<String>& val);
 
     /** @brief Writes a comment.
 
@@ -574,7 +576,6 @@ class CV_EXPORTS_W_SIMPLE FileNode
     //! returns the node content as double
     operator double() const;
     //! returns the node content as text string
-    operator String() const;
     operator std::string() const;
 
     //! returns pointer to the underlying file node
@@ -718,7 +719,6 @@ CV_EXPORTS void writeScalar( FileStorage& fs, const String& value );
 CV_EXPORTS void read(const FileNode& node, int& value, int default_value);
 CV_EXPORTS void read(const FileNode& node, float& value, float default_value);
 CV_EXPORTS void read(const FileNode& node, double& value, double default_value);
-CV_EXPORTS void read(const FileNode& node, String& value, const String& default_value);
 CV_EXPORTS void read(const FileNode& node, std::string& value, const std::string& default_value);
 CV_EXPORTS void read(const FileNode& node, Mat& mat, const Mat& default_mat = Mat() );
 CV_EXPORTS void read(const FileNode& node, SparseMat& mat, const SparseMat& default_mat = SparseMat() );
@@ -1332,7 +1332,6 @@ inline const CvFileNode* FileNode::operator* () const { return node; }
 inline FileNode::operator int() const    { int value;    read(*this, value, 0);     return value; }
 inline FileNode::operator float() const  { float value;  read(*this, value, 0.f);   return value; }
 inline FileNode::operator double() const { double value; read(*this, value, 0.);    return value; }
-inline FileNode::operator String() const { String value; read(*this, value, value); return value; }
 inline double FileNode::real() const  { return double(*this); }
 inline String FileNode::string() const { return String(*this); }
 inline Mat FileNode::mat() const { Mat value; read(*this, value, value);    return value; }
@@ -1341,7 +1340,6 @@ inline FileNodeIterator FileNode::end() const   { return FileNodeIterator(fs, no
 inline void FileNode::readRaw( const String& fmt, uchar* vec, size_t len ) const { begin().readRaw( fmt, vec, len ); }
 inline FileNode FileNodeIterator::operator *() const  { return FileNode(fs, (const CvFileNode*)(const void*)reader.ptr); }
 inline FileNode FileNodeIterator::operator ->() const { return FileNode(fs, (const CvFileNode*)(const void*)reader.ptr); }
-inline String::String(const FileNode& fn): cstr_(0), len_(0) { read(fn, *this, *this); }
 
 //! @endcond
 
diff --git a/modules/core/include/opencv2/core/private.hpp b/modules/core/include/opencv2/core/private.hpp
index 26d7c0f0f44..ca0d5f88f0b 100644
--- a/modules/core/include/opencv2/core/private.hpp
+++ b/modules/core/include/opencv2/core/private.hpp
@@ -624,15 +624,6 @@ typedef enum CvStatus
 }
 CvStatus;
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-namespace tegra {
-
-CV_EXPORTS bool useTegra();
-CV_EXPORTS void setUseTegra(bool flag);
-
-}
-#endif
-
 #ifdef ENABLE_INSTRUMENTATION
 namespace cv
 {
diff --git a/modules/core/include/opencv2/core/ptr.inl.hpp b/modules/core/include/opencv2/core/ptr.inl.hpp
index 466f6342ec5..9165de0993d 100644
--- a/modules/core/include/opencv2/core/ptr.inl.hpp
+++ b/modules/core/include/opencv2/core/ptr.inl.hpp
@@ -252,8 +252,6 @@ Ptr<Y> Ptr<T>::dynamicCast() const
     return Ptr<Y>(*this, dynamic_cast<Y*>(stored));
 }
 
-#ifdef CV_CXX_MOVE_SEMANTICS
-
 template<typename T>
 Ptr<T>::Ptr(Ptr&& o) : owner(o.owner), stored(o.stored)
 {
@@ -275,8 +273,6 @@ Ptr<T>& Ptr<T>::operator = (Ptr<T>&& o)
     return *this;
 }
 
-#endif
-
 
 template<typename T>
 void swap(Ptr<T>& ptr1, Ptr<T>& ptr2){
diff --git a/modules/core/include/opencv2/core/types.hpp b/modules/core/include/opencv2/core/types.hpp
index 63232e324cf..3aabfa138df 100644
--- a/modules/core/include/opencv2/core/types.hpp
+++ b/modules/core/include/opencv2/core/types.hpp
@@ -163,10 +163,12 @@ template<typename _Tp> class Point_
     Point_();
     Point_(_Tp _x, _Tp _y);
     Point_(const Point_& pt);
+    Point_(Point_&& pt) CV_NOEXCEPT;
     Point_(const Size_<_Tp>& sz);
     Point_(const Vec<_Tp, 2>& v);
 
     Point_& operator = (const Point_& pt);
+    Point_& operator = (Point_&& pt) CV_NOEXCEPT;
     //! conversion to another data type
     template<typename _Tp2> operator Point_<_Tp2>() const;
 
@@ -243,18 +245,16 @@ template<typename _Tp> class Point3_
     Point3_();
     Point3_(_Tp _x, _Tp _y, _Tp _z);
     Point3_(const Point3_& pt);
+    Point3_(Point3_&& pt) CV_NOEXCEPT;
     explicit Point3_(const Point_<_Tp>& pt);
     Point3_(const Vec<_Tp, 3>& v);
 
     Point3_& operator = (const Point3_& pt);
+    Point3_& operator = (Point3_&& pt) CV_NOEXCEPT;
     //! conversion to another data type
     template<typename _Tp2> operator Point3_<_Tp2>() const;
     //! conversion to cv::Vec<>
-#if OPENCV_ABI_COMPATIBILITY > 300
-    template<typename _Tp2> operator Vec<_Tp2, 3>() const;
-#else
     operator Vec<_Tp, 3>() const;
-#endif
 
     //! dot product
     _Tp dot(const Point3_& pt) const;
@@ -321,11 +321,15 @@ template<typename _Tp> class Size_
     Size_();
     Size_(_Tp _width, _Tp _height);
     Size_(const Size_& sz);
+    Size_(Size_&& sz) CV_NOEXCEPT;
     Size_(const Point_<_Tp>& pt);
 
     Size_& operator = (const Size_& sz);
+    Size_& operator = (Size_&& sz) CV_NOEXCEPT;
     //! the area (width*height)
     _Tp area() const;
+    //! aspect ratio (width/height)
+    double aspectRatio() const;
     //! true if empty
     bool empty() const;
 
@@ -422,10 +426,12 @@ template<typename _Tp> class Rect_
     Rect_();
     Rect_(_Tp _x, _Tp _y, _Tp _width, _Tp _height);
     Rect_(const Rect_& r);
+    Rect_(Rect_&& r) CV_NOEXCEPT;
     Rect_(const Point_<_Tp>& org, const Size_<_Tp>& sz);
     Rect_(const Point_<_Tp>& pt1, const Point_<_Tp>& pt2);
 
     Rect_& operator = ( const Rect_& r );
+    Rect_& operator = ( Rect_&& r ) CV_NOEXCEPT;
     //! the top-left corner
     Point_<_Tp> tl() const;
     //! the bottom-right corner
@@ -635,6 +641,12 @@ template<typename _Tp> class Scalar_ : public Vec<_Tp, 4>
     Scalar_(_Tp v0, _Tp v1, _Tp v2=0, _Tp v3=0);
     Scalar_(_Tp v0);
 
+    Scalar_(const Scalar_& s);
+    Scalar_(Scalar_&& s) CV_NOEXCEPT;
+
+    Scalar_& operator=(const Scalar_& s);
+    Scalar_& operator=(Scalar_&& s) CV_NOEXCEPT;
+
     template<typename _Tp2, int cn>
     Scalar_(const Vec<_Tp2, cn>& v);
 
@@ -1156,6 +1168,10 @@ template<typename _Tp> inline
 Point_<_Tp>::Point_(const Point_& pt)
     : x(pt.x), y(pt.y) {}
 
+template<typename _Tp> inline
+Point_<_Tp>::Point_(Point_&& pt) CV_NOEXCEPT
+    : x(std::move(pt.x)), y(std::move(pt.y)) {}
+
 template<typename _Tp> inline
 Point_<_Tp>::Point_(const Size_<_Tp>& sz)
     : x(sz.width), y(sz.height) {}
@@ -1171,6 +1187,13 @@ Point_<_Tp>& Point_<_Tp>::operator = (const Point_& pt)
     return *this;
 }
 
+template<typename _Tp> inline
+Point_<_Tp>& Point_<_Tp>::operator = (Point_&& pt) CV_NOEXCEPT
+{
+    x = std::move(pt.x); y = std::move(pt.y);
+    return *this;
+}
+
 template<typename _Tp> template<typename _Tp2> inline
 Point_<_Tp>::operator Point_<_Tp2>() const
 {
@@ -1412,6 +1435,10 @@ template<typename _Tp> inline
 Point3_<_Tp>::Point3_(const Point3_& pt)
     : x(pt.x), y(pt.y), z(pt.z) {}
 
+template<typename _Tp> inline
+Point3_<_Tp>::Point3_(Point3_&& pt) CV_NOEXCEPT
+    : x(std::move(pt.x)), y(std::move(pt.y)), z(std::move(pt.z)) {}
+
 template<typename _Tp> inline
 Point3_<_Tp>::Point3_(const Point_<_Tp>& pt)
     : x(pt.x), y(pt.y), z(_Tp()) {}
@@ -1426,19 +1453,11 @@ Point3_<_Tp>::operator Point3_<_Tp2>() const
     return Point3_<_Tp2>(saturate_cast<_Tp2>(x), saturate_cast<_Tp2>(y), saturate_cast<_Tp2>(z));
 }
 
-#if OPENCV_ABI_COMPATIBILITY > 300
-template<typename _Tp> template<typename _Tp2> inline
-Point3_<_Tp>::operator Vec<_Tp2, 3>() const
-{
-    return Vec<_Tp2, 3>(x, y, z);
-}
-#else
 template<typename _Tp> inline
 Point3_<_Tp>::operator Vec<_Tp, 3>() const
 {
     return Vec<_Tp, 3>(x, y, z);
 }
-#endif
 
 template<typename _Tp> inline
 Point3_<_Tp>& Point3_<_Tp>::operator = (const Point3_& pt)
@@ -1447,6 +1466,13 @@ Point3_<_Tp>& Point3_<_Tp>::operator = (const Point3_& pt)
     return *this;
 }
 
+template<typename _Tp> inline
+Point3_<_Tp>& Point3_<_Tp>::operator = (Point3_&& pt) CV_NOEXCEPT
+{
+    x = std::move(pt.x); y = std::move(pt.y); z = std::move(pt.z);
+    return *this;
+}
+
 template<typename _Tp> inline
 _Tp Point3_<_Tp>::dot(const Point3_& pt) const
 {
@@ -1663,6 +1689,10 @@ template<typename _Tp> inline
 Size_<_Tp>::Size_(const Size_& sz)
     : width(sz.width), height(sz.height) {}
 
+template<typename _Tp> inline
+Size_<_Tp>::Size_(Size_&& sz) CV_NOEXCEPT
+    : width(std::move(sz.width)), height(std::move(sz.height)) {}
+
 template<typename _Tp> inline
 Size_<_Tp>::Size_(const Point_<_Tp>& pt)
     : width(pt.x), height(pt.y) {}
@@ -1680,6 +1710,13 @@ Size_<_Tp>& Size_<_Tp>::operator = (const Size_<_Tp>& sz)
     return *this;
 }
 
+template<typename _Tp> inline
+Size_<_Tp>& Size_<_Tp>::operator = (Size_<_Tp>&& sz) CV_NOEXCEPT
+{
+    width = std::move(sz.width); height = std::move(sz.height);
+    return *this;
+}
+
 template<typename _Tp> inline
 _Tp Size_<_Tp>::area() const
 {
@@ -1689,6 +1726,12 @@ _Tp Size_<_Tp>::area() const
     return result;
 }
 
+template<typename _Tp> inline
+double Size_<_Tp>::aspectRatio() const
+{
+    return width / static_cast<double>(height);
+}
+
 template<typename _Tp> inline
 bool Size_<_Tp>::empty() const
 {
@@ -1788,6 +1831,10 @@ template<typename _Tp> inline
 Rect_<_Tp>::Rect_(const Rect_<_Tp>& r)
     : x(r.x), y(r.y), width(r.width), height(r.height) {}
 
+template<typename _Tp> inline
+Rect_<_Tp>::Rect_(Rect_<_Tp>&& r) CV_NOEXCEPT
+    : x(std::move(r.x)), y(std::move(r.y)), width(std::move(r.width)), height(std::move(r.height)) {}
+
 template<typename _Tp> inline
 Rect_<_Tp>::Rect_(const Point_<_Tp>& org, const Size_<_Tp>& sz)
     : x(org.x), y(org.y), width(sz.width), height(sz.height) {}
@@ -1811,6 +1858,16 @@ Rect_<_Tp>& Rect_<_Tp>::operator = ( const Rect_<_Tp>& r )
     return *this;
 }
 
+template<typename _Tp> inline
+Rect_<_Tp>& Rect_<_Tp>::operator = ( Rect_<_Tp>&& r ) CV_NOEXCEPT
+{
+    x = std::move(r.x);
+    y = std::move(r.y);
+    width = std::move(r.width);
+    height = std::move(r.height);
+    return *this;
+}
+
 template<typename _Tp> inline
 Point_<_Tp> Rect_<_Tp>::tl() const
 {
@@ -1995,8 +2052,6 @@ inline
 RotatedRect::RotatedRect(const Point2f& _center, const Size2f& _size, float _angle)
     : center(_center), size(_size), angle(_angle) {}
 
-
-
 ///////////////////////////////// Range /////////////////////////////////
 
 inline
@@ -2096,6 +2151,36 @@ Scalar_<_Tp>::Scalar_(_Tp v0, _Tp v1, _Tp v2, _Tp v3)
     this->val[3] = v3;
 }
 
+template<typename _Tp> inline
+Scalar_<_Tp>::Scalar_(const Scalar_<_Tp>& s) : Vec<_Tp, 4>(s) {
+}
+
+template<typename _Tp> inline
+Scalar_<_Tp>::Scalar_(Scalar_<_Tp>&& s) CV_NOEXCEPT {
+    this->val[0] = std::move(s.val[0]);
+    this->val[1] = std::move(s.val[1]);
+    this->val[2] = std::move(s.val[2]);
+    this->val[3] = std::move(s.val[3]);
+}
+
+template<typename _Tp> inline
+Scalar_<_Tp>& Scalar_<_Tp>::operator=(const Scalar_<_Tp>& s) {
+    this->val[0] = s.val[0];
+    this->val[1] = s.val[1];
+    this->val[2] = s.val[2];
+    this->val[3] = s.val[3];
+    return *this;
+}
+
+template<typename _Tp> inline
+Scalar_<_Tp>& Scalar_<_Tp>::operator=(Scalar_<_Tp>&& s) CV_NOEXCEPT {
+    this->val[0] = std::move(s.val[0]);
+    this->val[1] = std::move(s.val[1]);
+    this->val[2] = std::move(s.val[2]);
+    this->val[3] = std::move(s.val[3]);
+    return *this;
+}
+
 template<typename _Tp> template<typename _Tp2, int cn> inline
 Scalar_<_Tp>::Scalar_(const Vec<_Tp2, cn>& v)
 {
diff --git a/modules/core/include/opencv2/core/utility.hpp b/modules/core/include/opencv2/core/utility.hpp
index a15bbff0962..03f5d44ecbf 100644
--- a/modules/core/include/opencv2/core/utility.hpp
+++ b/modules/core/include/opencv2/core/utility.hpp
@@ -56,9 +56,9 @@
 #include "opencv2/core.hpp"
 #include <ostream>
 
-#ifdef CV_CXX11
 #include <functional>
-#endif
+
+#include <mutex>  // std::mutex, std::lock_guard
 
 namespace cv
 {
@@ -555,7 +555,6 @@ class CV_EXPORTS ParallelLoopBody
 */
 CV_EXPORTS void parallel_for_(const Range& range, const ParallelLoopBody& body, double nstripes=-1.);
 
-#ifdef CV_CXX11
 class ParallelLoopBodyLambdaWrapper : public ParallelLoopBody
 {
 private:
@@ -575,7 +574,6 @@ inline void parallel_for_(const Range& range, std::function<void(const Range&)>
 {
     parallel_for_(range, ParallelLoopBodyLambdaWrapper(functor), nstripes);
 }
-#endif
 
 /////////////////////////////// forEach method of cv::Mat ////////////////////////////
 template<typename _Tp, typename Functor> inline
@@ -676,34 +674,8 @@ void Mat::forEach_impl(const Functor& operation) {
 
 /////////////////////////// Synchronization Primitives ///////////////////////////////
 
-class CV_EXPORTS Mutex
-{
-public:
-    Mutex();
-    ~Mutex();
-    Mutex(const Mutex& m);
-    Mutex& operator = (const Mutex& m);
-
-    void lock();
-    bool trylock();
-    void unlock();
-
-    struct Impl;
-protected:
-    Impl* impl;
-};
-
-class CV_EXPORTS AutoLock
-{
-public:
-    AutoLock(Mutex& m) : mutex(&m) { mutex->lock(); }
-    ~AutoLock() { mutex->unlock(); }
-protected:
-    Mutex* mutex;
-private:
-    AutoLock(const AutoLock&);
-    AutoLock& operator = (const AutoLock&);
-};
+typedef std::recursive_mutex Mutex;
+typedef std::lock_guard<cv::Mutex> AutoLock;
 
 // TLS interface
 class CV_EXPORTS TLSDataContainer
@@ -713,17 +685,10 @@ class CV_EXPORTS TLSDataContainer
     virtual ~TLSDataContainer();
 
     void  gatherData(std::vector<void*> &data) const;
-#if OPENCV_ABI_COMPATIBILITY > 300
     void* getData() const;
     void  release();
 
 private:
-#else
-    void  release();
-
-public:
-    void* getData() const;
-#endif
     virtual void* createDataInstance() const = 0;
     virtual void  deleteDataInstance(void* pData) const = 0;
 
@@ -1088,15 +1053,6 @@ template<typename _Tp, size_t fixed_size> inline size_t
 AutoBuffer<_Tp, fixed_size>::size() const
 { return sz; }
 
-template<> inline std::string CommandLineParser::get<std::string>(int index, bool space_delete) const
-{
-    return get<String>(index, space_delete);
-}
-template<> inline std::string CommandLineParser::get<std::string>(const String& name, bool space_delete) const
-{
-    return get<String>(name, space_delete);
-}
-
 //! @endcond
 
 
@@ -1267,8 +1223,4 @@ CV_EXPORTS int getThreadID();
 
 } //namespace cv
 
-#ifndef DISABLE_OPENCV_24_COMPATIBILITY
-#include "opencv2/core/core_c.h"
-#endif
-
 #endif //OPENCV_CORE_UTILITY_H
diff --git a/modules/core/include/opencv2/core/version.hpp b/modules/core/include/opencv2/core/version.hpp
index 68f476ad638..73d61a50421 100644
--- a/modules/core/include/opencv2/core/version.hpp
+++ b/modules/core/include/opencv2/core/version.hpp
@@ -5,10 +5,10 @@
 #ifndef OPENCV_VERSION_HPP
 #define OPENCV_VERSION_HPP
 
-#define CV_VERSION_MAJOR    3
-#define CV_VERSION_MINOR    4
-#define CV_VERSION_REVISION 3
-#define CV_VERSION_STATUS   "-dev"
+#define CV_VERSION_MAJOR    4
+#define CV_VERSION_MINOR    0
+#define CV_VERSION_REVISION 0
+#define CV_VERSION_STATUS   "-pre"
 
 #define CVAUX_STR_EXP(__A)  #__A
 #define CVAUX_STR(__A)      CVAUX_STR_EXP(__A)
diff --git a/modules/core/misc/python/pyopencv_core.hpp b/modules/core/misc/python/pyopencv_core.hpp
new file mode 100644
index 00000000000..9017a5beccd
--- /dev/null
+++ b/modules/core/misc/python/pyopencv_core.hpp
@@ -0,0 +1,30 @@
+#ifdef HAVE_OPENCV_CORE
+
+#include "opencv2/core/cuda.hpp"
+
+typedef std::vector<cuda::GpuMat> vector_GpuMat;
+typedef cuda::GpuMat::Allocator GpuMat_Allocator;
+typedef cuda::HostMem::AllocType HostMem_AllocType;
+typedef cuda::Event::CreateFlags Event_CreateFlags;
+
+CV_PY_TO_CLASS(cuda::GpuMat);
+CV_PY_TO_CLASS(cuda::Stream);
+CV_PY_TO_CLASS(cuda::Event);
+CV_PY_TO_CLASS(cuda::HostMem);
+
+CV_PY_TO_CLASS_PTR(cuda::GpuMat);
+CV_PY_TO_CLASS_PTR(cuda::GpuMat::Allocator);
+
+CV_PY_TO_ENUM(cuda::Event::CreateFlags);
+CV_PY_TO_ENUM(cuda::HostMem::AllocType);
+CV_PY_TO_ENUM(cuda::FeatureSet);
+
+CV_PY_FROM_CLASS(cuda::GpuMat);
+CV_PY_FROM_CLASS(cuda::Stream);
+CV_PY_FROM_CLASS(cuda::HostMem);
+
+CV_PY_FROM_CLASS_PTR(cuda::GpuMat::Allocator);
+
+CV_PY_FROM_ENUM(cuda::DeviceInfo::ComputeMode);
+
+#endif
diff --git a/modules/core/misc/python/pyopencv_umat.hpp b/modules/core/misc/python/pyopencv_umat.hpp
new file mode 100644
index 00000000000..b49b71b10c2
--- /dev/null
+++ b/modules/core/misc/python/pyopencv_umat.hpp
@@ -0,0 +1,37 @@
+#ifdef HAVE_OPENCV_CORE
+
+#include "opencv2/core/mat.hpp"
+
+typedef std::vector<Range> vector_Range;
+
+CV_PY_TO_CLASS(UMat);
+CV_PY_FROM_CLASS(UMat);
+CV_PY_TO_ENUM(UMatUsageFlags);
+
+static bool cv_mappable_to(const Ptr<Mat>& src, Ptr<UMat>& dst)
+{
+    //dst.reset(new UMat(src->getUMat(ACCESS_RW)));
+    dst.reset(new UMat());
+    src->copyTo(*dst);
+    return true;
+}
+
+static void* cv_UMat_queue()
+{
+    return cv::ocl::Queue::getDefault().ptr();
+}
+
+static void* cv_UMat_context()
+{
+    return cv::ocl::Context::getDefault().ptr();
+}
+
+static Mat cv_UMat_get(const UMat* _self)
+{
+    Mat m;
+    m.allocator = &g_numpyAllocator;
+    _self->copyTo(m);
+    return m;
+}
+
+#endif
diff --git a/modules/core/misc/python/shadow_umat.hpp b/modules/core/misc/python/shadow_umat.hpp
new file mode 100644
index 00000000000..107aedb9286
--- /dev/null
+++ b/modules/core/misc/python/shadow_umat.hpp
@@ -0,0 +1,59 @@
+#error This is a shadow header file, which is not intended for processing by any compiler. \
+       Only bindings parser should handle this file.
+
+namespace cv
+{
+
+class CV_EXPORTS_W UMat
+{
+public:
+    //! default constructor
+    CV_WRAP UMat(UMatUsageFlags usageFlags = USAGE_DEFAULT);
+    //! constructs 2D matrix of the specified size and type
+    // (_type is CV_8UC1, CV_64FC3, CV_32SC(12) etc.)
+    CV_WRAP UMat(int rows, int cols, int type, UMatUsageFlags usageFlags = USAGE_DEFAULT);
+    CV_WRAP UMat(Size size, int type, UMatUsageFlags usageFlags = USAGE_DEFAULT);
+    //! constucts 2D matrix and fills it with the specified value _s.
+    CV_WRAP UMat(int rows, int cols, int type, const Scalar& s, UMatUsageFlags usageFlags = USAGE_DEFAULT);
+    CV_WRAP UMat(Size size, int type, const Scalar& s, UMatUsageFlags usageFlags = USAGE_DEFAULT);
+
+    //! Mat is mappable to UMat
+    CV_WRAP_MAPPABLE(Ptr<Mat>);
+
+    //! returns the OpenCL queue used by OpenCV UMat
+    CV_WRAP_PHANTOM(static void* queue());
+
+    //! returns the OpenCL context used by OpenCV UMat
+    CV_WRAP_PHANTOM(static void* context());
+
+    //! copy constructor
+    CV_WRAP UMat(const UMat& m);
+
+    //! creates a matrix header for a part of the bigger matrix
+    CV_WRAP UMat(const UMat& m, const Range& rowRange, const Range& colRange = Range::all());
+    CV_WRAP UMat(const UMat& m, const Rect& roi);
+    CV_WRAP UMat(const UMat& m, const std::vector<Range>& ranges);
+
+    //CV_WRAP_AS(get) Mat getMat(int flags CV_WRAP_DEFAULT(ACCESS_RW)) const;
+    //! returns a numpy matrix
+    CV_WRAP_PHANTOM(Mat get() const);
+
+    //! returns true iff the matrix data is continuous
+    // (i.e. when there are no gaps between successive rows).
+    // similar to CV_IS_MAT_CONT(cvmat->type)
+    CV_WRAP bool isContinuous() const;
+
+    //! returns true if the matrix is a submatrix of another matrix
+    CV_WRAP bool isSubmatrix() const;
+
+    /*! Returns the OpenCL buffer handle on which UMat operates on.
+    The UMat instance should be kept alive during the use of the handle to prevent the buffer to be
+    returned to the OpenCV buffer pool.
+    */
+    CV_WRAP void* handle(int accessFlags) const;
+
+    // offset of the submatrix (or 0)
+    CV_PROP_RW size_t offset;
+};
+
+} // namespace cv
diff --git a/modules/core/perf/perf_main.cpp b/modules/core/perf/perf_main.cpp
index 7c899c2446d..996dedfeb65 100644
--- a/modules/core/perf/perf_main.cpp
+++ b/modules/core/perf/perf_main.cpp
@@ -5,4 +5,8 @@
 # endif
 #endif
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_PERF_TEST_MAIN(core)
diff --git a/modules/core/src/arithm.cpp b/modules/core/src/arithm.cpp
index dbfcc5c7270..1a464c9aecc 100644
--- a/modules/core/src/arithm.cpp
+++ b/modules/core/src/arithm.cpp
@@ -270,7 +270,7 @@ static void binary_op( InputArray _src1, InputArray _src2, OutputArray _dst,
     if( !haveScalar )
     {
         const Mat* arrays[] = { &src1, &src2, &dst, &mask, 0 };
-        uchar* ptrs[4];
+        uchar* ptrs[4]{};
 
         NAryMatIterator it(arrays, ptrs);
         size_t total = it.size, blocksize = total;
@@ -306,7 +306,7 @@ static void binary_op( InputArray _src1, InputArray _src2, OutputArray _dst,
     else
     {
         const Mat* arrays[] = { &src1, &dst, &mask, 0 };
-        uchar* ptrs[3];
+        uchar* ptrs[3]{};
 
         NAryMatIterator it(arrays, ptrs);
         size_t total = it.size, blocksize = std::min(total, blocksize0);
@@ -745,7 +745,7 @@ static void arithm_op(InputArray _src1, InputArray _src2, OutputArray _dst,
     if( !haveScalar )
     {
         const Mat* arrays[] = { &src1, &src2, &dst, &mask, 0 };
-        uchar* ptrs[4];
+        uchar* ptrs[4]{};
 
         NAryMatIterator it(arrays, ptrs);
         size_t total = it.size, blocksize = total;
@@ -812,7 +812,7 @@ static void arithm_op(InputArray _src1, InputArray _src2, OutputArray _dst,
     else
     {
         const Mat* arrays[] = { &src1, &dst, &mask, 0 };
-        uchar* ptrs[3];
+        uchar* ptrs[3]{};
 
         NAryMatIterator it(arrays, ptrs);
         size_t total = it.size, blocksize = std::min(total, blocksize0);
@@ -931,59 +931,6 @@ void cv::subtract( InputArray _src1, InputArray _src2, OutputArray _dst,
 {
     CV_INSTRUMENT_REGION()
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    if (tegra::useTegra())
-    {
-        int kind1 = _src1.kind(), kind2 = _src2.kind();
-        Mat src1 = _src1.getMat(), src2 = _src2.getMat();
-        bool src1Scalar = checkScalar(src1, _src2.type(), kind1, kind2);
-        bool src2Scalar = checkScalar(src2, _src1.type(), kind2, kind1);
-
-        if (!src1Scalar && !src2Scalar &&
-            src1.depth() == CV_8U && src2.type() == src1.type() &&
-            src1.dims == 2 && src2.size() == src1.size() &&
-            mask.empty())
-        {
-            if (dtype < 0)
-            {
-                if (_dst.fixedType())
-                {
-                    dtype = _dst.depth();
-                }
-                else
-                {
-                    dtype = src1.depth();
-                }
-            }
-
-            dtype = CV_MAT_DEPTH(dtype);
-
-            if (!_dst.fixedType() || dtype == _dst.depth())
-            {
-                _dst.create(src1.size(), CV_MAKE_TYPE(dtype, src1.channels()));
-
-                if (dtype == CV_16S)
-                {
-                    Mat dst = _dst.getMat();
-                    if(tegra::subtract_8u8u16s(src1, src2, dst))
-                        return;
-                }
-                else if (dtype == CV_32F)
-                {
-                    Mat dst = _dst.getMat();
-                    if(tegra::subtract_8u8u32f(src1, src2, dst))
-                        return;
-                }
-                else if (dtype == CV_8S)
-                {
-                    Mat dst = _dst.getMat();
-                    if(tegra::subtract_8u8u8s(src1, src2, dst))
-                        return;
-                }
-            }
-        }
-    }
-#endif
     arithm_op(_src1, _src2, _dst, mask, dtype, getSubTab(), false, 0, OCL_OP_SUB );
 }
 
@@ -1293,7 +1240,7 @@ void cv::compare(InputArray _src1, InputArray _src2, OutputArray _dst, int op)
     if( !haveScalar )
     {
         const Mat* arrays[] = { &src1, &src2, &dst, 0 };
-        uchar* ptrs[3];
+        uchar* ptrs[3]{};
 
         NAryMatIterator it(arrays, ptrs);
         size_t total = it.size;
@@ -1304,7 +1251,7 @@ void cv::compare(InputArray _src1, InputArray _src2, OutputArray _dst, int op)
     else
     {
         const Mat* arrays[] = { &src1, &dst, 0 };
-        uchar* ptrs[2];
+        uchar* ptrs[2]{};
 
         NAryMatIterator it(arrays, ptrs);
         size_t total = it.size, blocksize = std::min(total, blocksize0);
@@ -1801,7 +1748,7 @@ void cv::inRange(InputArray _src, InputArray _lowerb,
 
     const Mat* arrays_sc[] = { &src, &dst, 0 };
     const Mat* arrays_nosc[] = { &src, &dst, &lb, &ub, 0 };
-    uchar* ptrs[4];
+    uchar* ptrs[4]{};
 
     NAryMatIterator it(lbScalar && ubScalar ? arrays_sc : arrays_nosc, ptrs);
     size_t total = it.size, blocksize = std::min(total, blocksize0);
diff --git a/modules/core/src/check.cpp b/modules/core/src/check.cpp
index fca982656e3..92a3b6006e4 100644
--- a/modules/core/src/check.cpp
+++ b/modules/core/src/check.cpp
@@ -67,7 +67,7 @@ void check_failed_auto_(const T& v1, const T& v2, const CheckContext& ctx)
         ss << "must be " << getTestOpPhraseStr(ctx.testOp) << std::endl;
     }
     ss  << "    '" << ctx.p2_str << "' is " << v2;
-    cv::errorNoReturn(cv::Error::StsError, ss.str(), ctx.func, ctx.file, ctx.line);
+    cv::error(cv::Error::StsError, ss.str(), ctx.func, ctx.file, ctx.line);
 }
 void check_failed_MatDepth(const int v1, const int v2, const CheckContext& ctx)
 {
@@ -79,7 +79,7 @@ void check_failed_MatDepth(const int v1, const int v2, const CheckContext& ctx)
         ss << "must be " << getTestOpPhraseStr(ctx.testOp) << std::endl;
     }
     ss  << "    '" << ctx.p2_str << "' is " << v2 << " (" << depthToString(v2) << ")";
-    cv::errorNoReturn(cv::Error::StsError, ss.str(), ctx.func, ctx.file, ctx.line);
+    cv::error(cv::Error::StsError, ss.str(), ctx.func, ctx.file, ctx.line);
 }
 void check_failed_MatType(const int v1, const int v2, const CheckContext& ctx)
 {
@@ -91,7 +91,7 @@ void check_failed_MatType(const int v1, const int v2, const CheckContext& ctx)
         ss << "must be " << getTestOpPhraseStr(ctx.testOp) << std::endl;
     }
     ss  << "    '" << ctx.p2_str << "' is " << v2 << " (" << typeToString(v2) << ")";
-    cv::errorNoReturn(cv::Error::StsError, ss.str(), ctx.func, ctx.file, ctx.line);
+    cv::error(cv::Error::StsError, ss.str(), ctx.func, ctx.file, ctx.line);
 }
 void check_failed_MatChannels(const int v1, const int v2, const CheckContext& ctx)
 {
@@ -123,7 +123,7 @@ void check_failed_auto_(const T& v, const CheckContext& ctx)
         << "    '" << ctx.p2_str << "'" << std::endl
         << "where" << std::endl
         << "    '" << ctx.p1_str << "' is " << v;
-    cv::errorNoReturn(cv::Error::StsError, ss.str(), ctx.func, ctx.file, ctx.line);
+    cv::error(cv::Error::StsError, ss.str(), ctx.func, ctx.file, ctx.line);
 }
 void check_failed_MatDepth(const int v, const CheckContext& ctx)
 {
@@ -132,7 +132,7 @@ void check_failed_MatDepth(const int v, const CheckContext& ctx)
         << "    '" << ctx.p2_str << "'" << std::endl
         << "where" << std::endl
         << "    '" << ctx.p1_str << "' is " << v << " (" << depthToString(v) << ")";
-    cv::errorNoReturn(cv::Error::StsError, ss.str(), ctx.func, ctx.file, ctx.line);
+    cv::error(cv::Error::StsError, ss.str(), ctx.func, ctx.file, ctx.line);
 }
 void check_failed_MatType(const int v, const CheckContext& ctx)
 {
@@ -141,7 +141,7 @@ void check_failed_MatType(const int v, const CheckContext& ctx)
         << "    '" << ctx.p2_str << "'" << std::endl
         << "where" << std::endl
         << "    '" << ctx.p1_str << "' is " << v << " (" << typeToString(v) << ")";
-    cv::errorNoReturn(cv::Error::StsError, ss.str(), ctx.func, ctx.file, ctx.line);
+    cv::error(cv::Error::StsError, ss.str(), ctx.func, ctx.file, ctx.line);
 }
 void check_failed_MatChannels(const int v, const CheckContext& ctx)
 {
diff --git a/modules/core/src/command_line_parser.cpp b/modules/core/src/command_line_parser.cpp
index 766835fe1d4..6ef24d2cd03 100644
--- a/modules/core/src/command_line_parser.cpp
+++ b/modules/core/src/command_line_parser.cpp
@@ -72,14 +72,9 @@ static const char* get_type_name(int type)
     return "unknown";
 }
 
-// std::tolower is int->int
-static char char_tolower(char ch)
-{
-    return (char)std::tolower((int)ch);
-}
 static bool parse_bool(std::string str)
 {
-    std::transform(str.begin(), str.end(), str.begin(), char_tolower);
+    std::transform(str.begin(), str.end(), str.begin(), details::char_tolower);
     std::istringstream is(str);
     bool b;
     is >> (str.size() > 1 ? std::boolalpha : std::noboolalpha) >> b;
diff --git a/modules/core/src/convert.cpp b/modules/core/src/convert.cpp
index e5fd24dfadc..7a027dd809e 100644
--- a/modules/core/src/convert.cpp
+++ b/modules/core/src/convert.cpp
@@ -1347,7 +1347,7 @@ void cv::Mat::convertTo(OutputArray _dst, int _type, double alpha, double beta)
     else
     {
         const Mat* arrays[] = {&src, &dst, 0};
-        uchar* ptrs[2];
+        uchar* ptrs[2]{};
         NAryMatIterator it(arrays, ptrs);
         Size sz((int)(it.size*cn), 1);
 
@@ -1496,7 +1496,7 @@ void cv::convertFp16( InputArray _src, OutputArray _dst)
     else
     {
         const Mat* arrays[] = {&src, &dst, 0};
-        uchar* ptrs[2];
+        uchar* ptrs[2]{};
         NAryMatIterator it(arrays, ptrs);
         Size sz((int)(it.size*cn), 1);
 
diff --git a/modules/core/src/convert_scale.cpp b/modules/core/src/convert_scale.cpp
index ff8398a27b9..44a968ff6c4 100644
--- a/modules/core/src/convert_scale.cpp
+++ b/modules/core/src/convert_scale.cpp
@@ -1775,7 +1775,7 @@ void cv::convertScaleAbs( InputArray _src, OutputArray _dst, double alpha, doubl
     else
     {
         const Mat* arrays[] = {&src, &dst, 0};
-        uchar* ptrs[2];
+        uchar* ptrs[2]{};
         NAryMatIterator it(arrays, ptrs);
         Size sz((int)it.size*cn, 1);
 
diff --git a/modules/core/src/copy.cpp b/modules/core/src/copy.cpp
index e89a17b323f..66ce393b3fa 100644
--- a/modules/core/src/copy.cpp
+++ b/modules/core/src/copy.cpp
@@ -306,7 +306,7 @@ void Mat::copyTo( OutputArray _dst ) const
     if( total() != 0 )
     {
         const Mat* arrays[] = { this, &dst };
-        uchar* ptrs[2];
+        uchar* ptrs[2]{};
         NAryMatIterator it(arrays, ptrs, 2);
         size_t sz = it.size*elemSize();
 
@@ -399,7 +399,7 @@ void Mat::copyTo( OutputArray _dst, InputArray _mask ) const
     }
 
     const Mat* arrays[] = { this, &dst, &mask, 0 };
-    uchar* ptrs[3];
+    uchar* ptrs[3]{};
     NAryMatIterator it(arrays, ptrs);
     Size sz((int)(it.size*mcn), 1);
 
diff --git a/modules/core/src/count_non_zero.cpp b/modules/core/src/count_non_zero.cpp
index 368dcfc3a64..804d46dc34e 100644
--- a/modules/core/src/count_non_zero.cpp
+++ b/modules/core/src/count_non_zero.cpp
@@ -378,7 +378,7 @@ int cv::countNonZero( InputArray _src )
     CV_Assert( func != 0 );
 
     const Mat* arrays[] = {&src, 0};
-    uchar* ptrs[1];
+    uchar* ptrs[1]{};
     NAryMatIterator it(arrays, ptrs);
     int total = (int)it.size, nz = 0;
 
@@ -393,25 +393,60 @@ void cv::findNonZero( InputArray _src, OutputArray _idx )
     CV_INSTRUMENT_REGION()
 
     Mat src = _src.getMat();
-    CV_Assert( src.type() == CV_8UC1 );
-    int n = countNonZero(src);
-    if( n == 0 )
+    CV_Assert( src.channels() == 1 && src.dims == 2 );
+
+    int depth = src.depth();
+    std::vector<Point> idxvec;
+    int rows = src.rows, cols = src.cols;
+    AutoBuffer<int> buf_(cols + 1);
+    int* buf = buf_.data();
+
+    for( int i = 0; i < rows; i++ )
     {
-        _idx.release();
-        return;
+        int j, k = 0;
+        const uchar* ptr8 = src.ptr(i);
+        if( depth == CV_8U || depth == CV_8S )
+        {
+            for( j = 0; j < cols; j++ )
+                if( ptr8[j] != 0 ) buf[k++] = j;
+        }
+        else if( depth == CV_16U || depth == CV_16S )
+        {
+            const ushort* ptr16 = (const ushort*)ptr8;
+            for( j = 0; j < cols; j++ )
+                if( ptr16[j] != 0 ) buf[k++] = j;
+        }
+        else if( depth == CV_32S )
+        {
+            const int* ptr32s = (const int*)ptr8;
+            for( j = 0; j < cols; j++ )
+                if( ptr32s[j] != 0 ) buf[k++] = j;
+        }
+        else if( depth == CV_32F )
+        {
+            const float* ptr32f = (const float*)ptr8;
+            for( j = 0; j < cols; j++ )
+                if( ptr32f[j] != 0 ) buf[k++] = j;
+        }
+        else
+        {
+            const double* ptr64f = (const double*)ptr8;
+            for( j = 0; j < cols; j++ )
+                if( ptr64f[j] != 0 ) buf[k++] = j;
+        }
+
+        if( k > 0 )
+        {
+            size_t sz = idxvec.size();
+            idxvec.resize(sz + k);
+            for( j = 0; j < k; j++ )
+                idxvec[sz + j] = Point(buf[j], i);
+        }
     }
-    if( _idx.kind() == _InputArray::MAT && !_idx.getMatRef().isContinuous() )
+
+    if( idxvec.empty() || (_idx.kind() == _InputArray::MAT && !_idx.getMatRef().isContinuous()) )
         _idx.release();
-    _idx.create(n, 1, CV_32SC2);
-    Mat idx = _idx.getMat();
-    CV_Assert(idx.isContinuous());
-    Point* idx_ptr = idx.ptr<Point>();
 
-    for( int i = 0; i < src.rows; i++ )
-    {
-        const uchar* bin_ptr = src.ptr(i);
-        for( int j = 0; j < src.cols; j++ )
-            if( bin_ptr[j] )
-                *idx_ptr++ = Point(j, i);
-    }
+    if( !idxvec.empty() )
+        Mat(idxvec).copyTo(_idx);
 }
diff --git a/modules/core/src/lda.cpp b/modules/core/src/lda.cpp
index 5acdb24c626..6d43270a2ae 100644
--- a/modules/core/src/lda.cpp
+++ b/modules/core/src/lda.cpp
@@ -996,9 +996,9 @@ void eigenNonSymmetric(InputArray _src, OutputArray _evals, OutputArray _evects)
 // Linear Discriminant Analysis implementation
 //------------------------------------------------------------------------------
 
-LDA::LDA(int num_components) : _dataAsRow(true), _num_components(num_components) { }
+LDA::LDA(int num_components) : _num_components(num_components) { }
 
-LDA::LDA(InputArrayOfArrays src, InputArray labels, int num_components) : _dataAsRow(true),  _num_components(num_components)
+LDA::LDA(InputArrayOfArrays src, InputArray labels, int num_components) : _num_components(num_components)
 {
     this->compute(src, labels); //! compute eigenvectors and eigenvalues
 }
diff --git a/modules/core/src/lut.cpp b/modules/core/src/lut.cpp
index 71f06ea5b25..6ed26b69097 100644
--- a/modules/core/src/lut.cpp
+++ b/modules/core/src/lut.cpp
@@ -342,7 +342,7 @@ class LUTParallelBody : public ParallelLoopBody
         int lutcn = lut_.channels();
 
         const Mat* arrays[] = {&src, &dst, 0};
-        uchar* ptrs[2];
+        uchar* ptrs[2]{};
         NAryMatIterator it(arrays, ptrs);
         int len = (int)it.size;
 
@@ -408,7 +408,7 @@ void cv::LUT( InputArray _src, InputArray _lut, OutputArray _dst )
     CV_Assert( func != 0 );
 
     const Mat* arrays[] = {&src, &dst, 0};
-    uchar* ptrs[2];
+    uchar* ptrs[2]{};
     NAryMatIterator it(arrays, ptrs);
     int len = (int)it.size;
 
diff --git a/modules/core/src/mathfuncs.cpp b/modules/core/src/mathfuncs.cpp
index 5737e8d0b34..89fad4e7344 100644
--- a/modules/core/src/mathfuncs.cpp
+++ b/modules/core/src/mathfuncs.cpp
@@ -158,7 +158,7 @@ void magnitude( InputArray src1, InputArray src2, OutputArray dst )
     Mat Mag = dst.getMat();
 
     const Mat* arrays[] = {&X, &Y, &Mag, 0};
-    uchar* ptrs[3];
+    uchar* ptrs[3]{};
     NAryMatIterator it(arrays, ptrs);
     int len = (int)it.size*cn;
 
@@ -194,7 +194,7 @@ void phase( InputArray src1, InputArray src2, OutputArray dst, bool angleInDegre
     Mat Angle = dst.getMat();
 
     const Mat* arrays[] = {&X, &Y, &Angle, 0};
-    uchar* ptrs[3];
+    uchar* ptrs[3]{};
     NAryMatIterator it(arrays, ptrs);
     int j, total = (int)(it.size*cn), blockSize = total;
     size_t esz1 = X.elemSize1();
@@ -280,7 +280,7 @@ void cartToPolar( InputArray src1, InputArray src2,
     Mat Mag = dst1.getMat(), Angle = dst2.getMat();
 
     const Mat* arrays[] = {&X, &Y, &Mag, &Angle, 0};
-    uchar* ptrs[4];
+    uchar* ptrs[4]{};
     NAryMatIterator it(arrays, ptrs);
     int j, total = (int)(it.size*cn), blockSize = std::min(total, ((BLOCK_SIZE+cn-1)/cn)*cn);
     size_t esz1 = X.elemSize1();
@@ -577,7 +577,7 @@ void polarToCart( InputArray src1, InputArray src2,
     CV_IPP_RUN(!angleInDegrees, ipp_polarToCart(Mag, Angle, X, Y));
 
     const Mat* arrays[] = {&Mag, &Angle, &X, &Y, 0};
-    uchar* ptrs[4];
+    uchar* ptrs[4]{};
     NAryMatIterator it(arrays, ptrs);
     cv::AutoBuffer<float> _buf;
     float* buf[2] = {0, 0};
@@ -676,7 +676,7 @@ void exp( InputArray _src, OutputArray _dst )
     Mat dst = _dst.getMat();
 
     const Mat* arrays[] = {&src, &dst, 0};
-    uchar* ptrs[2];
+    uchar* ptrs[2]{};
     NAryMatIterator it(arrays, ptrs);
     int len = (int)(it.size*cn);
 
@@ -709,7 +709,7 @@ void log( InputArray _src, OutputArray _dst )
     Mat dst = _dst.getMat();
 
     const Mat* arrays[] = {&src, &dst, 0};
-    uchar* ptrs[2];
+    uchar* ptrs[2]{};
     NAryMatIterator it(arrays, ptrs);
     int len = (int)(it.size*cn);
 
@@ -1241,7 +1241,7 @@ void pow( InputArray _src, double power, OutputArray _dst )
     Mat dst = _dst.getMat();
 
     const Mat* arrays[] = {&src, &dst, 0};
-    uchar* ptrs[2];
+    uchar* ptrs[2]{};
     NAryMatIterator it(arrays, ptrs);
     int len = (int)(it.size*cn);
 
@@ -1588,7 +1588,7 @@ void patchNaNs( InputOutputArray _a, double _val )
 
     Mat a = _a.getMat();
     const Mat* arrays[] = {&a, 0};
-    int* ptrs[1];
+    int* ptrs[1]{};
     NAryMatIterator it(arrays, (uchar**)ptrs);
     size_t len = it.size*a.channels();
     Cv32suf val;
diff --git a/modules/core/src/matmul.cpp b/modules/core/src/matmul.cpp
index 83607c71848..7c5655e9e6f 100644
--- a/modules/core/src/matmul.cpp
+++ b/modules/core/src/matmul.cpp
@@ -2144,7 +2144,7 @@ void cv::transform( InputArray _src, OutputArray _dst, InputArray _mtx )
     CV_Assert( func != 0 );
 
     const Mat* arrays[] = {&src, &dst, 0};
-    uchar* ptrs[2];
+    uchar* ptrs[2]{};
     NAryMatIterator it(arrays, ptrs);
     size_t i, total = it.size;
 
@@ -2290,7 +2290,7 @@ void cv::perspectiveTransform( InputArray _src, OutputArray _dst, InputArray _mt
     CV_Assert( func != 0 );
 
     const Mat* arrays[] = {&src, &dst, 0};
-    uchar* ptrs[2];
+    uchar* ptrs[2]{};
     NAryMatIterator it(arrays, ptrs);
     size_t i, total = it.size;
 
@@ -2441,7 +2441,7 @@ void cv::scaleAdd( InputArray _src1, double alpha, InputArray _src2, OutputArray
     }
 
     const Mat* arrays[] = {&src1, &src2, &dst, 0};
-    uchar* ptrs[3];
+    uchar* ptrs[3]{};
     NAryMatIterator it(arrays, ptrs);
     size_t i, len = it.size*cn;
 
@@ -3301,7 +3301,7 @@ double Mat::dot(InputArray _mat) const
     }
 
     const Mat* arrays[] = {this, &mat, 0};
-    uchar* ptrs[2];
+    uchar* ptrs[2]{};
     NAryMatIterator it(arrays, ptrs);
     int len = (int)(it.size*cn);
     double r = 0;
diff --git a/modules/core/src/matrix_sparse.cpp b/modules/core/src/matrix_sparse.cpp
index a2f061cab36..f30a389f4e2 100644
--- a/modules/core/src/matrix_sparse.cpp
+++ b/modules/core/src/matrix_sparse.cpp
@@ -228,7 +228,7 @@ void SparseMat::create(int d, const int* _sizes, int _type)
         }
     }
     int _sizes_backup[CV_MAX_DIM]; // #5991
-    if (_sizes == hdr->size)
+    if ( hdr && _sizes == hdr->size)
     {
         for(int i = 0; i < d; i++ )
             _sizes_backup[i] = _sizes[i];
diff --git a/modules/core/src/matrix_wrap.cpp b/modules/core/src/matrix_wrap.cpp
index bea5c670b62..d39de187013 100644
--- a/modules/core/src/matrix_wrap.cpp
+++ b/modules/core/src/matrix_wrap.cpp
@@ -939,7 +939,7 @@ bool _InputArray::isContinuous(int i) const
     if( k == STD_VECTOR_MAT )
     {
         const std::vector<Mat>& vv = *(const std::vector<Mat>*)obj;
-        CV_Assert((size_t)i < vv.size());
+        CV_Assert(i >= 0 && (size_t)i < vv.size());
         return vv[i].isContinuous();
     }
 
@@ -953,7 +953,7 @@ bool _InputArray::isContinuous(int i) const
     if( k == STD_VECTOR_UMAT )
     {
         const std::vector<UMat>& vv = *(const std::vector<UMat>*)obj;
-        CV_Assert((size_t)i < vv.size());
+        CV_Assert(i >= 0 && (size_t)i < vv.size());
         return vv[i].isContinuous();
     }
 
diff --git a/modules/core/src/mean.cpp b/modules/core/src/mean.cpp
index dcf1ae206cd..0badfa2f652 100644
--- a/modules/core/src/mean.cpp
+++ b/modules/core/src/mean.cpp
@@ -121,7 +121,7 @@ cv::Scalar cv::mean( InputArray _src, InputArray _mask )
     CV_Assert( cn <= 4 && func != 0 );
 
     const Mat* arrays[] = {&src, &mask, 0};
-    uchar* ptrs[2];
+    uchar* ptrs[2]{};
     NAryMatIterator it(arrays, ptrs);
     int total = (int)it.size, blockSize = total, intSumBlockSize = 0;
     int j, count = 0;
@@ -786,7 +786,7 @@ void cv::meanStdDev( InputArray _src, OutputArray _mean, OutputArray _sdv, Input
     CV_Assert( func != 0 );
 
     const Mat* arrays[] = {&src, &mask, 0};
-    uchar* ptrs[2];
+    uchar* ptrs[2]{};
     NAryMatIterator it(arrays, ptrs);
     int total = (int)it.size, blockSize = total, intSumBlockSize = 0;
     int j, count = 0, nz0 = 0;
diff --git a/modules/core/src/minmax.cpp b/modules/core/src/minmax.cpp
index d2b56646b88..371438184e7 100644
--- a/modules/core/src/minmax.cpp
+++ b/modules/core/src/minmax.cpp
@@ -770,7 +770,7 @@ void cv::minMaxIdx(InputArray _src, double* minVal,
     CV_Assert( func != 0 );
 
     const Mat* arrays[] = {&src, &mask, 0};
-    uchar* ptrs[2];
+    uchar* ptrs[2]{};
     NAryMatIterator it(arrays, ptrs);
 
     size_t minidx = 0, maxidx = 0;
diff --git a/modules/core/src/norm.cpp b/modules/core/src/norm.cpp
index d12dfc742d9..40d195c3f87 100644
--- a/modules/core/src/norm.cpp
+++ b/modules/core/src/norm.cpp
@@ -710,7 +710,7 @@ double cv::norm( InputArray _src, int normType, InputArray _mask )
         int cellSize = normType == NORM_HAMMING ? 1 : 2;
 
         const Mat* arrays[] = {&src, 0};
-        uchar* ptrs[1];
+        uchar* ptrs[1]{};
         NAryMatIterator it(arrays, ptrs);
         int total = (int)it.size;
         int result = 0;
@@ -727,7 +727,7 @@ double cv::norm( InputArray _src, int normType, InputArray _mask )
     CV_Assert( func != 0 );
 
     const Mat* arrays[] = {&src, &mask, 0};
-    uchar* ptrs[2];
+    uchar* ptrs[2]{};
     union
     {
         double d;
@@ -1168,7 +1168,7 @@ double cv::norm( InputArray _src1, InputArray _src2, int normType, InputArray _m
         int cellSize = normType == NORM_HAMMING ? 1 : 2;
 
         const Mat* arrays[] = {&src1, &src2, 0};
-        uchar* ptrs[2];
+        uchar* ptrs[2]{};
         NAryMatIterator it(arrays, ptrs);
         int total = (int)it.size;
         int result = 0;
@@ -1185,7 +1185,7 @@ double cv::norm( InputArray _src1, InputArray _src2, int normType, InputArray _m
     CV_Assert( func != 0 );
 
     const Mat* arrays[] = {&src1, &src2, &mask, 0};
-    uchar* ptrs[3];
+    uchar* ptrs[3]{};
     union
     {
         double d;
@@ -1251,13 +1251,13 @@ cv::Hamming::ResultType cv::Hamming::operator()( const unsigned char* a, const u
     return cv::hal::normHamming(a, b, size);
 }
 
-double cv::PSNR(InputArray _src1, InputArray _src2)
+double cv::PSNR(InputArray _src1, InputArray _src2, double R)
 {
     CV_INSTRUMENT_REGION()
 
     //Input arrays must have depth CV_8U
-    CV_Assert( _src1.depth() == CV_8U && _src2.depth() == CV_8U );
+    CV_Assert( _src1.type() == _src2.type() );
 
     double diff = std::sqrt(norm(_src1, _src2, NORM_L2SQR)/(_src1.total()*_src1.channels()));
-    return 20*log10(255./(diff+DBL_EPSILON));
+    return 20*log10(R/(diff+DBL_EPSILON));
 }
diff --git a/modules/core/src/ocl.cpp b/modules/core/src/ocl.cpp
index 05f128baa73..95d51f9cc5c 100644
--- a/modules/core/src/ocl.cpp
+++ b/modules/core/src/ocl.cpp
@@ -1691,11 +1691,6 @@ static cl_device_id selectOpenCLDevice()
     return NULL;
 }
 #else
-// std::tolower is int->int
-static char char_tolower(char ch)
-{
-    return (char)std::tolower((int)ch);
-}
 static cl_device_id selectOpenCLDevice()
 {
     std::string platform, deviceName;
@@ -1780,7 +1775,7 @@ static cl_device_id selectOpenCLDevice()
     {
         int deviceType = 0;
         std::string tempStrDeviceType = deviceTypes[t];
-        std::transform(tempStrDeviceType.begin(), tempStrDeviceType.end(), tempStrDeviceType.begin(), char_tolower);
+        std::transform(tempStrDeviceType.begin(), tempStrDeviceType.end(), tempStrDeviceType.begin(), details::char_tolower);
 
         if (tempStrDeviceType == "gpu" || tempStrDeviceType == "dgpu" || tempStrDeviceType == "igpu")
             deviceType = Device::TYPE_GPU;
diff --git a/modules/core/src/opengl.cpp b/modules/core/src/opengl.cpp
index 6661b669a4d..c9a790dd955 100644
--- a/modules/core/src/opengl.cpp
+++ b/modules/core/src/opengl.cpp
@@ -82,7 +82,7 @@ inline static bool checkError(const char* file, const int line, const char* func
         default:
             msg = "Unknown error";
         };
-        cv::errorNoReturn(Error::OpenGlApiCallError, func, msg, file, line);
+        cv::error(Error::OpenGlApiCallError, func, msg, file, line);
     }
     return true;
 }
diff --git a/modules/core/src/parallel.cpp b/modules/core/src/parallel.cpp
index 88075a6ce2f..225e766aa34 100644
--- a/modules/core/src/parallel.cpp
+++ b/modules/core/src/parallel.cpp
@@ -78,13 +78,13 @@
 #endif
 
 /* IMPORTANT: always use the same order of defines
-   1. HAVE_TBB         - 3rdparty library, should be explicitly enabled
-   2. HAVE_CSTRIPES    - 3rdparty library, should be explicitly enabled
-   3. HAVE_OPENMP      - integrated to compiler, should be explicitly enabled
-   4. HAVE_GCD         - system wide, used automatically        (APPLE only)
-   5. WINRT            - system wide, used automatically        (Windows RT only)
-   6. HAVE_CONCURRENCY - part of runtime, used automatically    (Windows only - MSVS 10, MSVS 11)
-   7. HAVE_PTHREADS_PF - pthreads if available
+   - HAVE_TBB         - 3rdparty library, should be explicitly enabled
+   - HAVE_HPX         - 3rdparty library, should be explicitly enabled
+   - HAVE_OPENMP      - integrated to compiler, should be explicitly enabled
+   - HAVE_GCD         - system wide, used automatically        (APPLE only)
+   - WINRT            - system wide, used automatically        (Windows RT only)
+   - HAVE_CONCURRENCY - part of runtime, used automatically    (Windows only - MSVS 10, MSVS 11)
+   - HAVE_PTHREADS_PF - pthreads if available
 */
 
 #if defined HAVE_TBB
@@ -96,9 +96,16 @@
     #endif
     #undef min
     #undef max
-#elif defined HAVE_CSTRIPES
-    #include "C=.h"
-    #undef shared
+#elif defined HAVE_HPX
+    #include <hpx/parallel/algorithms/for_loop.hpp>
+    #include <hpx/parallel/execution.hpp>
+    //
+    #include <hpx/hpx_start.hpp>
+    #include <hpx/hpx_suspend.hpp>
+    #include <hpx/include/apply.hpp>
+    #include <hpx/util/yield_while.hpp>
+    #include <hpx/include/threadmanager.hpp>
+
 #elif defined HAVE_OPENMP
     #include <omp.h>
 #elif defined HAVE_GCD
@@ -113,8 +120,8 @@
 
 #if defined HAVE_TBB
 #  define CV_PARALLEL_FRAMEWORK "tbb"
-#elif defined HAVE_CSTRIPES
-#  define CV_PARALLEL_FRAMEWORK "cstripes"
+#elif defined HAVE_HPX
+#  define CV_PARALLEL_FRAMEWORK "hpx"
 #elif defined HAVE_OPENMP
 #  define CV_PARALLEL_FRAMEWORK "openmp"
 #elif defined HAVE_GCD
@@ -383,8 +390,26 @@ namespace
             tbb::parallel_for(tbb::blocked_range<int>(range.start, range.end), *this);
         }
     };
-#elif defined HAVE_CSTRIPES || defined HAVE_OPENMP
-    typedef ParallelLoopBodyWrapper ProxyLoopBody;
+#elif defined HAVE_HPX
+    class ProxyLoopBody : public ParallelLoopBodyWrapper
+    {
+    public:
+        ProxyLoopBody(ParallelLoopBodyWrapperContext& ctx_)
+                : ParallelLoopBodyWrapper(ctx_)
+        {}
+
+        void operator ()() const  // run parallel job
+        {
+            cv::Range stripeRange = this->stripeRange();
+            hpx::parallel::for_loop(
+                    hpx::parallel::execution::par,
+                    stripeRange.start, stripeRange.end,
+                    [&](const int &i) { ;
+                        this->ParallelLoopBodyWrapper::operator()(
+                                cv::Range(i, i + 1));
+                    });
+        }
+    };
 #elif defined HAVE_GCD
     typedef ParallelLoopBodyWrapper ProxyLoopBody;
     static void block_function(void* context, size_t index)
@@ -417,8 +442,8 @@ static int numThreads = -1;
     #else
         static tbb::task_scheduler_init tbbScheduler(tbb::task_scheduler_init::deferred);
     #endif
-#elif defined HAVE_CSTRIPES
-// nothing for C=
+#elif defined HAVE_HPX
+// nothing for HPX
 #elif defined HAVE_OPENMP
 static int numThreadsMax = omp_get_max_threads();
 #elif defined HAVE_GCD
@@ -518,16 +543,8 @@ static void parallel_for_impl(const cv::Range& range, const cv::ParallelLoopBody
         pbody();
 #endif
 
-#elif defined HAVE_CSTRIPES
-
-        parallel(MAX(0, numThreads))
-        {
-            int offset = stripeRange.start;
-            int len = stripeRange.end - offset;
-            Range r(offset + CPX_RANGE_START(len), offset + CPX_RANGE_END(len));
-            pbody(r);
-            barrier();
-        }
+#elif defined HAVE_HPX
+        pbody();
 
 #elif defined HAVE_OPENMP
 
@@ -600,11 +617,8 @@ int cv::getNumThreads(void)
            : tbb::task_scheduler_init::default_num_threads();
 #endif
 
-#elif defined HAVE_CSTRIPES
-
-    return numThreads > 0
-            ? numThreads
-            : cv::getNumberOfCPUs();
+#elif defined HAVE_HPX
+    return numThreads;
 
 #elif defined HAVE_OPENMP
 
@@ -680,9 +694,8 @@ void cv::setNumThreads( int threads_ )
     if(threads > 0) tbbScheduler.initialize(threads);
 #endif
 
-#elif defined HAVE_CSTRIPES
-
-    return; // nothing needed
+#elif defined HAVE_HPX
+    return; // nothing needed as numThreads is used
 
 #elif defined HAVE_OPENMP
 
@@ -733,8 +746,8 @@ int cv::getThreadNum(void)
     #else
         return 0;
     #endif
-#elif defined HAVE_CSTRIPES
-    return pix();
+#elif defined HAVE_HPX
+        return (int)(hpx::get_num_worker_threads());
 #elif defined HAVE_OPENMP
     return omp_get_thread_num();
 #elif defined HAVE_GCD
diff --git a/modules/core/src/parallel_impl.cpp b/modules/core/src/parallel_impl.cpp
index bc64fce7a81..58dff9dc11c 100644
--- a/modules/core/src/parallel_impl.cpp
+++ b/modules/core/src/parallel_impl.cpp
@@ -21,27 +21,15 @@
 
 //#define CV_USE_GLOBAL_WORKERS_COND_VAR  // not effective on many-core systems (10+)
 
-#ifdef CV_CXX11
 #include <atomic>
-#else
-#include <unistd.h>  // _POSIX_PRIORITY_SCHEDULING
-#endif
 
 // Spin lock's OS-level yield
 #ifdef DECLARE_CV_YIELD
 DECLARE_CV_YIELD
 #endif
 #ifndef CV_YIELD
-# ifdef CV_CXX11
-#   include <thread>
-#   define CV_YIELD() std::this_thread::yield()
-# elif defined(_POSIX_PRIORITY_SCHEDULING)
-#   include <sched.h>
-#   define CV_YIELD() sched_yield()
-# else
-#   warning "Can't detect sched_yield() on the target platform. Specify CV_YIELD() definition via compiler flags."
-#   define CV_YIELD() /* no-op: works, but not effective */
-# endif
+# include <thread>
+# define CV_YIELD() std::this_thread::yield()
 #endif // CV_YIELD
 
 // Spin lock's CPU-level yield (required for Hyper-Threading)
@@ -198,9 +186,9 @@ class WorkerThread
     pthread_t posix_thread;
     bool is_created;
 
-    volatile bool stop_thread;
+    std::atomic<bool> stop_thread;
 
-    volatile bool has_wake_signal;
+    std::atomic<bool> has_wake_signal;
 
     Ptr<ParallelJob> job;
 
@@ -290,15 +278,9 @@ class ParallelJob
         is_completed(false)
     {
         CV_LOG_VERBOSE(NULL, 5, "ParallelJob::ParallelJob(" << (void*)this << ")");
-#ifdef CV_CXX11
         current_task.store(0, std::memory_order_relaxed);
         active_thread_count.store(0, std::memory_order_relaxed);
         completed_thread_count.store(0, std::memory_order_relaxed);
-#else
-        current_task = 0;
-        active_thread_count = 0;
-        completed_thread_count = 0;
-#endif
         dummy0_[0] = 0, dummy1_[0] = 0, dummy2_[0] = 0; // compiler warning
     }
 
@@ -319,11 +301,7 @@ class ParallelJob
         for (;;)
         {
             int chunk_size = std::max(1, (task_count - current_task) / remaining_multiplier);
-#ifdef CV_CXX11
             int id = current_task.fetch_add(chunk_size, std::memory_order_seq_cst);
-#else
-            int id = (int)CV_XADD(&current_task, chunk_size);
-#endif
             if (id >= task_count)
                 break; // no more free tasks
 
@@ -349,7 +327,7 @@ class ParallelJob
     const ParallelLoopBody& body;
     const Range range;
     const unsigned nstripes;
-#ifdef CV_CXX11
+
     std::atomic<int> current_task;  // next free part of job
     int64 dummy0_[8];  // avoid cache-line reusing for the same atomics
 
@@ -358,18 +336,8 @@ class ParallelJob
 
     std::atomic<int> completed_thread_count;  // number of threads completed any activities on this job
     int64 dummy2_[8];  // avoid cache-line reusing for the same atomics
-#else
-    /*CV_DECL_ALIGNED(64)*/ volatile int current_task;  // next free part of job
-    int64 dummy0_[8];  // avoid cache-line reusing for the same atomics
-
-    /*CV_DECL_ALIGNED(64)*/ volatile int active_thread_count;  // number of threads worked on this job
-    int64 dummy1_[8];  // avoid cache-line reusing for the same atomics
-
-    /*CV_DECL_ALIGNED(64)*/ volatile int completed_thread_count;  // number of threads completed any activities on this job
-    int64 dummy2_[8];  // avoid cache-line reusing for the same atomics
-#endif
 
-    volatile bool is_completed;  // std::atomic_flag ?
+    std::atomic<bool> is_completed;
 
     // TODO exception handling
 };
@@ -426,7 +394,7 @@ void WorkerThread::thread_body()
         if (CV_WORKER_ACTIVE_WAIT_THREADS_LIMIT == 0)
             allow_active_wait = true;
         Ptr<ParallelJob> j_ptr; swap(j_ptr, job);
-        has_wake_signal = false;    // TODO .store(false, std::memory_order_release)
+        has_wake_signal = false;
         pthread_mutex_unlock(&mutex);
 
         if (!stop_thread)
@@ -437,11 +405,7 @@ void WorkerThread::thread_body()
                 CV_LOG_VERBOSE(NULL, 5, "Thread: job size=" << j->range.size() << " done=" << j->current_task);
                 if (j->current_task < j->range.size())
                 {
-#ifdef CV_CXX11
                     int other = j->active_thread_count.fetch_add(1, std::memory_order_seq_cst);
-#else
-                    int other = CV_XADD(&j->active_thread_count, 1);
-#endif
                     CV_LOG_VERBOSE(NULL, 5, "Thread: processing new job (with " << other << " other threads)"); CV_UNUSED(other);
 #ifdef CV_PROFILE_THREADS
                     stat.threadExecuteStart = getTickCount();
@@ -450,13 +414,8 @@ void WorkerThread::thread_body()
 #else
                     j->execute(true);
 #endif
-#ifdef CV_CXX11
                     int completed = j->completed_thread_count.fetch_add(1, std::memory_order_seq_cst) + 1;
                     int active = j->active_thread_count.load(std::memory_order_acquire);
-#else
-                    int completed = (int)CV_XADD(&j->completed_thread_count, 1) + 1;
-                    int active = j->active_thread_count;
-#endif
                     if (CV_WORKER_ACTIVE_WAIT_THREADS_LIMIT > 0)
                     {
                         allow_active_wait = true;
diff --git a/modules/core/src/persistence.cpp b/modules/core/src/persistence.cpp
index 9b67a97e80e..6fbad8b72fb 100644
--- a/modules/core/src/persistence.cpp
+++ b/modules/core/src/persistence.cpp
@@ -149,7 +149,7 @@ void icvParseError( CvFileStorage* fs, const char* func_name,
                const char* err_msg, const char* source_file, int source_line )
 {
     cv::String msg = cv::format("%s(%d): %s", fs->filename, fs->lineno, err_msg);
-    cv::errorNoReturn(cv::Error::StsParseError, func_name, msg.c_str(), source_file, source_line );
+    cv::error(cv::Error::StsParseError, func_name, msg.c_str(), source_file, source_line );
 }
 
 void icvFSCreateCollection( CvFileStorage* fs, int tag, CvFileNode* collection )
diff --git a/modules/core/src/persistence_cpp.cpp b/modules/core/src/persistence_cpp.cpp
index ab1b1f09e86..e584a130dd7 100644
--- a/modules/core/src/persistence_cpp.cpp
+++ b/modules/core/src/persistence_cpp.cpp
@@ -194,9 +194,14 @@ void FileStorage::write( const String& name, const String& val )
     *this << name << val;
 }
 
-void FileStorage::write( const String& name, InputArray val )
+void FileStorage::write( const String& name, const Mat& val )
 {
-    *this << name << val.getMat();
+    *this << name << val;
+}
+
+void FileStorage::write( const String& name, const std::vector<String>& val )
+{
+    *this << name << val;
 }
 
 void FileStorage::writeComment( const String& comment, bool append )
@@ -662,11 +667,6 @@ void read(const FileNode& node, double& value, double default_value)
         CV_NODE_IS_REAL(node.node->tag) ? node.node->data.f : std::numeric_limits<double>::max();
 }
 
-void read(const FileNode& node, String& value, const String& default_value)
-{
-    value = !node.node ? default_value : CV_NODE_IS_STRING(node.node->tag) ? String(node.node->data.str.ptr) : String();
-}
-
 void read(const FileNode& node, std::string& value, const std::string& default_value)
 {
     value = !node.node ? default_value : CV_NODE_IS_STRING(node.node->tag) ? std::string(node.node->data.str.ptr) : default_value;
diff --git a/modules/core/src/persistence_json.cpp b/modules/core/src/persistence_json.cpp
index fe876473375..abbd292f13c 100644
--- a/modules/core/src/persistence_json.cpp
+++ b/modules/core/src/persistence_json.cpp
@@ -238,11 +238,11 @@ static char* icvJSONParseValue( CvFileStorage* fs, char* ptr, CvFileNode* node )
                         CV_PARSE_ERROR("Invalid `dt` in Base64 header");
                 }
 
-                /* set base64_beg to beginning of base64 data */
-                base64_beg = &base64_buffer.at( base64::ENCODED_HEADER_SIZE );
 
                 if ( base64_buffer.size() > base64::ENCODED_HEADER_SIZE )
                 {
+                    /* set base64_beg to beginning of base64 data */
+                    base64_beg = &base64_buffer.at( base64::ENCODED_HEADER_SIZE );
                     if ( !base64::base64_valid( base64_beg, 0U, base64_end - base64_beg ) )
                         CV_PARSE_ERROR( "Invalid Base64 data." );
 
diff --git a/modules/core/src/precomp.hpp b/modules/core/src/precomp.hpp
index 54d0a227cd6..0786743b43a 100644
--- a/modules/core/src/precomp.hpp
+++ b/modules/core/src/precomp.hpp
@@ -89,11 +89,7 @@
 #include "arithm_core.hpp"
 #include "hal_replacement.hpp"
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-#include "opencv2/core/core_tegra.hpp"
-#else
 #define GET_OPTIMIZED(func) (func)
-#endif
 
 namespace cv
 {
@@ -270,9 +266,6 @@ struct CoreTLSData
 //#endif
         useIPP(-1),
         useIPP_NE(-1)
-#ifdef HAVE_TEGRA_OPTIMIZATION
-        ,useTegra(-1)
-#endif
 #ifdef HAVE_OPENVX
         ,useOpenVX(-1)
 #endif
@@ -286,9 +279,6 @@ struct CoreTLSData
 //#endif
     int useIPP;    // 1 - use, 0 - do not use, -1 - auto/not initialized
     int useIPP_NE; // 1 - use, 0 - do not use, -1 - auto/not initialized
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    int useTegra; // 1 - use, 0 - do not use, -1 - auto/not initialized
-#endif
 #ifdef HAVE_OPENVX
     int useOpenVX; // 1 - use, 0 - do not use, -1 - auto/not initialized
 #endif
diff --git a/modules/core/src/stl.cpp b/modules/core/src/stl.cpp
index f03c1a2d79a..bd6ee10ef63 100644
--- a/modules/core/src/stl.cpp
+++ b/modules/core/src/stl.cpp
@@ -43,27 +43,3 @@
 
 
 #include "precomp.hpp"
-
-char* cv::String::allocate(size_t len)
-{
-    size_t totalsize = alignSize(len + 1, (int)sizeof(int));
-    int* data = (int*)cv::fastMalloc(totalsize + sizeof(int));
-    data[0] = 1;
-    cstr_ = (char*)(data + 1);
-    len_ = len;
-    cstr_[len] = 0;
-    return cstr_;
-}
-
-
-void cv::String::deallocate()
-{
-    int* data = (int*)cstr_;
-    len_ = 0;
-    cstr_ = 0;
-
-    if(data && 1 == CV_XADD(data-1, -1))
-    {
-        cv::fastFree(data-1);
-    }
-}
diff --git a/modules/core/src/sum.cpp b/modules/core/src/sum.cpp
index f9658238899..be68f13abd2 100644
--- a/modules/core/src/sum.cpp
+++ b/modules/core/src/sum.cpp
@@ -602,7 +602,7 @@ cv::Scalar cv::sum( InputArray _src )
     CV_Assert( cn <= 4 && func != 0 );
 
     const Mat* arrays[] = {&src, 0};
-    uchar* ptrs[1];
+    uchar* ptrs[1]{};
     NAryMatIterator it(arrays, ptrs);
     Scalar s;
     int total = (int)it.size, blockSize = total, intSumBlockSize = 0;
diff --git a/modules/core/src/system.cpp b/modules/core/src/system.cpp
index 1ebd993a2f9..23c9bfd5a6d 100644
--- a/modules/core/src/system.cpp
+++ b/modules/core/src/system.cpp
@@ -62,7 +62,7 @@ Mutex& getInitializationMutex()
 Mutex* __initialization_mutex_initializer = &getInitializationMutex();
 
 static bool param_dumpErrors = utils::getConfigurationParameterBool("OPENCV_DUMP_ERRORS",
-#if defined(_DEBUG) || defined(__ANDROID__) || (defined(__GNUC__) && !defined(__EXCEPTIONS))
+#if defined(_DEBUG) || defined(__ANDROID__)
     true
 #else
     false
@@ -91,7 +91,7 @@ static bool param_dumpErrors = utils::getConfigurationParameterBool("OPENCV_DUMP
 #include <cstdlib>        // std::abort
 #endif
 
-#if defined __ANDROID__ || defined __linux__ || defined __FreeBSD__ || defined __HAIKU__
+#if defined __ANDROID__ || defined __linux__ || defined __FreeBSD__ || defined __HAIKU__ || defined __Fuchsia__
 #  include <unistd.h>
 #  include <fcntl.h>
 #  include <elf.h>
@@ -686,9 +686,6 @@ void setUseOptimized( bool flag )
 #ifdef HAVE_OPENCL
     ocl::setUseOpenCL(flag);
 #endif
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    ::tegra::setUseTegra(flag);
-#endif
 }
 
 bool useOptimized(void)
@@ -993,6 +990,13 @@ static void cv_terminate_handler() {
 
 #endif
 
+#ifdef __GNUC__
+# if defined __clang__ || defined __APPLE__
+#   pragma GCC diagnostic push
+#   pragma GCC diagnostic ignored "-Winvalid-noreturn"
+# endif
+#endif
+
 void error( const Exception& exc )
 {
 #ifdef CV_ERROR_SET_TERMINATE_HANDLER
@@ -1023,13 +1027,33 @@ void error( const Exception& exc )
     }
 
     CV_THROW(exc);
+#ifdef __GNUC__
+# if !defined __clang__ && !defined __APPLE__
+    // this suppresses this warning: "noreturn" function does return [enabled by default]
+    __builtin_trap();
+    // or use infinite loop: for (;;) {}
+# endif
+#endif
 }
 
 void error(int _code, const String& _err, const char* _func, const char* _file, int _line)
 {
     error(cv::Exception(_code, _err, _func, _file, _line));
+#ifdef __GNUC__
+# if !defined __clang__ && !defined __APPLE__
+    // this suppresses this warning: "noreturn" function does return [enabled by default]
+    __builtin_trap();
+    // or use infinite loop: for (;;) {}
+# endif
+#endif
 }
 
+#ifdef __GNUC__
+# if defined __clang__ || defined __APPLE__
+#   pragma GCC diagnostic pop
+# endif
+#endif
+
 
 ErrorCallback
 redirectError( ErrorCallback errCallback, void* userdata, void** prevUserdata)
@@ -1205,93 +1229,6 @@ cvErrorFromIppStatus( int status )
 
 namespace cv {
 bool __termination = false;
-}
-
-namespace cv
-{
-
-#if defined _WIN32 || defined WINCE
-
-struct Mutex::Impl
-{
-    Impl()
-    {
-#if (_WIN32_WINNT >= 0x0600)
-        ::InitializeCriticalSectionEx(&cs, 1000, 0);
-#else
-        ::InitializeCriticalSection(&cs);
-#endif
-        refcount = 1;
-    }
-    ~Impl() { DeleteCriticalSection(&cs); }
-
-    void lock() { EnterCriticalSection(&cs); }
-    bool trylock() { return TryEnterCriticalSection(&cs) != 0; }
-    void unlock() { LeaveCriticalSection(&cs); }
-
-    CRITICAL_SECTION cs;
-    int refcount;
-};
-
-#else
-
-struct Mutex::Impl
-{
-    Impl()
-    {
-        pthread_mutexattr_t attr;
-        pthread_mutexattr_init(&attr);
-        pthread_mutexattr_settype(&attr, PTHREAD_MUTEX_RECURSIVE);
-        pthread_mutex_init(&mt, &attr);
-        pthread_mutexattr_destroy(&attr);
-
-        refcount = 1;
-    }
-    ~Impl() { pthread_mutex_destroy(&mt); }
-
-    void lock() { pthread_mutex_lock(&mt); }
-    bool trylock() { return pthread_mutex_trylock(&mt) == 0; }
-    void unlock() { pthread_mutex_unlock(&mt); }
-
-    pthread_mutex_t mt;
-    int refcount;
-};
-
-#endif
-
-Mutex::Mutex()
-{
-    impl = new Mutex::Impl;
-}
-
-Mutex::~Mutex()
-{
-    if( CV_XADD(&impl->refcount, -1) == 1 )
-        delete impl;
-    impl = 0;
-}
-
-Mutex::Mutex(const Mutex& m)
-{
-    impl = m.impl;
-    CV_XADD(&impl->refcount, 1);
-}
-
-Mutex& Mutex::operator = (const Mutex& m)
-{
-    if (this != &m)
-    {
-        CV_XADD(&m.impl->refcount, 1);
-        if( CV_XADD(&impl->refcount, -1) == 1 )
-            delete impl;
-        impl = m.impl;
-    }
-    return *this;
-}
-
-void Mutex::lock() { impl->lock(); }
-void Mutex::unlock() { impl->unlock(); }
-bool Mutex::trylock() { return impl->trylock(); }
 
 
 //////////////////////////////// thread-local storage ////////////////////////////////
@@ -1718,12 +1655,7 @@ cv::String utils::getConfigurationParameterString(const char* name, const char*
 #else
     const char* envValue = getenv(name);
 #endif
-    if (envValue == NULL)
-    {
-        return defaultValue;
-    }
-    cv::String value = envValue;
-    return value;
+    return envValue ? cv::String(envValue) : (defaultValue ? cv::String(defaultValue) : cv::String());
 }
 
 
@@ -2016,7 +1948,9 @@ struct IPPInitSingleton
         ippFeatures = cpuFeatures;
 
         const char* pIppEnv = getenv("OPENCV_IPP");
-        cv::String env = pIppEnv;
+        cv::String env;
+        if(pIppEnv != NULL)
+            env = pIppEnv;
         if(env.size())
         {
 #if IPP_VERSION_X100 >= 201703
@@ -2031,7 +1965,7 @@ struct IPPInitSingleton
             const Ipp64u minorFeatures = 0;
 #endif
 
-            env = env.toLowerCase();
+            env = toLowerCase(env);
             if(env.substr(0, 2) == "ne")
             {
                 useIPP_NE = true;
@@ -2124,18 +2058,10 @@ static IPPInitSingleton& getIPPSingleton()
 }
 #endif
 
-#if OPENCV_ABI_COMPATIBILITY > 300
 unsigned long long getIppFeatures()
-#else
-int getIppFeatures()
-#endif
 {
 #ifdef HAVE_IPP
-#if OPENCV_ABI_COMPATIBILITY > 300
     return getIPPSingleton().ippFeatures;
-#else
-    return (int)getIPPSingleton().ippFeatures;
-#endif
 #else
     return 0;
 #endif
@@ -2249,34 +2175,4 @@ void setUseIPP_NE(bool flag)
 
 } // namespace cv
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-
-namespace tegra {
-
-bool useTegra()
-{
-    cv::CoreTLSData* data = cv::getCoreTlsData().get();
-
-    if (data->useTegra < 0)
-    {
-        const char* pTegraEnv = getenv("OPENCV_TEGRA");
-        if (pTegraEnv && (cv::String(pTegraEnv) == "disabled"))
-            data->useTegra = false;
-        else
-            data->useTegra = true;
-    }
-
-    return (data->useTegra > 0);
-}
-
-void setUseTegra(bool flag)
-{
-    cv::CoreTLSData* data = cv::getCoreTlsData().get();
-    data->useTegra = flag;
-}
-
-} // namespace tegra
-
-#endif
-
 /* End of file. */
diff --git a/modules/core/src/utils/filesystem.cpp b/modules/core/src/utils/filesystem.cpp
index 366cdaf4f31..32183a2f6ca 100644
--- a/modules/core/src/utils/filesystem.cpp
+++ b/modules/core/src/utils/filesystem.cpp
@@ -470,7 +470,7 @@ cv::String getCacheDirectory(const char* sub_directory_name, const char* configu
             if (utils::fs::isDirectory(default_cache_path))
             {
                 cv::String default_cache_path_base = utils::fs::join(default_cache_path, "opencv");
-                default_cache_path = utils::fs::join(default_cache_path_base, "3.4.x" CV_VERSION_STATUS);
+                default_cache_path = utils::fs::join(default_cache_path_base, "4.0" CV_VERSION_STATUS);
                 if (utils::getConfigurationParameterBool("OPENCV_CACHE_SHOW_CLEANUP_MESSAGE", true)
                     && !utils::fs::isDirectory(default_cache_path))
                 {
diff --git a/modules/core/test/test_arithm.cpp b/modules/core/test/test_arithm.cpp
index 049c86dd0d3..c81f8d83e13 100644
--- a/modules/core/test/test_arithm.cpp
+++ b/modules/core/test/test_arithm.cpp
@@ -1847,13 +1847,54 @@ INSTANTIATE_TEST_CASE_P(Arithm, SubtractOutputMatNotEmpty, testing::Combine(
     testing::Values(-1, CV_16S, CV_32S, CV_32F),
     testing::Bool()));
 
-TEST(Core_FindNonZero, singular)
+TEST(Core_FindNonZero, regression)
 {
     Mat img(10, 10, CV_8U, Scalar::all(0));
-    vector<Point> pts, pts2(10);
+    vector<Point> pts, pts2(5);
     findNonZero(img, pts);
     findNonZero(img, pts2);
     ASSERT_TRUE(pts.empty() && pts2.empty());
+
+    RNG rng((uint64)-1);
+    size_t nz = 0;
+    for( int i = 0; i < 10; i++ )
+    {
+        int idx = rng.uniform(0, img.rows*img.cols);
+        if( !img.data[idx] ) nz++;
+        img.data[idx] = (uchar)rng.uniform(1, 256);
+    }
+    findNonZero(img, pts);
+    ASSERT_TRUE(pts.size() == nz);
+
+    img.convertTo( img, CV_8S );
+    pts.clear();
+    findNonZero(img, pts);
+    ASSERT_TRUE(pts.size() == nz);
+
+    img.convertTo( img, CV_16U );
+    pts.resize(pts.size()*2);
+    findNonZero(img, pts);
+    ASSERT_TRUE(pts.size() == nz);
+
+    img.convertTo( img, CV_16S );
+    pts.resize(pts.size()*3);
+    findNonZero(img, pts);
+    ASSERT_TRUE(pts.size() == nz);
+
+    img.convertTo( img, CV_32S );
+    pts.resize(pts.size()*4);
+    findNonZero(img, pts);
+    ASSERT_TRUE(pts.size() == nz);
+
+    img.convertTo( img, CV_32F );
+    pts.resize(pts.size()*5);
+    findNonZero(img, pts);
+    ASSERT_TRUE(pts.size() == nz);
+
+    img.convertTo( img, CV_64F );
+    pts.clear();
+    findNonZero(img, pts);
+    ASSERT_TRUE(pts.size() == nz);
 }
 
 TEST(Core_BoolVector, support)
diff --git a/modules/core/test/test_main.cpp b/modules/core/test/test_main.cpp
index 0e51ddfd050..93e4d2860eb 100644
--- a/modules/core/test/test_main.cpp
+++ b/modules/core/test/test_main.cpp
@@ -3,4 +3,8 @@
 // of this distribution and at http://opencv.org/license.html.
 #include "test_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_TEST_MAIN("cv")
diff --git a/modules/core/test/test_mat.cpp b/modules/core/test/test_mat.cpp
index 9622fa47d4f..4a8c347c68a 100644
--- a/modules/core/test/test_mat.cpp
+++ b/modules/core/test/test_mat.cpp
@@ -1344,8 +1344,6 @@ TEST(Core_Matx, fromMat_)
     ASSERT_EQ( cvtest::norm(a, b, NORM_INF), 0.);
 }
 
-#ifdef CV_CXX11
-
 TEST(Core_Matx, from_initializer_list)
 {
     Mat_<double> a = (Mat_<double>(2,2) << 10, 11, 12, 13);
@@ -1360,8 +1358,6 @@ TEST(Core_Mat, regression_9507)
     EXPECT_EQ(25u, m2.total());
 }
 
-#endif // CXX11
-
 TEST(Core_InputArray, empty)
 {
     vector<vector<Point> > data;
@@ -1638,7 +1634,6 @@ TEST(Mat, regression_10507_mat_setTo)
     }
 }
 
-#ifdef CV_CXX_STD_ARRAY
 TEST(Core_Mat_array, outputArray_create_getMat)
 {
     cv::Mat_<uchar> src_base(5, 1);
@@ -1727,7 +1722,6 @@ TEST(Core_Mat_array, SplitMerge)
         EXPECT_EQ(0, cvtest::norm(src[i], dst[i], NORM_INF));
     }
 }
-#endif
 
 TEST(Mat, regression_8680)
 {
@@ -1737,8 +1731,6 @@ TEST(Mat, regression_8680)
    ASSERT_EQ(mat.channels(), 2);
 }
 
-#ifdef CV_CXX11
-
 TEST(Mat_, range_based_for)
 {
     Mat_<uchar> img = Mat_<uchar>::zeros(3, 3);
@@ -1800,8 +1792,6 @@ TEST(Mat_, template_based_ptr)
     ASSERT_FLOAT_EQ(66.0f, *(mat.ptr<float>(idx)));
 }
 
-#endif
-
 
 BIGDATA_TEST(Mat, push_back_regression_4158)  // memory usage: ~10.6 Gb
 {
diff --git a/modules/cudaarithm/CMakeLists.txt b/modules/cudaarithm/CMakeLists.txt
index 29155560ef6..d552bb4ebe9 100644
--- a/modules/cudaarithm/CMakeLists.txt
+++ b/modules/cudaarithm/CMakeLists.txt
@@ -6,7 +6,7 @@ set(the_description "CUDA-accelerated Operations on Matrices")
 
 ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4127 /wd4324 /wd4512 -Wundef -Wmissing-declarations -Wshadow)
 
-ocv_add_module(cudaarithm opencv_core OPTIONAL opencv_cudev)
+ocv_add_module(cudaarithm opencv_core OPTIONAL opencv_cudev WRAP python)
 
 ocv_module_include_directories()
 ocv_glob_module_sources()
diff --git a/modules/cudaarithm/include/opencv2/cudaarithm.hpp b/modules/cudaarithm/include/opencv2/cudaarithm.hpp
index a482b49fcfd..c357f77b4f1 100644
--- a/modules/cudaarithm/include/opencv2/cudaarithm.hpp
+++ b/modules/cudaarithm/include/opencv2/cudaarithm.hpp
@@ -83,7 +83,7 @@ destination array to be changed. The mask can be used only with single channel i
 
 @sa add
  */
-CV_EXPORTS void add(InputArray src1, InputArray src2, OutputArray dst, InputArray mask = noArray(), int dtype = -1, Stream& stream = Stream::Null());
+CV_EXPORTS_W void add(InputArray src1, InputArray src2, OutputArray dst, InputArray mask = noArray(), int dtype = -1, Stream& stream = Stream::Null());
 
 /** @brief Computes a matrix-matrix or matrix-scalar difference.
 
@@ -98,7 +98,7 @@ destination array to be changed. The mask can be used only with single channel i
 
 @sa subtract
  */
-CV_EXPORTS void subtract(InputArray src1, InputArray src2, OutputArray dst, InputArray mask = noArray(), int dtype = -1, Stream& stream = Stream::Null());
+CV_EXPORTS_W void subtract(InputArray src1, InputArray src2, OutputArray dst, InputArray mask = noArray(), int dtype = -1, Stream& stream = Stream::Null());
 
 /** @brief Computes a matrix-matrix or matrix-scalar per-element product.
 
@@ -112,7 +112,7 @@ The depth is defined by dtype or src1 depth.
 
 @sa multiply
  */
-CV_EXPORTS void multiply(InputArray src1, InputArray src2, OutputArray dst, double scale = 1, int dtype = -1, Stream& stream = Stream::Null());
+CV_EXPORTS_W void multiply(InputArray src1, InputArray src2, OutputArray dst, double scale = 1, int dtype = -1, Stream& stream = Stream::Null());
 
 /** @brief Computes a matrix-matrix or matrix-scalar division.
 
@@ -128,7 +128,7 @@ This function, in contrast to divide, uses a round-down rounding mode.
 
 @sa divide
  */
-CV_EXPORTS void divide(InputArray src1, InputArray src2, OutputArray dst, double scale = 1, int dtype = -1, Stream& stream = Stream::Null());
+CV_EXPORTS_W void divide(InputArray src1, InputArray src2, OutputArray dst, double scale = 1, int dtype = -1, Stream& stream = Stream::Null());
 
 /** @brief Computes per-element absolute difference of two matrices (or of a matrix and scalar).
 
@@ -139,7 +139,7 @@ CV_EXPORTS void divide(InputArray src1, InputArray src2, OutputArray dst, double
 
 @sa absdiff
  */
-CV_EXPORTS void absdiff(InputArray src1, InputArray src2, OutputArray dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void absdiff(InputArray src1, InputArray src2, OutputArray dst, Stream& stream = Stream::Null());
 
 /** @brief Computes an absolute value of each matrix element.
 
@@ -149,7 +149,7 @@ CV_EXPORTS void absdiff(InputArray src1, InputArray src2, OutputArray dst, Strea
 
 @sa abs
  */
-CV_EXPORTS void abs(InputArray src, OutputArray dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void abs(InputArray src, OutputArray dst, Stream& stream = Stream::Null());
 
 /** @brief Computes a square value of each matrix element.
 
@@ -157,7 +157,7 @@ CV_EXPORTS void abs(InputArray src, OutputArray dst, Stream& stream = Stream::Nu
 @param dst Destination matrix with the same size and type as src .
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void sqr(InputArray src, OutputArray dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void sqr(InputArray src, OutputArray dst, Stream& stream = Stream::Null());
 
 /** @brief Computes a square root of each matrix element.
 
@@ -167,7 +167,7 @@ CV_EXPORTS void sqr(InputArray src, OutputArray dst, Stream& stream = Stream::Nu
 
 @sa sqrt
  */
-CV_EXPORTS void sqrt(InputArray src, OutputArray dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void sqrt(InputArray src, OutputArray dst, Stream& stream = Stream::Null());
 
 /** @brief Computes an exponent of each matrix element.
 
@@ -177,7 +177,7 @@ CV_EXPORTS void sqrt(InputArray src, OutputArray dst, Stream& stream = Stream::N
 
 @sa exp
  */
-CV_EXPORTS void exp(InputArray src, OutputArray dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void exp(InputArray src, OutputArray dst, Stream& stream = Stream::Null());
 
 /** @brief Computes a natural logarithm of absolute value of each matrix element.
 
@@ -187,7 +187,7 @@ CV_EXPORTS void exp(InputArray src, OutputArray dst, Stream& stream = Stream::Nu
 
 @sa log
  */
-CV_EXPORTS void log(InputArray src, OutputArray dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void log(InputArray src, OutputArray dst, Stream& stream = Stream::Null());
 
 /** @brief Raises every matrix element to a power.
 
@@ -202,7 +202,7 @@ The function pow raises every element of the input matrix to power :
 
 @sa pow
  */
-CV_EXPORTS void pow(InputArray src, double power, OutputArray dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void pow(InputArray src, double power, OutputArray dst, Stream& stream = Stream::Null());
 
 /** @brief Compares elements of two matrices (or of a matrix and scalar).
 
@@ -220,7 +220,7 @@ CV_EXPORTS void pow(InputArray src, double power, OutputArray dst, Stream& strea
 
 @sa compare
  */
-CV_EXPORTS void compare(InputArray src1, InputArray src2, OutputArray dst, int cmpop, Stream& stream = Stream::Null());
+CV_EXPORTS_W void compare(InputArray src1, InputArray src2, OutputArray dst, int cmpop, Stream& stream = Stream::Null());
 
 /** @brief Performs a per-element bitwise inversion.
 
@@ -230,7 +230,7 @@ CV_EXPORTS void compare(InputArray src1, InputArray src2, OutputArray dst, int c
 destination array to be changed. The mask can be used only with single channel images.
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void bitwise_not(InputArray src, OutputArray dst, InputArray mask = noArray(), Stream& stream = Stream::Null());
+CV_EXPORTS_W void bitwise_not(InputArray src, OutputArray dst, InputArray mask = noArray(), Stream& stream = Stream::Null());
 
 /** @brief Performs a per-element bitwise disjunction of two matrices (or of matrix and scalar).
 
@@ -241,7 +241,7 @@ CV_EXPORTS void bitwise_not(InputArray src, OutputArray dst, InputArray mask = n
 destination array to be changed. The mask can be used only with single channel images.
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void bitwise_or(InputArray src1, InputArray src2, OutputArray dst, InputArray mask = noArray(), Stream& stream = Stream::Null());
+CV_EXPORTS_W void bitwise_or(InputArray src1, InputArray src2, OutputArray dst, InputArray mask = noArray(), Stream& stream = Stream::Null());
 
 /** @brief Performs a per-element bitwise conjunction of two matrices (or of matrix and scalar).
 
@@ -252,7 +252,7 @@ CV_EXPORTS void bitwise_or(InputArray src1, InputArray src2, OutputArray dst, In
 destination array to be changed. The mask can be used only with single channel images.
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void bitwise_and(InputArray src1, InputArray src2, OutputArray dst, InputArray mask = noArray(), Stream& stream = Stream::Null());
+CV_EXPORTS_W void bitwise_and(InputArray src1, InputArray src2, OutputArray dst, InputArray mask = noArray(), Stream& stream = Stream::Null());
 
 /** @brief Performs a per-element bitwise exclusive or operation of two matrices (or of matrix and scalar).
 
@@ -263,7 +263,7 @@ CV_EXPORTS void bitwise_and(InputArray src1, InputArray src2, OutputArray dst, I
 destination array to be changed. The mask can be used only with single channel images.
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void bitwise_xor(InputArray src1, InputArray src2, OutputArray dst, InputArray mask = noArray(), Stream& stream = Stream::Null());
+CV_EXPORTS_W void bitwise_xor(InputArray src1, InputArray src2, OutputArray dst, InputArray mask = noArray(), Stream& stream = Stream::Null());
 
 /** @brief Performs pixel by pixel right shift of an image by a constant value.
 
@@ -293,7 +293,7 @@ CV_EXPORTS void lshift(InputArray src, Scalar_<int> val, OutputArray dst, Stream
 
 @sa min
  */
-CV_EXPORTS void min(InputArray src1, InputArray src2, OutputArray dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void min(InputArray src1, InputArray src2, OutputArray dst, Stream& stream = Stream::Null());
 
 /** @brief Computes the per-element maximum of two matrices (or a matrix and a scalar).
 
@@ -304,7 +304,7 @@ CV_EXPORTS void min(InputArray src1, InputArray src2, OutputArray dst, Stream& s
 
 @sa max
  */
-CV_EXPORTS void max(InputArray src1, InputArray src2, OutputArray dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void max(InputArray src1, InputArray src2, OutputArray dst, Stream& stream = Stream::Null());
 
 /** @brief Computes the weighted sum of two arrays.
 
@@ -327,7 +327,7 @@ channel is processed independently.
 
 @sa addWeighted
  */
-CV_EXPORTS void addWeighted(InputArray src1, double alpha, InputArray src2, double beta, double gamma, OutputArray dst,
+CV_EXPORTS_W void addWeighted(InputArray src1, double alpha, InputArray src2, double beta, double gamma, OutputArray dst,
                             int dtype = -1, Stream& stream = Stream::Null());
 
 //! adds scaled array to another one (dst = alpha*src1 + src2)
@@ -348,7 +348,7 @@ threshold types are not supported.
 
 @sa threshold
  */
-CV_EXPORTS double threshold(InputArray src, OutputArray dst, double thresh, double maxval, int type, Stream& stream = Stream::Null());
+CV_EXPORTS_W double threshold(InputArray src, OutputArray dst, double thresh, double maxval, int type, Stream& stream = Stream::Null());
 
 /** @brief Computes magnitudes of complex matrix elements.
 
@@ -358,7 +358,7 @@ CV_EXPORTS double threshold(InputArray src, OutputArray dst, double thresh, doub
 
 @sa magnitude
  */
-CV_EXPORTS void magnitude(InputArray xy, OutputArray magnitude, Stream& stream = Stream::Null());
+CV_EXPORTS_W void magnitude(InputArray xy, OutputArray magnitude, Stream& stream = Stream::Null());
 
 /** @brief Computes squared magnitudes of complex matrix elements.
 
@@ -366,7 +366,7 @@ CV_EXPORTS void magnitude(InputArray xy, OutputArray magnitude, Stream& stream =
 @param magnitude Destination matrix of float magnitude squares ( CV_32FC1 ).
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void magnitudeSqr(InputArray xy, OutputArray magnitude, Stream& stream = Stream::Null());
+CV_EXPORTS_W void magnitudeSqr(InputArray xy, OutputArray magnitude, Stream& stream = Stream::Null());
 
 /** @overload
  computes magnitude of each (x(i), y(i)) vector
@@ -376,7 +376,7 @@ CV_EXPORTS void magnitudeSqr(InputArray xy, OutputArray magnitude, Stream& strea
 @param magnitude Destination matrix of float magnitudes ( CV_32FC1 ).
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void magnitude(InputArray x, InputArray y, OutputArray magnitude, Stream& stream = Stream::Null());
+CV_EXPORTS_W void magnitude(InputArray x, InputArray y, OutputArray magnitude, Stream& stream = Stream::Null());
 
 /** @overload
  computes squared magnitude of each (x(i), y(i)) vector
@@ -386,7 +386,7 @@ CV_EXPORTS void magnitude(InputArray x, InputArray y, OutputArray magnitude, Str
 @param magnitude Destination matrix of float magnitude squares ( CV_32FC1 ).
 @param stream Stream for the asynchronous version.
 */
-CV_EXPORTS void magnitudeSqr(InputArray x, InputArray y, OutputArray magnitude, Stream& stream = Stream::Null());
+CV_EXPORTS_W void magnitudeSqr(InputArray x, InputArray y, OutputArray magnitude, Stream& stream = Stream::Null());
 
 /** @brief Computes polar angles of complex matrix elements.
 
@@ -398,7 +398,7 @@ CV_EXPORTS void magnitudeSqr(InputArray x, InputArray y, OutputArray magnitude,
 
 @sa phase
  */
-CV_EXPORTS void phase(InputArray x, InputArray y, OutputArray angle, bool angleInDegrees = false, Stream& stream = Stream::Null());
+CV_EXPORTS_W void phase(InputArray x, InputArray y, OutputArray angle, bool angleInDegrees = false, Stream& stream = Stream::Null());
 
 /** @brief Converts Cartesian coordinates into polar.
 
@@ -411,7 +411,7 @@ CV_EXPORTS void phase(InputArray x, InputArray y, OutputArray angle, bool angleI
 
 @sa cartToPolar
  */
-CV_EXPORTS void cartToPolar(InputArray x, InputArray y, OutputArray magnitude, OutputArray angle, bool angleInDegrees = false, Stream& stream = Stream::Null());
+CV_EXPORTS_W void cartToPolar(InputArray x, InputArray y, OutputArray magnitude, OutputArray angle, bool angleInDegrees = false, Stream& stream = Stream::Null());
 
 /** @brief Converts polar coordinates into Cartesian.
 
@@ -422,7 +422,7 @@ CV_EXPORTS void cartToPolar(InputArray x, InputArray y, OutputArray magnitude, O
 @param angleInDegrees Flag that indicates angles in degrees.
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void polarToCart(InputArray magnitude, InputArray angle, OutputArray x, OutputArray y, bool angleInDegrees = false, Stream& stream = Stream::Null());
+CV_EXPORTS_W void polarToCart(InputArray magnitude, InputArray angle, OutputArray x, OutputArray y, bool angleInDegrees = false, Stream& stream = Stream::Null());
 
 //! @} cudaarithm_elem
 
@@ -438,9 +438,9 @@ CV_EXPORTS void polarToCart(InputArray magnitude, InputArray angle, OutputArray
 
 @sa merge
  */
-CV_EXPORTS void merge(const GpuMat* src, size_t n, OutputArray dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void merge(const GpuMat* src, size_t n, OutputArray dst, Stream& stream = Stream::Null());
 /** @overload */
-CV_EXPORTS void merge(const std::vector<GpuMat>& src, OutputArray dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void merge(const std::vector<GpuMat>& src, OutputArray dst, Stream& stream = Stream::Null());
 
 /** @brief Copies each plane of a multi-channel matrix into an array.
 
@@ -450,9 +450,9 @@ CV_EXPORTS void merge(const std::vector<GpuMat>& src, OutputArray dst, Stream& s
 
 @sa split
  */
-CV_EXPORTS void split(InputArray src, GpuMat* dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void split(InputArray src, GpuMat* dst, Stream& stream = Stream::Null());
 /** @overload */
-CV_EXPORTS void split(InputArray src, std::vector<GpuMat>& dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void split(InputArray src, std::vector<GpuMat>& dst, Stream& stream = Stream::Null());
 
 /** @brief Transposes a matrix.
 
@@ -462,7 +462,7 @@ CV_EXPORTS void split(InputArray src, std::vector<GpuMat>& dst, Stream& stream =
 
 @sa transpose
  */
-CV_EXPORTS void transpose(InputArray src1, OutputArray dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void transpose(InputArray src1, OutputArray dst, Stream& stream = Stream::Null());
 
 /** @brief Flips a 2D matrix around vertical, horizontal, or both axes.
 
@@ -477,11 +477,11 @@ CV_32F depth.
 
 @sa flip
  */
-CV_EXPORTS void flip(InputArray src, OutputArray dst, int flipCode, Stream& stream = Stream::Null());
+CV_EXPORTS_W void flip(InputArray src, OutputArray dst, int flipCode, Stream& stream = Stream::Null());
 
 /** @brief Base class for transform using lookup table.
  */
-class CV_EXPORTS LookUpTable : public Algorithm
+class CV_EXPORTS_W LookUpTable : public Algorithm
 {
 public:
     /** @brief Transforms the source matrix into the destination matrix using the given look-up table:
@@ -491,14 +491,14 @@ class CV_EXPORTS LookUpTable : public Algorithm
     @param dst Destination matrix.
     @param stream Stream for the asynchronous version.
      */
-    virtual void transform(InputArray src, OutputArray dst, Stream& stream = Stream::Null()) = 0;
+    CV_WRAP virtual void transform(InputArray src, OutputArray dst, Stream& stream = Stream::Null()) = 0;
 };
 
 /** @brief Creates implementation for cuda::LookUpTable .
 
 @param lut Look-up table of 256 elements. It is a continuous CV_8U matrix.
  */
-CV_EXPORTS Ptr<LookUpTable> createLookUpTable(InputArray lut);
+CV_EXPORTS_W Ptr<LookUpTable> createLookUpTable(InputArray lut);
 
 /** @brief Forms a border around an image.
 
@@ -515,7 +515,7 @@ BORDER_REPLICATE , BORDER_CONSTANT , BORDER_REFLECT and BORDER_WRAP are supporte
 @param value Border value.
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void copyMakeBorder(InputArray src, OutputArray dst, int top, int bottom, int left, int right, int borderType,
+CV_EXPORTS_W void copyMakeBorder(InputArray src, OutputArray dst, int top, int bottom, int left, int right, int borderType,
                                Scalar value = Scalar(), Stream& stream = Stream::Null());
 
 //! @} cudaarithm_core
@@ -531,9 +531,9 @@ CV_EXPORTS void copyMakeBorder(InputArray src, OutputArray dst, int top, int bot
 
 @sa norm
  */
-CV_EXPORTS double norm(InputArray src1, int normType, InputArray mask = noArray());
+CV_EXPORTS_W double norm(InputArray src1, int normType, InputArray mask = noArray());
 /** @overload */
-CV_EXPORTS void calcNorm(InputArray src, OutputArray dst, int normType, InputArray mask = noArray(), Stream& stream = Stream::Null());
+CV_EXPORTS_W void calcNorm(InputArray src, OutputArray dst, int normType, InputArray mask = noArray(), Stream& stream = Stream::Null());
 
 /** @brief Returns the difference of two matrices.
 
@@ -543,9 +543,9 @@ CV_EXPORTS void calcNorm(InputArray src, OutputArray dst, int normType, InputArr
 
 @sa norm
  */
-CV_EXPORTS double norm(InputArray src1, InputArray src2, int normType=NORM_L2);
+CV_EXPORTS_W double norm(InputArray src1, InputArray src2, int normType=NORM_L2);
 /** @overload */
-CV_EXPORTS void calcNormDiff(InputArray src1, InputArray src2, OutputArray dst, int normType=NORM_L2, Stream& stream = Stream::Null());
+CV_EXPORTS_W void calcNormDiff(InputArray src1, InputArray src2, OutputArray dst, int normType=NORM_L2, Stream& stream = Stream::Null());
 
 /** @brief Returns the sum of matrix elements.
 
@@ -554,27 +554,27 @@ CV_EXPORTS void calcNormDiff(InputArray src1, InputArray src2, OutputArray dst,
 
 @sa sum
  */
-CV_EXPORTS Scalar sum(InputArray src, InputArray mask = noArray());
+CV_EXPORTS_W Scalar sum(InputArray src, InputArray mask = noArray());
 /** @overload */
-CV_EXPORTS void calcSum(InputArray src, OutputArray dst, InputArray mask = noArray(), Stream& stream = Stream::Null());
+CV_EXPORTS_W void calcSum(InputArray src, OutputArray dst, InputArray mask = noArray(), Stream& stream = Stream::Null());
 
 /** @brief Returns the sum of absolute values for matrix elements.
 
 @param src Source image of any depth except for CV_64F .
 @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.
  */
-CV_EXPORTS Scalar absSum(InputArray src, InputArray mask = noArray());
+CV_EXPORTS_W Scalar absSum(InputArray src, InputArray mask = noArray());
 /** @overload */
-CV_EXPORTS void calcAbsSum(InputArray src, OutputArray dst, InputArray mask = noArray(), Stream& stream = Stream::Null());
+CV_EXPORTS_W void calcAbsSum(InputArray src, OutputArray dst, InputArray mask = noArray(), Stream& stream = Stream::Null());
 
 /** @brief Returns the squared sum of matrix elements.
 
 @param src Source image of any depth except for CV_64F .
 @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.
  */
-CV_EXPORTS Scalar sqrSum(InputArray src, InputArray mask = noArray());
+CV_EXPORTS_W Scalar sqrSum(InputArray src, InputArray mask = noArray());
 /** @overload */
-CV_EXPORTS void calcSqrSum(InputArray src, OutputArray dst, InputArray mask = noArray(), Stream& stream = Stream::Null());
+CV_EXPORTS_W void calcSqrSum(InputArray src, OutputArray dst, InputArray mask = noArray(), Stream& stream = Stream::Null());
 
 /** @brief Finds global minimum and maximum matrix elements and returns their values.
 
@@ -587,9 +587,9 @@ The function does not work with CV_64F images on GPUs with the compute capabilit
 
 @sa minMaxLoc
  */
-CV_EXPORTS void minMax(InputArray src, double* minVal, double* maxVal, InputArray mask = noArray());
+CV_EXPORTS_W void minMax(InputArray src, double* minVal, double* maxVal, InputArray mask = noArray());
 /** @overload */
-CV_EXPORTS void findMinMax(InputArray src, OutputArray dst, InputArray mask = noArray(), Stream& stream = Stream::Null());
+CV_EXPORTS_W void findMinMax(InputArray src, OutputArray dst, InputArray mask = noArray(), Stream& stream = Stream::Null());
 
 /** @brief Finds global minimum and maximum matrix elements and returns their values with locations.
 
@@ -604,10 +604,10 @@ The function does not work with CV_64F images on GPU with the compute capability
 
 @sa minMaxLoc
  */
-CV_EXPORTS void minMaxLoc(InputArray src, double* minVal, double* maxVal, Point* minLoc, Point* maxLoc,
+CV_EXPORTS_W void minMaxLoc(InputArray src, double* minVal, double* maxVal, Point* minLoc, Point* maxLoc,
                           InputArray mask = noArray());
 /** @overload */
-CV_EXPORTS void findMinMaxLoc(InputArray src, OutputArray minMaxVals, OutputArray loc,
+CV_EXPORTS_W void findMinMaxLoc(InputArray src, OutputArray minMaxVals, OutputArray loc,
                               InputArray mask = noArray(), Stream& stream = Stream::Null());
 
 /** @brief Counts non-zero matrix elements.
@@ -618,9 +618,9 @@ The function does not work with CV_64F images on GPUs with the compute capabilit
 
 @sa countNonZero
  */
-CV_EXPORTS int countNonZero(InputArray src);
+CV_EXPORTS_W int countNonZero(InputArray src);
 /** @overload */
-CV_EXPORTS void countNonZero(InputArray src, OutputArray dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void countNonZero(InputArray src, OutputArray dst, Stream& stream = Stream::Null());
 
 /** @brief Reduces a matrix to a vector.
 
@@ -648,7 +648,7 @@ modes.
 
 @sa reduce
  */
-CV_EXPORTS void reduce(InputArray mtx, OutputArray vec, int dim, int reduceOp, int dtype = -1, Stream& stream = Stream::Null());
+CV_EXPORTS_W void reduce(InputArray mtx, OutputArray vec, int dim, int reduceOp, int dtype = -1, Stream& stream = Stream::Null());
 
 /** @brief Computes a mean value and a standard deviation of matrix elements.
 
@@ -658,9 +658,9 @@ CV_EXPORTS void reduce(InputArray mtx, OutputArray vec, int dim, int reduceOp, i
 
 @sa meanStdDev
  */
-CV_EXPORTS void meanStdDev(InputArray mtx, Scalar& mean, Scalar& stddev);
+CV_EXPORTS_W void meanStdDev(InputArray mtx, Scalar& mean, Scalar& stddev);
 /** @overload */
-CV_EXPORTS void meanStdDev(InputArray mtx, OutputArray dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void meanStdDev(InputArray mtx, OutputArray dst, Stream& stream = Stream::Null());
 
 /** @brief Computes a standard deviation of integral images.
 
@@ -670,7 +670,7 @@ CV_EXPORTS void meanStdDev(InputArray mtx, OutputArray dst, Stream& stream = Str
 @param rect Rectangular window.
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void rectStdDev(InputArray src, InputArray sqr, OutputArray dst, Rect rect, Stream& stream = Stream::Null());
+CV_EXPORTS_W void rectStdDev(InputArray src, InputArray sqr, OutputArray dst, Rect rect, Stream& stream = Stream::Null());
 
 /** @brief Normalizes the norm or value range of an array.
 
@@ -688,7 +688,7 @@ number of channels as src and the depth =CV_MAT_DEPTH(dtype).
 
 @sa normalize
  */
-CV_EXPORTS void normalize(InputArray src, OutputArray dst, double alpha, double beta,
+CV_EXPORTS_W void normalize(InputArray src, OutputArray dst, double alpha, double beta,
                           int norm_type, int dtype, InputArray mask = noArray(),
                           Stream& stream = Stream::Null());
 
@@ -700,7 +700,7 @@ CV_EXPORTS void normalize(InputArray src, OutputArray dst, double alpha, double
 
 @sa integral
  */
-CV_EXPORTS void integral(InputArray src, OutputArray sum, Stream& stream = Stream::Null());
+CV_EXPORTS_W void integral(InputArray src, OutputArray sum, Stream& stream = Stream::Null());
 
 /** @brief Computes a squared integral image.
 
@@ -709,7 +709,7 @@ CV_EXPORTS void integral(InputArray src, OutputArray sum, Stream& stream = Strea
 CV_64FC1 .
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void sqrIntegral(InputArray src, OutputArray sqsum, Stream& stream = Stream::Null());
+CV_EXPORTS_W void sqrIntegral(InputArray src, OutputArray sqsum, Stream& stream = Stream::Null());
 
 //! @} cudaarithm_reduce
 
@@ -741,7 +741,7 @@ The function performs generalized matrix multiplication similar to the gemm func
 
 @sa gemm
  */
-CV_EXPORTS void gemm(InputArray src1, InputArray src2, double alpha,
+CV_EXPORTS_W void gemm(InputArray src1, InputArray src2, double alpha,
                      InputArray src3, double beta, OutputArray dst, int flags = 0, Stream& stream = Stream::Null());
 
 /** @brief Performs a per-element multiplication of two Fourier spectrums.
@@ -758,7 +758,7 @@ Only full (not packed) CV_32FC2 complex spectrums in the interleaved format are
 
 @sa mulSpectrums
  */
-CV_EXPORTS void mulSpectrums(InputArray src1, InputArray src2, OutputArray dst, int flags, bool conjB=false, Stream& stream = Stream::Null());
+CV_EXPORTS_W void mulSpectrums(InputArray src1, InputArray src2, OutputArray dst, int flags, bool conjB=false, Stream& stream = Stream::Null());
 
 /** @brief Performs a per-element multiplication of two Fourier spectrums and scales the result.
 
@@ -775,7 +775,7 @@ Only full (not packed) CV_32FC2 complex spectrums in the interleaved format are
 
 @sa mulSpectrums
  */
-CV_EXPORTS void mulAndScaleSpectrums(InputArray src1, InputArray src2, OutputArray dst, int flags, float scale, bool conjB=false, Stream& stream = Stream::Null());
+CV_EXPORTS_W void mulAndScaleSpectrums(InputArray src1, InputArray src2, OutputArray dst, int flags, float scale, bool conjB=false, Stream& stream = Stream::Null());
 
 /** @brief Performs a forward or inverse discrete Fourier transform (1D or 2D) of the floating point matrix.
 
@@ -812,11 +812,11 @@ instead of the width.
 
 @sa dft
  */
-CV_EXPORTS void dft(InputArray src, OutputArray dst, Size dft_size, int flags=0, Stream& stream = Stream::Null());
+CV_EXPORTS_W void dft(InputArray src, OutputArray dst, Size dft_size, int flags=0, Stream& stream = Stream::Null());
 
 /** @brief Base class for DFT operator as a cv::Algorithm. :
  */
-class CV_EXPORTS DFT : public Algorithm
+class CV_EXPORTS_W DFT : public Algorithm
 {
 public:
     /** @brief Computes an FFT of a given image.
@@ -825,7 +825,7 @@ class CV_EXPORTS DFT : public Algorithm
     @param result Result image.
     @param stream Stream for the asynchronous version.
      */
-    virtual void compute(InputArray image, OutputArray result, Stream& stream = Stream::Null()) = 0;
+    CV_WRAP virtual void compute(InputArray image, OutputArray result, Stream& stream = Stream::Null()) = 0;
 };
 
 /** @brief Creates implementation for cuda::DFT.
@@ -841,11 +841,11 @@ cases are always forward and inverse, respectively).
 -   **DFT_REAL_OUTPUT** specifies the output as real. The source matrix is the result of
 real-complex transform, so the destination matrix must be real.
  */
-CV_EXPORTS Ptr<DFT> createDFT(Size dft_size, int flags);
+CV_EXPORTS_W Ptr<DFT> createDFT(Size dft_size, int flags);
 
 /** @brief Base class for convolution (or cross-correlation) operator. :
  */
-class CV_EXPORTS Convolution : public Algorithm
+class CV_EXPORTS_W Convolution : public Algorithm
 {
 public:
     /** @brief Computes a convolution (or cross-correlation) of two images.
@@ -867,7 +867,7 @@ class CV_EXPORTS Convolution : public Algorithm
 estimation of block size will be used (which is optimized for speed). By varying user_block_size
 you can reduce memory requirements at the cost of speed.
  */
-CV_EXPORTS Ptr<Convolution> createConvolution(Size user_block_size = Size());
+CV_EXPORTS_W Ptr<Convolution> createConvolution(Size user_block_size = Size());
 
 //! @} cudaarithm_arithm
 
diff --git a/modules/cudaarithm/src/arithm.cpp b/modules/cudaarithm/src/arithm.cpp
index 01a0169136e..a8f70dd2057 100644
--- a/modules/cudaarithm/src/arithm.cpp
+++ b/modules/cudaarithm/src/arithm.cpp
@@ -451,7 +451,6 @@ namespace
         Size block_size;
         Size user_block_size;
         Size dft_size;
-        int spect_len;
 
         GpuMat image_spect, templ_spect, result_spect;
         GpuMat image_block, templ_block, result_data;
@@ -484,7 +483,7 @@ namespace
         createContinuous(dft_size, CV_32F, templ_block);
         createContinuous(dft_size, CV_32F, result_data);
 
-        spect_len = dft_size.height * (dft_size.width / 2 + 1);
+        int spect_len = dft_size.height * (dft_size.width / 2 + 1);
         createContinuous(1, spect_len, CV_32FC2, image_spect);
         createContinuous(1, spect_len, CV_32FC2, templ_spect);
         createContinuous(1, spect_len, CV_32FC2, result_spect);
diff --git a/modules/cudabgsegm/CMakeLists.txt b/modules/cudabgsegm/CMakeLists.txt
index c60fdd07696..ffc6a628aea 100644
--- a/modules/cudabgsegm/CMakeLists.txt
+++ b/modules/cudabgsegm/CMakeLists.txt
@@ -6,4 +6,4 @@ set(the_description "CUDA-accelerated Background Segmentation")
 
 ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4127 /wd4324 /wd4512 -Wundef -Wmissing-declarations -Wshadow)
 
-ocv_define_module(cudabgsegm opencv_video)
+ocv_define_module(cudabgsegm opencv_video WRAP python)
diff --git a/modules/cudabgsegm/include/opencv2/cudabgsegm.hpp b/modules/cudabgsegm/include/opencv2/cudabgsegm.hpp
index 6149a5cf445..1c051e4a501 100644
--- a/modules/cudabgsegm/include/opencv2/cudabgsegm.hpp
+++ b/modules/cudabgsegm/include/opencv2/cudabgsegm.hpp
@@ -77,27 +77,27 @@ class implements algorithm described in @cite MOG2001 .
    -   An example on gaussian mixture based background/foreground segmantation can be found at
         opencv_source_code/samples/gpu/bgfg_segm.cpp
  */
-class CV_EXPORTS BackgroundSubtractorMOG : public cv::BackgroundSubtractor
+class CV_EXPORTS_W BackgroundSubtractorMOG : public cv::BackgroundSubtractor
 {
 public:
 
     using cv::BackgroundSubtractor::apply;
-    virtual void apply(InputArray image, OutputArray fgmask, double learningRate, Stream& stream) = 0;
+    CV_WRAP virtual void apply(InputArray image, OutputArray fgmask, double learningRate, Stream& stream) = 0;
 
     using cv::BackgroundSubtractor::getBackgroundImage;
-    virtual void getBackgroundImage(OutputArray backgroundImage, Stream& stream) const = 0;
+    CV_WRAP virtual void getBackgroundImage(OutputArray backgroundImage, Stream& stream) const = 0;
 
-    virtual int getHistory() const = 0;
-    virtual void setHistory(int nframes) = 0;
+    CV_WRAP virtual int getHistory() const = 0;
+    CV_WRAP virtual void setHistory(int nframes) = 0;
 
-    virtual int getNMixtures() const = 0;
-    virtual void setNMixtures(int nmix) = 0;
+    CV_WRAP virtual int getNMixtures() const = 0;
+    CV_WRAP virtual void setNMixtures(int nmix) = 0;
 
-    virtual double getBackgroundRatio() const = 0;
-    virtual void setBackgroundRatio(double backgroundRatio) = 0;
+    CV_WRAP virtual double getBackgroundRatio() const = 0;
+    CV_WRAP virtual void setBackgroundRatio(double backgroundRatio) = 0;
 
-    virtual double getNoiseSigma() const = 0;
-    virtual void setNoiseSigma(double noiseSigma) = 0;
+    CV_WRAP virtual double getNoiseSigma() const = 0;
+    CV_WRAP virtual void setNoiseSigma(double noiseSigma) = 0;
 };
 
 /** @brief Creates mixture-of-gaussian background subtractor
@@ -108,7 +108,7 @@ class CV_EXPORTS BackgroundSubtractorMOG : public cv::BackgroundSubtractor
 @param noiseSigma Noise strength (standard deviation of the brightness or each color channel). 0
 means some automatic value.
  */
-CV_EXPORTS Ptr<cuda::BackgroundSubtractorMOG>
+CV_EXPORTS_W Ptr<cuda::BackgroundSubtractorMOG>
     createBackgroundSubtractorMOG(int history = 200, int nmixtures = 5,
                                   double backgroundRatio = 0.7, double noiseSigma = 0);
 
@@ -123,15 +123,15 @@ class implements algorithm described in @cite Zivkovic2004 .
 
 @sa BackgroundSubtractorMOG2
  */
-class CV_EXPORTS BackgroundSubtractorMOG2 : public cv::BackgroundSubtractorMOG2
+class CV_EXPORTS_W BackgroundSubtractorMOG2 : public cv::BackgroundSubtractorMOG2
 {
 public:
     using cv::BackgroundSubtractorMOG2::apply;
     using cv::BackgroundSubtractorMOG2::getBackgroundImage;
 
-    virtual void apply(InputArray image, OutputArray fgmask, double learningRate, Stream& stream) = 0;
+    CV_WRAP virtual void apply(InputArray image, OutputArray fgmask, double learningRate, Stream& stream) = 0;
 
-    virtual void getBackgroundImage(OutputArray backgroundImage, Stream& stream) const = 0;
+    CV_WRAP virtual void getBackgroundImage(OutputArray backgroundImage, Stream& stream) const = 0;
 };
 
 /** @brief Creates MOG2 Background Subtractor
@@ -143,7 +143,7 @@ affect the background update.
 @param detectShadows If true, the algorithm will detect shadows and mark them. It decreases the
 speed a bit, so if you do not need this feature, set the parameter to false.
  */
-CV_EXPORTS Ptr<cuda::BackgroundSubtractorMOG2>
+CV_EXPORTS_W Ptr<cuda::BackgroundSubtractorMOG2>
     createBackgroundSubtractorMOG2(int history = 500, double varThreshold = 16,
                                    bool detectShadows = true);
 
diff --git a/modules/cudacodec/CMakeLists.txt b/modules/cudacodec/CMakeLists.txt
index 6aecd26db04..071404ecc76 100644
--- a/modules/cudacodec/CMakeLists.txt
+++ b/modules/cudacodec/CMakeLists.txt
@@ -6,7 +6,7 @@ set(the_description "CUDA-accelerated Video Encoding/Decoding")
 
 ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4127 /wd4324 /wd4512 -Wundef -Wshadow)
 
-ocv_add_module(cudacodec opencv_core opencv_videoio OPTIONAL opencv_cudev)
+ocv_add_module(cudacodec opencv_core opencv_videoio OPTIONAL opencv_cudev WRAP python)
 
 ocv_module_include_directories()
 ocv_glob_module_sources()
diff --git a/modules/cudacodec/include/opencv2/cudacodec.hpp b/modules/cudacodec/include/opencv2/cudacodec.hpp
index 8263d69b57e..e404a48ce96 100644
--- a/modules/cudacodec/include/opencv2/cudacodec.hpp
+++ b/modules/cudacodec/include/opencv2/cudacodec.hpp
@@ -80,7 +80,7 @@ enum SurfaceFormat
 
 /** @brief Different parameters for CUDA video encoder.
  */
-struct CV_EXPORTS EncoderParams
+struct CV_EXPORTS_W EncoderParams
 {
     int P_Interval;      //!< NVVE_P_INTERVAL,
     int IDR_Period;      //!< NVVE_IDR_PERIOD,
@@ -125,7 +125,7 @@ struct CV_EXPORTS EncoderParams
 
 /** @brief Callbacks for CUDA video encoder.
  */
-class CV_EXPORTS EncoderCallBack
+class CV_EXPORTS_W EncoderCallBack
 {
 public:
     enum PicType
@@ -152,14 +152,14 @@ class CV_EXPORTS EncoderCallBack
     @param frameNumber
     @param picType Specify frame type (I-Frame, P-Frame or B-Frame).
      */
-    virtual void onBeginFrame(int frameNumber, PicType picType) = 0;
+    CV_WRAP virtual void onBeginFrame(int frameNumber, EncoderCallBack::PicType picType) = 0;
 
     /** @brief Callback function signals that the encoding operation on the frame has finished.
 
     @param frameNumber
     @param picType Specify frame type (I-Frame, P-Frame or B-Frame).
      */
-    virtual void onEndFrame(int frameNumber, PicType picType) = 0;
+    CV_WRAP virtual void onEndFrame(int frameNumber, EncoderCallBack::PicType picType) = 0;
 };
 
 /** @brief Video writer interface.
@@ -172,7 +172,7 @@ The implementation uses H264 video codec.
    -   An example on how to use the videoWriter class can be found at
         opencv_source_code/samples/gpu/video_writer.cpp
  */
-class CV_EXPORTS VideoWriter
+class CV_EXPORTS_W VideoWriter
 {
 public:
     virtual ~VideoWriter() {}
@@ -185,9 +185,9 @@ class CV_EXPORTS VideoWriter
     The method write the specified image to video file. The image must have the same size and the same
     surface format as has been specified when opening the video writer.
      */
-    virtual void write(InputArray frame, bool lastFrame = false) = 0;
+    CV_WRAP virtual void write(InputArray frame, bool lastFrame = false) = 0;
 
-    virtual EncoderParams getEncoderParams() const = 0;
+    CV_WRAP virtual EncoderParams getEncoderParams() const = 0;
 };
 
 /** @brief Creates video writer.
@@ -202,7 +202,7 @@ encoding, frames with other formats will be used as is.
 The constructors initialize video writer. FFMPEG is used to write videos. User can implement own
 multiplexing with cudacodec::EncoderCallBack .
  */
-CV_EXPORTS Ptr<VideoWriter> createVideoWriter(const String& fileName, Size frameSize, double fps, SurfaceFormat format = SF_BGR);
+CV_EXPORTS_W Ptr<cudacodec::VideoWriter> createVideoWriter(const String& fileName, Size frameSize, double fps, SurfaceFormat format = SF_BGR);
 /** @overload
 @param fileName Name of the output video file. Only AVI file format is supported.
 @param frameSize Size of the input video frames.
@@ -212,7 +212,7 @@ CV_EXPORTS Ptr<VideoWriter> createVideoWriter(const String& fileName, Size frame
 SF_IYUV , SF_BGR or SF_GRAY). BGR or gray frames will be converted to YV12 format before
 encoding, frames with other formats will be used as is.
 */
-CV_EXPORTS Ptr<VideoWriter> createVideoWriter(const String& fileName, Size frameSize, double fps, const EncoderParams& params, SurfaceFormat format = SF_BGR);
+CV_EXPORTS_W Ptr<cudacodec::VideoWriter> createVideoWriter(const String& fileName, Size frameSize, double fps, const EncoderParams& params, SurfaceFormat format = SF_BGR);
 
 /** @overload
 @param encoderCallback Callbacks for video encoder. See cudacodec::EncoderCallBack . Use it if you
@@ -223,7 +223,7 @@ want to work with raw video stream.
 SF_IYUV , SF_BGR or SF_GRAY). BGR or gray frames will be converted to YV12 format before
 encoding, frames with other formats will be used as is.
 */
-CV_EXPORTS Ptr<VideoWriter> createVideoWriter(const Ptr<EncoderCallBack>& encoderCallback, Size frameSize, double fps, SurfaceFormat format = SF_BGR);
+CV_EXPORTS_W Ptr<cudacodec::VideoWriter> createVideoWriter(const Ptr<EncoderCallBack>& encoderCallback, Size frameSize, double fps, SurfaceFormat format = SF_BGR);
 /** @overload
 @param encoderCallback Callbacks for video encoder. See cudacodec::EncoderCallBack . Use it if you
 want to work with raw video stream.
@@ -234,7 +234,7 @@ want to work with raw video stream.
 SF_IYUV , SF_BGR or SF_GRAY). BGR or gray frames will be converted to YV12 format before
 encoding, frames with other formats will be used as is.
 */
-CV_EXPORTS Ptr<VideoWriter> createVideoWriter(const Ptr<EncoderCallBack>& encoderCallback, Size frameSize, double fps, const EncoderParams& params, SurfaceFormat format = SF_BGR);
+CV_EXPORTS_W Ptr<cudacodec::VideoWriter> createVideoWriter(const Ptr<EncoderCallBack>& encoderCallback, Size frameSize, double fps, const EncoderParams& params, SurfaceFormat format = SF_BGR);
 
 ////////////////////////////////// Video Decoding //////////////////////////////////////////
 
@@ -284,7 +284,7 @@ struct FormatInfo
    -   An example on how to use the videoReader class can be found at
         opencv_source_code/samples/gpu/video_reader.cpp
  */
-class CV_EXPORTS VideoReader
+class CV_EXPORTS_W VideoReader
 {
 public:
     virtual ~VideoReader() {}
@@ -294,7 +294,7 @@ class CV_EXPORTS VideoReader
     If no frames has been grabbed (there are no more frames in video file), the methods return false .
     The method throws Exception if error occurs.
      */
-    virtual bool nextFrame(OutputArray frame) = 0;
+    CV_WRAP virtual bool nextFrame(OutputArray frame) = 0;
 
     /** @brief Returns information about video file format.
     */
@@ -305,7 +305,7 @@ class CV_EXPORTS VideoReader
 
 User can implement own demultiplexing by implementing this interface.
  */
-class CV_EXPORTS RawVideoSource
+class CV_EXPORTS_W RawVideoSource
 {
 public:
     virtual ~RawVideoSource() {}
@@ -329,11 +329,11 @@ class CV_EXPORTS RawVideoSource
 
 FFMPEG is used to read videos. User can implement own demultiplexing with cudacodec::RawVideoSource
  */
-CV_EXPORTS Ptr<VideoReader> createVideoReader(const String& filename);
+CV_EXPORTS_W Ptr<VideoReader> createVideoReader(const String& filename);
 /** @overload
 @param source RAW video source implemented by user.
 */
-CV_EXPORTS Ptr<VideoReader> createVideoReader(const Ptr<RawVideoSource>& source);
+CV_EXPORTS_W Ptr<VideoReader> createVideoReader(const Ptr<RawVideoSource>& source);
 
 //! @}
 
diff --git a/modules/cudacodec/misc/python/pyopencv_cudacodec.hpp b/modules/cudacodec/misc/python/pyopencv_cudacodec.hpp
new file mode 100644
index 00000000000..6a4066edadf
--- /dev/null
+++ b/modules/cudacodec/misc/python/pyopencv_cudacodec.hpp
@@ -0,0 +1,14 @@
+#ifdef HAVE_OPENCV_CUDACODEC
+
+#include "opencv2/cudacodec.hpp"
+
+typedef cudacodec::EncoderCallBack::PicType EncoderCallBack_PicType;
+
+CV_PY_TO_CLASS(cudacodec::EncoderParams);
+
+CV_PY_TO_ENUM(cudacodec::EncoderCallBack::PicType);
+CV_PY_TO_ENUM(cudacodec::SurfaceFormat);
+
+CV_PY_FROM_CLASS(cudacodec::EncoderParams);
+
+#endif
diff --git a/modules/cudafeatures2d/CMakeLists.txt b/modules/cudafeatures2d/CMakeLists.txt
index af1945a250a..aba40283dd9 100644
--- a/modules/cudafeatures2d/CMakeLists.txt
+++ b/modules/cudafeatures2d/CMakeLists.txt
@@ -6,4 +6,4 @@ set(the_description "CUDA-accelerated Feature Detection and Description")
 
 ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4127 /wd4100 /wd4324 /wd4512 /wd4515 -Wundef -Wmissing-declarations -Wshadow -Wunused-parameter -Wshadow)
 
-ocv_define_module(cudafeatures2d opencv_features2d opencv_cudafilters opencv_cudawarping)
+ocv_define_module(cudafeatures2d opencv_features2d opencv_cudafilters opencv_cudawarping WRAP python)
diff --git a/modules/cudafeatures2d/include/opencv2/cudafeatures2d.hpp b/modules/cudafeatures2d/include/opencv2/cudafeatures2d.hpp
index 27a0ddd3086..91e85cff141 100644
--- a/modules/cudafeatures2d/include/opencv2/cudafeatures2d.hpp
+++ b/modules/cudafeatures2d/include/opencv2/cudafeatures2d.hpp
@@ -72,7 +72,7 @@ namespace cv { namespace cuda {
 It has two groups of match methods: for matching descriptors of an image with another image or with
 an image set.
  */
-class CV_EXPORTS DescriptorMatcher : public cv::Algorithm
+class CV_EXPORTS_W DescriptorMatcher : public cv::Algorithm
 {
 public:
     //
@@ -89,7 +89,7 @@ class CV_EXPORTS DescriptorMatcher : public cv::Algorithm
     preferable choices for SIFT and SURF descriptors, NORM_HAMMING should be used with ORB, BRISK and
     BRIEF).
      */
-    static Ptr<DescriptorMatcher> createBFMatcher(int normType = cv::NORM_L2);
+    CV_WRAP static Ptr<cuda::DescriptorMatcher> createBFMatcher(int normType = cv::NORM_L2);
 
     //
     // Utility
@@ -97,7 +97,7 @@ class CV_EXPORTS DescriptorMatcher : public cv::Algorithm
 
     /** @brief Returns true if the descriptor matcher supports masking permissible matches.
      */
-    virtual bool isMaskSupported() const = 0;
+    CV_WRAP virtual bool isMaskSupported() const = 0;
 
     //
     // Descriptor collection
@@ -110,26 +110,26 @@ class CV_EXPORTS DescriptorMatcher : public cv::Algorithm
     @param descriptors Descriptors to add. Each descriptors[i] is a set of descriptors from the same
     train image.
      */
-    virtual void add(const std::vector<GpuMat>& descriptors) = 0;
+    CV_WRAP virtual void add(const std::vector<GpuMat>& descriptors) = 0;
 
     /** @brief Returns a constant link to the train descriptor collection.
      */
-    virtual const std::vector<GpuMat>& getTrainDescriptors() const = 0;
+    CV_WRAP virtual const std::vector<GpuMat>& getTrainDescriptors() const = 0;
 
     /** @brief Clears the train descriptor collection.
      */
-    virtual void clear() = 0;
+    CV_WRAP virtual void clear() = 0;
 
     /** @brief Returns true if there are no train descriptors in the collection.
      */
-    virtual bool empty() const = 0;
+    CV_WRAP virtual bool empty() const = 0;
 
     /** @brief Trains a descriptor matcher.
 
     Trains a descriptor matcher (for example, the flann index). In all methods to match, the method
     train() is run every time before matching.
      */
-    virtual void train() = 0;
+    CV_WRAP virtual void train() = 0;
 
     //
     // 1 to 1 match
@@ -151,14 +151,14 @@ class CV_EXPORTS DescriptorMatcher : public cv::Algorithm
     matched. Namely, queryDescriptors[i] can be matched with trainDescriptors[j] only if
     mask.at\<uchar\>(i,j) is non-zero.
      */
-    virtual void match(InputArray queryDescriptors, InputArray trainDescriptors,
-                       std::vector<DMatch>& matches,
+    CV_WRAP virtual void match(InputArray queryDescriptors, InputArray trainDescriptors,
+                       CV_OUT std::vector<DMatch>& matches,
                        InputArray mask = noArray()) = 0;
 
     /** @overload
      */
-    virtual void match(InputArray queryDescriptors,
-                       std::vector<DMatch>& matches,
+    CV_WRAP virtual void match(InputArray queryDescriptors,
+                       CV_OUT std::vector<DMatch>& matches,
                        const std::vector<GpuMat>& masks = std::vector<GpuMat>()) = 0;
 
     /** @brief Finds the best match for each descriptor from a query set (asynchronous version).
@@ -178,14 +178,14 @@ class CV_EXPORTS DescriptorMatcher : public cv::Algorithm
     matched. Namely, queryDescriptors[i] can be matched with trainDescriptors[j] only if
     mask.at\<uchar\>(i,j) is non-zero.
      */
-    virtual void matchAsync(InputArray queryDescriptors, InputArray trainDescriptors,
+    CV_WRAP virtual void matchAsync(InputArray queryDescriptors, InputArray trainDescriptors,
                             OutputArray matches,
                             InputArray mask = noArray(),
                             Stream& stream = Stream::Null()) = 0;
 
     /** @overload
      */
-    virtual void matchAsync(InputArray queryDescriptors,
+    CV_WRAP virtual void matchAsync(InputArray queryDescriptors,
                             OutputArray matches,
                             const std::vector<GpuMat>& masks = std::vector<GpuMat>(),
                             Stream& stream = Stream::Null()) = 0;
@@ -198,8 +198,8 @@ class CV_EXPORTS DescriptorMatcher : public cv::Algorithm
     @param gpu_matches Matches, returned from DescriptorMatcher::matchAsync.
     @param matches Vector of DMatch objects.
      */
-    virtual void matchConvert(InputArray gpu_matches,
-                              std::vector<DMatch>& matches) = 0;
+    CV_WRAP virtual void matchConvert(InputArray gpu_matches,
+                              CV_OUT std::vector<DMatch>& matches) = 0;
 
     //
     // knn match
@@ -223,16 +223,16 @@ class CV_EXPORTS DescriptorMatcher : public cv::Algorithm
     descriptor. The matches are returned in the distance increasing order. See DescriptorMatcher::match
     for the details about query and train descriptors.
      */
-    virtual void knnMatch(InputArray queryDescriptors, InputArray trainDescriptors,
-                          std::vector<std::vector<DMatch> >& matches,
+    CV_WRAP virtual void knnMatch(InputArray queryDescriptors, InputArray trainDescriptors,
+                          CV_OUT std::vector<std::vector<DMatch> >& matches,
                           int k,
                           InputArray mask = noArray(),
                           bool compactResult = false) = 0;
 
     /** @overload
      */
-    virtual void knnMatch(InputArray queryDescriptors,
-                          std::vector<std::vector<DMatch> >& matches,
+    CV_WRAP virtual void knnMatch(InputArray queryDescriptors,
+                          CV_OUT std::vector<std::vector<DMatch> >& matches,
                           int k,
                           const std::vector<GpuMat>& masks = std::vector<GpuMat>(),
                           bool compactResult = false) = 0;
@@ -254,7 +254,7 @@ class CV_EXPORTS DescriptorMatcher : public cv::Algorithm
     descriptor. The matches are returned in the distance increasing order. See DescriptorMatcher::matchAsync
     for the details about query and train descriptors.
      */
-    virtual void knnMatchAsync(InputArray queryDescriptors, InputArray trainDescriptors,
+    CV_WRAP virtual void knnMatchAsync(InputArray queryDescriptors, InputArray trainDescriptors,
                                OutputArray matches,
                                int k,
                                InputArray mask = noArray(),
@@ -262,7 +262,7 @@ class CV_EXPORTS DescriptorMatcher : public cv::Algorithm
 
     /** @overload
      */
-    virtual void knnMatchAsync(InputArray queryDescriptors,
+    CV_WRAP virtual void knnMatchAsync(InputArray queryDescriptors,
                                OutputArray matches,
                                int k,
                                const std::vector<GpuMat>& masks = std::vector<GpuMat>(),
@@ -279,7 +279,7 @@ class CV_EXPORTS DescriptorMatcher : public cv::Algorithm
     false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,
     the matches vector does not contain matches for fully masked-out query descriptors.
      */
-    virtual void knnMatchConvert(InputArray gpu_matches,
+    CV_WRAP virtual void knnMatchConvert(InputArray gpu_matches,
                                  std::vector< std::vector<DMatch> >& matches,
                                  bool compactResult = false) = 0;
 
@@ -306,16 +306,16 @@ class CV_EXPORTS DescriptorMatcher : public cv::Algorithm
     query descriptor and the training descriptor is equal or smaller than maxDistance. Found matches are
     returned in the distance increasing order.
      */
-    virtual void radiusMatch(InputArray queryDescriptors, InputArray trainDescriptors,
-                             std::vector<std::vector<DMatch> >& matches,
+    CV_WRAP virtual void radiusMatch(InputArray queryDescriptors, InputArray trainDescriptors,
+                             CV_OUT std::vector<std::vector<DMatch> >& matches,
                              float maxDistance,
                              InputArray mask = noArray(),
                              bool compactResult = false) = 0;
 
     /** @overload
      */
-    virtual void radiusMatch(InputArray queryDescriptors,
-                             std::vector<std::vector<DMatch> >& matches,
+    CV_WRAP virtual void radiusMatch(InputArray queryDescriptors,
+                             CV_OUT std::vector<std::vector<DMatch> >& matches,
                              float maxDistance,
                              const std::vector<GpuMat>& masks = std::vector<GpuMat>(),
                              bool compactResult = false) = 0;
@@ -338,7 +338,7 @@ class CV_EXPORTS DescriptorMatcher : public cv::Algorithm
     query descriptor and the training descriptor is equal or smaller than maxDistance. Found matches are
     returned in the distance increasing order.
      */
-    virtual void radiusMatchAsync(InputArray queryDescriptors, InputArray trainDescriptors,
+    CV_WRAP virtual void radiusMatchAsync(InputArray queryDescriptors, InputArray trainDescriptors,
                                   OutputArray matches,
                                   float maxDistance,
                                   InputArray mask = noArray(),
@@ -346,7 +346,7 @@ class CV_EXPORTS DescriptorMatcher : public cv::Algorithm
 
     /** @overload
      */
-    virtual void radiusMatchAsync(InputArray queryDescriptors,
+    CV_WRAP virtual void radiusMatchAsync(InputArray queryDescriptors,
                                   OutputArray matches,
                                   float maxDistance,
                                   const std::vector<GpuMat>& masks = std::vector<GpuMat>(),
@@ -363,7 +363,7 @@ class CV_EXPORTS DescriptorMatcher : public cv::Algorithm
     false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,
     the matches vector does not contain matches for fully masked-out query descriptors.
      */
-    virtual void radiusMatchConvert(InputArray gpu_matches,
+    CV_WRAP virtual void radiusMatchConvert(InputArray gpu_matches,
                                     std::vector< std::vector<DMatch> >& matches,
                                     bool compactResult = false) = 0;
 };
@@ -374,10 +374,10 @@ class CV_EXPORTS DescriptorMatcher : public cv::Algorithm
 
 /** @brief Abstract base class for CUDA asynchronous 2D image feature detectors and descriptor extractors.
  */
-class CV_EXPORTS Feature2DAsync
+class CV_EXPORTS_W Feature2DAsync : public cv::Feature2D
 {
 public:
-    virtual ~Feature2DAsync();
+    CV_WRAP virtual ~Feature2DAsync();
 
     /** @brief Detects keypoints in an image.
 
@@ -387,7 +387,7 @@ class CV_EXPORTS Feature2DAsync
     matrix with non-zero values in the region of interest.
     @param stream CUDA stream.
      */
-    virtual void detectAsync(InputArray image,
+    CV_WRAP virtual void detectAsync(InputArray image,
                              OutputArray keypoints,
                              InputArray mask = noArray(),
                              Stream& stream = Stream::Null());
@@ -399,13 +399,13 @@ class CV_EXPORTS Feature2DAsync
     @param descriptors Computed descriptors. Row j is the descriptor for j-th keypoint.
     @param stream CUDA stream.
      */
-    virtual void computeAsync(InputArray image,
+    CV_WRAP virtual void computeAsync(InputArray image,
                               OutputArray keypoints,
                               OutputArray descriptors,
                               Stream& stream = Stream::Null());
 
     /** Detects keypoints and computes the descriptors. */
-    virtual void detectAndComputeAsync(InputArray image,
+    CV_WRAP virtual void detectAndComputeAsync(InputArray image,
                                        InputArray mask,
                                        OutputArray keypoints,
                                        OutputArray descriptors,
@@ -413,7 +413,7 @@ class CV_EXPORTS Feature2DAsync
                                        Stream& stream = Stream::Null());
 
     /** Converts keypoints array from internal representation to standard vector. */
-    virtual void convert(InputArray gpu_keypoints,
+    CV_WRAP virtual void convert(InputArray gpu_keypoints,
                          std::vector<KeyPoint>& keypoints) = 0;
 };
 
@@ -423,7 +423,7 @@ class CV_EXPORTS Feature2DAsync
 
 /** @brief Wrapping class for feature detection using the FAST method.
  */
-class CV_EXPORTS FastFeatureDetector : public cv::FastFeatureDetector, public Feature2DAsync
+class CV_EXPORTS_W FastFeatureDetector : public Feature2DAsync
 {
 public:
     enum
@@ -435,13 +435,14 @@ class CV_EXPORTS FastFeatureDetector : public cv::FastFeatureDetector, public Fe
         FEATURE_SIZE = 7
     };
 
-    static Ptr<FastFeatureDetector> create(int threshold=10,
+    CV_WRAP static Ptr<cuda::FastFeatureDetector> create(int threshold=10,
                                            bool nonmaxSuppression=true,
-                                           int type=FastFeatureDetector::TYPE_9_16,
+                                           int type=cv::FastFeatureDetector::TYPE_9_16,
                                            int max_npoints = 5000);
+    CV_WRAP virtual void setThreshold(int threshold) = 0;
 
-    virtual void setMaxNumPoints(int max_npoints) = 0;
-    virtual int getMaxNumPoints() const = 0;
+    CV_WRAP virtual void setMaxNumPoints(int max_npoints) = 0;
+    CV_WRAP virtual int getMaxNumPoints() const = 0;
 };
 
 //
@@ -452,7 +453,7 @@ class CV_EXPORTS FastFeatureDetector : public cv::FastFeatureDetector, public Fe
  *
  * @sa cv::ORB
  */
-class CV_EXPORTS ORB : public cv::ORB, public Feature2DAsync
+class CV_EXPORTS_W ORB : public Feature2DAsync
 {
 public:
     enum
@@ -466,20 +467,20 @@ class CV_EXPORTS ORB : public cv::ORB, public Feature2DAsync
         ROWS_COUNT
     };
 
-    static Ptr<ORB> create(int nfeatures=500,
+    CV_WRAP static Ptr<cuda::ORB> create(int nfeatures=500,
                            float scaleFactor=1.2f,
                            int nlevels=8,
                            int edgeThreshold=31,
                            int firstLevel=0,
                            int WTA_K=2,
-                           int scoreType=ORB::HARRIS_SCORE,
+                           int scoreType=cv::ORB::HARRIS_SCORE,
                            int patchSize=31,
                            int fastThreshold=20,
                            bool blurForDescriptor=false);
 
     //! if true, image will be blurred before descriptors calculation
-    virtual void setBlurForDescriptor(bool blurForDescriptor) = 0;
-    virtual bool getBlurForDescriptor() const = 0;
+    CV_WRAP virtual void setBlurForDescriptor(bool blurForDescriptor) = 0;
+    CV_WRAP virtual bool getBlurForDescriptor() const = 0;
 };
 
 //! @}
diff --git a/modules/cudafeatures2d/src/brute_force_matcher.cpp b/modules/cudafeatures2d/src/brute_force_matcher.cpp
index 5287546bbe3..87316846d55 100644
--- a/modules/cudafeatures2d/src/brute_force_matcher.cpp
+++ b/modules/cudafeatures2d/src/brute_force_matcher.cpp
@@ -564,12 +564,8 @@ namespace
 
             if (compactResult)
             {
-#ifdef CV_CXX11
                 std::vector< std::vector<DMatch> >::iterator new_end = std::remove_if(matches.begin(), matches.end(),
                     [](const std::vector<DMatch>& e)->bool { return e.empty(); });
-#else
-                std::vector< std::vector<DMatch> >::iterator new_end = std::remove_if(matches.begin(), matches.end(), std::mem_fun_ref(&std::vector<DMatch>::empty));
-#endif
                 matches.erase(new_end, matches.end());
             }
         }
diff --git a/modules/cudafeatures2d/src/fast.cpp b/modules/cudafeatures2d/src/fast.cpp
index e48ef189495..e2c13b06b2b 100644
--- a/modules/cudafeatures2d/src/fast.cpp
+++ b/modules/cudafeatures2d/src/fast.cpp
@@ -81,8 +81,8 @@ namespace
         virtual void setMaxNumPoints(int max_npoints) { max_npoints_ = max_npoints; }
         virtual int getMaxNumPoints() const { return max_npoints_; }
 
-        virtual void setType(int type) { CV_Assert( type == TYPE_9_16 ); }
-        virtual int getType() const { return TYPE_9_16; }
+        virtual void setType(int type) { CV_Assert( type == cv::FastFeatureDetector::TYPE_9_16 ); }
+        virtual int getType() const { return cv::FastFeatureDetector::TYPE_9_16; }
 
     private:
         int threshold_;
@@ -207,7 +207,7 @@ namespace
 
 Ptr<cv::cuda::FastFeatureDetector> cv::cuda::FastFeatureDetector::create(int threshold, bool nonmaxSuppression, int type, int max_npoints)
 {
-    CV_Assert( type == TYPE_9_16 );
+    CV_Assert( type == cv::FastFeatureDetector::TYPE_9_16 );
     return makePtr<FAST_Impl>(threshold, nonmaxSuppression, max_npoints);
 }
 
diff --git a/modules/cudafeatures2d/src/orb.cpp b/modules/cudafeatures2d/src/orb.cpp
index 41a431d5589..75cdd7efa88 100644
--- a/modules/cudafeatures2d/src/orb.cpp
+++ b/modules/cudafeatures2d/src/orb.cpp
@@ -354,7 +354,7 @@ namespace
 
         virtual void convert(InputArray _gpu_keypoints, std::vector<KeyPoint>& keypoints);
 
-        virtual int descriptorSize() const { return kBytes; }
+        virtual int descriptorSize() const { return cv::ORB::kBytes; }
         virtual int descriptorType() const { return CV_8U; }
         virtual int defaultNorm() const { return NORM_HAMMING; }
 
@@ -764,7 +764,7 @@ namespace
 
             const int n_features = static_cast<int>(n_features_per_level_[level]);
 
-            if (scoreType_ == ORB::HARRIS_SCORE)
+            if (scoreType_ == cv::ORB::HARRIS_SCORE)
             {
                 // Keep more points than necessary as FAST does not give amazing corners
                 cull(keyPointsPyr_[level], keyPointsCount_[level], 2 * n_features, stream);
diff --git a/modules/cudafilters/CMakeLists.txt b/modules/cudafilters/CMakeLists.txt
index 04f2d19212e..08281c135ce 100644
--- a/modules/cudafilters/CMakeLists.txt
+++ b/modules/cudafilters/CMakeLists.txt
@@ -6,4 +6,4 @@ set(the_description "CUDA-accelerated Image Filtering")
 
 ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4127 /wd4324 /wd4512 -Wundef -Wmissing-declarations -Wshadow)
 
-ocv_define_module(cudafilters opencv_imgproc opencv_cudaarithm)
+ocv_define_module(cudafilters opencv_imgproc opencv_cudaarithm WRAP python)
diff --git a/modules/cudafilters/include/opencv2/cudafilters.hpp b/modules/cudafilters/include/opencv2/cudafilters.hpp
index 1e25e5602db..fd28150f310 100644
--- a/modules/cudafilters/include/opencv2/cudafilters.hpp
+++ b/modules/cudafilters/include/opencv2/cudafilters.hpp
@@ -72,7 +72,7 @@ namespace cv { namespace cuda {
 
 /** @brief Common interface for all CUDA filters :
  */
-class CV_EXPORTS Filter : public Algorithm
+class CV_EXPORTS_W Filter : public Algorithm
 {
 public:
     /** @brief Applies the specified filter to the image.
@@ -81,7 +81,7 @@ class CV_EXPORTS Filter : public Algorithm
     @param dst Output image.
     @param stream Stream for the asynchronous version.
      */
-    virtual void apply(InputArray src, OutputArray dst, Stream& stream = Stream::Null()) = 0;
+    CV_WRAP virtual void apply(InputArray src, OutputArray dst, Stream& stream = Stream::Null()) = 0;
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
@@ -99,7 +99,7 @@ center.
 
 @sa boxFilter
  */
-CV_EXPORTS Ptr<Filter> createBoxFilter(int srcType, int dstType, Size ksize, Point anchor = Point(-1,-1),
+CV_EXPORTS_W Ptr<Filter> createBoxFilter(int srcType, int dstType, Size ksize, Point anchor = Point(-1, -1),
                                        int borderMode = BORDER_DEFAULT, Scalar borderVal = Scalar::all(0));
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
@@ -117,7 +117,7 @@ center.
 
 @sa filter2D
  */
-CV_EXPORTS Ptr<Filter> createLinearFilter(int srcType, int dstType, InputArray kernel, Point anchor = Point(-1,-1),
+CV_EXPORTS_W Ptr<Filter> createLinearFilter(int srcType, int dstType, InputArray kernel, Point anchor = Point(-1, -1),
                                           int borderMode = BORDER_DEFAULT, Scalar borderVal = Scalar::all(0));
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
@@ -136,7 +136,7 @@ applied (see getDerivKernels ).
 
 @sa Laplacian
  */
-CV_EXPORTS Ptr<Filter> createLaplacianFilter(int srcType, int dstType, int ksize = 1, double scale = 1,
+CV_EXPORTS_W Ptr<Filter> createLaplacianFilter(int srcType, int dstType, int ksize = 1, double scale = 1,
                                              int borderMode = BORDER_DEFAULT, Scalar borderVal = Scalar::all(0));
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
@@ -156,7 +156,7 @@ borderInterpolate.
 
 @sa sepFilter2D
  */
-CV_EXPORTS Ptr<Filter> createSeparableLinearFilter(int srcType, int dstType, InputArray rowKernel, InputArray columnKernel,
+CV_EXPORTS_W Ptr<Filter> createSeparableLinearFilter(int srcType, int dstType, InputArray rowKernel, InputArray columnKernel,
                                                    Point anchor = Point(-1,-1), int rowBorderMode = BORDER_DEFAULT, int columnBorderMode = -1);
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
@@ -177,7 +177,7 @@ applied. For details, see getDerivKernels .
 borderInterpolate.
 @param columnBorderMode Pixel extrapolation method in the horizontal direction.
  */
-CV_EXPORTS Ptr<Filter> createDerivFilter(int srcType, int dstType, int dx, int dy,
+CV_EXPORTS_W Ptr<Filter> createDerivFilter(int srcType, int dstType, int dx, int dy,
                                          int ksize, bool normalize = false, double scale = 1,
                                          int rowBorderMode = BORDER_DEFAULT, int columnBorderMode = -1);
 
@@ -196,7 +196,7 @@ borderInterpolate.
 
 @sa Sobel
  */
-CV_EXPORTS Ptr<Filter> createSobelFilter(int srcType, int dstType, int dx, int dy, int ksize = 3,
+CV_EXPORTS_W Ptr<Filter> createSobelFilter(int srcType, int dstType, int dx, int dy, int ksize = 3,
                                          double scale = 1, int rowBorderMode = BORDER_DEFAULT, int columnBorderMode = -1);
 
 /** @brief Creates a vertical or horizontal Scharr operator.
@@ -213,7 +213,7 @@ borderInterpolate.
 
 @sa Scharr
  */
-CV_EXPORTS Ptr<Filter> createScharrFilter(int srcType, int dstType, int dx, int dy,
+CV_EXPORTS_W Ptr<Filter> createScharrFilter(int srcType, int dstType, int dx, int dy,
                                           double scale = 1, int rowBorderMode = BORDER_DEFAULT, int columnBorderMode = -1);
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
@@ -233,7 +233,7 @@ borderInterpolate.
 
 @sa GaussianBlur
  */
-CV_EXPORTS Ptr<Filter> createGaussianFilter(int srcType, int dstType, Size ksize,
+CV_EXPORTS_W Ptr<Filter> createGaussianFilter(int srcType, int dstType, Size ksize,
                                             double sigma1, double sigma2 = 0,
                                             int rowBorderMode = BORDER_DEFAULT, int columnBorderMode = -1);
 
@@ -258,7 +258,7 @@ is at the center.
 
 @sa morphologyEx
  */
-CV_EXPORTS Ptr<Filter> createMorphologyFilter(int op, int srcType, InputArray kernel, Point anchor = Point(-1, -1), int iterations = 1);
+CV_EXPORTS_W Ptr<Filter> createMorphologyFilter(int op, int srcType, InputArray kernel, Point anchor = Point(-1, -1), int iterations = 1);
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 // Image Rank Filter
@@ -271,7 +271,7 @@ CV_EXPORTS Ptr<Filter> createMorphologyFilter(int op, int srcType, InputArray ke
 @param borderMode Pixel extrapolation method. For details, see borderInterpolate .
 @param borderVal Default border value.
  */
-CV_EXPORTS Ptr<Filter> createBoxMaxFilter(int srcType, Size ksize,
+CV_EXPORTS_W Ptr<Filter> createBoxMaxFilter(int srcType, Size ksize,
                                           Point anchor = Point(-1, -1),
                                           int borderMode = BORDER_DEFAULT, Scalar borderVal = Scalar::all(0));
 
@@ -283,7 +283,7 @@ CV_EXPORTS Ptr<Filter> createBoxMaxFilter(int srcType, Size ksize,
 @param borderMode Pixel extrapolation method. For details, see borderInterpolate .
 @param borderVal Default border value.
  */
-CV_EXPORTS Ptr<Filter> createBoxMinFilter(int srcType, Size ksize,
+CV_EXPORTS_W Ptr<Filter> createBoxMinFilter(int srcType, Size ksize,
                                           Point anchor = Point(-1, -1),
                                           int borderMode = BORDER_DEFAULT, Scalar borderVal = Scalar::all(0));
 
@@ -299,7 +299,7 @@ CV_EXPORTS Ptr<Filter> createBoxMinFilter(int srcType, Size ksize,
 @param borderMode Pixel extrapolation method. For details, see borderInterpolate .
 @param borderVal Default border value.
  */
-CV_EXPORTS Ptr<Filter> createRowSumFilter(int srcType, int dstType, int ksize, int anchor = -1, int borderMode = BORDER_DEFAULT, Scalar borderVal = Scalar::all(0));
+CV_EXPORTS_W Ptr<Filter> createRowSumFilter(int srcType, int dstType, int ksize, int anchor = -1, int borderMode = BORDER_DEFAULT, Scalar borderVal = Scalar::all(0));
 
 /** @brief Creates a vertical 1D box filter.
 
@@ -310,7 +310,7 @@ CV_EXPORTS Ptr<Filter> createRowSumFilter(int srcType, int dstType, int ksize, i
 @param borderMode Pixel extrapolation method. For details, see borderInterpolate .
 @param borderVal Default border value.
  */
-CV_EXPORTS Ptr<Filter> createColumnSumFilter(int srcType, int dstType, int ksize, int anchor = -1, int borderMode = BORDER_DEFAULT, Scalar borderVal = Scalar::all(0));
+CV_EXPORTS_W Ptr<Filter> createColumnSumFilter(int srcType, int dstType, int ksize, int anchor = -1, int borderMode = BORDER_DEFAULT, Scalar borderVal = Scalar::all(0));
 
 //! @}
 
@@ -324,7 +324,7 @@ CV_EXPORTS Ptr<Filter> createColumnSumFilter(int srcType, int dstType, int ksize
 
 Outputs an image that has been filtered using median-filtering formulation.
  */
-CV_EXPORTS Ptr<Filter> createMedianFilter(int srcType, int windowSize, int partition=128);
+CV_EXPORTS_W Ptr<Filter> createMedianFilter(int srcType, int windowSize, int partition = 128);
 
 }} // namespace cv { namespace cuda {
 
diff --git a/modules/cudaimgproc/CMakeLists.txt b/modules/cudaimgproc/CMakeLists.txt
index 84ee2f91bac..8d06804ddcc 100644
--- a/modules/cudaimgproc/CMakeLists.txt
+++ b/modules/cudaimgproc/CMakeLists.txt
@@ -6,4 +6,4 @@ set(the_description "CUDA-accelerated Image Processing")
 
 ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4127 /wd4100 /wd4324 /wd4512 /wd4515 -Wundef -Wmissing-declarations -Wshadow -Wunused-parameter)
 
-ocv_define_module(cudaimgproc opencv_imgproc OPTIONAL opencv_cudev opencv_cudaarithm opencv_cudafilters)
+ocv_define_module(cudaimgproc opencv_imgproc OPTIONAL opencv_cudev opencv_cudaarithm opencv_cudafilters WRAP python)
diff --git a/modules/cudaimgproc/include/opencv2/cudaimgproc.hpp b/modules/cudaimgproc/include/opencv2/cudaimgproc.hpp
index 50c6a749777..038dc9d053d 100644
--- a/modules/cudaimgproc/include/opencv2/cudaimgproc.hpp
+++ b/modules/cudaimgproc/include/opencv2/cudaimgproc.hpp
@@ -87,7 +87,7 @@ performance.
 
 @sa cvtColor
  */
-CV_EXPORTS void cvtColor(InputArray src, OutputArray dst, int code, int dcn = 0, Stream& stream = Stream::Null());
+CV_EXPORTS_W void cvtColor(InputArray src, OutputArray dst, int code, int dcn = 0, Stream& stream = Stream::Null());
 
 enum DemosaicTypes
 {
@@ -133,7 +133,7 @@ The function can do the following transformations:
 
 @sa cvtColor
  */
-CV_EXPORTS void demosaicing(InputArray src, OutputArray dst, int code, int dcn = -1, Stream& stream = Stream::Null());
+CV_EXPORTS_W void demosaicing(InputArray src, OutputArray dst, int code, int dcn = -1, Stream& stream = Stream::Null());
 
 /** @brief Exchanges the color channels of an image in-place.
 
@@ -154,7 +154,7 @@ CV_EXPORTS void swapChannels(InputOutputArray image, const int dstOrder[4], Stre
 @param forward true for forward gamma correction or false for inverse gamma correction.
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void gammaCorrection(InputArray src, OutputArray dst, bool forward = true, Stream& stream = Stream::Null());
+CV_EXPORTS_W void gammaCorrection(InputArray src, OutputArray dst, bool forward = true, Stream& stream = Stream::Null());
 
 enum AlphaCompTypes { ALPHA_OVER, ALPHA_IN, ALPHA_OUT, ALPHA_ATOP, ALPHA_XOR, ALPHA_PLUS, ALPHA_OVER_PREMUL, ALPHA_IN_PREMUL, ALPHA_OUT_PREMUL,
        ALPHA_ATOP_PREMUL, ALPHA_XOR_PREMUL, ALPHA_PLUS_PREMUL, ALPHA_PREMUL};
@@ -184,7 +184,7 @@ enum AlphaCompTypes { ALPHA_OVER, ALPHA_IN, ALPHA_OUT, ALPHA_ATOP, ALPHA_XOR, AL
    -   An example demonstrating the use of alphaComp can be found at
         opencv_source_code/samples/gpu/alpha_comp.cpp
  */
-CV_EXPORTS void alphaComp(InputArray img1, InputArray img2, OutputArray dst, int alpha_op, Stream& stream = Stream::Null());
+CV_EXPORTS_W void alphaComp(InputArray img1, InputArray img2, OutputArray dst, int alpha_op, Stream& stream = Stream::Null());
 
 //! @} cudaimgproc_color
 
@@ -199,7 +199,7 @@ CV_EXPORTS void alphaComp(InputArray img1, InputArray img2, OutputArray dst, int
 @param hist Destination histogram with one row, 256 columns, and the CV_32SC1 type.
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void calcHist(InputArray src, OutputArray hist, Stream& stream = Stream::Null());
+CV_EXPORTS_W void calcHist(InputArray src, OutputArray hist, Stream& stream = Stream::Null());
 
 /** @brief Calculates histogram for one channel 8-bit image confined in given mask.
 
@@ -208,7 +208,7 @@ CV_EXPORTS void calcHist(InputArray src, OutputArray hist, Stream& stream = Stre
 @param mask A mask image same size as src and of type CV_8UC1.
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void calcHist(InputArray src, InputArray mask, OutputArray hist, Stream& stream = Stream::Null());
+CV_EXPORTS_W void calcHist(InputArray src, InputArray mask, OutputArray hist, Stream& stream = Stream::Null());
 
 /** @brief Equalizes the histogram of a grayscale image.
 
@@ -218,11 +218,11 @@ CV_EXPORTS void calcHist(InputArray src, InputArray mask, OutputArray hist, Stre
 
 @sa equalizeHist
  */
-CV_EXPORTS void equalizeHist(InputArray src, OutputArray dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void equalizeHist(InputArray src, OutputArray dst, Stream& stream = Stream::Null());
 
 /** @brief Base class for Contrast Limited Adaptive Histogram Equalization. :
  */
-class CV_EXPORTS CLAHE : public cv::CLAHE
+class CV_EXPORTS_W CLAHE : public cv::CLAHE
 {
 public:
     using cv::CLAHE::apply;
@@ -232,7 +232,7 @@ class CV_EXPORTS CLAHE : public cv::CLAHE
     @param dst Destination image.
     @param stream Stream for the asynchronous version.
      */
-    virtual void apply(InputArray src, OutputArray dst, Stream& stream) = 0;
+    CV_WRAP virtual void apply(InputArray src, OutputArray dst, Stream& stream) = 0;
 };
 
 /** @brief Creates implementation for cuda::CLAHE .
@@ -241,7 +241,7 @@ class CV_EXPORTS CLAHE : public cv::CLAHE
 @param tileGridSize Size of grid for histogram equalization. Input image will be divided into
 equally sized rectangular tiles. tileGridSize defines the number of tiles in row and column.
  */
-CV_EXPORTS Ptr<cuda::CLAHE> createCLAHE(double clipLimit = 40.0, Size tileGridSize = Size(8, 8));
+CV_EXPORTS_W Ptr<cuda::CLAHE> createCLAHE(double clipLimit = 40.0, Size tileGridSize = Size(8, 8));
 
 /** @brief Computes levels with even distribution.
 
@@ -251,7 +251,7 @@ CV_EXPORTS Ptr<cuda::CLAHE> createCLAHE(double clipLimit = 40.0, Size tileGridSi
 @param upperLevel Upper boundary value of the greatest level.
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void evenLevels(OutputArray levels, int nLevels, int lowerLevel, int upperLevel, Stream& stream = Stream::Null());
+CV_EXPORTS_W void evenLevels(OutputArray levels, int nLevels, int lowerLevel, int upperLevel, Stream& stream = Stream::Null());
 
 /** @brief Calculates a histogram with evenly distributed bins.
 
@@ -263,9 +263,9 @@ a four-channel image, all channels are processed separately.
 @param upperLevel Upper boundary of highest-level bin.
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void histEven(InputArray src, OutputArray hist, int histSize, int lowerLevel, int upperLevel, Stream& stream = Stream::Null());
+CV_EXPORTS_W void histEven(InputArray src, OutputArray hist, int histSize, int lowerLevel, int upperLevel, Stream& stream = Stream::Null());
 /** @overload */
-CV_EXPORTS void histEven(InputArray src, GpuMat hist[4], int histSize[4], int lowerLevel[4], int upperLevel[4], Stream& stream = Stream::Null());
+CV_EXPORTS_W void histEven(InputArray src, GpuMat hist[4], int histSize[4], int lowerLevel[4], int upperLevel[4], Stream& stream = Stream::Null());
 
 /** @brief Calculates a histogram with bins determined by the levels array.
 
@@ -275,9 +275,9 @@ For a four-channel image, all channels are processed separately.
 @param levels Number of levels in the histogram.
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void histRange(InputArray src, OutputArray hist, InputArray levels, Stream& stream = Stream::Null());
+CV_EXPORTS_W void histRange(InputArray src, OutputArray hist, InputArray levels, Stream& stream = Stream::Null());
 /** @overload */
-CV_EXPORTS void histRange(InputArray src, GpuMat hist[4], const GpuMat levels[4], Stream& stream = Stream::Null());
+CV_EXPORTS_W void histRange(InputArray src, GpuMat hist[4], const GpuMat levels[4], Stream& stream = Stream::Null());
 
 //! @} cudaimgproc_hist
 
@@ -285,7 +285,7 @@ CV_EXPORTS void histRange(InputArray src, GpuMat hist[4], const GpuMat levels[4]
 
 /** @brief Base class for Canny Edge Detector. :
  */
-class CV_EXPORTS CannyEdgeDetector : public Algorithm
+class CV_EXPORTS_W CannyEdgeDetector : public Algorithm
 {
 public:
     /** @brief Finds edges in an image using the @cite Canny86 algorithm.
@@ -294,26 +294,26 @@ class CV_EXPORTS CannyEdgeDetector : public Algorithm
     @param edges Output edge map. It has the same size and type as image.
     @param stream Stream for the asynchronous version.
      */
-    virtual void detect(InputArray image, OutputArray edges, Stream& stream = Stream::Null()) = 0;
+    CV_WRAP virtual void detect(InputArray image, OutputArray edges, Stream& stream = Stream::Null()) = 0;
     /** @overload
     @param dx First derivative of image in the vertical direction. Support only CV_32S type.
     @param dy First derivative of image in the horizontal direction. Support only CV_32S type.
     @param edges Output edge map. It has the same size and type as image.
     @param stream Stream for the asynchronous version.
     */
-    virtual void detect(InputArray dx, InputArray dy, OutputArray edges, Stream& stream = Stream::Null()) = 0;
+    CV_WRAP virtual void detect(InputArray dx, InputArray dy, OutputArray edges, Stream& stream = Stream::Null()) = 0;
 
-    virtual void setLowThreshold(double low_thresh) = 0;
-    virtual double getLowThreshold() const = 0;
+    CV_WRAP virtual void setLowThreshold(double low_thresh) = 0;
+    CV_WRAP virtual double getLowThreshold() const = 0;
 
-    virtual void setHighThreshold(double high_thresh) = 0;
-    virtual double getHighThreshold() const = 0;
+    CV_WRAP virtual void setHighThreshold(double high_thresh) = 0;
+    CV_WRAP virtual double getHighThreshold() const = 0;
 
-    virtual void setAppertureSize(int apperture_size) = 0;
-    virtual int getAppertureSize() const = 0;
+    CV_WRAP virtual void setAppertureSize(int apperture_size) = 0;
+    CV_WRAP virtual int getAppertureSize() const = 0;
 
-    virtual void setL2Gradient(bool L2gradient) = 0;
-    virtual bool getL2Gradient() const = 0;
+    CV_WRAP virtual void setL2Gradient(bool L2gradient) = 0;
+    CV_WRAP virtual bool getL2Gradient() const = 0;
 };
 
 /** @brief Creates implementation for cuda::CannyEdgeDetector .
@@ -326,7 +326,7 @@ class CV_EXPORTS CannyEdgeDetector : public Algorithm
 L2gradient=true ), or a faster default \f$L_1\f$ norm \f$=|dI/dx|+|dI/dy|\f$ is enough ( L2gradient=false
 ).
  */
-CV_EXPORTS Ptr<CannyEdgeDetector> createCannyEdgeDetector(double low_thresh, double high_thresh, int apperture_size = 3, bool L2gradient = false);
+CV_EXPORTS_W Ptr<CannyEdgeDetector> createCannyEdgeDetector(double low_thresh, double high_thresh, int apperture_size = 3, bool L2gradient = false);
 
 /////////////////////////// Hough Transform ////////////////////////////
 
@@ -338,7 +338,7 @@ CV_EXPORTS Ptr<CannyEdgeDetector> createCannyEdgeDetector(double low_thresh, dou
 
 /** @brief Base class for lines detector algorithm. :
  */
-class CV_EXPORTS HoughLinesDetector : public Algorithm
+class CV_EXPORTS_W HoughLinesDetector : public Algorithm
 {
 public:
     /** @brief Finds lines in a binary image using the classical Hough transform.
@@ -352,7 +352,7 @@ class CV_EXPORTS HoughLinesDetector : public Algorithm
 
     @sa HoughLines
      */
-    virtual void detect(InputArray src, OutputArray lines, Stream& stream = Stream::Null()) = 0;
+    CV_WRAP virtual void detect(InputArray src, OutputArray lines, Stream& stream = Stream::Null()) = 0;
 
     /** @brief Downloads results from cuda::HoughLinesDetector::detect to host memory.
 
@@ -361,22 +361,22 @@ class CV_EXPORTS HoughLinesDetector : public Algorithm
     @param h_votes Optional output array for line's votes.
     @param stream Stream for the asynchronous version.
      */
-    virtual void downloadResults(InputArray d_lines, OutputArray h_lines, OutputArray h_votes = noArray(), Stream& stream = Stream::Null()) = 0;
+    CV_WRAP virtual void downloadResults(InputArray d_lines, OutputArray h_lines, OutputArray h_votes = noArray(), Stream& stream = Stream::Null()) = 0;
 
-    virtual void setRho(float rho) = 0;
-    virtual float getRho() const = 0;
+    CV_WRAP virtual void setRho(float rho) = 0;
+    CV_WRAP virtual float getRho() const = 0;
 
-    virtual void setTheta(float theta) = 0;
-    virtual float getTheta() const = 0;
+    CV_WRAP virtual void setTheta(float theta) = 0;
+    CV_WRAP virtual float getTheta() const = 0;
 
-    virtual void setThreshold(int threshold) = 0;
-    virtual int getThreshold() const = 0;
+    CV_WRAP virtual void setThreshold(int threshold) = 0;
+    CV_WRAP virtual int getThreshold() const = 0;
 
-    virtual void setDoSort(bool doSort) = 0;
-    virtual bool getDoSort() const = 0;
+    CV_WRAP virtual void setDoSort(bool doSort) = 0;
+    CV_WRAP virtual bool getDoSort() const = 0;
 
-    virtual void setMaxLines(int maxLines) = 0;
-    virtual int getMaxLines() const = 0;
+    CV_WRAP virtual void setMaxLines(int maxLines) = 0;
+    CV_WRAP virtual int getMaxLines() const = 0;
 };
 
 /** @brief Creates implementation for cuda::HoughLinesDetector .
@@ -388,7 +388,7 @@ votes ( \f$>\texttt{threshold}\f$ ).
 @param doSort Performs lines sort by votes.
 @param maxLines Maximum number of output lines.
  */
-CV_EXPORTS Ptr<HoughLinesDetector> createHoughLinesDetector(float rho, float theta, int threshold, bool doSort = false, int maxLines = 4096);
+CV_EXPORTS_W Ptr<HoughLinesDetector> createHoughLinesDetector(float rho, float theta, int threshold, bool doSort = false, int maxLines = 4096);
 
 
 //////////////////////////////////////
@@ -396,7 +396,7 @@ CV_EXPORTS Ptr<HoughLinesDetector> createHoughLinesDetector(float rho, float the
 
 /** @brief Base class for line segments detector algorithm. :
  */
-class CV_EXPORTS HoughSegmentDetector : public Algorithm
+class CV_EXPORTS_W HoughSegmentDetector : public Algorithm
 {
 public:
     /** @brief Finds line segments in a binary image using the probabilistic Hough transform.
@@ -409,22 +409,22 @@ class CV_EXPORTS HoughSegmentDetector : public Algorithm
 
     @sa HoughLinesP
      */
-    virtual void detect(InputArray src, OutputArray lines, Stream& stream = Stream::Null()) = 0;
+    CV_WRAP virtual void detect(InputArray src, OutputArray lines, Stream& stream = Stream::Null()) = 0;
 
-    virtual void setRho(float rho) = 0;
-    virtual float getRho() const = 0;
+    CV_WRAP virtual void setRho(float rho) = 0;
+    CV_WRAP virtual float getRho() const = 0;
 
-    virtual void setTheta(float theta) = 0;
-    virtual float getTheta() const = 0;
+    CV_WRAP virtual void setTheta(float theta) = 0;
+    CV_WRAP virtual float getTheta() const = 0;
 
-    virtual void setMinLineLength(int minLineLength) = 0;
-    virtual int getMinLineLength() const = 0;
+    CV_WRAP virtual void setMinLineLength(int minLineLength) = 0;
+    CV_WRAP virtual int getMinLineLength() const = 0;
 
-    virtual void setMaxLineGap(int maxLineGap) = 0;
-    virtual int getMaxLineGap() const = 0;
+    CV_WRAP virtual void setMaxLineGap(int maxLineGap) = 0;
+    CV_WRAP virtual int getMaxLineGap() const = 0;
 
-    virtual void setMaxLines(int maxLines) = 0;
-    virtual int getMaxLines() const = 0;
+    CV_WRAP virtual void setMaxLines(int maxLines) = 0;
+    CV_WRAP virtual int getMaxLines() const = 0;
 };
 
 /** @brief Creates implementation for cuda::HoughSegmentDetector .
@@ -435,14 +435,14 @@ class CV_EXPORTS HoughSegmentDetector : public Algorithm
 @param maxLineGap Maximum allowed gap between points on the same line to link them.
 @param maxLines Maximum number of output lines.
  */
-CV_EXPORTS Ptr<HoughSegmentDetector> createHoughSegmentDetector(float rho, float theta, int minLineLength, int maxLineGap, int maxLines = 4096);
+CV_EXPORTS_W Ptr<HoughSegmentDetector> createHoughSegmentDetector(float rho, float theta, int minLineLength, int maxLineGap, int maxLines = 4096);
 
 //////////////////////////////////////
 // HoughCircles
 
 /** @brief Base class for circles detector algorithm. :
  */
-class CV_EXPORTS HoughCirclesDetector : public Algorithm
+class CV_EXPORTS_W HoughCirclesDetector : public Algorithm
 {
 public:
     /** @brief Finds circles in a grayscale image using the Hough transform.
@@ -454,28 +454,28 @@ class CV_EXPORTS HoughCirclesDetector : public Algorithm
 
     @sa HoughCircles
      */
-    virtual void detect(InputArray src, OutputArray circles, Stream& stream = Stream::Null()) = 0;
+    CV_WRAP virtual void detect(InputArray src, OutputArray circles, Stream& stream = Stream::Null()) = 0;
 
-    virtual void setDp(float dp) = 0;
-    virtual float getDp() const = 0;
+    CV_WRAP virtual void setDp(float dp) = 0;
+    CV_WRAP virtual float getDp() const = 0;
 
-    virtual void setMinDist(float minDist) = 0;
-    virtual float getMinDist() const = 0;
+    CV_WRAP virtual void setMinDist(float minDist) = 0;
+    CV_WRAP virtual float getMinDist() const = 0;
 
-    virtual void setCannyThreshold(int cannyThreshold) = 0;
-    virtual int getCannyThreshold() const = 0;
+    CV_WRAP virtual void setCannyThreshold(int cannyThreshold) = 0;
+    CV_WRAP virtual int getCannyThreshold() const = 0;
 
-    virtual void setVotesThreshold(int votesThreshold) = 0;
-    virtual int getVotesThreshold() const = 0;
+    CV_WRAP virtual void setVotesThreshold(int votesThreshold) = 0;
+    CV_WRAP virtual int getVotesThreshold() const = 0;
 
-    virtual void setMinRadius(int minRadius) = 0;
-    virtual int getMinRadius() const = 0;
+    CV_WRAP virtual void setMinRadius(int minRadius) = 0;
+    CV_WRAP virtual int getMinRadius() const = 0;
 
-    virtual void setMaxRadius(int maxRadius) = 0;
-    virtual int getMaxRadius() const = 0;
+    CV_WRAP virtual void setMaxRadius(int maxRadius) = 0;
+    CV_WRAP virtual int getMaxRadius() const = 0;
 
-    virtual void setMaxCircles(int maxCircles) = 0;
-    virtual int getMaxCircles() const = 0;
+    CV_WRAP virtual void setMaxCircles(int maxCircles) = 0;
+    CV_WRAP virtual int getMaxCircles() const = 0;
 };
 
 /** @brief Creates implementation for cuda::HoughCirclesDetector .
@@ -494,18 +494,18 @@ smaller it is, the more false circles may be detected.
 @param maxRadius Maximum circle radius.
 @param maxCircles Maximum number of output circles.
  */
-CV_EXPORTS Ptr<HoughCirclesDetector> createHoughCirclesDetector(float dp, float minDist, int cannyThreshold, int votesThreshold, int minRadius, int maxRadius, int maxCircles = 4096);
+CV_EXPORTS_W Ptr<HoughCirclesDetector> createHoughCirclesDetector(float dp, float minDist, int cannyThreshold, int votesThreshold, int minRadius, int maxRadius, int maxCircles = 4096);
 
 //////////////////////////////////////
 // GeneralizedHough
 
 /** @brief Creates implementation for generalized hough transform from @cite Ballard1981 .
  */
-CV_EXPORTS Ptr<GeneralizedHoughBallard> createGeneralizedHoughBallard();
+CV_EXPORTS_W Ptr<GeneralizedHoughBallard> createGeneralizedHoughBallard();
 
 /** @brief Creates implementation for generalized hough transform from @cite Guil1999 .
  */
-CV_EXPORTS Ptr<GeneralizedHoughGuil> createGeneralizedHoughGuil();
+CV_EXPORTS_W Ptr<GeneralizedHoughGuil> createGeneralizedHoughGuil();
 
 //! @} cudaimgproc_hough
 
@@ -516,7 +516,7 @@ CV_EXPORTS Ptr<GeneralizedHoughGuil> createGeneralizedHoughGuil();
 
 /** @brief Base class for Cornerness Criteria computation. :
  */
-class CV_EXPORTS CornernessCriteria : public Algorithm
+class CV_EXPORTS_W CornernessCriteria : public Algorithm
 {
 public:
     /** @brief Computes the cornerness criteria at each image pixel.
@@ -526,7 +526,7 @@ class CV_EXPORTS CornernessCriteria : public Algorithm
     CV_32FC1 type.
     @param stream Stream for the asynchronous version.
      */
-    virtual void compute(InputArray src, OutputArray dst, Stream& stream = Stream::Null()) = 0;
+    CV_WRAP virtual void compute(InputArray src, OutputArray dst, Stream& stream = Stream::Null()) = 0;
 };
 
 /** @brief Creates implementation for Harris cornerness criteria.
@@ -540,7 +540,7 @@ supported for now.
 
 @sa cornerHarris
  */
-CV_EXPORTS Ptr<CornernessCriteria> createHarrisCorner(int srcType, int blockSize, int ksize, double k, int borderType = BORDER_REFLECT101);
+CV_EXPORTS_W Ptr<CornernessCriteria> createHarrisCorner(int srcType, int blockSize, int ksize, double k, int borderType = BORDER_REFLECT101);
 
 /** @brief Creates implementation for the minimum eigen value of a 2x2 derivative covariation matrix (the
 cornerness criteria).
@@ -553,13 +553,13 @@ supported for now.
 
 @sa cornerMinEigenVal
  */
-CV_EXPORTS Ptr<CornernessCriteria> createMinEigenValCorner(int srcType, int blockSize, int ksize, int borderType = BORDER_REFLECT101);
+CV_EXPORTS_W Ptr<CornernessCriteria> createMinEigenValCorner(int srcType, int blockSize, int ksize, int borderType = BORDER_REFLECT101);
 
 ////////////////////////// Corners Detection ///////////////////////////
 
 /** @brief Base class for Corners Detector. :
  */
-class CV_EXPORTS CornersDetector : public Algorithm
+class CV_EXPORTS_W CornersDetector : public Algorithm
 {
 public:
     /** @brief Determines strong corners on an image.
@@ -571,7 +571,7 @@ class CV_EXPORTS CornersDetector : public Algorithm
     CV_8UC1 and the same size as image ), it specifies the region in which the corners are detected.
     @param stream Stream for the asynchronous version.
      */
-    virtual void detect(InputArray image, OutputArray corners, InputArray mask = noArray(), Stream& stream = Stream::Null()) = 0;
+    CV_WRAP virtual void detect(InputArray image, OutputArray corners, InputArray mask = noArray(), Stream& stream = Stream::Null()) = 0;
 };
 
 /** @brief Creates implementation for cuda::CornersDetector .
@@ -592,7 +592,7 @@ pixel neighborhood. See cornerEigenValsAndVecs .
 or cornerMinEigenVal.
 @param harrisK Free parameter of the Harris detector.
  */
-CV_EXPORTS Ptr<CornersDetector> createGoodFeaturesToTrackDetector(int srcType, int maxCorners = 1000, double qualityLevel = 0.01, double minDistance = 0.0,
+CV_EXPORTS_W Ptr<CornersDetector> createGoodFeaturesToTrackDetector(int srcType, int maxCorners = 1000, double qualityLevel = 0.01, double minDistance = 0.0,
                                                                   int blockSize = 3, bool useHarrisDetector = false, double harrisK = 0.04);
 
 //! @} cudaimgproc_feature
@@ -613,7 +613,7 @@ as src .
 It maps each point of the source image into another point. As a result, you have a new color and new
 position of each point.
  */
-CV_EXPORTS void meanShiftFiltering(InputArray src, OutputArray dst, int sp, int sr,
+CV_EXPORTS_W void meanShiftFiltering(InputArray src, OutputArray dst, int sp, int sr,
                                    TermCriteria criteria = TermCriteria(TermCriteria::MAX_ITER + TermCriteria::EPS, 5, 1),
                                    Stream& stream = Stream::Null());
 
@@ -632,21 +632,21 @@ src size. The type is CV_16SC2 .
 
 @sa cuda::meanShiftFiltering
  */
-CV_EXPORTS void meanShiftProc(InputArray src, OutputArray dstr, OutputArray dstsp, int sp, int sr,
+CV_EXPORTS_W void meanShiftProc(InputArray src, OutputArray dstr, OutputArray dstsp, int sp, int sr,
                               TermCriteria criteria = TermCriteria(TermCriteria::MAX_ITER + TermCriteria::EPS, 5, 1),
                               Stream& stream = Stream::Null());
 
 /** @brief Performs a mean-shift segmentation of the source image and eliminates small segments.
 
 @param src Source image. Only CV_8UC4 images are supported for now.
-@param dst Segmented image with the same size and type as src (host memory).
+@param dst Segmented image with the same size and type as src (host or gpu memory).
 @param sp Spatial window radius.
 @param sr Color window radius.
 @param minsize Minimum segment size. Smaller segments are merged.
 @param criteria Termination criteria. See TermCriteria.
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void meanShiftSegmentation(InputArray src, OutputArray dst, int sp, int sr, int minsize,
+CV_EXPORTS_W void meanShiftSegmentation(InputArray src, OutputArray dst, int sp, int sr, int minsize,
                                       TermCriteria criteria = TermCriteria(TermCriteria::MAX_ITER + TermCriteria::EPS, 5, 1),
                                       Stream& stream = Stream::Null());
 
@@ -654,7 +654,7 @@ CV_EXPORTS void meanShiftSegmentation(InputArray src, OutputArray dst, int sp, i
 
 /** @brief Base class for Template Matching. :
  */
-class CV_EXPORTS TemplateMatching : public Algorithm
+class CV_EXPORTS_W TemplateMatching : public Algorithm
 {
 public:
     /** @brief Computes a proximity map for a raster template and an image where the template is searched for.
@@ -665,7 +665,7 @@ class CV_EXPORTS TemplateMatching : public Algorithm
     x h*, then result must be *W-w+1 x H-h+1*.
     @param stream Stream for the asynchronous version.
      */
-    virtual void match(InputArray image, InputArray templ, OutputArray result, Stream& stream = Stream::Null()) = 0;
+    CV_WRAP virtual void match(InputArray image, InputArray templ, OutputArray result, Stream& stream = Stream::Null()) = 0;
 };
 
 /** @brief Creates implementation for cuda::TemplateMatching .
@@ -694,7 +694,7 @@ The following methods are supported for the CV_32F images for now:
 
 @sa matchTemplate
  */
-CV_EXPORTS Ptr<TemplateMatching> createTemplateMatching(int srcType, int method, Size user_block_size = Size());
+CV_EXPORTS_W Ptr<TemplateMatching> createTemplateMatching(int srcType, int method, Size user_block_size = Size());
 
 ////////////////////////// Bilateral Filter ///////////////////////////
 
@@ -712,7 +712,7 @@ BORDER_REPLICATE , BORDER_CONSTANT , BORDER_REFLECT and BORDER_WRAP are supporte
 
 @sa bilateralFilter
  */
-CV_EXPORTS void bilateralFilter(InputArray src, OutputArray dst, int kernel_size, float sigma_color, float sigma_spatial,
+CV_EXPORTS_W void bilateralFilter(InputArray src, OutputArray dst, int kernel_size, float sigma_color, float sigma_spatial,
                                 int borderMode = BORDER_DEFAULT, Stream& stream = Stream::Null());
 
 ///////////////////////////// Blending ////////////////////////////////
@@ -728,7 +728,7 @@ type.
 @param result Destination image.
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void blendLinear(InputArray img1, InputArray img2, InputArray weights1, InputArray weights2,
+CV_EXPORTS_W void blendLinear(InputArray img1, InputArray img2, InputArray weights1, InputArray weights2,
                             OutputArray result, Stream& stream = Stream::Null());
 
 //! @}
diff --git a/modules/cudaimgproc/src/canny.cpp b/modules/cudaimgproc/src/canny.cpp
index 8c3fd4a2b59..9a1125d1cdd 100644
--- a/modules/cudaimgproc/src/canny.cpp
+++ b/modules/cudaimgproc/src/canny.cpp
@@ -74,6 +74,7 @@ namespace
             low_thresh_(low_thresh), high_thresh_(high_thresh), apperture_size_(apperture_size), L2gradient_(L2gradient)
         {
             old_apperture_size_ = -1;
+            d_counter = nullptr;
         }
 
         void detect(InputArray image, OutputArray edges, Stream& stream);
diff --git a/modules/cudaimgproc/src/mssegmentation.cpp b/modules/cudaimgproc/src/mssegmentation.cpp
index 2bc071813e8..de8ed841468 100644
--- a/modules/cudaimgproc/src/mssegmentation.cpp
+++ b/modules/cudaimgproc/src/mssegmentation.cpp
@@ -372,8 +372,7 @@ void cv::cuda::meanShiftSegmentation(InputArray _src, OutputArray _dst, int sp,
     }
 
     // Create final image, color of each segment is the average color of its pixels
-    _dst.create(src.size(), src.type());
-    Mat dst = _dst.getMat();
+    Mat dst(src.size(), src.type());
 
     for (int y = 0; y < nrows; ++y)
     {
@@ -389,6 +388,7 @@ void cv::cuda::meanShiftSegmentation(InputArray _src, OutputArray _dst, int sp,
             dstcol[3] = 255;
         }
     }
+    dst.copyTo(_dst);
 }
 
 #endif // #if !defined (HAVE_CUDA) || defined (CUDA_DISABLER)
diff --git a/modules/cudalegacy/src/cuda/NCVBroxOpticalFlow.cu b/modules/cudalegacy/src/cuda/NCVBroxOpticalFlow.cu
index c51b946d314..690bf8e1cc3 100644
--- a/modules/cudalegacy/src/cuda/NCVBroxOpticalFlow.cu
+++ b/modules/cudalegacy/src/cuda/NCVBroxOpticalFlow.cu
@@ -816,10 +816,10 @@ NCVStatus NCVBroxOpticalFlow(const NCVBroxOpticalFlowDescriptor desc,
     float scale = 1.0f;
 
     //cuda arrays for frames
-    std::auto_ptr<FloatVector> pI0(new FloatVector(gpu_mem_allocator, kSizeInPixelsAligned));
+    std::unique_ptr<FloatVector> pI0(new FloatVector(gpu_mem_allocator, kSizeInPixelsAligned));
     ncvAssertReturn(pI0->isMemAllocated(), NCV_ALLOCATOR_BAD_ALLOC);
 
-    std::auto_ptr<FloatVector> pI1(new FloatVector(gpu_mem_allocator, kSizeInPixelsAligned));
+    std::unique_ptr<FloatVector> pI1(new FloatVector(gpu_mem_allocator, kSizeInPixelsAligned));
     ncvAssertReturn(pI1->isMemAllocated(), NCV_ALLOCATOR_BAD_ALLOC);
 
     if (!kSkipProcessing)
@@ -862,10 +862,10 @@ NCVStatus NCVBroxOpticalFlow(const NCVBroxOpticalFlowDescriptor desc,
 
         Ncv32u prev_level_pitch = alignUp(prev_level_width, kStrideAlignmentFloat) * sizeof(float);
 
-        std::auto_ptr<FloatVector> level_frame0(new FloatVector(gpu_mem_allocator, buffer_size));
+        std::unique_ptr<FloatVector> level_frame0(new FloatVector(gpu_mem_allocator, buffer_size));
         ncvAssertReturn(level_frame0->isMemAllocated(), NCV_ALLOCATOR_BAD_ALLOC);
 
-        std::auto_ptr<FloatVector> level_frame1(new FloatVector(gpu_mem_allocator, buffer_size));
+        std::unique_ptr<FloatVector> level_frame1(new FloatVector(gpu_mem_allocator, buffer_size));
         ncvAssertReturn(level_frame1->isMemAllocated(), NCV_ALLOCATOR_BAD_ALLOC);
 
         if (!kSkipProcessing)
diff --git a/modules/cudalegacy/src/cuda/NCVHaarObjectDetection.cu b/modules/cudalegacy/src/cuda/NCVHaarObjectDetection.cu
index 5e260397575..102c0ee4dcb 100644
--- a/modules/cudalegacy/src/cuda/NCVHaarObjectDetection.cu
+++ b/modules/cudalegacy/src/cuda/NCVHaarObjectDetection.cu
@@ -2388,7 +2388,7 @@ NCVStatus ncvHaarGetClassifierSize(const cv::String &filename, Ncv32u &numStages
     NCVStatus ncvStat;
 
     cv::String fext = filename.substr(filename.find_last_of(".") + 1);
-    fext = fext.toLowerCase();
+    std::transform(fext.begin(), fext.end(), fext.begin(), ::tolower);
 
     if (fext == "nvbin")
     {
@@ -2446,7 +2446,7 @@ NCVStatus ncvHaarLoadFromFile_host(const cv::String &filename,
     NCVStatus ncvStat;
 
     cv::String fext = filename.substr(filename.find_last_of(".") + 1);
-    fext = fext.toLowerCase();
+    std::transform(fext.begin(), fext.end(), fext.begin(), ::tolower);
 
     std::vector<HaarStage64> haarStages;
     std::vector<HaarClassifierNode128> haarNodes;
diff --git a/modules/cudalegacy/test/NCVTest.hpp b/modules/cudalegacy/test/NCVTest.hpp
index 3d7bf47ff11..8461c271505 100644
--- a/modules/cudalegacy/test/NCVTest.hpp
+++ b/modules/cudalegacy/test/NCVTest.hpp
@@ -151,8 +151,8 @@ class NCVTestProvider : public INCVTest
 protected:
 
     cudaDeviceProp devProp;
-    std::auto_ptr<INCVMemAllocator> allocatorGPU;
-    std::auto_ptr<INCVMemAllocator> allocatorCPU;
+    std::unique_ptr<INCVMemAllocator> allocatorGPU;
+    std::unique_ptr<INCVMemAllocator> allocatorCPU;
 
 private:
 
diff --git a/modules/cudalegacy/test/NCVTestSourceProvider.hpp b/modules/cudalegacy/test/NCVTestSourceProvider.hpp
index 8e0c94749fa..58e92cea5a3 100644
--- a/modules/cudalegacy/test/NCVTestSourceProvider.hpp
+++ b/modules/cudalegacy/test/NCVTestSourceProvider.hpp
@@ -184,8 +184,8 @@ class NCVTestSourceProvider
     }
 
     NcvBool bInit;
-    std::auto_ptr< INCVMemAllocator > allocatorCPU;
-    std::auto_ptr< NCVMatrixAlloc<T> > data;
+    std::unique_ptr< INCVMemAllocator > allocatorCPU;
+    std::unique_ptr< NCVMatrixAlloc<T> > data;
     Ncv32u dataWidth;
     Ncv32u dataHeight;
 };
diff --git a/modules/cudaobjdetect/CMakeLists.txt b/modules/cudaobjdetect/CMakeLists.txt
index 351f6e87b45..0001afaffd0 100644
--- a/modules/cudaobjdetect/CMakeLists.txt
+++ b/modules/cudaobjdetect/CMakeLists.txt
@@ -6,4 +6,4 @@ set(the_description "CUDA-accelerated Object Detection")
 
 ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4127 /wd4324 /wd4512 -Wundef -Wmissing-declarations -Wshadow)
 
-ocv_define_module(cudaobjdetect opencv_objdetect opencv_cudaarithm opencv_cudawarping OPTIONAL opencv_cudalegacy)
+ocv_define_module(cudaobjdetect opencv_objdetect opencv_cudaarithm opencv_cudawarping OPTIONAL opencv_cudalegacy WRAP python)
diff --git a/modules/cudaobjdetect/include/opencv2/cudaobjdetect.hpp b/modules/cudaobjdetect/include/opencv2/cudaobjdetect.hpp
index 6034a680cd6..29703694ee6 100644
--- a/modules/cudaobjdetect/include/opencv2/cudaobjdetect.hpp
+++ b/modules/cudaobjdetect/include/opencv2/cudaobjdetect.hpp
@@ -75,7 +75,7 @@ namespace cv { namespace cuda {
     -   (Python) An example applying the HOG descriptor for people detection can be found at
         opencv_source_code/samples/python/peopledetect.py
  */
-class CV_EXPORTS HOG : public Algorithm
+class CV_EXPORTS_W HOG : public Algorithm
 {
 public:
     enum
@@ -92,70 +92,70 @@ class CV_EXPORTS HOG : public Algorithm
     @param cell_size Cell size. Only (8, 8) is supported for now.
     @param nbins Number of bins. Only 9 bins per cell are supported for now.
      */
-    static Ptr<HOG> create(Size win_size = Size(64, 128),
+    CV_WRAP static Ptr<HOG> create(Size win_size = Size(64, 128),
                            Size block_size = Size(16, 16),
                            Size block_stride = Size(8, 8),
                            Size cell_size = Size(8, 8),
                            int nbins = 9);
 
     //! Gaussian smoothing window parameter.
-    virtual void setWinSigma(double win_sigma) = 0;
-    virtual double getWinSigma() const = 0;
+    CV_WRAP virtual void setWinSigma(double win_sigma) = 0;
+    CV_WRAP virtual double getWinSigma() const = 0;
 
     //! L2-Hys normalization method shrinkage.
-    virtual void setL2HysThreshold(double threshold_L2hys) = 0;
-    virtual double getL2HysThreshold() const = 0;
+    CV_WRAP virtual void setL2HysThreshold(double threshold_L2hys) = 0;
+    CV_WRAP virtual double getL2HysThreshold() const = 0;
 
     //! Flag to specify whether the gamma correction preprocessing is required or not.
-    virtual void setGammaCorrection(bool gamma_correction) = 0;
-    virtual bool getGammaCorrection() const = 0;
+    CV_WRAP virtual void setGammaCorrection(bool gamma_correction) = 0;
+    CV_WRAP virtual bool getGammaCorrection() const = 0;
 
     //! Maximum number of detection window increases.
-    virtual void setNumLevels(int nlevels) = 0;
-    virtual int getNumLevels() const = 0;
+    CV_WRAP virtual void setNumLevels(int nlevels) = 0;
+    CV_WRAP virtual int getNumLevels() const = 0;
 
     //! Threshold for the distance between features and SVM classifying plane.
     //! Usually it is 0 and should be specified in the detector coefficients (as the last free
     //! coefficient). But if the free coefficient is omitted (which is allowed), you can specify it
     //! manually here.
-    virtual void setHitThreshold(double hit_threshold) = 0;
-    virtual double getHitThreshold() const = 0;
+    CV_WRAP virtual void setHitThreshold(double hit_threshold) = 0;
+    CV_WRAP virtual double getHitThreshold() const = 0;
 
     //! Window stride. It must be a multiple of block stride.
-    virtual void setWinStride(Size win_stride) = 0;
-    virtual Size getWinStride() const = 0;
+    CV_WRAP virtual void setWinStride(Size win_stride) = 0;
+    CV_WRAP virtual Size getWinStride() const = 0;
 
     //! Coefficient of the detection window increase.
-    virtual void setScaleFactor(double scale0) = 0;
-    virtual double getScaleFactor() const = 0;
+    CV_WRAP virtual void setScaleFactor(double scale0) = 0;
+    CV_WRAP virtual double getScaleFactor() const = 0;
 
     //! Coefficient to regulate the similarity threshold. When detected, some
     //! objects can be covered by many rectangles. 0 means not to perform grouping.
     //! See groupRectangles.
-    virtual void setGroupThreshold(int group_threshold) = 0;
-    virtual int getGroupThreshold() const = 0;
+    CV_WRAP virtual void setGroupThreshold(int group_threshold) = 0;
+    CV_WRAP virtual int getGroupThreshold() const = 0;
 
     //! Descriptor storage format:
     //!   - **DESCR_FORMAT_ROW_BY_ROW** - Row-major order.
     //!   - **DESCR_FORMAT_COL_BY_COL** - Column-major order.
-    virtual void setDescriptorFormat(int descr_format) = 0;
-    virtual int getDescriptorFormat() const = 0;
+    CV_WRAP virtual void setDescriptorFormat(int descr_format) = 0;
+    CV_WRAP virtual int getDescriptorFormat() const = 0;
 
     /** @brief Returns the number of coefficients required for the classification.
      */
-    virtual size_t getDescriptorSize() const = 0;
+    CV_WRAP virtual size_t getDescriptorSize() const = 0;
 
     /** @brief Returns the block histogram size.
      */
-    virtual size_t getBlockHistogramSize() const = 0;
+    CV_WRAP virtual size_t getBlockHistogramSize() const = 0;
 
     /** @brief Sets coefficients for the linear SVM classifier.
      */
-    virtual void setSVMDetector(InputArray detector) = 0;
+    CV_WRAP virtual void setSVMDetector(InputArray detector) = 0;
 
     /** @brief Returns coefficients of the classifier trained for people detection.
      */
-    virtual Mat getDefaultPeopleDetector() const = 0;
+    CV_WRAP virtual Mat getDefaultPeopleDetector() const = 0;
 
     /** @brief Performs object detection without a multi-scale window.
 
@@ -183,7 +183,7 @@ class CV_EXPORTS HOG : public Algorithm
     @param descriptors 2D array of descriptors.
     @param stream CUDA stream.
      */
-    virtual void compute(InputArray img,
+    CV_WRAP virtual void compute(InputArray img,
                          OutputArray descriptors,
                          Stream& stream = Stream::Null()) = 0;
 };
@@ -200,7 +200,7 @@ class CV_EXPORTS HOG : public Algorithm
     -   A Nvidea API specific cascade classifier example can be found at
         opencv_source_code/samples/gpu/cascadeclassifier_nvidia_api.cpp
  */
-class CV_EXPORTS CascadeClassifier : public Algorithm
+class CV_EXPORTS_W CascadeClassifier : public Algorithm
 {
 public:
     /** @brief Loads the classifier from a file. Cascade type is detected automatically by constructor parameter.
@@ -209,36 +209,36 @@ class CV_EXPORTS CascadeClassifier : public Algorithm
     (trained by the haar training application) and NVIDIA's nvbin are supported for HAAR and only new
     type of OpenCV XML cascade supported for LBP. The working haar models can be found at opencv_folder/data/haarcascades_cuda/
      */
-    static Ptr<CascadeClassifier> create(const String& filename);
+    CV_WRAP static Ptr<cuda::CascadeClassifier> create(const String& filename);
     /** @overload
      */
-    static Ptr<CascadeClassifier> create(const FileStorage& file);
+    static Ptr<cuda::CascadeClassifier> create(const FileStorage& file);
 
     //! Maximum possible object size. Objects larger than that are ignored. Used for
     //! second signature and supported only for LBP cascades.
-    virtual void setMaxObjectSize(Size maxObjectSize) = 0;
-    virtual Size getMaxObjectSize() const = 0;
+    CV_WRAP virtual void setMaxObjectSize(Size maxObjectSize) = 0;
+    CV_WRAP virtual Size getMaxObjectSize() const = 0;
 
     //! Minimum possible object size. Objects smaller than that are ignored.
-    virtual void setMinObjectSize(Size minSize) = 0;
-    virtual Size getMinObjectSize() const = 0;
+    CV_WRAP virtual void setMinObjectSize(Size minSize) = 0;
+    CV_WRAP virtual Size getMinObjectSize() const = 0;
 
     //! Parameter specifying how much the image size is reduced at each image scale.
-    virtual void setScaleFactor(double scaleFactor) = 0;
-    virtual double getScaleFactor() const = 0;
+    CV_WRAP virtual void setScaleFactor(double scaleFactor) = 0;
+    CV_WRAP virtual double getScaleFactor() const = 0;
 
     //! Parameter specifying how many neighbors each candidate rectangle should have
     //! to retain it.
-    virtual void setMinNeighbors(int minNeighbors) = 0;
-    virtual int getMinNeighbors() const = 0;
+    CV_WRAP virtual void setMinNeighbors(int minNeighbors) = 0;
+    CV_WRAP virtual int getMinNeighbors() const = 0;
 
-    virtual void setFindLargestObject(bool findLargestObject) = 0;
-    virtual bool getFindLargestObject() = 0;
+    CV_WRAP virtual void setFindLargestObject(bool findLargestObject) = 0;
+    CV_WRAP virtual bool getFindLargestObject() = 0;
 
-    virtual void setMaxNumObjects(int maxNumObjects) = 0;
-    virtual int getMaxNumObjects() const = 0;
+    CV_WRAP virtual void setMaxNumObjects(int maxNumObjects) = 0;
+    CV_WRAP virtual int getMaxNumObjects() const = 0;
 
-    virtual Size getClassifierSize() const = 0;
+    CV_WRAP virtual Size getClassifierSize() const = 0;
 
     /** @brief Detects objects of different sizes in the input image.
 
@@ -268,7 +268,7 @@ class CV_EXPORTS CascadeClassifier : public Algorithm
 
     @sa CascadeClassifier::detectMultiScale
      */
-    virtual void detectMultiScale(InputArray image,
+    CV_WRAP virtual void detectMultiScale(InputArray image,
                                   OutputArray objects,
                                   Stream& stream = Stream::Null()) = 0;
 
@@ -277,7 +277,7 @@ class CV_EXPORTS CascadeClassifier : public Algorithm
     @param gpu_objects Objects array in internal representation.
     @param objects Resulting array.
      */
-    virtual void convert(OutputArray gpu_objects,
+    CV_WRAP virtual void convert(OutputArray gpu_objects,
                          std::vector<Rect>& objects) = 0;
 };
 
diff --git a/modules/cudaobjdetect/src/cascadeclassifier.cpp b/modules/cudaobjdetect/src/cascadeclassifier.cpp
index 4013ca10dbd..c264e182f3b 100644
--- a/modules/cudaobjdetect/src/cascadeclassifier.cpp
+++ b/modules/cudaobjdetect/src/cascadeclassifier.cpp
@@ -809,7 +809,7 @@ namespace
 Ptr<cuda::CascadeClassifier> cv::cuda::CascadeClassifier::create(const String& filename)
 {
     String fext = filename.substr(filename.find_last_of(".") + 1);
-    fext = fext.toLowerCase();
+    std::transform(fext.begin(), fext.end(), fext.begin(), ::tolower);
 
     if (fext == "nvbin")
     {
diff --git a/modules/cudaoptflow/CMakeLists.txt b/modules/cudaoptflow/CMakeLists.txt
index 5db2b096c2d..d40dc97e9b9 100644
--- a/modules/cudaoptflow/CMakeLists.txt
+++ b/modules/cudaoptflow/CMakeLists.txt
@@ -6,4 +6,4 @@ set(the_description "CUDA-accelerated Optical Flow")
 
 ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4127 /wd4324 /wd4512 -Wundef -Wmissing-declarations -Wshadow)
 
-ocv_define_module(cudaoptflow opencv_video opencv_cudaarithm opencv_cudawarping opencv_cudaimgproc OPTIONAL opencv_cudalegacy)
+ocv_define_module(cudaoptflow opencv_video opencv_cudaarithm opencv_cudawarping opencv_cudaimgproc OPTIONAL opencv_cudalegacy WRAP python)
diff --git a/modules/cudaoptflow/include/opencv2/cudaoptflow.hpp b/modules/cudaoptflow/include/opencv2/cudaoptflow.hpp
index eb8c5ef6e28..ce1d183fe23 100644
--- a/modules/cudaoptflow/include/opencv2/cudaoptflow.hpp
+++ b/modules/cudaoptflow/include/opencv2/cudaoptflow.hpp
@@ -67,7 +67,7 @@ namespace cv { namespace cuda {
 
 /** @brief Base interface for dense optical flow algorithms.
  */
-class CV_EXPORTS DenseOpticalFlow : public Algorithm
+class CV_EXPORTS_W DenseOpticalFlow : public Algorithm
 {
 public:
     /** @brief Calculates a dense optical flow.
@@ -77,12 +77,12 @@ class CV_EXPORTS DenseOpticalFlow : public Algorithm
     @param flow computed flow image that has the same size as I0 and type CV_32FC2.
     @param stream Stream for the asynchronous version.
      */
-    virtual void calc(InputArray I0, InputArray I1, InputOutputArray flow, Stream& stream = Stream::Null()) = 0;
+    CV_WRAP virtual void calc(InputArray I0, InputArray I1, InputOutputArray flow, Stream& stream = Stream::Null()) = 0;
 };
 
 /** @brief Base interface for sparse optical flow algorithms.
  */
-class CV_EXPORTS SparseOpticalFlow : public Algorithm
+class CV_EXPORTS_W SparseOpticalFlow : public Algorithm
 {
 public:
     /** @brief Calculates a sparse optical flow.
@@ -96,7 +96,7 @@ class CV_EXPORTS SparseOpticalFlow : public Algorithm
     @param err Optional output vector that contains error response for each point (inverse confidence).
     @param stream Stream for the asynchronous version.
      */
-    virtual void calc(InputArray prevImg, InputArray nextImg,
+    CV_WRAP virtual void calc(InputArray prevImg, InputArray nextImg,
                       InputArray prevPts, InputOutputArray nextPts,
                       OutputArray status,
                       OutputArray err = cv::noArray(),
@@ -109,31 +109,31 @@ class CV_EXPORTS SparseOpticalFlow : public Algorithm
 
 /** @brief Class computing the optical flow for two images using Brox et al Optical Flow algorithm (@cite Brox2004).
  */
-class CV_EXPORTS BroxOpticalFlow : public DenseOpticalFlow
+class CV_EXPORTS_W BroxOpticalFlow : public DenseOpticalFlow
 {
 public:
-    virtual double getFlowSmoothness() const = 0;
-    virtual void setFlowSmoothness(double alpha) = 0;
+    CV_WRAP virtual double getFlowSmoothness() const = 0;
+    CV_WRAP virtual void setFlowSmoothness(double alpha) = 0;
 
-    virtual double getGradientConstancyImportance() const = 0;
-    virtual void setGradientConstancyImportance(double gamma) = 0;
+    CV_WRAP virtual double getGradientConstancyImportance() const = 0;
+    CV_WRAP virtual void setGradientConstancyImportance(double gamma) = 0;
 
-    virtual double getPyramidScaleFactor() const = 0;
-    virtual void setPyramidScaleFactor(double scale_factor) = 0;
+    CV_WRAP virtual double getPyramidScaleFactor() const = 0;
+    CV_WRAP virtual void setPyramidScaleFactor(double scale_factor) = 0;
 
     //! number of lagged non-linearity iterations (inner loop)
-    virtual int getInnerIterations() const = 0;
-    virtual void setInnerIterations(int inner_iterations) = 0;
+    CV_WRAP virtual int getInnerIterations() const = 0;
+    CV_WRAP virtual void setInnerIterations(int inner_iterations) = 0;
 
     //! number of warping iterations (number of pyramid levels)
-    virtual int getOuterIterations() const = 0;
-    virtual void setOuterIterations(int outer_iterations) = 0;
+    CV_WRAP virtual int getOuterIterations() const = 0;
+    CV_WRAP virtual void setOuterIterations(int outer_iterations) = 0;
 
     //! number of linear system solver iterations
-    virtual int getSolverIterations() const = 0;
-    virtual void setSolverIterations(int solver_iterations) = 0;
+    CV_WRAP virtual int getSolverIterations() const = 0;
+    CV_WRAP virtual void setSolverIterations(int solver_iterations) = 0;
 
-    static Ptr<BroxOpticalFlow> create(
+    CV_WRAP static Ptr<BroxOpticalFlow> create(
             double alpha = 0.197,
             double gamma = 50.0,
             double scale_factor = 0.8,
@@ -157,22 +157,22 @@ iterative Lucas-Kanade method with pyramids.
    -   An example of the Lucas Kanade optical flow algorithm can be found at
         opencv_source_code/samples/gpu/pyrlk_optical_flow.cpp
  */
-class CV_EXPORTS SparsePyrLKOpticalFlow : public SparseOpticalFlow
+class CV_EXPORTS_W SparsePyrLKOpticalFlow : public SparseOpticalFlow
 {
 public:
-    virtual Size getWinSize() const = 0;
-    virtual void setWinSize(Size winSize) = 0;
+    CV_WRAP virtual Size getWinSize() const = 0;
+    CV_WRAP virtual void setWinSize(Size winSize) = 0;
 
-    virtual int getMaxLevel() const = 0;
-    virtual void setMaxLevel(int maxLevel) = 0;
+    CV_WRAP virtual int getMaxLevel() const = 0;
+    CV_WRAP virtual void setMaxLevel(int maxLevel) = 0;
 
-    virtual int getNumIters() const = 0;
-    virtual void setNumIters(int iters) = 0;
+    CV_WRAP virtual int getNumIters() const = 0;
+    CV_WRAP virtual void setNumIters(int iters) = 0;
 
-    virtual bool getUseInitialFlow() const = 0;
-    virtual void setUseInitialFlow(bool useInitialFlow) = 0;
+    CV_WRAP virtual bool getUseInitialFlow() const = 0;
+    CV_WRAP virtual void setUseInitialFlow(bool useInitialFlow) = 0;
 
-    static Ptr<SparsePyrLKOpticalFlow> create(
+    CV_WRAP static Ptr<cuda::SparsePyrLKOpticalFlow> create(
             Size winSize = Size(21, 21),
             int maxLevel = 3,
             int iters = 30,
@@ -184,22 +184,22 @@ class CV_EXPORTS SparsePyrLKOpticalFlow : public SparseOpticalFlow
 The class can calculate an optical flow for a dense optical flow using the
 iterative Lucas-Kanade method with pyramids.
  */
-class CV_EXPORTS DensePyrLKOpticalFlow : public DenseOpticalFlow
+class CV_EXPORTS_W DensePyrLKOpticalFlow : public DenseOpticalFlow
 {
 public:
-    virtual Size getWinSize() const = 0;
-    virtual void setWinSize(Size winSize) = 0;
+    CV_WRAP virtual Size getWinSize() const = 0;
+    CV_WRAP virtual void setWinSize(Size winSize) = 0;
 
-    virtual int getMaxLevel() const = 0;
-    virtual void setMaxLevel(int maxLevel) = 0;
+    CV_WRAP virtual int getMaxLevel() const = 0;
+    CV_WRAP virtual void setMaxLevel(int maxLevel) = 0;
 
-    virtual int getNumIters() const = 0;
-    virtual void setNumIters(int iters) = 0;
+    CV_WRAP virtual int getNumIters() const = 0;
+    CV_WRAP virtual void setNumIters(int iters) = 0;
 
-    virtual bool getUseInitialFlow() const = 0;
-    virtual void setUseInitialFlow(bool useInitialFlow) = 0;
+    CV_WRAP virtual bool getUseInitialFlow() const = 0;
+    CV_WRAP virtual void setUseInitialFlow(bool useInitialFlow) = 0;
 
-    static Ptr<DensePyrLKOpticalFlow> create(
+    CV_WRAP static Ptr<DensePyrLKOpticalFlow> create(
             Size winSize = Size(13, 13),
             int maxLevel = 3,
             int iters = 30,
@@ -212,34 +212,34 @@ class CV_EXPORTS DensePyrLKOpticalFlow : public DenseOpticalFlow
 
 /** @brief Class computing a dense optical flow using the Gunnar Farneback's algorithm.
  */
-class CV_EXPORTS FarnebackOpticalFlow : public DenseOpticalFlow
+class CV_EXPORTS_W FarnebackOpticalFlow : public DenseOpticalFlow
 {
 public:
-    virtual int getNumLevels() const = 0;
-    virtual void setNumLevels(int numLevels) = 0;
+    CV_WRAP virtual int getNumLevels() const = 0;
+    CV_WRAP virtual void setNumLevels(int numLevels) = 0;
 
-    virtual double getPyrScale() const = 0;
-    virtual void setPyrScale(double pyrScale) = 0;
+    CV_WRAP virtual double getPyrScale() const = 0;
+    CV_WRAP virtual void setPyrScale(double pyrScale) = 0;
 
-    virtual bool getFastPyramids() const = 0;
-    virtual void setFastPyramids(bool fastPyramids) = 0;
+    CV_WRAP virtual bool getFastPyramids() const = 0;
+    CV_WRAP virtual void setFastPyramids(bool fastPyramids) = 0;
 
-    virtual int getWinSize() const = 0;
-    virtual void setWinSize(int winSize) = 0;
+    CV_WRAP virtual int getWinSize() const = 0;
+    CV_WRAP virtual void setWinSize(int winSize) = 0;
 
-    virtual int getNumIters() const = 0;
-    virtual void setNumIters(int numIters) = 0;
+    CV_WRAP virtual int getNumIters() const = 0;
+    CV_WRAP virtual void setNumIters(int numIters) = 0;
 
-    virtual int getPolyN() const = 0;
-    virtual void setPolyN(int polyN) = 0;
+    CV_WRAP virtual int getPolyN() const = 0;
+    CV_WRAP virtual void setPolyN(int polyN) = 0;
 
-    virtual double getPolySigma() const = 0;
-    virtual void setPolySigma(double polySigma) = 0;
+    CV_WRAP virtual double getPolySigma() const = 0;
+    CV_WRAP virtual void setPolySigma(double polySigma) = 0;
 
-    virtual int getFlags() const = 0;
-    virtual void setFlags(int flags) = 0;
+    CV_WRAP virtual int getFlags() const = 0;
+    CV_WRAP virtual void setFlags(int flags) = 0;
 
-    static Ptr<FarnebackOpticalFlow> create(
+    CV_WRAP static Ptr<cuda::FarnebackOpticalFlow> create(
             int numLevels = 5,
             double pyrScale = 0.5,
             bool fastPyramids = false,
@@ -259,14 +259,14 @@ class CV_EXPORTS FarnebackOpticalFlow : public DenseOpticalFlow
  * @sa C. Zach, T. Pock and H. Bischof, "A Duality Based Approach for Realtime TV-L1 Optical Flow".
  * @sa Javier Sanchez, Enric Meinhardt-Llopis and Gabriele Facciolo. "TV-L1 Optical Flow Estimation".
  */
-class CV_EXPORTS OpticalFlowDual_TVL1 : public DenseOpticalFlow
+class CV_EXPORTS_W OpticalFlowDual_TVL1 : public DenseOpticalFlow
 {
 public:
     /**
      * Time step of the numerical scheme.
      */
-    virtual double getTau() const = 0;
-    virtual void setTau(double tau) = 0;
+    CV_WRAP virtual double getTau() const = 0;
+    CV_WRAP virtual void setTau(double tau) = 0;
 
     /**
      * Weight parameter for the data term, attachment parameter.
@@ -274,8 +274,8 @@ class CV_EXPORTS OpticalFlowDual_TVL1 : public DenseOpticalFlow
      * The smaller this parameter is, the smoother the solutions we obtain.
      * It depends on the range of motions of the images, so its value should be adapted to each image sequence.
      */
-    virtual double getLambda() const = 0;
-    virtual void setLambda(double lambda) = 0;
+    CV_WRAP virtual double getLambda() const = 0;
+    CV_WRAP virtual void setLambda(double lambda) = 0;
 
     /**
      * Weight parameter for (u - v)^2, tightness parameter.
@@ -283,8 +283,8 @@ class CV_EXPORTS OpticalFlowDual_TVL1 : public DenseOpticalFlow
      * In theory, it should have a small value in order to maintain both parts in correspondence.
      * The method is stable for a large range of values of this parameter.
      */
-    virtual double getGamma() const = 0;
-    virtual void setGamma(double gamma) = 0;
+    CV_WRAP virtual double getGamma() const = 0;
+    CV_WRAP virtual void setGamma(double gamma) = 0;
 
     /**
      * parameter used for motion estimation. It adds a variable allowing for illumination variations
@@ -292,14 +292,14 @@ class CV_EXPORTS OpticalFlowDual_TVL1 : public DenseOpticalFlow
      * See: Chambolle et al, A First-Order Primal-Dual Algorithm for Convex Problems with Applications to Imaging
      * Journal of Mathematical imaging and vision, may 2011 Vol 40 issue 1, pp 120-145
      */
-    virtual double getTheta() const = 0;
-    virtual void setTheta(double theta) = 0;
+    CV_WRAP virtual double getTheta() const = 0;
+    CV_WRAP virtual void setTheta(double theta) = 0;
 
     /**
      * Number of scales used to create the pyramid of images.
      */
-    virtual int getNumScales() const = 0;
-    virtual void setNumScales(int nscales) = 0;
+    CV_WRAP virtual int getNumScales() const = 0;
+    CV_WRAP virtual void setNumScales(int nscales) = 0;
 
     /**
      * Number of warpings per scale.
@@ -307,29 +307,29 @@ class CV_EXPORTS OpticalFlowDual_TVL1 : public DenseOpticalFlow
      * This is a parameter that assures the stability of the method.
      * It also affects the running time, so it is a compromise between speed and accuracy.
      */
-    virtual int getNumWarps() const = 0;
-    virtual void setNumWarps(int warps) = 0;
+    CV_WRAP virtual int getNumWarps() const = 0;
+    CV_WRAP virtual void setNumWarps(int warps) = 0;
 
     /**
      * Stopping criterion threshold used in the numerical scheme, which is a trade-off between precision and running time.
      * A small value will yield more accurate solutions at the expense of a slower convergence.
      */
-    virtual double getEpsilon() const = 0;
-    virtual void setEpsilon(double epsilon) = 0;
+    CV_WRAP virtual double getEpsilon() const = 0;
+    CV_WRAP virtual void setEpsilon(double epsilon) = 0;
 
     /**
      * Stopping criterion iterations number used in the numerical scheme.
      */
-    virtual int getNumIterations() const = 0;
-    virtual void setNumIterations(int iterations) = 0;
+    CV_WRAP virtual int getNumIterations() const = 0;
+    CV_WRAP virtual void setNumIterations(int iterations) = 0;
 
-    virtual double getScaleStep() const = 0;
-    virtual void setScaleStep(double scaleStep) = 0;
+    CV_WRAP virtual double getScaleStep() const = 0;
+    CV_WRAP virtual void setScaleStep(double scaleStep) = 0;
 
-    virtual bool getUseInitialFlow() const = 0;
-    virtual void setUseInitialFlow(bool useInitialFlow) = 0;
+    CV_WRAP virtual bool getUseInitialFlow() const = 0;
+    CV_WRAP virtual void setUseInitialFlow(bool useInitialFlow) = 0;
 
-    static Ptr<OpticalFlowDual_TVL1> create(
+    CV_WRAP static Ptr<OpticalFlowDual_TVL1> create(
             double tau = 0.25,
             double lambda = 0.15,
             double theta = 0.3,
diff --git a/modules/cudastereo/CMakeLists.txt b/modules/cudastereo/CMakeLists.txt
index 982609b82f5..c02086913cf 100644
--- a/modules/cudastereo/CMakeLists.txt
+++ b/modules/cudastereo/CMakeLists.txt
@@ -6,4 +6,4 @@ set(the_description "CUDA-accelerated Stereo Correspondence")
 
 ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4127 /wd4324 /wd4512 -Wundef -Wmissing-declarations -Wshadow)
 
-ocv_define_module(cudastereo opencv_calib3d)
+ocv_define_module(cudastereo opencv_calib3d WRAP python)
diff --git a/modules/cudastereo/include/opencv2/cudastereo.hpp b/modules/cudastereo/include/opencv2/cudastereo.hpp
index c9afd479fbc..0c312054d7c 100644
--- a/modules/cudastereo/include/opencv2/cudastereo.hpp
+++ b/modules/cudastereo/include/opencv2/cudastereo.hpp
@@ -69,12 +69,12 @@ namespace cv { namespace cuda {
 
 @sa StereoBM
  */
-class CV_EXPORTS StereoBM : public cv::StereoBM
+class CV_EXPORTS_W StereoBM : public cv::StereoBM
 {
 public:
     using cv::StereoBM::compute;
 
-    virtual void compute(InputArray left, InputArray right, OutputArray disparity, Stream& stream) = 0;
+    CV_WRAP virtual void compute(InputArray left, InputArray right, OutputArray disparity, Stream& stream) = 0;
 };
 
 /** @brief Creates StereoBM object.
@@ -87,7 +87,7 @@ shifted by changing the minimum disparity.
 accurate disparity map. Smaller block size gives more detailed disparity map, but there is higher
 chance for algorithm to find a wrong correspondence.
  */
-CV_EXPORTS Ptr<cuda::StereoBM> createStereoBM(int numDisparities = 64, int blockSize = 19);
+CV_EXPORTS_W Ptr<cuda::StereoBM> createStereoBM(int numDisparities = 64, int blockSize = 19);
 
 /////////////////////////////////////////
 // StereoBeliefPropagation
@@ -125,13 +125,13 @@ performance. To avoid an overflow in this case, the parameters must satisfy the
 
 @sa StereoMatcher
  */
-class CV_EXPORTS StereoBeliefPropagation : public cv::StereoMatcher
+class CV_EXPORTS_W StereoBeliefPropagation : public cv::StereoMatcher
 {
 public:
     using cv::StereoMatcher::compute;
 
     /** @overload */
-    virtual void compute(InputArray left, InputArray right, OutputArray disparity, Stream& stream) = 0;
+    CV_WRAP virtual void compute(InputArray left, InputArray right, OutputArray disparity, Stream& stream) = 0;
 
     /** @brief Enables the stereo correspondence operator that finds the disparity for the specified data cost.
 
@@ -142,40 +142,40 @@ class CV_EXPORTS StereoBeliefPropagation : public cv::StereoMatcher
     fractional bits.
     @param stream Stream for the asynchronous version.
      */
-    virtual void compute(InputArray data, OutputArray disparity, Stream& stream = Stream::Null()) = 0;
+    CV_WRAP virtual void compute(InputArray data, OutputArray disparity, Stream& stream = Stream::Null()) = 0;
 
     //! number of BP iterations on each level
-    virtual int getNumIters() const = 0;
-    virtual void setNumIters(int iters) = 0;
+    CV_WRAP virtual int getNumIters() const = 0;
+    CV_WRAP virtual void setNumIters(int iters) = 0;
 
     //! number of levels
-    virtual int getNumLevels() const = 0;
-    virtual void setNumLevels(int levels) = 0;
+    CV_WRAP virtual int getNumLevels() const = 0;
+    CV_WRAP virtual void setNumLevels(int levels) = 0;
 
     //! truncation of data cost
-    virtual double getMaxDataTerm() const = 0;
-    virtual void setMaxDataTerm(double max_data_term) = 0;
+    CV_WRAP virtual double getMaxDataTerm() const = 0;
+    CV_WRAP virtual void setMaxDataTerm(double max_data_term) = 0;
 
     //! data weight
-    virtual double getDataWeight() const = 0;
-    virtual void setDataWeight(double data_weight) = 0;
+    CV_WRAP virtual double getDataWeight() const = 0;
+    CV_WRAP virtual void setDataWeight(double data_weight) = 0;
 
     //! truncation of discontinuity cost
-    virtual double getMaxDiscTerm() const = 0;
-    virtual void setMaxDiscTerm(double max_disc_term) = 0;
+    CV_WRAP virtual double getMaxDiscTerm() const = 0;
+    CV_WRAP virtual void setMaxDiscTerm(double max_disc_term) = 0;
 
     //! discontinuity single jump
-    virtual double getDiscSingleJump() const = 0;
-    virtual void setDiscSingleJump(double disc_single_jump) = 0;
+    CV_WRAP virtual double getDiscSingleJump() const = 0;
+    CV_WRAP virtual void setDiscSingleJump(double disc_single_jump) = 0;
 
     //! type for messages (CV_16SC1 or CV_32FC1)
-    virtual int getMsgType() const = 0;
-    virtual void setMsgType(int msg_type) = 0;
+    CV_WRAP virtual int getMsgType() const = 0;
+    CV_WRAP virtual void setMsgType(int msg_type) = 0;
 
     /** @brief Uses a heuristic method to compute the recommended parameters ( ndisp, iters and levels ) for the
     specified image size ( width and height ).
      */
-    static void estimateRecommendedParams(int width, int height, int& ndisp, int& iters, int& levels);
+    CV_WRAP static void estimateRecommendedParams(int width, int height, int& ndisp, int& iters, int& levels);
 };
 
 /** @brief Creates StereoBeliefPropagation object.
@@ -185,7 +185,7 @@ class CV_EXPORTS StereoBeliefPropagation : public cv::StereoMatcher
 @param levels Number of levels.
 @param msg_type Type for messages. CV_16SC1 and CV_32FC1 types are supported.
  */
-CV_EXPORTS Ptr<cuda::StereoBeliefPropagation>
+CV_EXPORTS_W Ptr<cuda::StereoBeliefPropagation>
     createStereoBeliefPropagation(int ndisp = 64, int iters = 5, int levels = 5, int msg_type = CV_32F);
 
 /////////////////////////////////////////
@@ -214,20 +214,20 @@ performance. To avoid an overflow in this case, the parameters must satisfy the
 \f[10  \cdot 2^{levels-1}  \cdot max \_ data \_ term < SHRT \_ MAX\f]
 
  */
-class CV_EXPORTS StereoConstantSpaceBP : public cuda::StereoBeliefPropagation
+class CV_EXPORTS_W StereoConstantSpaceBP : public cuda::StereoBeliefPropagation
 {
 public:
     //! number of active disparity on the first level
-    virtual int getNrPlane() const = 0;
-    virtual void setNrPlane(int nr_plane) = 0;
+    CV_WRAP virtual int getNrPlane() const = 0;
+    CV_WRAP virtual void setNrPlane(int nr_plane) = 0;
 
-    virtual bool getUseLocalInitDataCost() const = 0;
-    virtual void setUseLocalInitDataCost(bool use_local_init_data_cost) = 0;
+    CV_WRAP virtual bool getUseLocalInitDataCost() const = 0;
+    CV_WRAP virtual void setUseLocalInitDataCost(bool use_local_init_data_cost) = 0;
 
     /** @brief Uses a heuristic method to compute parameters (ndisp, iters, levelsand nrplane) for the specified
     image size (widthand height).
      */
-    static void estimateRecommendedParams(int width, int height, int& ndisp, int& iters, int& levels, int& nr_plane);
+    CV_WRAP static void estimateRecommendedParams(int width, int height, int& ndisp, int& iters, int& levels, int& nr_plane);
 };
 
 /** @brief Creates StereoConstantSpaceBP object.
@@ -238,7 +238,7 @@ class CV_EXPORTS StereoConstantSpaceBP : public cuda::StereoBeliefPropagation
 @param nr_plane Number of disparity levels on the first level.
 @param msg_type Type for messages. CV_16SC1 and CV_32FC1 types are supported.
  */
-CV_EXPORTS Ptr<cuda::StereoConstantSpaceBP>
+CV_EXPORTS_W Ptr<cuda::StereoConstantSpaceBP>
     createStereoConstantSpaceBP(int ndisp = 128, int iters = 8, int levels = 4, int nr_plane = 4, int msg_type = CV_32F);
 
 /////////////////////////////////////////
@@ -248,7 +248,7 @@ CV_EXPORTS Ptr<cuda::StereoConstantSpaceBP>
 
 The class implements @cite Yang2010 algorithm.
  */
-class CV_EXPORTS DisparityBilateralFilter : public cv::Algorithm
+class CV_EXPORTS_W DisparityBilateralFilter : public cv::Algorithm
 {
 public:
     /** @brief Refines a disparity map using joint bilateral filtering.
@@ -258,28 +258,28 @@ class CV_EXPORTS DisparityBilateralFilter : public cv::Algorithm
     @param dst Destination disparity map. It has the same size and type as disparity .
     @param stream Stream for the asynchronous version.
      */
-    virtual void apply(InputArray disparity, InputArray image, OutputArray dst, Stream& stream = Stream::Null()) = 0;
+    CV_WRAP virtual void apply(InputArray disparity, InputArray image, OutputArray dst, Stream& stream = Stream::Null()) = 0;
 
-    virtual int getNumDisparities() const = 0;
-    virtual void setNumDisparities(int numDisparities) = 0;
+    CV_WRAP virtual int getNumDisparities() const = 0;
+    CV_WRAP virtual void setNumDisparities(int numDisparities) = 0;
 
-    virtual int getRadius() const = 0;
-    virtual void setRadius(int radius) = 0;
+    CV_WRAP virtual int getRadius() const = 0;
+    CV_WRAP virtual void setRadius(int radius) = 0;
 
-    virtual int getNumIters() const = 0;
-    virtual void setNumIters(int iters) = 0;
+    CV_WRAP virtual int getNumIters() const = 0;
+    CV_WRAP virtual void setNumIters(int iters) = 0;
 
     //! truncation of data continuity
-    virtual double getEdgeThreshold() const = 0;
-    virtual void setEdgeThreshold(double edge_threshold) = 0;
+    CV_WRAP virtual double getEdgeThreshold() const = 0;
+    CV_WRAP virtual void setEdgeThreshold(double edge_threshold) = 0;
 
     //! truncation of disparity continuity
-    virtual double getMaxDiscThreshold() const = 0;
-    virtual void setMaxDiscThreshold(double max_disc_threshold) = 0;
+    CV_WRAP virtual double getMaxDiscThreshold() const = 0;
+    CV_WRAP virtual void setMaxDiscThreshold(double max_disc_threshold) = 0;
 
     //! filter range sigma
-    virtual double getSigmaRange() const = 0;
-    virtual void setSigmaRange(double sigma_range) = 0;
+    CV_WRAP virtual double getSigmaRange() const = 0;
+    CV_WRAP virtual void setSigmaRange(double sigma_range) = 0;
 };
 
 /** @brief Creates DisparityBilateralFilter object.
@@ -288,7 +288,7 @@ class CV_EXPORTS DisparityBilateralFilter : public cv::Algorithm
 @param radius Filter radius.
 @param iters Number of iterations.
  */
-CV_EXPORTS Ptr<cuda::DisparityBilateralFilter>
+CV_EXPORTS_W Ptr<cuda::DisparityBilateralFilter>
     createDisparityBilateralFilter(int ndisp = 64, int radius = 3, int iters = 1);
 
 /////////////////////////////////////////
@@ -308,7 +308,7 @@ disparity map.
 
 @sa reprojectImageTo3D
  */
-CV_EXPORTS void reprojectImageTo3D(InputArray disp, OutputArray xyzw, InputArray Q, int dst_cn = 4, Stream& stream = Stream::Null());
+CV_EXPORTS_W void reprojectImageTo3D(InputArray disp, OutputArray xyzw, InputArray Q, int dst_cn = 4, Stream& stream = Stream::Null());
 
 /** @brief Colors a disparity image.
 
@@ -324,7 +324,7 @@ This function draws a colored disparity map by converting disparity values from
 first to HSV color space (where different disparity values correspond to different hues) and then
 converting the pixels to RGB for visualization.
  */
-CV_EXPORTS void drawColorDisp(InputArray src_disp, OutputArray dst_disp, int ndisp, Stream& stream = Stream::Null());
+CV_EXPORTS_W void drawColorDisp(InputArray src_disp, OutputArray dst_disp, int ndisp, Stream& stream = Stream::Null());
 
 //! @}
 
diff --git a/modules/cudawarping/CMakeLists.txt b/modules/cudawarping/CMakeLists.txt
index 5d0fa4ad934..6370189b75c 100644
--- a/modules/cudawarping/CMakeLists.txt
+++ b/modules/cudawarping/CMakeLists.txt
@@ -6,4 +6,4 @@ set(the_description "CUDA-accelerated Image Warping")
 
 ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4127 /wd4324 /wd4512 -Wundef -Wmissing-declarations -Wshadow)
 
-ocv_define_module(cudawarping opencv_core opencv_imgproc OPTIONAL opencv_cudev)
+ocv_define_module(cudawarping opencv_core opencv_imgproc OPTIONAL opencv_cudev WRAP python)
diff --git a/modules/cudawarping/include/opencv2/cudawarping.hpp b/modules/cudawarping/include/opencv2/cudawarping.hpp
index ca2357a6242..aa00ac009dc 100644
--- a/modules/cudawarping/include/opencv2/cudawarping.hpp
+++ b/modules/cudawarping/include/opencv2/cudawarping.hpp
@@ -83,7 +83,7 @@ Values of pixels with non-integer coordinates are computed using the bilinear in
 
 @sa remap
  */
-CV_EXPORTS void remap(InputArray src, OutputArray dst, InputArray xmap, InputArray ymap,
+CV_EXPORTS_W void remap(InputArray src, OutputArray dst, InputArray xmap, InputArray ymap,
                       int interpolation, int borderMode = BORDER_CONSTANT, Scalar borderValue = Scalar(),
                       Stream& stream = Stream::Null());
 
@@ -105,7 +105,7 @@ supported for now.
 
 @sa resize
  */
-CV_EXPORTS void resize(InputArray src, OutputArray dst, Size dsize, double fx=0, double fy=0, int interpolation = INTER_LINEAR, Stream& stream = Stream::Null());
+CV_EXPORTS_W void resize(InputArray src, OutputArray dst, Size dsize, double fx=0, double fy=0, int interpolation = INTER_LINEAR, Stream& stream = Stream::Null());
 
 /** @brief Applies an affine transformation to an image.
 
@@ -123,7 +123,7 @@ INTER_NEAREST , INTER_LINEAR , and INTER_CUBIC interpolation methods are support
 
 @sa warpAffine
  */
-CV_EXPORTS void warpAffine(InputArray src, OutputArray dst, InputArray M, Size dsize, int flags = INTER_LINEAR,
+CV_EXPORTS_W void warpAffine(InputArray src, OutputArray dst, InputArray M, Size dsize, int flags = INTER_LINEAR,
     int borderMode = BORDER_CONSTANT, Scalar borderValue = Scalar(), Stream& stream = Stream::Null());
 
 /** @brief Builds transformation maps for affine transformation.
@@ -137,7 +137,7 @@ CV_EXPORTS void warpAffine(InputArray src, OutputArray dst, InputArray M, Size d
 
 @sa cuda::warpAffine , cuda::remap
  */
-CV_EXPORTS void buildWarpAffineMaps(InputArray M, bool inverse, Size dsize, OutputArray xmap, OutputArray ymap, Stream& stream = Stream::Null());
+CV_EXPORTS_W void buildWarpAffineMaps(InputArray M, bool inverse, Size dsize, OutputArray xmap, OutputArray ymap, Stream& stream = Stream::Null());
 
 /** @brief Applies a perspective transformation to an image.
 
@@ -155,7 +155,7 @@ INTER_NEAREST , INTER_LINEAR , and INTER_CUBIC interpolation methods are support
 
 @sa warpPerspective
  */
-CV_EXPORTS void warpPerspective(InputArray src, OutputArray dst, InputArray M, Size dsize, int flags = INTER_LINEAR,
+CV_EXPORTS_W void warpPerspective(InputArray src, OutputArray dst, InputArray M, Size dsize, int flags = INTER_LINEAR,
     int borderMode = BORDER_CONSTANT, Scalar borderValue = Scalar(), Stream& stream = Stream::Null());
 
 /** @brief Builds transformation maps for perspective transformation.
@@ -169,7 +169,7 @@ CV_EXPORTS void warpPerspective(InputArray src, OutputArray dst, InputArray M, S
 
 @sa cuda::warpPerspective , cuda::remap
  */
-CV_EXPORTS void buildWarpPerspectiveMaps(InputArray M, bool inverse, Size dsize, OutputArray xmap, OutputArray ymap, Stream& stream = Stream::Null());
+CV_EXPORTS_W void buildWarpPerspectiveMaps(InputArray M, bool inverse, Size dsize, OutputArray xmap, OutputArray ymap, Stream& stream = Stream::Null());
 
 /** @brief Rotates an image around the origin (0,0) and then shifts it.
 
@@ -186,7 +186,7 @@ are supported.
 
 @sa cuda::warpAffine
  */
-CV_EXPORTS void rotate(InputArray src, OutputArray dst, Size dsize, double angle, double xShift = 0, double yShift = 0,
+CV_EXPORTS_W void rotate(InputArray src, OutputArray dst, Size dsize, double angle, double xShift = 0, double yShift = 0,
                        int interpolation = INTER_LINEAR, Stream& stream = Stream::Null());
 
 /** @brief Smoothes an image and downsamples it.
@@ -198,7 +198,7 @@ type as src .
 
 @sa pyrDown
  */
-CV_EXPORTS void pyrDown(InputArray src, OutputArray dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void pyrDown(InputArray src, OutputArray dst, Stream& stream = Stream::Null());
 
 /** @brief Upsamples an image and then smoothes it.
 
@@ -207,7 +207,7 @@ CV_EXPORTS void pyrDown(InputArray src, OutputArray dst, Stream& stream = Stream
 src .
 @param stream Stream for the asynchronous version.
  */
-CV_EXPORTS void pyrUp(InputArray src, OutputArray dst, Stream& stream = Stream::Null());
+CV_EXPORTS_W void pyrUp(InputArray src, OutputArray dst, Stream& stream = Stream::Null());
 
 //! @}
 
diff --git a/modules/cudev/test/CMakeLists.txt b/modules/cudev/test/CMakeLists.txt
index ab9fd425297..3a321c6409d 100644
--- a/modules/cudev/test/CMakeLists.txt
+++ b/modules/cudev/test/CMakeLists.txt
@@ -15,7 +15,7 @@ if(OCV_DEPENDENCIES_FOUND)
 
   ocv_cuda_filter_options()
 
-  CUDA_ADD_EXECUTABLE(${the_target} ${OPENCV_TEST_${the_module}_SOURCES})
+  CUDA_ADD_EXECUTABLE(${the_target} ${OPENCV_TEST_${the_module}_SOURCES} OPTIONS -std=c++11)
   ocv_target_link_libraries(${the_target} LINK_PRIVATE
       ${test_deps} ${OPENCV_LINKER_LIBS} ${CUDA_LIBRARIES}
   )
diff --git a/modules/dnn/include/opencv2/dnn/all_layers.hpp b/modules/dnn/include/opencv2/dnn/all_layers.hpp
index b5416142c9a..cd4cca4c287 100644
--- a/modules/dnn/include/opencv2/dnn/all_layers.hpp
+++ b/modules/dnn/include/opencv2/dnn/all_layers.hpp
@@ -45,7 +45,7 @@
 
 namespace cv {
 namespace dnn {
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+CV__DNN_INLINE_NS_BEGIN
 //! @addtogroup dnn
 //! @{
 
@@ -617,7 +617,7 @@ CV__DNN_EXPERIMENTAL_NS_BEGIN
 
 //! @}
 //! @}
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }
 }
 #endif
diff --git a/modules/dnn/include/opencv2/dnn/dict.hpp b/modules/dnn/include/opencv2/dnn/dict.hpp
index 69287dc1cc8..64ef2f7a22c 100644
--- a/modules/dnn/include/opencv2/dnn/dict.hpp
+++ b/modules/dnn/include/opencv2/dnn/dict.hpp
@@ -50,7 +50,7 @@
 
 namespace cv {
 namespace dnn {
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+CV__DNN_INLINE_NS_BEGIN
 //! @addtogroup dnn
 //! @{
 
@@ -149,7 +149,7 @@ class CV_EXPORTS Dict
 };
 
 //! @}
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }
 }
 
diff --git a/modules/dnn/include/opencv2/dnn/dnn.hpp b/modules/dnn/include/opencv2/dnn/dnn.hpp
index e99f8448fd4..a50c50cd058 100644
--- a/modules/dnn/include/opencv2/dnn/dnn.hpp
+++ b/modules/dnn/include/opencv2/dnn/dnn.hpp
@@ -45,20 +45,13 @@
 #include <vector>
 #include <opencv2/core.hpp>
 
-#if !defined CV_DOXYGEN && !defined CV_DNN_DONT_ADD_EXPERIMENTAL_NS
-#define CV__DNN_EXPERIMENTAL_NS_BEGIN namespace experimental_dnn_34_v7 {
-#define CV__DNN_EXPERIMENTAL_NS_END }
-namespace cv { namespace dnn { namespace experimental_dnn_34_v7 { } using namespace experimental_dnn_34_v7; }}
-#else
-#define CV__DNN_EXPERIMENTAL_NS_BEGIN
-#define CV__DNN_EXPERIMENTAL_NS_END
-#endif
+#include "../dnn/version.hpp"
 
 #include <opencv2/dnn/dict.hpp>
 
 namespace cv {
 namespace dnn {
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+CV__DNN_INLINE_NS_BEGIN
 //! @addtogroup dnn
 //! @{
 
@@ -906,7 +899,7 @@ CV__DNN_EXPERIMENTAL_NS_BEGIN
                              const float eta = 1.f, const int top_k = 0);
 
 //! @}
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }
 }
 
diff --git a/modules/dnn/include/opencv2/dnn/dnn.inl.hpp b/modules/dnn/include/opencv2/dnn/dnn.inl.hpp
index 4231896187b..4be49bcc904 100644
--- a/modules/dnn/include/opencv2/dnn/dnn.inl.hpp
+++ b/modules/dnn/include/opencv2/dnn/dnn.inl.hpp
@@ -46,7 +46,7 @@
 
 namespace cv {
 namespace dnn {
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+CV__DNN_INLINE_NS_BEGIN
 
 template<typename TypeIter>
 DictValue DictValue::arrayInt(TypeIter begin, int size)
@@ -274,11 +274,7 @@ inline int DictValue::size() const
     case Param::REAL:
         return (int)pd->size();
     }
-#ifdef __OPENCV_BUILD
     CV_Error(Error::StsInternal, "");
-#else
-    CV_ErrorNoReturn(Error::StsInternal, "");
-#endif
 }
 
 inline std::ostream &operator<<(std::ostream &stream, const DictValue &dictv)
@@ -383,7 +379,7 @@ inline std::map<String, DictValue>::const_iterator Dict::end() const
     return dict.end();
 }
 
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }
 }
 
diff --git a/modules/dnn/include/opencv2/dnn/layer.details.hpp b/modules/dnn/include/opencv2/dnn/layer.details.hpp
index 619514e8274..1133da562e2 100644
--- a/modules/dnn/include/opencv2/dnn/layer.details.hpp
+++ b/modules/dnn/include/opencv2/dnn/layer.details.hpp
@@ -9,7 +9,7 @@
 
 namespace cv {
 namespace dnn {
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+CV__DNN_INLINE_NS_BEGIN
 
 /** @brief Registers layer constructor in runtime.
 *   @param type string, containing type name of the layer.
@@ -72,7 +72,7 @@ class _LayerStaticRegisterer
 };
 
 } // namespace
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }} // namespace
 
 #endif
diff --git a/modules/dnn/include/opencv2/dnn/layer.hpp b/modules/dnn/include/opencv2/dnn/layer.hpp
index c4712b8e7ad..85005993716 100644
--- a/modules/dnn/include/opencv2/dnn/layer.hpp
+++ b/modules/dnn/include/opencv2/dnn/layer.hpp
@@ -45,7 +45,7 @@
 
 namespace cv {
 namespace dnn {
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+CV__DNN_INLINE_NS_BEGIN
 //! @addtogroup dnn
 //! @{
 //!
@@ -79,7 +79,7 @@ class CV_EXPORTS LayerFactory
 
 //! @}
 //! @}
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }
 }
 #endif
diff --git a/modules/dnn/include/opencv2/dnn/shape_utils.hpp b/modules/dnn/include/opencv2/dnn/shape_utils.hpp
index b0ed3afc542..98adcc382dd 100644
--- a/modules/dnn/include/opencv2/dnn/shape_utils.hpp
+++ b/modules/dnn/include/opencv2/dnn/shape_utils.hpp
@@ -50,7 +50,7 @@
 
 namespace cv {
 namespace dnn {
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+CV__DNN_INLINE_NS_BEGIN
 
 //Slicing
 
@@ -213,7 +213,7 @@ inline Range clamp(const Range& r, int axisSize)
     return clamped;
 }
 
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }
 }
 #endif
diff --git a/modules/dnn/include/opencv2/dnn/version.hpp b/modules/dnn/include/opencv2/dnn/version.hpp
new file mode 100644
index 00000000000..6d1568cb455
--- /dev/null
+++ b/modules/dnn/include/opencv2/dnn/version.hpp
@@ -0,0 +1,21 @@
+// This file is part of OpenCV project.
+// It is subject to the license terms in the LICENSE file found in the top-level directory
+// of this distribution and at http://opencv.org/license.html.
+
+#ifndef OPENCV_DNN_VERSION_HPP
+#define OPENCV_DNN_VERSION_HPP
+
+/// Use with major OpenCV version only.
+#define OPENCV_DNN_API_VERSION 20180903
+
+#if !defined CV_DOXYGEN && !defined CV_DNN_DONT_ADD_INLINE_NS
+#define CV__DNN_INLINE_NS __CV_CAT(dnn4_v, OPENCV_DNN_API_VERSION)
+#define CV__DNN_INLINE_NS_BEGIN namespace CV__DNN_INLINE_NS {
+#define CV__DNN_INLINE_NS_END }
+namespace cv { namespace dnn { namespace CV__DNN_INLINE_NS { } using namespace CV__DNN_INLINE_NS; }}
+#else
+#define CV__DNN_INLINE_NS_BEGIN
+#define CV__DNN_INLINE_NS_END
+#endif
+
+#endif  // OPENCV_DNN_VERSION_HPP
diff --git a/modules/dnn/perf/perf_main.cpp b/modules/dnn/perf/perf_main.cpp
index d66f19c9dd3..073921efafe 100644
--- a/modules/dnn/perf/perf_main.cpp
+++ b/modules/dnn/perf/perf_main.cpp
@@ -7,6 +7,10 @@ static const char* extraTestDataPath =
         getenv("OPENCV_DNN_TEST_DATA_PATH");
 #endif
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_PERF_TEST_MAIN(dnn,
     extraTestDataPath ? (void)cvtest::addDataSearchPath(extraTestDataPath) : (void)0
 )
diff --git a/modules/dnn/src/caffe/caffe_importer.cpp b/modules/dnn/src/caffe/caffe_importer.cpp
index 24e918d7dc3..c09b5b20a07 100644
--- a/modules/dnn/src/caffe/caffe_importer.cpp
+++ b/modules/dnn/src/caffe/caffe_importer.cpp
@@ -54,7 +54,7 @@
 
 namespace cv {
 namespace dnn {
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+CV__DNN_INLINE_NS_BEGIN
 
 #ifdef HAVE_PROTOBUF
 using ::google::protobuf::RepeatedField;
@@ -464,5 +464,5 @@ Net readNetFromCaffe(const std::vector<uchar>& bufferProto, const std::vector<uc
 
 #endif //HAVE_PROTOBUF
 
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }} // namespace
diff --git a/modules/dnn/src/caffe/caffe_shrinker.cpp b/modules/dnn/src/caffe/caffe_shrinker.cpp
index 9dc6f9f862a..99e0ef85c12 100644
--- a/modules/dnn/src/caffe/caffe_shrinker.cpp
+++ b/modules/dnn/src/caffe/caffe_shrinker.cpp
@@ -13,7 +13,7 @@
 #endif
 
 namespace cv { namespace dnn {
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+CV__DNN_INLINE_NS_BEGIN
 
 #ifdef HAVE_PROTOBUF
 
@@ -76,5 +76,5 @@ void shrinkCaffeModel(const String& src, const String& dst, const std::vector<St
 
 #endif  // HAVE_PROTOBUF
 
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }} // namespace
diff --git a/modules/dnn/src/darknet/darknet_importer.cpp b/modules/dnn/src/darknet/darknet_importer.cpp
index 282b37277c5..f1269bd979d 100644
--- a/modules/dnn/src/darknet/darknet_importer.cpp
+++ b/modules/dnn/src/darknet/darknet_importer.cpp
@@ -54,7 +54,7 @@
 
 namespace cv {
 namespace dnn {
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+CV__DNN_INLINE_NS_BEGIN
 
 namespace
 {
@@ -251,5 +251,5 @@ Net readNetFromDarknet(const std::vector<uchar>& bufferCfg, const std::vector<uc
                               bufferModelPtr, bufferModel.size());
 }
 
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }} // namespace
diff --git a/modules/dnn/src/dnn.cpp b/modules/dnn/src/dnn.cpp
index bc186955215..5248d74cb60 100644
--- a/modules/dnn/src/dnn.cpp
+++ b/modules/dnn/src/dnn.cpp
@@ -57,7 +57,7 @@
 
 namespace cv {
 namespace dnn {
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+CV__DNN_INLINE_NS_BEGIN
 
 // this option is useful to run valgrind memory errors detection
 static bool DNN_DISABLE_MEMORY_OPTIMIZATIONS = utils::getConfigurationParameterBool("OPENCV_DNN_DISABLE_MEMORY_OPTIMIZATIONS", false);
@@ -3328,7 +3328,7 @@ void LayerFactory::registerLayer(const String &type, Constructor constructor)
     CV_TRACE_ARG_VALUE(type, "type", type.c_str());
 
     cv::AutoLock lock(getLayerFactoryMutex());
-    String type_ = type.toLowerCase();
+    String type_ = toLowerCase(type);
     LayerFactory_Impl::iterator it = getLayerFactoryImpl().find(type_);
 
     if (it != getLayerFactoryImpl().end())
@@ -3346,7 +3346,7 @@ void LayerFactory::unregisterLayer(const String &type)
     CV_TRACE_ARG_VALUE(type, "type", type.c_str());
 
     cv::AutoLock lock(getLayerFactoryMutex());
-    String type_ = type.toLowerCase();
+    String type_ = toLowerCase(type);
 
     LayerFactory_Impl::iterator it = getLayerFactoryImpl().find(type_);
     if (it != getLayerFactoryImpl().end())
@@ -3364,7 +3364,7 @@ Ptr<Layer> LayerFactory::createLayerInstance(const String &type, LayerParams& pa
     CV_TRACE_ARG_VALUE(type, "type", type.c_str());
 
     cv::AutoLock lock(getLayerFactoryMutex());
-    String type_ = type.toLowerCase();
+    String type_ = toLowerCase(type);
     LayerFactory_Impl::const_iterator it = getLayerFactoryImpl().find(type_);
 
     if (it != getLayerFactoryImpl().end())
@@ -3401,7 +3401,7 @@ BackendWrapper::~BackendWrapper() {}
 
 Net readNet(const String& _model, const String& _config, const String& _framework)
 {
-    String framework = _framework.toLowerCase();
+    String framework = toLowerCase(_framework);
     String model = _model;
     String config = _config;
     const std::string modelExt = model.substr(model.rfind('.') + 1);
@@ -3446,7 +3446,7 @@ Net readNet(const String& _model, const String& _config, const String& _framewor
 Net readNet(const String& _framework, const std::vector<uchar>& bufferModel,
             const std::vector<uchar>& bufferConfig)
 {
-    String framework = _framework.toLowerCase();
+    String framework = toLowerCase(_framework);
     if (framework == "caffe")
         return readNetFromCaffe(bufferConfig, bufferModel);
     else if (framework == "tensorflow")
@@ -3465,5 +3465,5 @@ Net readNetFromModelOptimizer(const String &xml, const String &bin)
     return Net::readFromModelOptimizer(xml, bin);
 }
 
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }} // namespace
diff --git a/modules/dnn/src/init.cpp b/modules/dnn/src/init.cpp
index 8db0828e62e..c78ec3533c6 100644
--- a/modules/dnn/src/init.cpp
+++ b/modules/dnn/src/init.cpp
@@ -46,7 +46,7 @@
 
 namespace cv {
 namespace dnn {
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+CV__DNN_INLINE_NS_BEGIN
 
 static Mutex* __initialization_mutex = NULL;
 Mutex& getInitializationMutex()
@@ -132,5 +132,5 @@ void initializeLayerFactory()
     CV_DNN_REGISTER_LAYER_CLASS(LSTM,           LSTMLayer);
 }
 
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }} // namespace
diff --git a/modules/dnn/src/layers/detection_output_layer.cpp b/modules/dnn/src/layers/detection_output_layer.cpp
index a3879128f97..bd926e49ced 100644
--- a/modules/dnn/src/layers/detection_output_layer.cpp
+++ b/modules/dnn/src/layers/detection_output_layer.cpp
@@ -164,7 +164,7 @@ class DetectionOutputLayerImpl CV_FINAL : public DetectionOutputLayer
 
     void getCodeType(const LayerParams &params)
     {
-        String codeTypeString = params.get<String>("code_type").toLowerCase();
+        String codeTypeString = toLowerCase(params.get<String>("code_type"));
         if (codeTypeString == "center_size")
             _codeType = "CENTER_SIZE";
         else
diff --git a/modules/dnn/src/layers/eltwise_layer.cpp b/modules/dnn/src/layers/eltwise_layer.cpp
index 567d5984169..b1a3493a90f 100644
--- a/modules/dnn/src/layers/eltwise_layer.cpp
+++ b/modules/dnn/src/layers/eltwise_layer.cpp
@@ -71,7 +71,7 @@ class EltwiseLayerImpl CV_FINAL : public EltwiseLayer
         op = SUM;
         if (params.has("operation"))
         {
-            String operation = params.get<String>("operation").toLowerCase();
+            String operation = toLowerCase(params.get<String>("operation"));
             if (operation == "prod")
                 op = PROD;
             else if (operation == "sum")
diff --git a/modules/dnn/src/layers/pooling_layer.cpp b/modules/dnn/src/layers/pooling_layer.cpp
index 573565d0253..200751d9b24 100644
--- a/modules/dnn/src/layers/pooling_layer.cpp
+++ b/modules/dnn/src/layers/pooling_layer.cpp
@@ -76,7 +76,7 @@ class PoolingLayerImpl CV_FINAL : public PoolingLayer
         if (params.has("pool") || params.has("kernel_size") ||
             params.has("kernel_w") || params.has("kernel_h"))
         {
-            String pool = params.get<String>("pool", "max").toLowerCase();
+            String pool = toLowerCase(params.get<String>("pool", "max"));
             if (pool == "max")
                 type = MAX;
             else if (pool == "ave")
diff --git a/modules/dnn/src/layers/recurrent_layers.cpp b/modules/dnn/src/layers/recurrent_layers.cpp
index b356b7627c5..15f791a0b04 100644
--- a/modules/dnn/src/layers/recurrent_layers.cpp
+++ b/modules/dnn/src/layers/recurrent_layers.cpp
@@ -349,16 +349,16 @@ Ptr<LSTMLayer> LSTMLayer::create(const LayerParams& params)
 
 int LSTMLayer::inputNameToIndex(String inputName)
 {
-    if (inputName.toLowerCase() == "x")
+    if (toLowerCase(inputName) == "x")
         return 0;
     return -1;
 }
 
 int LSTMLayer::outputNameToIndex(const String& outputName)
 {
-    if (outputName.toLowerCase() == "h")
+    if (toLowerCase(outputName) == "h")
         return 0;
-    else if (outputName.toLowerCase() == "c")
+    else if (toLowerCase(outputName) == "c")
         return 1;
     return -1;
 }
diff --git a/modules/dnn/src/nms.cpp b/modules/dnn/src/nms.cpp
index 051a9cbd28a..d8d2189926c 100644
--- a/modules/dnn/src/nms.cpp
+++ b/modules/dnn/src/nms.cpp
@@ -10,11 +10,8 @@
 
 #include <opencv2/imgproc.hpp>
 
-namespace cv
-{
-namespace dnn
-{
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+namespace cv { namespace dnn {
+CV__DNN_INLINE_NS_BEGIN
 
 static inline float rectOverlap(const Rect& a, const Rect& b)
 {
@@ -51,6 +48,6 @@ void NMSBoxes(const std::vector<RotatedRect>& bboxes, const std::vector<float>&
     NMSFast_(bboxes, scores, score_threshold, nms_threshold, eta, top_k, indices, rotatedRectIOU);
 }
 
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }// dnn
 }// cv
diff --git a/modules/dnn/src/precomp.hpp b/modules/dnn/src/precomp.hpp
index f6230c4c6dc..6266e1e9f89 100644
--- a/modules/dnn/src/precomp.hpp
+++ b/modules/dnn/src/precomp.hpp
@@ -63,9 +63,9 @@
 
 
 namespace cv { namespace dnn {
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+CV__DNN_INLINE_NS_BEGIN
 #define IS_DNN_OPENCL_TARGET(id) (id == DNN_TARGET_OPENCL || id == DNN_TARGET_OPENCL_FP16)
 Mutex& getInitializationMutex();
 void initializeLayerFactory();
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }} // namespace
diff --git a/modules/dnn/src/tensorflow/tf_graph_simplifier.cpp b/modules/dnn/src/tensorflow/tf_graph_simplifier.cpp
index a766d2a0243..51a249e73c6 100644
--- a/modules/dnn/src/tensorflow/tf_graph_simplifier.cpp
+++ b/modules/dnn/src/tensorflow/tf_graph_simplifier.cpp
@@ -12,7 +12,7 @@
 #include "tf_graph_simplifier.hpp"
 
 namespace cv { namespace dnn {
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+CV__DNN_INLINE_NS_BEGIN
 
 using ::google::protobuf::RepeatedField;
 using ::google::protobuf::MapPair;
@@ -782,7 +782,7 @@ void releaseTensor(tensorflow::TensorProto* tensor)
     }
 }
 
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }}  // namespace dnn, namespace cv
 
 #endif  // HAVE_PROTOBUF
diff --git a/modules/dnn/src/tensorflow/tf_graph_simplifier.hpp b/modules/dnn/src/tensorflow/tf_graph_simplifier.hpp
index d60ced78946..8b760520146 100644
--- a/modules/dnn/src/tensorflow/tf_graph_simplifier.hpp
+++ b/modules/dnn/src/tensorflow/tf_graph_simplifier.hpp
@@ -15,7 +15,7 @@
 #include "tf_io.hpp"
 
 namespace cv { namespace dnn {
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+CV__DNN_INLINE_NS_BEGIN
 
 void RemoveIdentityOps(tensorflow::GraphDef& net);
 
@@ -25,7 +25,7 @@ Mat getTensorContent(const tensorflow::TensorProto &tensor);
 
 void releaseTensor(tensorflow::TensorProto* tensor);
 
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }}  // namespace dnn, namespace cv
 
 #endif  // HAVE_PROTOBUF
diff --git a/modules/dnn/src/tensorflow/tf_importer.cpp b/modules/dnn/src/tensorflow/tf_importer.cpp
index 264d3cbc86f..86596c1b379 100644
--- a/modules/dnn/src/tensorflow/tf_importer.cpp
+++ b/modules/dnn/src/tensorflow/tf_importer.cpp
@@ -24,7 +24,7 @@ Implementation of Tensorflow models parser
 
 namespace cv {
 namespace dnn {
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+CV__DNN_INLINE_NS_BEGIN
 
 #if HAVE_PROTOBUF
 
@@ -1950,5 +1950,5 @@ Net readNetFromTensorflow(const std::vector<uchar>& bufferModel, const std::vect
                                  bufferConfigPtr, bufferConfig.size());
 }
 
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }} // namespace
diff --git a/modules/dnn/src/torch/torch_importer.cpp b/modules/dnn/src/torch/torch_importer.cpp
index 2338c73d96a..4f0041eeb68 100644
--- a/modules/dnn/src/torch/torch_importer.cpp
+++ b/modules/dnn/src/torch/torch_importer.cpp
@@ -51,7 +51,7 @@
 
 namespace cv {
 namespace dnn {
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+CV__DNN_INLINE_NS_BEGIN
 
 using namespace TH;
 
@@ -1240,5 +1240,5 @@ Net readNetFromTorch(const String &model, bool isBinary)
     return net;
 }
 
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }} // namespace
diff --git a/modules/dnn/test/pascal_semsegm_test_fcn.py b/modules/dnn/test/pascal_semsegm_test_fcn.py
index 0de7bf0ee36..af4bc2aedea 100644
--- a/modules/dnn/test/pascal_semsegm_test_fcn.py
+++ b/modules/dnn/test/pascal_semsegm_test_fcn.py
@@ -205,9 +205,9 @@ def process(self, frameworks, data_fetcher):
     parser.add_argument("--val_names", help="path to file with validation set image names, download it here: "
                         "https://github.com/shelhamer/fcn.berkeleyvision.org/blob/master/data/pascal/seg11valid.txt")
     parser.add_argument("--cls_file", help="path to file with colors for classes, download it here: "
-                        "https://github.com/opencv/opencv/blob/3.4/samples/data/dnn/pascal-classes.txt")
+                        "https://github.com/opencv/opencv/blob/master/samples/data/dnn/pascal-classes.txt")
     parser.add_argument("--prototxt", help="path to caffe prototxt, download it here: "
-                        "https://github.com/opencv/opencv/blob/3.4/samples/data/dnn/fcn8s-heavy-pascal.prototxt")
+                        "https://github.com/opencv/opencv/blob/master/samples/data/dnn/fcn8s-heavy-pascal.prototxt")
     parser.add_argument("--caffemodel", help="path to caffemodel file, download it here: "
                                              "http://dl.caffe.berkeleyvision.org/fcn8s-heavy-pascal.caffemodel")
     parser.add_argument("--log", help="path to logging file")
diff --git a/modules/dnn/test/test_main.cpp b/modules/dnn/test/test_main.cpp
index 4842c15240f..ce526d2e0f1 100644
--- a/modules/dnn/test/test_main.cpp
+++ b/modules/dnn/test/test_main.cpp
@@ -7,6 +7,10 @@ static const char* extraTestDataPath =
         getenv("OPENCV_DNN_TEST_DATA_PATH");
 #endif
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_TEST_MAIN("",
     extraTestDataPath ? (void)cvtest::addDataSearchPath(extraTestDataPath) : (void)0
 )
diff --git a/modules/dnn/test/test_precomp.hpp b/modules/dnn/test/test_precomp.hpp
index a0a46ab271a..d74e0bf9afa 100644
--- a/modules/dnn/test/test_precomp.hpp
+++ b/modules/dnn/test/test_precomp.hpp
@@ -51,7 +51,7 @@
 
 namespace cv {
 namespace dnn {
-CV__DNN_EXPERIMENTAL_NS_BEGIN
+CV__DNN_INLINE_NS_BEGIN
 
 static inline void PrintTo(const cv::dnn::Backend& v, std::ostream* os)
 {
@@ -75,7 +75,7 @@ static inline void PrintTo(const cv::dnn::Target& v, std::ostream* os)
     *os << "DNN_TARGET_UNKNOWN(" << v << ")";
 }
 
-CV__DNN_EXPERIMENTAL_NS_END
+CV__DNN_INLINE_NS_END
 }} // namespace
 
 namespace opencv_test {
diff --git a/modules/features2d/misc/java/filelist b/modules/features2d/misc/java/filelist
index 0430b5423a4..6c1b8ad8fd5 100644
--- a/modules/features2d/misc/java/filelist
+++ b/modules/features2d/misc/java/filelist
@@ -1,2 +1 @@
-misc/java/src/cpp/features2d_manual.hpp
 include/opencv2/features2d.hpp
diff --git a/modules/features2d/misc/java/gen_dict.json b/modules/features2d/misc/java/gen_dict.json
index 5ed56c88eec..299749ac854 100644
--- a/modules/features2d/misc/java/gen_dict.json
+++ b/modules/features2d/misc/java/gen_dict.json
@@ -2,12 +2,6 @@
     "class_ignore_list" : [
         "SimpleBlobDetector"
     ],
-    "const_private_list" : [
-        "OPPONENTEXTRACTOR",
-        "GRIDDETECTOR",
-        "PYRAMIDDETECTOR",
-        "DYNAMICDETECTOR"
-    ],
     "type_dict" : {
         "Feature2D": {
             "j_type": "Feature2D",
diff --git a/modules/features2d/misc/java/src/cpp/features2d_manual.hpp b/modules/features2d/misc/java/src/cpp/features2d_manual.hpp
deleted file mode 100644
index d9fd3fbded9..00000000000
--- a/modules/features2d/misc/java/src/cpp/features2d_manual.hpp
+++ /dev/null
@@ -1,320 +0,0 @@
-#ifndef __OPENCV_FEATURES_2D_MANUAL_HPP__
-#define __OPENCV_FEATURES_2D_MANUAL_HPP__
-
-#include "opencv2/opencv_modules.hpp"
-
-#ifdef HAVE_OPENCV_FEATURES2D
-#include "opencv2/features2d.hpp"
-#include "features2d_converters.hpp"
-
-#undef SIMPLEBLOB // to solve conflict with wincrypt.h on windows
-
-namespace cv
-{
-
-/**
- * @deprecated Please use direct instantiation of Feature2D classes
- */
-class CV_EXPORTS_AS(FeatureDetector) javaFeatureDetector
-{
-public:
-    CV_WRAP void detect( const Mat& image, CV_OUT std::vector<KeyPoint>& keypoints, const Mat& mask=Mat() ) const
-    { return wrapped->detect(image, keypoints, mask); }
-
-    CV_WRAP void detect( const std::vector<Mat>& images, CV_OUT std::vector<std::vector<KeyPoint> >& keypoints, const std::vector<Mat>& masks=std::vector<Mat>() ) const
-    { return wrapped->detect(images, keypoints, masks); }
-
-    CV_WRAP bool empty() const
-    { return wrapped->empty(); }
-
-    enum
-    {
-        FAST          = 1,
-        STAR          = 2,
-        SIFT          = 3,
-        SURF          = 4,
-        ORB           = 5,
-        MSER          = 6,
-        GFTT          = 7,
-        HARRIS        = 8,
-        SIMPLEBLOB    = 9,
-        DENSE         = 10,
-        BRISK         = 11,
-        AKAZE         = 12,
-
-
-        GRIDDETECTOR = 1000,
-
-        GRID_FAST          = GRIDDETECTOR + FAST,
-        GRID_STAR          = GRIDDETECTOR + STAR,
-        GRID_SIFT          = GRIDDETECTOR + SIFT,
-        GRID_SURF          = GRIDDETECTOR + SURF,
-        GRID_ORB           = GRIDDETECTOR + ORB,
-        GRID_MSER          = GRIDDETECTOR + MSER,
-        GRID_GFTT          = GRIDDETECTOR + GFTT,
-        GRID_HARRIS        = GRIDDETECTOR + HARRIS,
-        GRID_SIMPLEBLOB    = GRIDDETECTOR + SIMPLEBLOB,
-        GRID_DENSE         = GRIDDETECTOR + DENSE,
-        GRID_BRISK         = GRIDDETECTOR + BRISK,
-        GRID_AKAZE         = GRIDDETECTOR + AKAZE,
-
-
-        PYRAMIDDETECTOR = 2000,
-
-        PYRAMID_FAST       = PYRAMIDDETECTOR + FAST,
-        PYRAMID_STAR       = PYRAMIDDETECTOR + STAR,
-        PYRAMID_SIFT       = PYRAMIDDETECTOR + SIFT,
-        PYRAMID_SURF       = PYRAMIDDETECTOR + SURF,
-        PYRAMID_ORB        = PYRAMIDDETECTOR + ORB,
-        PYRAMID_MSER       = PYRAMIDDETECTOR + MSER,
-        PYRAMID_GFTT       = PYRAMIDDETECTOR + GFTT,
-        PYRAMID_HARRIS     = PYRAMIDDETECTOR + HARRIS,
-        PYRAMID_SIMPLEBLOB = PYRAMIDDETECTOR + SIMPLEBLOB,
-        PYRAMID_DENSE      = PYRAMIDDETECTOR + DENSE,
-        PYRAMID_BRISK      = PYRAMIDDETECTOR + BRISK,
-        PYRAMID_AKAZE      = PYRAMIDDETECTOR + AKAZE,
-
-        DYNAMICDETECTOR = 3000,
-
-        DYNAMIC_FAST       = DYNAMICDETECTOR + FAST,
-        DYNAMIC_STAR       = DYNAMICDETECTOR + STAR,
-        DYNAMIC_SIFT       = DYNAMICDETECTOR + SIFT,
-        DYNAMIC_SURF       = DYNAMICDETECTOR + SURF,
-        DYNAMIC_ORB        = DYNAMICDETECTOR + ORB,
-        DYNAMIC_MSER       = DYNAMICDETECTOR + MSER,
-        DYNAMIC_GFTT       = DYNAMICDETECTOR + GFTT,
-        DYNAMIC_HARRIS     = DYNAMICDETECTOR + HARRIS,
-        DYNAMIC_SIMPLEBLOB = DYNAMICDETECTOR + SIMPLEBLOB,
-        DYNAMIC_DENSE      = DYNAMICDETECTOR + DENSE,
-        DYNAMIC_BRISK      = DYNAMICDETECTOR + BRISK,
-        DYNAMIC_AKAZE      = DYNAMICDETECTOR + AKAZE
-    };
-
-    /**
-     * supported: FAST STAR SIFT SURF ORB MSER GFTT HARRIS BRISK AKAZE Grid(XXXX) Pyramid(XXXX) Dynamic(XXXX)
-     * not supported: SimpleBlob, Dense
-     * @deprecated
-     */
-    CV_WRAP static Ptr<javaFeatureDetector> create( int detectorType )
-    {
-        //String name;
-        if (detectorType > DYNAMICDETECTOR)
-        {
-            //name = "Dynamic";
-            detectorType -= DYNAMICDETECTOR;
-        }
-        if (detectorType > PYRAMIDDETECTOR)
-        {
-            //name = "Pyramid";
-            detectorType -= PYRAMIDDETECTOR;
-        }
-        if (detectorType > GRIDDETECTOR)
-        {
-            //name = "Grid";
-            detectorType -= GRIDDETECTOR;
-        }
-
-        Ptr<FeatureDetector> fd;
-        switch(detectorType)
-        {
-        case FAST:
-            fd = FastFeatureDetector::create();
-            break;
-        //case STAR:
-        //    fd = xfeatures2d::StarDetector::create();
-        //    break;
-        //case SIFT:
-        //    name = name + "SIFT";
-        //    break;
-        //case SURF:
-        //    name = name + "SURF";
-        //    break;
-        case ORB:
-            fd = ORB::create();
-            break;
-        case MSER:
-            fd = MSER::create();
-            break;
-        case GFTT:
-            fd = GFTTDetector::create();
-            break;
-        case HARRIS:
-            {
-            Ptr<GFTTDetector> gftt = GFTTDetector::create();
-            gftt->setHarrisDetector(true);
-            fd = gftt;
-            }
-            break;
-        case SIMPLEBLOB:
-            fd = SimpleBlobDetector::create();
-            break;
-        //case DENSE:
-        //    name = name + "Dense";
-        //    break;
-        case BRISK:
-            fd = BRISK::create();
-            break;
-        case AKAZE:
-            fd = AKAZE::create();
-            break;
-        default:
-            CV_Error( Error::StsBadArg, "Specified feature detector type is not supported." );
-            break;
-        }
-
-        return makePtr<javaFeatureDetector>(fd);
-    }
-
-    CV_WRAP void write( const String& fileName ) const
-    {
-        FileStorage fs(fileName, FileStorage::WRITE);
-        wrapped->write(fs);
-    }
-
-    CV_WRAP void read( const String& fileName )
-    {
-        FileStorage fs(fileName, FileStorage::READ);
-        wrapped->read(fs.root());
-    }
-
-    javaFeatureDetector(Ptr<FeatureDetector> _wrapped) : wrapped(_wrapped)
-    {}
-
-private:
-
-    Ptr<FeatureDetector> wrapped;
-};
-
-/**
- * @deprecated
- */
-class CV_EXPORTS_AS(DescriptorExtractor) javaDescriptorExtractor
-{
-public:
-    CV_WRAP void compute( const Mat& image, CV_IN_OUT std::vector<KeyPoint>& keypoints, Mat& descriptors ) const
-    { return wrapped->compute(image, keypoints, descriptors); }
-
-    CV_WRAP void compute( const std::vector<Mat>& images, CV_IN_OUT std::vector<std::vector<KeyPoint> >& keypoints, CV_OUT std::vector<Mat>& descriptors ) const
-    { return wrapped->compute(images, keypoints, descriptors); }
-
-    CV_WRAP int descriptorSize() const
-    { return wrapped->descriptorSize(); }
-
-    CV_WRAP int descriptorType() const
-    { return wrapped->descriptorType(); }
-
-    CV_WRAP bool empty() const
-    { return wrapped->empty(); }
-
-    enum
-    {
-        SIFT  = 1,
-        SURF  = 2,
-        ORB   = 3,
-        BRIEF = 4,
-        BRISK = 5,
-        FREAK = 6,
-        AKAZE = 7,
-
-
-        OPPONENTEXTRACTOR = 1000,
-
-
-
-        OPPONENT_SIFT  = OPPONENTEXTRACTOR + SIFT,
-        OPPONENT_SURF  = OPPONENTEXTRACTOR + SURF,
-        OPPONENT_ORB   = OPPONENTEXTRACTOR + ORB,
-        OPPONENT_BRIEF = OPPONENTEXTRACTOR + BRIEF,
-        OPPONENT_BRISK = OPPONENTEXTRACTOR + BRISK,
-        OPPONENT_FREAK = OPPONENTEXTRACTOR + FREAK,
-        OPPONENT_AKAZE = OPPONENTEXTRACTOR + AKAZE
-    };
-
-    //supported SIFT, SURF, ORB, BRIEF, BRISK, FREAK, AKAZE, Opponent(XXXX)
-    //not supported: Calonder
-    CV_WRAP static Ptr<javaDescriptorExtractor> create( int extractorType )
-    {
-        //String name;
-
-        if (extractorType > OPPONENTEXTRACTOR)
-        {
-            //name = "Opponent";
-            extractorType -= OPPONENTEXTRACTOR;
-        }
-
-        Ptr<DescriptorExtractor> de;
-        switch(extractorType)
-        {
-        //case SIFT:
-        //    name = name + "SIFT";
-        //    break;
-        //case SURF:
-        //    name = name + "SURF";
-        //    break;
-        case ORB:
-            de = ORB::create();
-            break;
-        //case BRIEF:
-        //    name = name + "BRIEF";
-        //    break;
-        case BRISK:
-            de = BRISK::create();
-            break;
-        //case FREAK:
-        //    name = name + "FREAK";
-        //    break;
-        case AKAZE:
-            de = AKAZE::create();
-            break;
-        default:
-            CV_Error( Error::StsBadArg, "Specified descriptor extractor type is not supported." );
-            break;
-        }
-
-        return makePtr<javaDescriptorExtractor>(de);
-    }
-
-    CV_WRAP void write( const String& fileName ) const
-    {
-        FileStorage fs(fileName, FileStorage::WRITE);
-        wrapped->write(fs);
-    }
-
-    CV_WRAP void read( const String& fileName )
-    {
-        FileStorage fs(fileName, FileStorage::READ);
-        wrapped->read(fs.root());
-    }
-
-    javaDescriptorExtractor(Ptr<DescriptorExtractor> _wrapped) : wrapped(_wrapped)
-    {}
-
-private:
-
-    Ptr<DescriptorExtractor> wrapped;
-};
-
-#if 0
-//DO NOT REMOVE! The block is required for sources parser
-enum
-{
-          DRAW_OVER_OUTIMG = 1, // Output image matrix will not be created (Mat::create).
-                                // Matches will be drawn on existing content of output image.
-          NOT_DRAW_SINGLE_POINTS = 2, // Single keypoints will not be drawn.
-          DRAW_RICH_KEYPOINTS = 4 // For each keypoint the circle around keypoint with keypoint size and
-                                  // orientation will be drawn.
-};
-
-CV_EXPORTS_AS(drawMatches2) void drawMatches( const Mat& img1, const std::vector<KeyPoint>& keypoints1,
-                             const Mat& img2, const std::vector<KeyPoint>& keypoints2,
-                             const std::vector<std::vector<DMatch> >& matches1to2, Mat& outImg,
-                             const Scalar& matchColor=Scalar::all(-1), const Scalar& singlePointColor=Scalar::all(-1),
-                             const std::vector<std::vector<char> >& matchesMask=std::vector<std::vector<char> >(), int flags=0);
-
-#endif
-
-} //cv
-
-#endif // HAVE_OPENCV_FEATURES2D
-
-#endif // __OPENCV_FEATURES_2D_MANUAL_HPP__
diff --git a/modules/features2d/misc/java/test/BruteForceHammingDescriptorMatcherTest.java b/modules/features2d/misc/java/test/BruteForceHammingDescriptorMatcherTest.java
index 6bcc3ea6c16..2bdcc589f9a 100644
--- a/modules/features2d/misc/java/test/BruteForceHammingDescriptorMatcherTest.java
+++ b/modules/features2d/misc/java/test/BruteForceHammingDescriptorMatcherTest.java
@@ -12,7 +12,7 @@
 import org.opencv.core.Scalar;
 import org.opencv.core.DMatch;
 import org.opencv.features2d.DescriptorMatcher;
-import org.opencv.features2d.FeatureDetector;
+import org.opencv.features2d.FastFeatureDetector;
 import org.opencv.test.OpenCVTestCase;
 import org.opencv.test.OpenCVTestRunner;
 import org.opencv.imgproc.Imgproc;
@@ -46,7 +46,7 @@ private Mat getTestDescriptors(Mat img) {
         MatOfKeyPoint keypoints = new MatOfKeyPoint();
         Mat descriptors = new Mat();
 
-        FeatureDetector detector = FeatureDetector.create(FeatureDetector.FAST);
+        Feature2D detector = FastFeatureDetector.create();
         Feature2D extractor = createClassInstance(XFEATURES2D+"BriefDescriptorExtractor", DEFAULT_FACTORY, null, null);
 
         detector.detect(img, keypoints);
diff --git a/modules/features2d/misc/java/test/BruteForceHammingLUTDescriptorMatcherTest.java b/modules/features2d/misc/java/test/BruteForceHammingLUTDescriptorMatcherTest.java
index 67ceb0b60f7..60baa7c246a 100644
--- a/modules/features2d/misc/java/test/BruteForceHammingLUTDescriptorMatcherTest.java
+++ b/modules/features2d/misc/java/test/BruteForceHammingLUTDescriptorMatcherTest.java
@@ -11,7 +11,7 @@
 import org.opencv.core.Scalar;
 import org.opencv.core.DMatch;
 import org.opencv.features2d.DescriptorMatcher;
-import org.opencv.features2d.FeatureDetector;
+import org.opencv.features2d.FastFeatureDetector;
 import org.opencv.test.OpenCVTestCase;
 import org.opencv.test.OpenCVTestRunner;
 import org.opencv.imgproc.Imgproc;
@@ -45,7 +45,7 @@ private Mat getTestDescriptors(Mat img) {
         MatOfKeyPoint keypoints = new MatOfKeyPoint();
         Mat descriptors = new Mat();
 
-        FeatureDetector detector = FeatureDetector.create(FeatureDetector.FAST);
+        Feature2D detector = FastFeatureDetector.create();
         Feature2D extractor = createClassInstance(XFEATURES2D+"BriefDescriptorExtractor", DEFAULT_FACTORY, null, null);
 
         detector.detect(img, keypoints);
diff --git a/modules/features2d/misc/java/test/FASTFeatureDetectorTest.java b/modules/features2d/misc/java/test/FASTFeatureDetectorTest.java
index 091f4a7b502..044e70d0ede 100644
--- a/modules/features2d/misc/java/test/FASTFeatureDetectorTest.java
+++ b/modules/features2d/misc/java/test/FASTFeatureDetectorTest.java
@@ -8,7 +8,8 @@
 import org.opencv.core.MatOfKeyPoint;
 import org.opencv.core.Point;
 import org.opencv.core.Scalar;
-import org.opencv.features2d.FeatureDetector;
+import org.opencv.features2d.Feature2D;
+import org.opencv.features2d.FastFeatureDetector;
 import org.opencv.core.KeyPoint;
 import org.opencv.test.OpenCVTestCase;
 import org.opencv.test.OpenCVTestRunner;
@@ -16,7 +17,7 @@
 
 public class FASTFeatureDetectorTest extends OpenCVTestCase {
 
-    FeatureDetector detector;
+    Feature2D detector;
     KeyPoint[] truth;
 
     private Mat getMaskImg() {
@@ -35,7 +36,7 @@ private Mat getTestImg() {
     @Override
     protected void setUp() throws Exception {
         super.setUp();
-        detector = FeatureDetector.create(FeatureDetector.FAST);
+        detector = FastFeatureDetector.create();
         truth = new KeyPoint[] { new KeyPoint(32, 27, 7, -1, 254, 0, -1), new KeyPoint(27, 32, 7, -1, 254, 0, -1), new KeyPoint(73, 68, 7, -1, 254, 0, -1),
                 new KeyPoint(68, 73, 7, -1, 254, 0, -1) };
     }
diff --git a/modules/features2d/misc/java/test/ORBDescriptorExtractorTest.java b/modules/features2d/misc/java/test/ORBDescriptorExtractorTest.java
index 1009e1bfd5d..dd7ee3e8994 100644
--- a/modules/features2d/misc/java/test/ORBDescriptorExtractorTest.java
+++ b/modules/features2d/misc/java/test/ORBDescriptorExtractorTest.java
@@ -6,7 +6,6 @@
 import org.opencv.core.MatOfKeyPoint;
 import org.opencv.core.Point;
 import org.opencv.core.Scalar;
-import org.opencv.features2d.DescriptorExtractor;
 import org.opencv.core.KeyPoint;
 import org.opencv.features2d.ORB;
 import org.opencv.test.OpenCVTestCase;
diff --git a/modules/features2d/perf/perf_main.cpp b/modules/features2d/perf/perf_main.cpp
index 17a99fcc195..7119d254434 100644
--- a/modules/features2d/perf/perf_main.cpp
+++ b/modules/features2d/perf/perf_main.cpp
@@ -1,3 +1,7 @@
 #include "perf_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_PERF_TEST_MAIN(features2d)
diff --git a/modules/features2d/src/fast.cpp b/modules/features2d/src/fast.cpp
index 4a7071bc989..0d3c418fa15 100644
--- a/modules/features2d/src/fast.cpp
+++ b/modules/features2d/src/fast.cpp
@@ -497,10 +497,6 @@ void FAST(InputArray _img, std::vector<KeyPoint>& keypoints, int threshold, bool
         FAST_t<12>(_img, keypoints, threshold, nonmax_suppression);
         break;
     case FastFeatureDetector::TYPE_9_16:
-#ifdef HAVE_TEGRA_OPTIMIZATION
-        if(tegra::useTegra() && tegra::FAST(_img, keypoints, threshold, nonmax_suppression))
-          break;
-#endif
         FAST_t<16>(_img, keypoints, threshold, nonmax_suppression);
         break;
     }
diff --git a/modules/features2d/src/precomp.hpp b/modules/features2d/src/precomp.hpp
index c3db78b9da3..27feebcd547 100644
--- a/modules/features2d/src/precomp.hpp
+++ b/modules/features2d/src/precomp.hpp
@@ -53,8 +53,4 @@
 
 #include <algorithm>
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-#include "opencv2/features2d/features2d_tegra.hpp"
-#endif
-
 #endif
diff --git a/modules/features2d/test/test_main.cpp b/modules/features2d/test/test_main.cpp
index 0e51ddfd050..93e4d2860eb 100644
--- a/modules/features2d/test/test_main.cpp
+++ b/modules/features2d/test/test_main.cpp
@@ -3,4 +3,8 @@
 // of this distribution and at http://opencv.org/license.html.
 #include "test_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_TEST_MAIN("cv")
diff --git a/modules/flann/test/test_main.cpp b/modules/flann/test/test_main.cpp
index 6b249934475..f377a339c4f 100644
--- a/modules/flann/test/test_main.cpp
+++ b/modules/flann/test/test_main.cpp
@@ -1,3 +1,7 @@
 #include "test_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_TEST_MAIN("cv")
diff --git a/modules/highgui/include/opencv2/highgui.hpp b/modules/highgui/include/opencv2/highgui.hpp
index 994a1d1efb2..6e02662e709 100644
--- a/modules/highgui/include/opencv2/highgui.hpp
+++ b/modules/highgui/include/opencv2/highgui.hpp
@@ -838,8 +838,4 @@ CV_EXPORTS int createButton( const String& bar_name, ButtonCallback on_change,
 
 } // cv
 
-#ifndef DISABLE_OPENCV_24_COMPATIBILITY
-#include "opencv2/highgui/highgui_c.h"
-#endif
-
 #endif
diff --git a/modules/highgui/src/precomp.hpp b/modules/highgui/src/precomp.hpp
index 1d72a5d7a20..cf23a39e17a 100644
--- a/modules/highgui/src/precomp.hpp
+++ b/modules/highgui/src/precomp.hpp
@@ -68,10 +68,6 @@
     #undef abs
 #endif
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-#include "opencv2/highgui/highgui_tegra.hpp"
-#endif
-
 /* Errors */
 #define HG_OK          0 /* Don't bet on it! */
 #define HG_BADNAME    -1 /* Bad window or file name */
diff --git a/modules/highgui/src/window.cpp b/modules/highgui/src/window.cpp
index 663b4458fcf..7bc9d432c3f 100644
--- a/modules/highgui/src/window.cpp
+++ b/modules/highgui/src/window.cpp
@@ -603,7 +603,7 @@ void cv::setWindowTitle(const String&, const String&)
 }
 
 #define CV_NO_GUI_ERROR(funcname) \
-    cv::errorNoReturn(cv::Error::StsError, \
+    cv::error(cv::Error::StsError, \
     "The function is not implemented. " \
     "Rebuild the library with Windows, GTK+ 2.x or Carbon support. "\
     "If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script", \
diff --git a/modules/highgui/test/test_main.cpp b/modules/highgui/test/test_main.cpp
index 4eb2abd8f87..d2483270466 100644
--- a/modules/highgui/test/test_main.cpp
+++ b/modules/highgui/test/test_main.cpp
@@ -3,4 +3,8 @@
 // of this distribution and at http://opencv.org/license.html.
 #include "test_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_TEST_MAIN("highgui")
diff --git a/modules/imgcodecs/CMakeLists.txt b/modules/imgcodecs/CMakeLists.txt
index 434278c2a5c..d771224d4c9 100644
--- a/modules/imgcodecs/CMakeLists.txt
+++ b/modules/imgcodecs/CMakeLists.txt
@@ -72,6 +72,10 @@ if(HAVE_IMGCODEC_PXM)
   add_definitions(-DHAVE_IMGCODEC_PXM)
 endif()
 
+if (HAVE_IMGCODEC_PFM)
+  add_definitions(-DHAVE_IMGCODEC_PFM)
+endif()
+
 file(GLOB grfmt_hdrs ${CMAKE_CURRENT_LIST_DIR}/src/grfmt*.hpp)
 file(GLOB grfmt_srcs ${CMAKE_CURRENT_LIST_DIR}/src/grfmt*.cpp)
 
diff --git a/modules/imgcodecs/perf/perf_main.cpp b/modules/imgcodecs/perf/perf_main.cpp
index 421ae829e45..3455d44953c 100644
--- a/modules/imgcodecs/perf/perf_main.cpp
+++ b/modules/imgcodecs/perf/perf_main.cpp
@@ -3,4 +3,8 @@
 // of this distribution and at http://opencv.org/license.html
 #include "perf_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_PERF_TEST_MAIN(imgcodecs)
diff --git a/modules/imgcodecs/src/grfmt_jpeg2000.cpp b/modules/imgcodecs/src/grfmt_jpeg2000.cpp
index b8b70fee85b..be280e285a2 100644
--- a/modules/imgcodecs/src/grfmt_jpeg2000.cpp
+++ b/modules/imgcodecs/src/grfmt_jpeg2000.cpp
@@ -179,7 +179,7 @@ bool  Jpeg2KDecoder::readData( Mat& img )
 {
     Ptr<Jpeg2KDecoder> close_this(this, Jpeg2KDecoder_close);
     bool result = false;
-    int color = img.channels() > 1;
+    bool color = img.channels() > 1;
     uchar* data = img.ptr();
     size_t step = img.step;
     jas_stream_t* stream = (jas_stream_t*)m_stream;
diff --git a/modules/imgcodecs/src/grfmt_pfm.cpp b/modules/imgcodecs/src/grfmt_pfm.cpp
new file mode 100644
index 00000000000..f4180169633
--- /dev/null
+++ b/modules/imgcodecs/src/grfmt_pfm.cpp
@@ -0,0 +1,264 @@
+// This file is part of OpenCV project.
+// It is subject to the license terms in the LICENSE file found in the top-level directory
+// of this distribution and at http://opencv.org/license.html.
+
+#include "precomp.hpp"
+#include "utils.hpp"
+#include "grfmt_pfm.hpp"
+#include <iostream>
+
+#ifdef HAVE_IMGCODEC_PFM
+
+namespace {
+
+static_assert(sizeof(float) == 4, "float must be 32 bit.");
+
+
+bool is_byte_order_swapped(double scale)
+{
+  // ".pfm" format file specifies that:
+  // positive scale means big endianess;
+  // negative scale means little endianess.
+
+  #ifdef WORDS_BIGENDIAN
+    return scale < 0.0;
+  #else
+    return scale >= 0.0;
+  #endif
+}
+
+void swap_endianess(uint32_t& ui)
+{
+  static const uint32_t A(0x000000ffU);
+  static const uint32_t B(0x0000ff00U);
+  static const uint32_t C(0x00ff0000U);
+  static const uint32_t D(0xff000000U);
+
+  ui = ( (ui & A) << 24 )
+     | ( (ui & B) <<  8 )
+     | ( (ui & C) >>  8 )
+     | ( (ui & D) >> 24 );
+}
+
+template<typename T> T atoT(const std::string& s);
+template<> int atoT<int>(const std::string& s) { return std::atoi(s.c_str()); }
+template<> double atoT<double>(const std::string& s) { return std::atof(s.c_str()); }
+
+template<typename T>
+T read_number(cv::RLByteStream& strm)
+{
+  // should be enogh to take string representation of any number
+  const size_t buffer_size = 2048;
+
+  std::vector<char> buffer(buffer_size, 0);
+  for (size_t i = 0; i < buffer_size; ++i) {
+    const int intc = strm.getByte();
+    CV_Assert(intc >= -128 && intc < 128);
+    char c = static_cast<char>(intc);
+    if (std::isspace(c)) {
+      break;
+    }
+    buffer[i] = c;
+  }
+  const std::string str(buffer.begin(), buffer.end());
+  return atoT<T>(str);
+}
+
+template<typename T> void write_anything(cv::WLByteStream& strm, const T& t)
+{
+  std::ostringstream ss;
+  ss << t;
+  strm.putBytes(ss.str().c_str(), static_cast<int>(ss.str().size()));
+}
+
+}
+
+namespace cv {
+
+PFMDecoder::~PFMDecoder()
+{
+}
+
+PFMDecoder::PFMDecoder()
+{
+  m_strm.close();
+}
+
+bool PFMDecoder::readHeader()
+{
+  if (m_buf.empty()) {
+    if (!m_strm.open(m_filename)) {
+      return false;
+    }
+  } else {
+    if (!m_strm.open(m_buf)) {
+      return false;
+    }
+  }
+
+  if (m_strm.getByte() != 'P') {
+    CV_Error(Error::StsError, "Unexpected file type (expected P)");
+  }
+
+  switch (m_strm.getByte()) {
+  case 'f':
+    m_type = CV_32FC1;
+    break;
+  case 'F':
+    m_type = CV_32FC3;
+    break;
+  default:
+    CV_Error(Error::StsError, "Unexpected file type (expected `f` or `F`)");
+  }
+
+  if ('\n' != m_strm.getByte()) {
+    CV_Error(Error::StsError, "Unexpected header format (expected line break)");
+  }
+
+
+  m_width = read_number<int>(m_strm);
+  m_height = read_number<int>(m_strm);
+  m_scale_factor = read_number<double>(m_strm);
+  m_swap_byte_order = is_byte_order_swapped(m_scale_factor);
+
+  return true;
+}
+
+bool PFMDecoder::readData(Mat& mat)
+{
+  if (!m_strm.isOpened()) {
+    CV_Error(Error::StsError, "Unexpected status in data stream");
+  }
+
+  Mat buffer(mat.size(), m_type);
+  for (int y = m_height - 1; y >= 0; --y) {
+    m_strm.getBytes(buffer.ptr(y), static_cast<int>(m_width * buffer.elemSize()));
+    if (is_byte_order_swapped(m_scale_factor)) {
+      for (int i = 0; i < m_width * buffer.channels(); ++i) {
+        static_assert( sizeof(uint32_t) == sizeof(float),
+                       "uint32_t and float must have same size." );
+        swap_endianess(buffer.ptr<uint32_t>(y)[i]);
+      }
+    }
+  }
+
+  if (buffer.channels() == 3) {
+    cv::cvtColor(buffer, buffer, cv::COLOR_BGR2RGB);
+  }
+
+  CV_Assert(fabs(m_scale_factor) > 0.0f);
+  buffer *= 1.f / fabs(m_scale_factor);
+
+  buffer.convertTo(mat, mat.type());
+
+  return true;
+}
+
+size_t PFMDecoder::signatureLength() const
+{
+    return 3;
+}
+
+bool PFMDecoder::checkSignature( const String& signature ) const
+{
+    return signature.size() >= 3
+        && signature[0] == 'P'
+        && ( signature[1] == 'f' || signature[1] == 'F' )
+        && isspace(signature[2]);
+}
+
+void PFMDecoder::close()
+{
+  // noop
+}
+
+//////////////////////////////////////////////////////////////////////////////////////////
+
+PFMEncoder::PFMEncoder()
+{
+  m_description = "Portable image format - float (*.pfm)";
+}
+
+PFMEncoder::~PFMEncoder()
+{
+}
+
+bool PFMEncoder::isFormatSupported(int depth) const
+{
+  // any depth will be converted into 32-bit float.
+  (void) depth;
+  return true;
+}
+
+bool PFMEncoder::write(const Mat& img, const std::vector<int>& params)
+{
+  (void) params;
+
+  WLByteStream strm;
+  if (m_buf) {
+    if (!strm.open(*m_buf)) {
+      return false;
+    } else {
+      m_buf->reserve(alignSize(256 + sizeof(float) * img.channels() * img.total(), 256));
+    }
+  } else if (!strm.open(m_filename)) {
+    return false;
+  }
+
+  Mat float_img;
+  strm.putByte('P');
+  switch (img.channels()) {
+  case 1:
+    strm.putByte('f');
+    img.convertTo(float_img, CV_32FC1);
+    break;
+  case 3:
+    strm.putByte('F');
+    img.convertTo(float_img, CV_32FC3);
+    break;
+  default:
+    CV_Error(Error::StsBadArg, "Expected 1 or 3 channel image.");
+  }
+  strm.putByte('\n');
+
+
+  write_anything(strm, float_img.cols);
+  strm.putByte(' ');
+  write_anything(strm, float_img.rows);
+  strm.putByte('\n');
+#ifdef WORDS_BIGENDIAN
+  write_anything(strm, 1.0);
+#else
+  write_anything(strm, -1.0);
+#endif
+
+  strm.putByte('\n');
+
+  // Comments are not officially supported in this file format.
+  // write_anything(strm, "# Generated by OpenCV " CV_VERSION "\n");
+
+  for (int y = float_img.rows - 1; y >= 0; --y)
+  {
+    if (float_img.channels() == 3) {
+      const float* bgr_row = float_img.ptr<float>(y);
+      size_t row_size = float_img.cols * float_img.channels();
+      std::vector<float> rgb_row(row_size);
+      for (int x = 0; x < float_img.cols; ++x) {
+        rgb_row[x*3+0] = bgr_row[x*3+2];
+        rgb_row[x*3+1] = bgr_row[x*3+1];
+        rgb_row[x*3+2] = bgr_row[x*3+0];
+      }
+      strm.putBytes( reinterpret_cast<const uchar*>(rgb_row.data()),
+                     static_cast<int>(sizeof(float) * row_size) );
+    } else if (float_img.channels() == 1) {
+      strm.putBytes(float_img.ptr(y), sizeof(float) * float_img.cols);
+    }
+  }
+  return true;
+}
+
+
+}
+
+
+#endif // HAVE_IMGCODEC_PFM
diff --git a/modules/imgcodecs/src/grfmt_pfm.hpp b/modules/imgcodecs/src/grfmt_pfm.hpp
new file mode 100644
index 00000000000..9284f605155
--- /dev/null
+++ b/modules/imgcodecs/src/grfmt_pfm.hpp
@@ -0,0 +1,57 @@
+// This file is part of OpenCV project.
+// It is subject to the license terms in the LICENSE file found in the top-level directory
+// of this distribution and at http://opencv.org/license.html.
+
+#ifndef _GRFMT_PFM_H_
+#define _GRFMT_PFM_H_
+
+#include "grfmt_base.hpp"
+#include "bitstrm.hpp"
+
+#ifdef HAVE_IMGCODEC_PFM
+namespace cv
+{
+
+class PFMDecoder CV_FINAL : public BaseImageDecoder
+{
+public:
+    PFMDecoder();
+    virtual ~PFMDecoder() CV_OVERRIDE;
+
+    bool  readData( Mat& img ) CV_OVERRIDE;
+    bool  readHeader() CV_OVERRIDE;
+    void  close();
+
+    size_t signatureLength() const CV_OVERRIDE;
+    bool checkSignature( const String& signature ) const CV_OVERRIDE;
+    ImageDecoder newDecoder() const CV_OVERRIDE
+    {
+        return makePtr<PFMDecoder>();
+    }
+
+private:
+    RLByteStream m_strm;
+    double m_scale_factor;
+    bool m_swap_byte_order;
+};
+
+class PFMEncoder CV_FINAL : public BaseImageEncoder
+{
+public:
+    PFMEncoder();
+    virtual ~PFMEncoder() CV_OVERRIDE;
+
+    bool  isFormatSupported( int depth ) const CV_OVERRIDE;
+    bool  write( const Mat& img, const std::vector<int>& params ) CV_OVERRIDE;
+
+    ImageEncoder newEncoder() const CV_OVERRIDE
+    {
+        return makePtr<PFMEncoder>();
+    }
+};
+
+}
+
+#endif // HAVE_IMGCODEC_PXM
+
+#endif/*_GRFMT_PFM_H_*/
\ No newline at end of file
diff --git a/modules/imgcodecs/src/grfmt_png.cpp b/modules/imgcodecs/src/grfmt_png.cpp
index 36324c2e6c5..f26262282a3 100644
--- a/modules/imgcodecs/src/grfmt_png.cpp
+++ b/modules/imgcodecs/src/grfmt_png.cpp
@@ -226,7 +226,7 @@ bool  PngDecoder::readData( Mat& img )
     volatile bool result = false;
     AutoBuffer<uchar*> _buffer(m_height);
     uchar** buffer = _buffer.data();
-    int color = img.channels() > 1;
+    bool color = img.channels() > 1;
 
     png_structp png_ptr = (png_structp)m_png_ptr;
     png_infop info_ptr = (png_infop)m_info_ptr;
diff --git a/modules/imgcodecs/src/grfmt_pxm.cpp b/modules/imgcodecs/src/grfmt_pxm.cpp
index 7c5c9910be0..b41fd95edcf 100644
--- a/modules/imgcodecs/src/grfmt_pxm.cpp
+++ b/modules/imgcodecs/src/grfmt_pxm.cpp
@@ -208,7 +208,7 @@ bool PxMDecoder::readHeader()
 
 bool PxMDecoder::readData( Mat& img )
 {
-    int color = img.channels() > 1;
+    bool color = img.channels() > 1;
     uchar* data = img.ptr();
     PaletteEntry palette[256];
     bool   result = false;
@@ -225,7 +225,7 @@ bool PxMDecoder::readData( Mat& img )
     // create LUT for converting colors
     if( bit_depth == 8 )
     {
-        CV_Assert(m_maxval < 256);
+        CV_Assert(m_maxval < 256 && m_maxval > 0);
 
         for (int i = 0; i <= m_maxval; i++)
             gray_palette[i] = (uchar)((i*255/m_maxval)^(m_bpp == 1 ? 255 : 0));
diff --git a/modules/imgcodecs/src/grfmt_sunras.cpp b/modules/imgcodecs/src/grfmt_sunras.cpp
index ec17685850a..4865edaa26f 100644
--- a/modules/imgcodecs/src/grfmt_sunras.cpp
+++ b/modules/imgcodecs/src/grfmt_sunras.cpp
@@ -160,7 +160,7 @@ bool  SunRasterDecoder::readHeader()
 
 bool  SunRasterDecoder::readData( Mat& img )
 {
-    int color = img.channels() > 1;
+    bool color = img.channels() > 1;
     uchar* data = img.ptr();
     size_t step = img.step;
     uchar  gray_palette[256] = {0};
diff --git a/modules/imgcodecs/src/grfmts.hpp b/modules/imgcodecs/src/grfmts.hpp
index 10bd88264e8..4fd58d022db 100644
--- a/modules/imgcodecs/src/grfmts.hpp
+++ b/modules/imgcodecs/src/grfmts.hpp
@@ -47,6 +47,7 @@
 #include "grfmt_sunras.hpp"
 #include "grfmt_jpeg.hpp"
 #include "grfmt_pxm.hpp"
+#include "grfmt_pfm.hpp"
 #include "grfmt_tiff.hpp"
 #include "grfmt_png.hpp"
 #include "grfmt_jpeg2000.hpp"
diff --git a/modules/imgcodecs/src/loadsave.cpp b/modules/imgcodecs/src/loadsave.cpp
index f5d9c98a3be..20444094352 100644
--- a/modules/imgcodecs/src/loadsave.cpp
+++ b/modules/imgcodecs/src/loadsave.cpp
@@ -156,6 +156,10 @@ struct ImageCodecInitializer
         decoders.push_back( makePtr<PAMDecoder>() );
         encoders.push_back( makePtr<PAMEncoder>() );
     #endif
+    #ifdef HAVE_IMGCODEC_PFM
+        decoders.push_back( makePtr<PFMDecoder>() );
+        encoders.push_back( makePtr<PFMEncoder>() );
+    #endif
     #ifdef HAVE_TIFF
         decoders.push_back( makePtr<TiffDecoder>() );
         encoders.push_back( makePtr<TiffEncoder>() );
diff --git a/modules/imgcodecs/test/test_grfmt.cpp b/modules/imgcodecs/test/test_grfmt.cpp
index 70b2f2714e5..1b1eaa743e8 100644
--- a/modules/imgcodecs/test/test_grfmt.cpp
+++ b/modules/imgcodecs/test/test_grfmt.cpp
@@ -158,6 +158,7 @@ TEST_P(Imgcodecs_ExtSize, write_imageseq)
 
         Mat img_gt(size, CV_MAKETYPE(CV_8U, cn), Scalar::all(0));
         circle(img_gt, center, radius, Scalar::all(255));
+
 #if 1
         if (ext == ".pbm" || ext == ".pgm" || ext == ".ppm")
         {
@@ -172,6 +173,7 @@ TEST_P(Imgcodecs_ExtSize, write_imageseq)
         EXPECT_EQ(img.type(), img.type());
         EXPECT_EQ(cn, img.channels());
 
+
         if (ext == ".jpg")
         {
             // JPEG format does not provide 100% accuracy
@@ -181,14 +183,21 @@ TEST_P(Imgcodecs_ExtSize, write_imageseq)
             EXPECT_LT(n, expected);
             EXPECT_PRED_FORMAT2(cvtest::MatComparator(10, 0), img, img_gt);
         }
+        else if (ext == ".pfm")
+        {
+            img_gt.convertTo(img_gt, CV_MAKETYPE(CV_32F, img.channels()));
+            double n = cvtest::norm(img, img_gt, NORM_L2);
+            EXPECT_LT(n, 1.);
+            EXPECT_PRED_FORMAT2(cvtest::MatComparator(0, 0), img, img_gt);
+        }
         else
         {
             double n = cvtest::norm(img, img_gt, NORM_L2);
             EXPECT_LT(n, 1.);
             EXPECT_PRED_FORMAT2(cvtest::MatComparator(0, 0), img, img_gt);
         }
+
 #if 0
-        std::cout << filename << std::endl;
         imshow("loaded", img);
         waitKey(0);
 #else
@@ -214,7 +223,10 @@ const string all_exts[] =
     ".ppm",
     ".pgm",
     ".pbm",
-    ".pnm"
+    ".pnm",
+#endif
+#ifdef HAVE_IMGCODEC_PFM
+    ".pfm",
 #endif
 };
 
@@ -337,6 +349,30 @@ TEST(Imgcodecs_Pam, read_write)
 }
 #endif
 
+#ifdef HAVE_IMGCODEC_PFM
+TEST(Imgcodecs_Pfm, read_write)
+{
+  Mat img = imread(findDataFile("readwrite/lena.pam"));
+  ASSERT_FALSE(img.empty());
+  img.convertTo(img, CV_32F, 1/255.0f);
+
+  std::vector<int> params;
+  string writefile = cv::tempfile(".pfm");
+  EXPECT_NO_THROW(cv::imwrite(writefile, img, params));
+  cv::Mat reread = cv::imread(writefile, IMREAD_UNCHANGED);
+
+  string writefile_no_param = cv::tempfile(".pfm");
+  EXPECT_NO_THROW(cv::imwrite(writefile_no_param, img));
+  cv::Mat reread_no_param = cv::imread(writefile_no_param, IMREAD_UNCHANGED);
+
+  EXPECT_EQ(0, cvtest::norm(reread, reread_no_param, NORM_INF));
+  EXPECT_EQ(0, cvtest::norm(img, reread, NORM_INF));
+
+  EXPECT_EQ(0, remove(writefile.c_str()));
+  EXPECT_EQ(0, remove(writefile_no_param.c_str()));
+}
+#endif
+
 TEST(Imgcodecs, write_parameter_type)
 {
     cv::Mat m(10, 10, CV_8UC1, cv::Scalar::all(0));
diff --git a/modules/imgcodecs/test/test_main.cpp b/modules/imgcodecs/test/test_main.cpp
index dffac7e48ff..77f7366dae0 100644
--- a/modules/imgcodecs/test/test_main.cpp
+++ b/modules/imgcodecs/test/test_main.cpp
@@ -3,4 +3,8 @@
 // of this distribution and at http://opencv.org/license.html
 #include "test_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_TEST_MAIN("highgui")
diff --git a/modules/imgproc/include/opencv2/imgproc.hpp b/modules/imgproc/include/opencv2/imgproc.hpp
index b1ad3ca1ce6..e236e08adb3 100644
--- a/modules/imgproc/include/opencv2/imgproc.hpp
+++ b/modules/imgproc/include/opencv2/imgproc.hpp
@@ -788,56 +788,96 @@ enum RectanglesIntersectTypes {
     INTERSECT_FULL  = 2 //!< One of the rectangle is fully enclosed in the other
 };
 
+
+/** types of line
+@ingroup imgproc_draw
+*/
+enum LineTypes {
+    FILLED  = -1,
+    LINE_4  = 4, //!< 4-connected line
+    LINE_8  = 8, //!< 8-connected line
+    LINE_AA = 16 //!< antialiased line
+};
+
+/** Only a subset of Hershey fonts <https://en.wikipedia.org/wiki/Hershey_fonts> are supported
+@ingroup imgproc_draw
+*/
+enum HersheyFonts {
+    FONT_HERSHEY_SIMPLEX        = 0, //!< normal size sans-serif font
+    FONT_HERSHEY_PLAIN          = 1, //!< small size sans-serif font
+    FONT_HERSHEY_DUPLEX         = 2, //!< normal size sans-serif font (more complex than FONT_HERSHEY_SIMPLEX)
+    FONT_HERSHEY_COMPLEX        = 3, //!< normal size serif font
+    FONT_HERSHEY_TRIPLEX        = 4, //!< normal size serif font (more complex than FONT_HERSHEY_COMPLEX)
+    FONT_HERSHEY_COMPLEX_SMALL  = 5, //!< smaller version of FONT_HERSHEY_COMPLEX
+    FONT_HERSHEY_SCRIPT_SIMPLEX = 6, //!< hand-writing style font
+    FONT_HERSHEY_SCRIPT_COMPLEX = 7, //!< more complex variant of FONT_HERSHEY_SCRIPT_SIMPLEX
+    FONT_ITALIC                 = 16 //!< flag for italic font
+};
+
+/** Possible set of marker types used for the cv::drawMarker function
+@ingroup imgproc_draw
+*/
+enum MarkerTypes
+{
+    MARKER_CROSS = 0,           //!< A crosshair marker shape
+    MARKER_TILTED_CROSS = 1,    //!< A 45 degree tilted crosshair marker shape
+    MARKER_STAR = 2,            //!< A star marker shape, combination of cross and tilted cross
+    MARKER_DIAMOND = 3,         //!< A diamond marker shape
+    MARKER_SQUARE = 4,          //!< A square marker shape
+    MARKER_TRIANGLE_UP = 5,     //!< An upwards pointing triangle marker shape
+    MARKER_TRIANGLE_DOWN = 6    //!< A downwards pointing triangle marker shape
+};
+
 //! finds arbitrary template in the grayscale image using Generalized Hough Transform
-class CV_EXPORTS GeneralizedHough : public Algorithm
+class CV_EXPORTS_W GeneralizedHough : public Algorithm
 {
 public:
     //! set template to search
-    virtual void setTemplate(InputArray templ, Point templCenter = Point(-1, -1)) = 0;
-    virtual void setTemplate(InputArray edges, InputArray dx, InputArray dy, Point templCenter = Point(-1, -1)) = 0;
+    CV_WRAP virtual void setTemplate(InputArray templ, Point templCenter = Point(-1, -1)) = 0;
+    CV_WRAP virtual void setTemplate(InputArray edges, InputArray dx, InputArray dy, Point templCenter = Point(-1, -1)) = 0;
 
     //! find template on image
-    virtual void detect(InputArray image, OutputArray positions, OutputArray votes = noArray()) = 0;
-    virtual void detect(InputArray edges, InputArray dx, InputArray dy, OutputArray positions, OutputArray votes = noArray()) = 0;
+    CV_WRAP virtual void detect(InputArray image, OutputArray positions, OutputArray votes = noArray()) = 0;
+    CV_WRAP virtual void detect(InputArray edges, InputArray dx, InputArray dy, OutputArray positions, OutputArray votes = noArray()) = 0;
 
     //! Canny low threshold.
-    virtual void setCannyLowThresh(int cannyLowThresh) = 0;
-    virtual int getCannyLowThresh() const = 0;
+    CV_WRAP virtual void setCannyLowThresh(int cannyLowThresh) = 0;
+    CV_WRAP virtual int getCannyLowThresh() const = 0;
 
     //! Canny high threshold.
-    virtual void setCannyHighThresh(int cannyHighThresh) = 0;
-    virtual int getCannyHighThresh() const = 0;
+    CV_WRAP virtual void setCannyHighThresh(int cannyHighThresh) = 0;
+    CV_WRAP virtual int getCannyHighThresh() const = 0;
 
     //! Minimum distance between the centers of the detected objects.
-    virtual void setMinDist(double minDist) = 0;
-    virtual double getMinDist() const = 0;
+    CV_WRAP virtual void setMinDist(double minDist) = 0;
+    CV_WRAP virtual double getMinDist() const = 0;
 
     //! Inverse ratio of the accumulator resolution to the image resolution.
-    virtual void setDp(double dp) = 0;
-    virtual double getDp() const = 0;
+    CV_WRAP virtual void setDp(double dp) = 0;
+    CV_WRAP virtual double getDp() const = 0;
 
     //! Maximal size of inner buffers.
-    virtual void setMaxBufferSize(int maxBufferSize) = 0;
-    virtual int getMaxBufferSize() const = 0;
+    CV_WRAP virtual void setMaxBufferSize(int maxBufferSize) = 0;
+    CV_WRAP virtual int getMaxBufferSize() const = 0;
 };
 
 //! Ballard, D.H. (1981). Generalizing the Hough transform to detect arbitrary shapes. Pattern Recognition 13 (2): 111-122.
 //! Detects position only without translation and rotation
-class CV_EXPORTS GeneralizedHoughBallard : public GeneralizedHough
+class CV_EXPORTS_W GeneralizedHoughBallard : public GeneralizedHough
 {
 public:
     //! R-Table levels.
-    virtual void setLevels(int levels) = 0;
-    virtual int getLevels() const = 0;
+    CV_WRAP virtual void setLevels(int levels) = 0;
+    CV_WRAP virtual int getLevels() const = 0;
 
     //! The accumulator threshold for the template centers at the detection stage. The smaller it is, the more false positions may be detected.
-    virtual void setVotesThreshold(int votesThreshold) = 0;
-    virtual int getVotesThreshold() const = 0;
+    CV_WRAP virtual void setVotesThreshold(int votesThreshold) = 0;
+    CV_WRAP virtual int getVotesThreshold() const = 0;
 };
 
 //! Guil, N., Gonzlez-Linares, J.M. and Zapata, E.L. (1999). Bidimensional shape detection using an invariant approach. Pattern Recognition 32 (6): 1025-1038.
 //! Detects position, translation and rotation
-class CV_EXPORTS GeneralizedHoughGuil : public GeneralizedHough
+class CV_EXPORTS_W GeneralizedHoughGuil : public GeneralizedHough
 {
 public:
     //! Angle difference in degrees between two points in feature.
@@ -2363,9 +2403,6 @@ coordinate origin is assumed to be the top-left corner).
  */
 CV_EXPORTS_W Mat getRotationMatrix2D( Point2f center, double angle, double scale );
 
-//! returns 3x3 perspective transformation for the corresponding 4 point pairs.
-CV_EXPORTS Mat getPerspectiveTransform( const Point2f src[], const Point2f dst[] );
-
 /** @brief Calculates an affine transform from three pairs of the corresponding points.
 
 The function calculates the \f$2 \times 3\f$ matrix of an affine transform so that:
@@ -2408,10 +2445,15 @@ where
 
 @param src Coordinates of quadrangle vertices in the source image.
 @param dst Coordinates of the corresponding quadrangle vertices in the destination image.
+@param solveMethod method passed to cv::solve (#DecompTypes)
 
 @sa  findHomography, warpPerspective, perspectiveTransform
  */
-CV_EXPORTS_W Mat getPerspectiveTransform( InputArray src, InputArray dst );
+CV_EXPORTS_W Mat getPerspectiveTransform(InputArray src, InputArray dst, int solveMethod = DECOMP_LU);
+
+/** @overload */
+CV_EXPORTS Mat getPerspectiveTransform(const Point2f src[], const Point2f dst[], int solveMethod = DECOMP_LU);
+
 
 CV_EXPORTS_W Mat getAffineTransform( InputArray src, InputArray dst );
 
@@ -4358,7 +4400,7 @@ CV_EXPORTS_W void rectangle(InputOutputArray img, Point pt1, Point pt2,
 use `rec` parameter as alternative specification of the drawn rectangle: `r.tl() and
 r.br()-Point(1,1)` are opposite corners
 */
-CV_EXPORTS void rectangle(CV_IN_OUT Mat& img, Rect rec,
+CV_EXPORTS_W void rectangle(InputOutputArray img, Rect rec,
                           const Scalar& color, int thickness = 1,
                           int lineType = LINE_8, int shift = 0);
 
@@ -4428,18 +4470,6 @@ CV_EXPORTS_W void ellipse(InputOutputArray img, const RotatedRect& box, const Sc
 /* ADDING A SET OF PREDEFINED MARKERS WHICH COULD BE USED TO HIGHLIGHT POSITIONS IN AN IMAGE */
 /* ----------------------------------------------------------------------------------------- */
 
-//! Possible set of marker types used for the cv::drawMarker function
-enum MarkerTypes
-{
-    MARKER_CROSS = 0,           //!< A crosshair marker shape
-    MARKER_TILTED_CROSS = 1,    //!< A 45 degree tilted crosshair marker shape
-    MARKER_STAR = 2,            //!< A star marker shape, combination of cross and tilted cross
-    MARKER_DIAMOND = 3,         //!< A diamond marker shape
-    MARKER_SQUARE = 4,          //!< A square marker shape
-    MARKER_TRIANGLE_UP = 5,     //!< An upwards pointing triangle marker shape
-    MARKER_TRIANGLE_DOWN = 6    //!< A downwards pointing triangle marker shape
-};
-
 /** @brief Draws a marker on a predefined position in an image.
 
 The function cv::drawMarker draws a marker on a given position in the image. For the moment several
@@ -4453,7 +4483,7 @@ marker types are supported, see #MarkerTypes for more information.
 @param line_type Type of the line, See #LineTypes
 @param markerSize The length of the marker axis [default = 20 pixels]
  */
-CV_EXPORTS_W void drawMarker(CV_IN_OUT Mat& img, Point position, const Scalar& color,
+CV_EXPORTS_W void drawMarker(InputOutputArray img, Point position, const Scalar& color,
                              int markerType = MARKER_CROSS, int markerSize=20, int thickness=1,
                              int line_type=8);
 
@@ -4828,8 +4858,4 @@ Point LineIterator::pos() const
 
 } // cv
 
-#ifndef DISABLE_OPENCV_24_COMPATIBILITY
-#include "opencv2/imgproc/imgproc_c.h"
-#endif
-
 #endif
diff --git a/modules/imgproc/include/opencv2/imgproc/hal/hal.hpp b/modules/imgproc/include/opencv2/imgproc/hal/hal.hpp
index a435fd6b855..ac20725e634 100644
--- a/modules/imgproc/include/opencv2/imgproc/hal/hal.hpp
+++ b/modules/imgproc/include/opencv2/imgproc/hal/hal.hpp
@@ -108,7 +108,7 @@ CV_EXPORTS void warpAffine(int src_type,
                            uchar * dst_data, size_t dst_step, int dst_width, int dst_height,
                            const double M[6], int interpolation, int borderType, const double borderValue[4]);
 
-CV_EXPORTS void warpPerspectve(int src_type,
+CV_EXPORTS void warpPerspective(int src_type,
                                const uchar * src_data, size_t src_step, int src_width, int src_height,
                                uchar * dst_data, size_t dst_step, int dst_width, int dst_height,
                                const double M[9], int interpolation, int borderType, const double borderValue[4]);
diff --git a/modules/imgproc/misc/java/gen_dict.json b/modules/imgproc/misc/java/gen_dict.json
index 45cc7dad93b..5559abc8afb 100644
--- a/modules/imgproc/misc/java/gen_dict.json
+++ b/modules/imgproc/misc/java/gen_dict.json
@@ -25,9 +25,6 @@
                 ["IPL_BORDER_WRAP",        3 ],
                 ["IPL_BORDER_REFLECT_101", 4 ],
                 ["IPL_BORDER_TRANSPARENT", 5 ]
-            ],
-            "public" : [
-                ["LINE_AA", 16], ["LINE_8", 8], ["LINE_4", 4]
             ]
         }
     },
diff --git a/modules/imgproc/misc/java/test/ImgprocTest.java b/modules/imgproc/misc/java/test/ImgprocTest.java
index ca23ee35b33..fc9d92ed9b9 100644
--- a/modules/imgproc/misc/java/test/ImgprocTest.java
+++ b/modules/imgproc/misc/java/test/ImgprocTest.java
@@ -584,7 +584,7 @@ public void testCornerSubPix() {
         Point truthPosition = new Point(img.cols() / 2, img.rows() / 2);
 
         Rect r = new Rect(new Point(0, 0), truthPosition);
-        Imgproc.rectangle(img, r.tl(), r.br(), new Scalar(0), Core.FILLED);
+        Imgproc.rectangle(img, r.tl(), r.br(), new Scalar(0), Imgproc.FILLED);
         MatOfPoint2f corners = new MatOfPoint2f(new Point(truthPosition.x + 1, truthPosition.y + 1));
         Size winSize = new Size(2, 2);
         Size zeroZone = new Size(-1, -1);
@@ -657,7 +657,7 @@ public void testDrawContoursMatListOfMatIntScalarInt() {
         List<MatOfPoint> contours = new ArrayList<MatOfPoint>();
         Imgproc.findContours(gray0, contours, new Mat(), Imgproc.RETR_EXTERNAL, Imgproc.CHAIN_APPROX_SIMPLE);
 
-        Imgproc.drawContours(gray0, contours, -1, new Scalar(0), Core.FILLED);
+        Imgproc.drawContours(gray0, contours, -1, new Scalar(0), Imgproc.FILLED);
 
         assertEquals(0, Core.countNonZero(gray0));
     }
@@ -1938,8 +1938,8 @@ public void testGetTextSize() {
         int thickness = 3;
         int baseLine[] = new int[1];
 
-        Imgproc.getTextSize(text, Core.FONT_HERSHEY_SCRIPT_SIMPLEX, fontScale, thickness, null);
-        Size res = Imgproc.getTextSize(text, Core.FONT_HERSHEY_SCRIPT_SIMPLEX, fontScale, thickness, baseLine);
+        Imgproc.getTextSize(text, Imgproc.FONT_HERSHEY_SCRIPT_SIMPLEX, fontScale, thickness, null);
+        Size res = Imgproc.getTextSize(text, Imgproc.FONT_HERSHEY_SCRIPT_SIMPLEX, fontScale, thickness, baseLine);
 
         assertEquals(543.0, res.width);
         assertEquals(44.0, res.height);
@@ -1961,7 +1961,7 @@ public void testCircleMatPointIntScalarInt() {
         int radius = Math.min(gray0.cols() / 4, gray0.rows() / 4);
         Scalar color = new Scalar(128);
 
-        Imgproc.circle(gray0, center, radius, color, Core.FILLED);
+        Imgproc.circle(gray0, center, radius, color, Imgproc.FILLED);
 
         assertTrue(0 != Core.countNonZero(gray0));
     }
@@ -2042,7 +2042,7 @@ public void testEllipseMatPointSizeDoubleDoubleDoubleScalarInt() {
         Size axes = new Size(2, 2);
         double angle = 30, startAngle = 60, endAngle = 90;
 
-        Imgproc.ellipse(gray0, center, axes, angle, startAngle, endAngle, colorWhite, Core.FILLED);
+        Imgproc.ellipse(gray0, center, axes, angle, startAngle, endAngle, colorWhite, Imgproc.FILLED);
 
         assertTrue(0 != Core.countNonZero(gray0));
     }
@@ -2054,11 +2054,11 @@ public void testEllipseMatPointSizeDoubleDoubleDoubleScalarIntIntInt() {
         Size axes2 = new Size(4, 4);
         double angle = 30, startAngle = 0, endAngle = 30;
 
-        Imgproc.ellipse(gray0, center, axes, angle, startAngle, endAngle, colorWhite, Core.FILLED, Imgproc.LINE_4, 0);
+        Imgproc.ellipse(gray0, center, axes, angle, startAngle, endAngle, colorWhite, Imgproc.FILLED, Imgproc.LINE_4, 0);
 
         assertTrue(0 != Core.countNonZero(gray0));
 
-        Imgproc.ellipse(gray0, center2, axes2, angle, startAngle, endAngle, colorBlack, Core.FILLED, Imgproc.LINE_4, 1);
+        Imgproc.ellipse(gray0, center2, axes2, angle, startAngle, endAngle, colorBlack, Imgproc.FILLED, Imgproc.LINE_4, 1);
 
         assertEquals(0, Core.countNonZero(gray0));
     }
@@ -2096,7 +2096,7 @@ public void testEllipseMatRotatedRectScalarInt() {
         Size size = new Size(matSize / 4, matSize / 2);
         RotatedRect box = new RotatedRect(center, size, 45);
 
-        Imgproc.ellipse(gray0, box, new Scalar(1), Core.FILLED);
+        Imgproc.ellipse(gray0, box, new Scalar(1), Imgproc.FILLED);
         Imgproc.ellipse(gray0, box, new Scalar(0));
 
         assertTrue(0 < Core.countNonZero(gray0));
@@ -2159,11 +2159,11 @@ public void testPutTextMatStringPointIntDoubleScalar() {
         Mat img = new Mat(20 + (int) labelSize.height, 20 + (int) labelSize.width, CvType.CV_8U, colorBlack);
         Point origin = new Point(10, labelSize.height + 10);
 
-        Imgproc.putText(img, text, origin, Core.FONT_HERSHEY_SIMPLEX, 1.0, colorWhite);
+        Imgproc.putText(img, text, origin, Imgproc.FONT_HERSHEY_SIMPLEX, 1.0, colorWhite);
 
         assertTrue(Core.countNonZero(img) > 0);
         // check that border is not corrupted
-        Imgproc.rectangle(img, new Point(11, 11), new Point(labelSize.width + 10, labelSize.height + 10), colorBlack, Core.FILLED);
+        Imgproc.rectangle(img, new Point(11, 11), new Point(labelSize.width + 10, labelSize.height + 10), colorBlack, Imgproc.FILLED);
         assertEquals(0, Core.countNonZero(img));
     }
 
@@ -2173,11 +2173,11 @@ public void testPutTextMatStringPointIntDoubleScalarInt() {
         Mat img = new Mat(20 + (int) labelSize.height, 20 + (int) labelSize.width, CvType.CV_8U, colorBlack);
         Point origin = new Point(10, labelSize.height + 10);
 
-        Imgproc.putText(img, text, origin, Core.FONT_HERSHEY_SIMPLEX, 1.0, colorWhite, 2);
+        Imgproc.putText(img, text, origin, Imgproc.FONT_HERSHEY_SIMPLEX, 1.0, colorWhite, 2);
 
         assertTrue(Core.countNonZero(img) > 0);
         // check that border is not corrupted
-        Imgproc.rectangle(img, new Point(10, 10), new Point(labelSize.width + 10 + 1, labelSize.height + 10 + 1), colorBlack, Core.FILLED);
+        Imgproc.rectangle(img, new Point(10, 10), new Point(labelSize.width + 10 + 1, labelSize.height + 10 + 1), colorBlack, Imgproc.FILLED);
         assertEquals(0, Core.countNonZero(img));
     }
 
@@ -2188,11 +2188,11 @@ public void testPutTextMatStringPointIntDoubleScalarIntIntBoolean() {
         Mat img = new Mat(20 + (int) labelSize.height, 20 + (int) labelSize.width, CvType.CV_8U, colorBlack);
         Point origin = new Point(10, 10);
 
-        Imgproc.putText(img, text, origin, Core.FONT_HERSHEY_SIMPLEX, 1.0, colorWhite, 1, Imgproc.LINE_8, true);
+        Imgproc.putText(img, text, origin, Imgproc.FONT_HERSHEY_SIMPLEX, 1.0, colorWhite, 1, Imgproc.LINE_8, true);
 
         assertTrue(Core.countNonZero(img) > 0);
         // check that border is not corrupted
-        Imgproc.rectangle(img, new Point(10, 10), new Point(labelSize.width + 9, labelSize.height + 9), colorBlack, Core.FILLED);
+        Imgproc.rectangle(img, new Point(10, 10), new Point(labelSize.width + 9, labelSize.height + 9), colorBlack, Imgproc.FILLED);
         assertEquals(0, Core.countNonZero(img));
     }
 }
diff --git a/modules/imgproc/perf/perf_main.cpp b/modules/imgproc/perf/perf_main.cpp
index 807d8bab225..e4f1816cd63 100644
--- a/modules/imgproc/perf/perf_main.cpp
+++ b/modules/imgproc/perf/perf_main.cpp
@@ -3,4 +3,8 @@
 // of this distribution and at http://opencv.org/license.html.
 #include "perf_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_PERF_TEST_MAIN(imgproc)
diff --git a/modules/imgproc/perf/perf_warp.cpp b/modules/imgproc/perf/perf_warp.cpp
index b51e9ae75c5..cb974e9f09f 100644
--- a/modules/imgproc/perf/perf_warp.cpp
+++ b/modules/imgproc/perf/perf_warp.cpp
@@ -290,4 +290,23 @@ PERF_TEST(Transform, getPerspectiveTransform_1000)
     SANITY_CHECK_NOTHING();
 }
 
+PERF_TEST(Transform, getPerspectiveTransform_QR_1000)
+{
+    unsigned int size = 8;
+    Mat source(1, size/2, CV_32FC2);
+    Mat destination(1, size/2, CV_32FC2);
+    Mat transformCoefficient;
+
+    declare.in(source, destination, WARMUP_RNG);
+
+    PERF_SAMPLE_BEGIN()
+    for (int i = 0; i < 1000; i++)
+    {
+        transformCoefficient = getPerspectiveTransform(source, destination, DECOMP_QR);
+    }
+    PERF_SAMPLE_END()
+
+    SANITY_CHECK_NOTHING();
+}
+
 } // namespace
diff --git a/modules/imgproc/src/accum.cpp b/modules/imgproc/src/accum.cpp
index 2b43f4e42c8..fece3139e70 100644
--- a/modules/imgproc/src/accum.cpp
+++ b/modules/imgproc/src/accum.cpp
@@ -332,7 +332,7 @@ void cv::accumulate( InputArray _src, InputOutputArray _dst, InputArray _mask )
     CV_Assert( func != 0 );
 
     const Mat* arrays[] = {&src, &dst, &mask, 0};
-    uchar* ptrs[3];
+    uchar* ptrs[3]{};
     NAryMatIterator it(arrays, ptrs);
     int len = (int)it.size;
 
@@ -430,7 +430,7 @@ void cv::accumulateSquare( InputArray _src, InputOutputArray _dst, InputArray _m
     CV_Assert( func != 0 );
 
     const Mat* arrays[] = {&src, &dst, &mask, 0};
-    uchar* ptrs[3];
+    uchar* ptrs[3]{};
     NAryMatIterator it(arrays, ptrs);
     int len = (int)it.size;
 
@@ -533,7 +533,7 @@ void cv::accumulateProduct( InputArray _src1, InputArray _src2,
     CV_Assert( func != 0 );
 
     const Mat* arrays[] = {&src1, &src2, &dst, &mask, 0};
-    uchar* ptrs[4];
+    uchar* ptrs[4]{};
     NAryMatIterator it(arrays, ptrs);
     int len = (int)it.size;
 
@@ -635,7 +635,7 @@ void cv::accumulateWeighted( InputArray _src, InputOutputArray _dst,
     CV_Assert( func != 0 );
 
     const Mat* arrays[] = {&src, &dst, &mask, 0};
-    uchar* ptrs[3];
+    uchar* ptrs[3]{};
     NAryMatIterator it(arrays, ptrs);
     int len = (int)it.size;
 
diff --git a/modules/imgproc/src/canny.cpp b/modules/imgproc/src/canny.cpp
index eaea6b2f8f4..dd26d9bc5c6 100644
--- a/modules/imgproc/src/canny.cpp
+++ b/modules/imgproc/src/canny.cpp
@@ -996,11 +996,6 @@ void Canny( InputArray _src, OutputArray _dst,
             aperture_size,
             L2gradient ) )
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    if (tegra::useTegra() && tegra::canny(src, dst, low_thresh, high_thresh, aperture_size, L2gradient))
-        return;
-#endif
-
     CV_IPP_RUN_FAST(ipp_Canny(src, Mat(), Mat(), dst, (float)low_thresh, (float)high_thresh, L2gradient, aperture_size))
 
     if (L2gradient)
diff --git a/modules/imgproc/src/corner.cpp b/modules/imgproc/src/corner.cpp
index 8d1857fa3d5..96e49e2b37b 100644
--- a/modules/imgproc/src/corner.cpp
+++ b/modules/imgproc/src/corner.cpp
@@ -247,10 +247,6 @@ cornerEigenValsVecs( const Mat& src, Mat& eigenv, int block_size,
                      int aperture_size, int op_type, double k=0.,
                      int borderType=BORDER_DEFAULT )
 {
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    if (tegra::useTegra() && tegra::cornerEigenValsVecs(src, eigenv, block_size, aperture_size, op_type, k, borderType))
-        return;
-#endif
 #if CV_TRY_AVX
     bool haveAvx = CV_CPU_HAS_SUPPORT_AVX;
 #endif
diff --git a/modules/imgproc/src/deriv.cpp b/modules/imgproc/src/deriv.cpp
index 2a1a73d7aa7..999ce959c92 100644
--- a/modules/imgproc/src/deriv.cpp
+++ b/modules/imgproc/src/deriv.cpp
@@ -808,20 +808,6 @@ void cv::Laplacian( InputArray _src, OutputArray _dst, int ddepth, int ksize,
 
     CV_IPP_RUN(!(cv::ocl::isOpenCLActivated() && _dst.isUMat()), ipp_Laplacian(_src, _dst, ksize, scale, delta, borderType));
 
-
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    if (tegra::useTegra() && scale == 1.0 && delta == 0)
-    {
-        Mat src = _src.getMat(), dst = _dst.getMat();
-        if (ksize == 1 && tegra::laplace1(src, dst, borderType))
-            return;
-        if (ksize == 3 && tegra::laplace3(src, dst, borderType))
-            return;
-        if (ksize == 5 && tegra::laplace5(src, dst, borderType))
-            return;
-    }
-#endif
-
     if( ksize == 1 || ksize == 3 )
     {
         float K[2][9] =
diff --git a/modules/imgproc/src/drawing.cpp b/modules/imgproc/src/drawing.cpp
index 0d44e444240..09fb6363e28 100644
--- a/modules/imgproc/src/drawing.cpp
+++ b/modules/imgproc/src/drawing.cpp
@@ -1733,7 +1733,7 @@ PolyLine( Mat& img, const Point2l* v, int count, bool is_closed,
 /* ADDING A SET OF PREDEFINED MARKERS WHICH COULD BE USED TO HIGHLIGHT POSITIONS IN AN IMAGE */
 /* ----------------------------------------------------------------------------------------- */
 
-void drawMarker(Mat& img, Point position, const Scalar& color, int markerType, int markerSize, int thickness, int line_type)
+void drawMarker(InputOutputArray img, Point position, const Scalar& color, int markerType, int markerSize, int thickness, int line_type)
 {
     switch(markerType)
     {
@@ -1869,13 +1869,12 @@ void rectangle( InputOutputArray _img, Point pt1, Point pt2,
 }
 
 
-void rectangle( Mat& img, Rect rec,
+void rectangle( InputOutputArray img, Rect rec,
                 const Scalar& color, int thickness,
                 int lineType, int shift )
 {
     CV_INSTRUMENT_REGION()
 
-    CV_Assert( 0 <= shift && shift <= XY_SHIFT );
     if( rec.area() > 0 )
         rectangle( img, rec.tl(), rec.br() - Point(1<<shift,1<<shift),
                    color, thickness, lineType, shift );
diff --git a/modules/imgproc/src/featureselect.cpp b/modules/imgproc/src/featureselect.cpp
index 95b44b3742d..c384a811482 100644
--- a/modules/imgproc/src/featureselect.cpp
+++ b/modules/imgproc/src/featureselect.cpp
@@ -52,11 +52,7 @@
 namespace cv
 {
 
-#ifdef CV_CXX11
 struct greaterThanPtr
-#else
-struct greaterThanPtr : public std::binary_function<const float *, const float *, bool>
-#endif
 {
     bool operator () (const float * a, const float * b) const
     // Ensure a fully deterministic result of the sort
diff --git a/modules/imgproc/src/generalized_hough.cpp b/modules/imgproc/src/generalized_hough.cpp
index 027e67a77ef..c4f121df8af 100644
--- a/modules/imgproc/src/generalized_hough.cpp
+++ b/modules/imgproc/src/generalized_hough.cpp
@@ -385,11 +385,7 @@ namespace
         const double thetaScale = levels_ / 360.0;
 
         r_table_.resize(levels_ + 1);
-#ifdef CV_CXX11
         std::for_each(r_table_.begin(), r_table_.end(), [](std::vector<Point>& e)->void { e.clear(); });
-#else
-        std::for_each(r_table_.begin(), r_table_.end(), std::mem_fun_ref(&std::vector<Point>::clear));
-#endif
 
         for (int y = 0; y < templSize_.height; ++y)
         {
@@ -696,12 +692,7 @@ namespace
         getContourPoints(edges, dx, dy, points);
 
         features.resize(levels_ + 1);
-#ifdef CV_CXX11
         std::for_each(features.begin(), features.end(), [=](std::vector<Feature>& e) { e.clear(); e.reserve(maxBufferSize_); });
-#else
-        std::for_each(features.begin(), features.end(), std::mem_fun_ref(&std::vector<Feature>::clear));
-        std::for_each(features.begin(), features.end(), std::bind2nd(std::mem_fun_ref(&std::vector<Feature>::reserve), maxBufferSize_));
-#endif
 
         for (size_t i = 0; i < points.size(); ++i)
         {
diff --git a/modules/imgproc/src/hal_replacement.hpp b/modules/imgproc/src/hal_replacement.hpp
index d6b1d782736..40f9d302df0 100644
--- a/modules/imgproc/src/hal_replacement.hpp
+++ b/modules/imgproc/src/hal_replacement.hpp
@@ -271,7 +271,7 @@ inline int hal_ni_resize(int src_type, const uchar *src_data, size_t src_step, i
  */
 inline int hal_ni_warpAffine(int src_type, const uchar *src_data, size_t src_step, int src_width, int src_height, uchar *dst_data, size_t dst_step, int dst_width, int dst_height, const double M[6], int interpolation, int borderType, const double borderValue[4]) { return CV_HAL_ERROR_NOT_IMPLEMENTED; }
 /**
-   @brief hal_warpPerspectve
+   @brief hal_warpPerspective
    @param src_type source and destination image type
    @param src_data source image data
    @param src_step source image step
@@ -287,12 +287,12 @@ inline int hal_ni_warpAffine(int src_type, const uchar *src_data, size_t src_ste
    @param borderValue values to use for CV_HAL_BORDER_CONSTANT mode
    @sa cv::warpPerspective, cv::hal::warpPerspective
  */
-inline int hal_ni_warpPerspectve(int src_type, const uchar *src_data, size_t src_step, int src_width, int src_height, uchar *dst_data, size_t dst_step, int dst_width, int dst_height, const double M[9], int interpolation, int borderType, const double borderValue[4]) { return CV_HAL_ERROR_NOT_IMPLEMENTED; }
+inline int hal_ni_warpPerspective(int src_type, const uchar *src_data, size_t src_step, int src_width, int src_height, uchar *dst_data, size_t dst_step, int dst_width, int dst_height, const double M[9], int interpolation, int borderType, const double borderValue[4]) { return CV_HAL_ERROR_NOT_IMPLEMENTED; }
 
 //! @cond IGNORED
 #define cv_hal_resize hal_ni_resize
 #define cv_hal_warpAffine hal_ni_warpAffine
-#define cv_hal_warpPerspective hal_ni_warpPerspectve
+#define cv_hal_warpPerspective hal_ni_warpPerspective
 //! @endcond
 
 /**
diff --git a/modules/imgproc/src/imgwarp.cpp b/modules/imgproc/src/imgwarp.cpp
index ad090fd247b..f4f276a5b13 100644
--- a/modules/imgproc/src/imgwarp.cpp
+++ b/modules/imgproc/src/imgwarp.cpp
@@ -2878,7 +2878,7 @@ class IPPWarpPerspectiveInvoker :
 
 namespace hal {
 
-void warpPerspectve(int src_type,
+void warpPerspective(int src_type,
                     const uchar * src_data, size_t src_step, int src_width, int src_height,
                     uchar * dst_data, size_t dst_step, int dst_width, int dst_height,
                     const double M[9], int interpolation, int borderType, const double borderValue[4])
@@ -2989,7 +2989,7 @@ void cv::warpPerspective( InputArray _src, OutputArray _dst, InputArray _M0,
     if( !(flags & WARP_INVERSE_MAP) )
         invert(matM, matM);
 
-    hal::warpPerspectve(src.type(), src.data, src.step, src.cols, src.rows, dst.data, dst.step, dst.cols, dst.rows,
+    hal::warpPerspective(src.type(), src.data, src.step, src.cols, src.rows, dst.data, dst.step, dst.cols, dst.rows,
                         matM.ptr<double>(), interpolation, borderType, borderValue.val);
 }
 
@@ -3039,7 +3039,7 @@ cv::Mat cv::getRotationMatrix2D( Point2f center, double angle, double scale )
  * where:
  *   cij - matrix coefficients, c22 = 1
  */
-cv::Mat cv::getPerspectiveTransform( const Point2f src[], const Point2f dst[] )
+cv::Mat cv::getPerspectiveTransform(const Point2f src[], const Point2f dst[], int solveMethod)
 {
     CV_INSTRUMENT_REGION()
 
@@ -3062,9 +3062,7 @@ cv::Mat cv::getPerspectiveTransform( const Point2f src[], const Point2f dst[] )
         b[i+4] = dst[i].y;
     }
 
-    static int param_IMGPROC_GETPERSPECTIVETRANSFORM_SOLVE_METHOD =
-        (int)utils::getConfigurationParameterSizeT("OPENCV_IMGPROC_GETPERSPECTIVETRANSFORM_SOLVE_METHOD", (size_t)DECOMP_LU);
-    solve(A, B, X, param_IMGPROC_GETPERSPECTIVETRANSFORM_SOLVE_METHOD);
+    solve(A, B, X, solveMethod);
     M.ptr<double>()[8] = 1.;
 
     return M;
@@ -3153,11 +3151,11 @@ void cv::invertAffineTransform(InputArray _matM, OutputArray __iM)
         CV_Error( CV_StsUnsupportedFormat, "" );
 }
 
-cv::Mat cv::getPerspectiveTransform(InputArray _src, InputArray _dst)
+cv::Mat cv::getPerspectiveTransform(InputArray _src, InputArray _dst, int solveMethod)
 {
     Mat src = _src.getMat(), dst = _dst.getMat();
     CV_Assert(src.checkVector(2, CV_32F) == 4 && dst.checkVector(2, CV_32F) == 4);
-    return getPerspectiveTransform((const Point2f*)src.data, (const Point2f*)dst.data);
+    return getPerspectiveTransform((const Point2f*)src.data, (const Point2f*)dst.data, solveMethod);
 }
 
 cv::Mat cv::getAffineTransform(InputArray _src, InputArray _dst)
diff --git a/modules/imgproc/src/linefit.cpp b/modules/imgproc/src/linefit.cpp
index 103fa55950d..c6e4e4a014a 100644
--- a/modules/imgproc/src/linefit.cpp
+++ b/modules/imgproc/src/linefit.cpp
@@ -321,7 +321,7 @@ static void fitLine2D( const Point2f * points, int count, int dist,
     void (*calc_weights) (float *, int, float *) = 0;
     void (*calc_weights_param) (float *, int, float *, float) = 0;
     int i, j, k;
-    float _line[6], _lineprev[6];
+    float _line[4], _lineprev[4];
     float rdelta = reps != 0 ? reps : 1.0f;
     float adelta = aeps != 0 ? aeps : 0.01f;
     double min_err = DBL_MAX, err = 0;
diff --git a/modules/imgproc/src/precomp.hpp b/modules/imgproc/src/precomp.hpp
index 400b7cc2db8..405a799b1ef 100644
--- a/modules/imgproc/src/precomp.hpp
+++ b/modules/imgproc/src/precomp.hpp
@@ -61,11 +61,7 @@
 #include <limits.h>
 #include <float.h>
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-#include "opencv2/imgproc/imgproc_tegra.hpp"
-#else
 #define GET_OPTIMIZED(func) (func)
-#endif
 
 /* helper tables */
 extern const uchar icvSaturate8u_cv[];
diff --git a/modules/imgproc/src/pyramids.cpp b/modules/imgproc/src/pyramids.cpp
index def3dc1d681..1e058feb1f4 100644
--- a/modules/imgproc/src/pyramids.cpp
+++ b/modules/imgproc/src/pyramids.cpp
@@ -1355,11 +1355,6 @@ void cv::pyrDown( InputArray _src, OutputArray _dst, const Size& _dsz, int borde
 
     CALL_HAL(pyrDown, cv_hal_pyrdown, src.data, src.step, src.cols, src.rows, dst.data, dst.step, dst.cols, dst.rows, depth, src.channels(), borderType);
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    if(borderType == BORDER_DEFAULT && tegra::useTegra() && tegra::pyrDown(src, dst))
-        return;
-#endif
-
 #ifdef HAVE_IPP
     bool isolated = (borderType & BORDER_ISOLATED) != 0;
     int borderTypeNI = borderType & ~BORDER_ISOLATED;
@@ -1463,11 +1458,6 @@ void cv::pyrUp( InputArray _src, OutputArray _dst, const Size& _dsz, int borderT
     Mat dst = _dst.getMat();
     int depth = src.depth();
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    if(borderType == BORDER_DEFAULT && tegra::useTegra() && tegra::pyrUp(src, dst))
-        return;
-#endif
-
 #ifdef HAVE_IPP
     bool isolated = (borderType & BORDER_ISOLATED) != 0;
     int borderTypeNI = borderType & ~BORDER_ISOLATED;
diff --git a/modules/imgproc/src/smooth.cpp b/modules/imgproc/src/smooth.cpp
index d54065f8015..f4077521e15 100644
--- a/modules/imgproc/src/smooth.cpp
+++ b/modules/imgproc/src/smooth.cpp
@@ -5201,11 +5201,6 @@ void cv::medianBlur( InputArray _src0, OutputArray _dst, int ksize )
 
     CV_IPP_RUN_FAST(ipp_medianFilter(src0, dst, ksize));
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    if (tegra::useTegra() && tegra::medianBlur(src0, dst, ksize))
-        return;
-#endif
-
     bool useSortNet = ksize == 3 || (ksize == 5
 #if !(CV_SIMD128)
             && ( src0.depth() > CV_8U || src0.channels() == 2 || src0.channels() > 4 )
diff --git a/modules/imgproc/src/templmatch.cpp b/modules/imgproc/src/templmatch.cpp
index 302e26ef677..b21a485b33e 100644
--- a/modules/imgproc/src/templmatch.cpp
+++ b/modules/imgproc/src/templmatch.cpp
@@ -1118,11 +1118,6 @@ void cv::matchTemplate( InputArray _img, InputArray _templ, OutputArray _result,
     _result.create(corrSize, CV_32F);
     Mat result = _result.getMat();
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    if (tegra::useTegra() && tegra::matchTemplate(img, templ, result, method))
-        return;
-#endif
-
     CV_IPP_RUN_FAST(ipp_matchTemplate(img, templ, result, method))
 
     crossCorr( img, templ, result, result.size(), result.type(), Point(0,0), 0, 0);
diff --git a/modules/imgproc/src/thresh.cpp b/modules/imgproc/src/thresh.cpp
index 520a9c8fe99..375f1f7b3b8 100644
--- a/modules/imgproc/src/thresh.cpp
+++ b/modules/imgproc/src/thresh.cpp
@@ -136,11 +136,6 @@ thresh_8u( const Mat& _src, Mat& _dst, uchar thresh, uchar maxval, int type )
         src_step = dst_step = roi.width;
     }
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    if (tegra::useTegra() && tegra::thresh_8u(_src, _dst, roi.width, roi.height, thresh, maxval, type))
-        return;
-#endif
-
 #if defined(HAVE_IPP)
     CV_IPP_CHECK()
     {
@@ -356,8 +351,6 @@ thresh_16u(const Mat& _src, Mat& _dst, ushort thresh, ushort maxval, int type)
         src_step = dst_step = roi.width;
     }
 
-    // HAVE_TEGRA_OPTIMIZATION not supported
-
     // HAVE_IPP not supported
 
     const ushort* src = _src.ptr<ushort>();
@@ -500,11 +493,6 @@ thresh_16s( const Mat& _src, Mat& _dst, short thresh, short maxval, int type )
         src_step = dst_step = roi.width;
     }
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    if (tegra::useTegra() && tegra::thresh_16s(_src, _dst, roi.width, roi.height, thresh, maxval, type))
-        return;
-#endif
-
 #if defined(HAVE_IPP)
     CV_IPP_CHECK()
     {
@@ -697,11 +685,6 @@ thresh_32f( const Mat& _src, Mat& _dst, float thresh, float maxval, int type )
         roi.height = 1;
     }
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    if (tegra::useTegra() && tegra::thresh_32f(_src, _dst, roi.width, roi.height, thresh, maxval, type))
-        return;
-#endif
-
 #if defined(HAVE_IPP)
     CV_IPP_CHECK()
     {
diff --git a/modules/imgproc/test/test_goodfeaturetotrack.cpp b/modules/imgproc/test/test_goodfeaturetotrack.cpp
index 362cc014cff..1a339bea55e 100644
--- a/modules/imgproc/test/test_goodfeaturetotrack.cpp
+++ b/modules/imgproc/test/test_goodfeaturetotrack.cpp
@@ -56,11 +56,7 @@ enum { MINEIGENVAL=0, HARRIS=1, EIGENVALSVECS=2 };
 
 /////////////////////ref//////////////////////
 
-#ifdef CV_CXX11
 struct greaterThanPtr
-#else
-struct greaterThanPtr : public std::binary_function<const float *, const float *, bool>
-#endif
 {
     bool operator () (const float * a, const float * b) const
     { return *a > *b; }
diff --git a/modules/imgproc/test/test_main.cpp b/modules/imgproc/test/test_main.cpp
index 0e51ddfd050..93e4d2860eb 100644
--- a/modules/imgproc/test/test_main.cpp
+++ b/modules/imgproc/test/test_main.cpp
@@ -3,4 +3,8 @@
 // of this distribution and at http://opencv.org/license.html.
 #include "test_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_TEST_MAIN("cv")
diff --git a/modules/java/android_sdk/build.gradle.in b/modules/java/android_sdk/build.gradle.in
index 6d317fcd396..f4c260e40d5 100644
--- a/modules/java/android_sdk/build.gradle.in
+++ b/modules/java/android_sdk/build.gradle.in
@@ -49,7 +49,7 @@
 // - avoid using of "OpenCVLoader.initAsync()" approach - it is deprecated
 //   It may load library with different version (from OpenCV Android Manager, which is installed separatelly on device)
 //
-// - use "System.loadLibrary("opencv_java3")" or "OpenCVLoader.initDebug()"
+// - use "System.loadLibrary("opencv_java4")" or "OpenCVLoader.initDebug()"
 //   TODO: Add accurate API to load OpenCV native library
 //
 //
diff --git a/modules/java/generator/android/java/org/opencv/android/AsyncServiceHelper.java b/modules/java/generator/android/java/org/opencv/android/AsyncServiceHelper.java
index 04a4ac62579..a718ca3c5d3 100644
--- a/modules/java/generator/android/java/org/opencv/android/AsyncServiceHelper.java
+++ b/modules/java/generator/android/java/org/opencv/android/AsyncServiceHelper.java
@@ -376,7 +376,7 @@ private boolean initOpenCVLibs(String Path, String Libs)
             else
             {
                 // If the dependencies list is not defined or empty.
-                String AbsLibraryPath = Path + File.separator + "libopencv_java3.so";
+                String AbsLibraryPath = Path + File.separator + "libopencv_java4.so";
                 result = loadLibrary(AbsLibraryPath);
             }
 
diff --git a/modules/java/generator/android/java/org/opencv/android/StaticHelper.java b/modules/java/generator/android/java/org/opencv/android/StaticHelper.java
index f670d933e6d..934dd7570c1 100644
--- a/modules/java/generator/android/java/org/opencv/android/StaticHelper.java
+++ b/modules/java/generator/android/java/org/opencv/android/StaticHelper.java
@@ -92,7 +92,7 @@ private static boolean initOpenCVLibs(String Libs)
         else
         {
             // If dependencies list is not defined or empty.
-            result = loadLibrary("opencv_java3");
+            result = loadLibrary("opencv_java4");
         }
 
         return result;
diff --git a/modules/java/generator/gen_java.py b/modules/java/generator/gen_java.py
index d3a4664d388..c2f6e8514c5 100755
--- a/modules/java/generator/gen_java.py
+++ b/modules/java/generator/gen_java.py
@@ -140,17 +140,18 @@ def parseName(self, name, namespaces):
 
     def fullName(self, isCPP=False):
         result = ".".join([self.fullClass(), self.name])
-        return result if not isCPP else result.replace(".", "::")
+        return result if not isCPP else get_cname(result)
 
     def fullClass(self, isCPP=False):
         result = ".".join([f for f in [self.namespace] + self.classpath.split(".") if len(f)>0])
-        return result if not isCPP else result.replace(".", "::")
+        return result if not isCPP else get_cname(result)
 
 class ConstInfo(GeneralInfo):
-    def __init__(self, decl, addedManually=False, namespaces=[]):
+    def __init__(self, decl, addedManually=False, namespaces=[], enumType=None):
         GeneralInfo.__init__(self, "const", decl, namespaces)
-        self.cname = self.name.replace(".", "::")
+        self.cname = get_cname(self.name)
         self.value = decl[1]
+        self.enumType = enumType
         self.addedManually = addedManually
         if self.namespace in namespaces_dict:
             self.name = '%s_%s' % (namespaces_dict[self.namespace], self.name)
@@ -166,6 +167,25 @@ def isIgnored(self):
                 return True
         return False
 
+def normalize_field_name(name):
+    return name.replace(".","_").replace("[","").replace("]","").replace("_getNativeObjAddr()","_nativeObj")
+
+def normalize_class_name(name):
+    return re.sub(r"^cv\.", "", name).replace(".", "_")
+
+def get_cname(name):
+    return name.replace(".", "::")
+
+def cast_from(t):
+    if t in type_dict and "cast_from" in type_dict[t]:
+        return type_dict[t]["cast_from"]
+    return t
+
+def cast_to(t):
+    if t in type_dict and "cast_to" in type_dict[t]:
+        return type_dict[t]["cast_to"]
+    return t
+
 class ClassPropInfo():
     def __init__(self, decl): # [f_ctype, f_name, '', '/RW']
         self.ctype = decl[0]
@@ -178,7 +198,7 @@ def __repr__(self):
 class ClassInfo(GeneralInfo):
     def __init__(self, decl, namespaces=[]): # [ 'class/struct cname', ': base', [modlist] ]
         GeneralInfo.__init__(self, "class", decl, namespaces)
-        self.cname = self.name.replace(".", "::")
+        self.cname = get_cname(self.name)
         self.methods = []
         self.methods_suffixes = {}
         self.consts = [] # using a list to save the occurrence order
@@ -303,7 +323,7 @@ def __repr__(self):
 class FuncInfo(GeneralInfo):
     def __init__(self, decl, namespaces=[]): # [ funcname, return_ctype, [modifiers], [args] ]
         GeneralInfo.__init__(self, "func", decl, namespaces)
-        self.cname = decl[0].replace(".", "::")
+        self.cname = get_cname(decl[0])
         self.jname = self.name
         self.isconstructor = self.name == self.classname
         if "[" in self.name:
@@ -403,8 +423,8 @@ def add_class(self, decl):
         )
         logging.info('ok: class %s, name: %s, base: %s', classinfo, name, classinfo.base)
 
-    def add_const(self, decl): # [ "const cname", val, [], [] ]
-        constinfo = ConstInfo(decl, namespaces=self.namespaces)
+    def add_const(self, decl, enumType=None): # [ "const cname", val, [], [] ]
+        constinfo = ConstInfo(decl, namespaces=self.namespaces, enumType=enumType)
         if constinfo.isIgnored():
             logging.info('ignored: %s', constinfo)
         elif not self.isWrapped(constinfo.classname):
@@ -421,6 +441,18 @@ def add_const(self, decl): # [ "const cname", val, [], [] ]
                 ci.addConst(constinfo)
                 logging.info('ok: %s', constinfo)
 
+    def add_enum(self, decl): # [ "enum cname", "", [], [] ]
+        enumType = decl[0].rsplit(" ", 1)[1]
+        if enumType.endswith("<unnamed>"):
+            enumType = None
+        else:
+            ctype = normalize_class_name(enumType)
+            type_dict[ctype] = { "cast_from" : "int", "cast_to" : get_cname(enumType), "j_type" : "int", "jn_type" : "int", "jni_type" : "jint", "suffix" : "I" }
+        const_decls = decl[3]
+
+        for decl in const_decls:
+            self.add_const(decl, enumType)
+
     def add_func(self, decl):
         fi = FuncInfo(decl, namespaces=self.namespaces)
         classname = fi.classname or self.Module
@@ -479,6 +511,9 @@ def gen(self, srcfiles, module, output_path, output_jni_path, output_java_path,
                     self.add_class(decl)
                 elif name.startswith("const"):
                     self.add_const(decl)
+                elif name.startswith("enum"):
+                    # enum
+                    self.add_enum(decl)
                 else: # function
                     self.add_func(decl)
 
@@ -518,7 +553,7 @@ def fullTypeName(self, t):
         if self.isWrapped(t):
             return self.getClass(t).fullName(isCPP=True)
         else:
-            return t
+            return cast_from(t)
 
     def gen_func(self, ci, fi, prop_name=''):
         logging.info("%s", fi)
@@ -551,7 +586,7 @@ def gen_func(self, ci, fi, prop_name=''):
             msg = "// Return type '%s' is not supported, skipping the function\n\n" % fi.ctype
             self.skipped_func_list.append(c_decl + "\n" + msg)
             j_code.write( " "*4 + msg )
-            logging.warning("SKIP:" + c_decl.strip() + "\t due to RET type" + fi.ctype)
+            logging.warning("SKIP:" + c_decl.strip() + "\t due to RET type " + fi.ctype)
             return
         for a in fi.args:
             if a.ctype not in type_dict:
@@ -563,7 +598,7 @@ def gen_func(self, ci, fi, prop_name=''):
                 msg = "// Unknown type '%s' (%s), skipping the function\n\n" % (a.ctype, a.out or "I")
                 self.skipped_func_list.append(c_decl + "\n" + msg)
                 j_code.write( " "*4 + msg )
-                logging.warning("SKIP:" + c_decl.strip() + "\t due to ARG type" + a.ctype + "/" + (a.out or "I"))
+                logging.warning("SKIP:" + c_decl.strip() + "\t due to ARG type " + a.ctype + "/" + (a.out or "I"))
                 return
 
         self.ported_func_list.append(c_decl)
@@ -642,7 +677,7 @@ def gen_func(self, ci, fi, prop_name=''):
                     if "I" in a.out or not a.out or self.isWrapped(a.ctype): # input arg, pass by primitive fields
                         for f in fields:
                             jn_args.append ( ArgInfo([ f[0], a.name + f[1], "", [], "" ]) )
-                            jni_args.append( ArgInfo([ f[0], a.name + f[1].replace(".","_").replace("[","").replace("]","").replace("_getNativeObjAddr()","_nativeObj"), "", [], "" ]) )
+                            jni_args.append( ArgInfo([ f[0], a.name + normalize_field_name(f[1]), "", [], "" ]) )
                     if "O" in a.out and not self.isWrapped(a.ctype): # out arg, pass as double[]
                         jn_args.append ( ArgInfo([ "double[]", "%s_out" % a.name, "", [], "" ]) )
                         jni_args.append ( ArgInfo([ "double[]", "%s_out" % a.name, "", [], "" ]) )
@@ -690,7 +725,7 @@ def gen_func(self, ci, fi, prop_name=''):
                 "    private static native $type $name($args);\n").substitute(\
                 type = type_dict[fi.ctype].get("jn_type", "double[]"), \
                 name = fi.jname + '_' + str(suffix_counter), \
-                args = ", ".join(["%s %s" % (type_dict[a.ctype]["jn_type"], a.name.replace(".","_").replace("[","").replace("]","").replace("_getNativeObjAddr()","_nativeObj")) for a in jn_args])
+                args = ", ".join(["%s %s" % (type_dict[a.ctype]["jn_type"], normalize_field_name(a.name)) for a in jn_args])
             ) );
 
             # java part:
@@ -848,7 +883,7 @@ def gen_func(self, ci, fi, prop_name=''):
                     if not a.out and not "jni_var" in type_dict[a.ctype]:
                         # explicit cast to C type to avoid ambiguous call error on platforms (mingw)
                         # where jni types are different from native types (e.g. jint is not the same as int)
-                        jni_name  = "(%s)%s" % (a.ctype, jni_name)
+                        jni_name  = "(%s)%s" % (cast_to(a.ctype), jni_name)
                 if not a.ctype: # hidden
                     jni_name = a.defval
                 cvargs.append( type_dict[a.ctype].get("jni_name", jni_name) % {"n" : a.name})
@@ -922,11 +957,35 @@ def gen_class(self, ci):
             %s;\n\n""" % (",\n"+" "*12).join(["%s = %s" % (c.name, c.value) for c in ci.private_consts])
             )
         if ci.consts:
-            logging.info("%s", ci.consts)
-            ci.j_code.write("""
+            enumTypes = set(map(lambda c: c.enumType, ci.consts))
+            grouped_consts = {enumType: [c for c in ci.consts if c.enumType == enumType] for enumType in enumTypes}
+            for typeName, consts in grouped_consts.items():
+                logging.info("%s", consts)
+                if typeName:
+                    typeName = typeName.rsplit(".", 1)[-1]
+###################### Utilize Java enums ######################
+#                    ci.j_code.write("""
+#    public enum {1} {{
+#        {0};
+#
+#        private final int id;
+#        {1}(int id) {{ this.id = id; }}
+#        {1}({1} _this) {{ this.id = _this.id; }}
+#        public int getValue() {{ return id; }}
+#    }}\n\n""".format((",\n"+" "*8).join(["%s(%s)" % (c.name, c.value) for c in consts]), typeName)
+#                    )
+################################################################
+                    ci.j_code.write("""
+    // C++: enum {1}
     public static final int
-            %s;\n\n""" % (",\n"+" "*12).join(["%s = %s" % (c.name, c.value) for c in ci.consts])
-            )
+            {0};\n\n""".format((",\n"+" "*12).join(["%s = %s" % (c.name, c.value) for c in consts]), typeName)
+                    )
+                else:
+                    ci.j_code.write("""
+    // C++: enum <unnamed>
+    public static final int
+            {0};\n\n""".format((",\n"+" "*12).join(["%s = %s" % (c.name, c.value) for c in consts]))
+                    )
         # methods
         for fi in ci.getAllMethods():
             self.gen_func(ci, fi)
diff --git a/modules/js/src/embindgen.py b/modules/js/src/embindgen.py
index a27fba2f217..a35671fbf5c 100644
--- a/modules/js/src/embindgen.py
+++ b/modules/js/src/embindgen.py
@@ -120,7 +120,7 @@
              'HOGDescriptor': ['load', 'HOGDescriptor', 'getDefaultPeopleDetector', 'getDaimlerPeopleDetector', 'setSVMDetector', 'detectMultiScale'],
              'CascadeClassifier': ['load', 'detectMultiScale2', 'CascadeClassifier', 'detectMultiScale3', 'empty', 'detectMultiScale']}
 
-video = {'': ['CamShift', 'calcOpticalFlowFarneback', 'calcOpticalFlowPyrLK', 'createBackgroundSubtractorMOG2', 'estimateRigidTransform',\
+video = {'': ['CamShift', 'calcOpticalFlowFarneback', 'calcOpticalFlowPyrLK', 'createBackgroundSubtractorMOG2', \
              'findTransformECC', 'meanShift'],
          'BackgroundSubtractorMOG2': ['BackgroundSubtractorMOG2', 'apply'],
          'BackgroundSubtractor': ['apply', 'getBackgroundImage']}
diff --git a/modules/ml/include/opencv2/ml.hpp b/modules/ml/include/opencv2/ml.hpp
index f2ca78fe916..1d8889cbcf6 100644
--- a/modules/ml/include/opencv2/ml.hpp
+++ b/modules/ml/include/opencv2/ml.hpp
@@ -198,7 +198,7 @@ class CV_EXPORTS_W TrainData
     CV_WRAP virtual Mat getTestSampleWeights() const = 0;
     CV_WRAP virtual Mat getVarIdx() const = 0;
     CV_WRAP virtual Mat getVarType() const = 0;
-    CV_WRAP Mat getVarSymbolFlags() const;
+    CV_WRAP virtual Mat getVarSymbolFlags() const = 0;
     CV_WRAP virtual int getResponseType() const = 0;
     CV_WRAP virtual Mat getTrainSampleIdx() const = 0;
     CV_WRAP virtual Mat getTestSampleIdx() const = 0;
@@ -234,10 +234,10 @@ class CV_EXPORTS_W TrainData
     CV_WRAP virtual void shuffleTrainTest() = 0;
 
     /** @brief Returns matrix of test samples */
-    CV_WRAP Mat getTestSamples() const;
+    CV_WRAP virtual Mat getTestSamples() const = 0;
 
     /** @brief Returns vector of symbolic names captured in loadFromCSV() */
-    CV_WRAP void getNames(std::vector<String>& names) const;
+    CV_WRAP virtual void getNames(std::vector<String>& names) const = 0;
 
     /** @brief Extract from 1D vector elements specified by passed indexes.
     @param vec input vector (supported types: CV_32S, CV_32F, CV_64F)
@@ -738,7 +738,7 @@ class CV_EXPORTS_W SVM : public StatModel
     regression (SVM::EPS_SVR or SVM::NU_SVR). If it is SVM::ONE_CLASS, no optimization is made and
     the usual %SVM with parameters specified in params is executed.
     */
-    CV_WRAP bool trainAuto(InputArray samples,
+    CV_WRAP virtual bool trainAuto(InputArray samples,
             int layout,
             InputArray responses,
             int kFold = 10,
@@ -748,7 +748,7 @@ class CV_EXPORTS_W SVM : public StatModel
             Ptr<ParamGrid> nuGrid     = SVM::getDefaultGridPtr(SVM::NU),
             Ptr<ParamGrid> coeffGrid  = SVM::getDefaultGridPtr(SVM::COEF),
             Ptr<ParamGrid> degreeGrid = SVM::getDefaultGridPtr(SVM::DEGREE),
-            bool balanced=false);
+            bool balanced=false) = 0;
 
     /** @brief Retrieves all the support vectors
 
@@ -763,7 +763,7 @@ class CV_EXPORTS_W SVM : public StatModel
     support vector, used for prediction, was derived from. They are returned in a floating-point
     matrix, where the support vectors are stored as matrix rows.
      */
-    CV_WRAP Mat getUncompressedSupportVectors() const;
+    CV_WRAP virtual Mat getUncompressedSupportVectors() const = 0;
 
     /** @brief Retrieves the decision function
 
@@ -1284,7 +1284,7 @@ class CV_EXPORTS_W RTrees : public DTrees
         @param results Array where the result of the calculation will be written.
         @param flags Flags for defining the type of RTrees.
     */
-    CV_WRAP void getVotes(InputArray samples, OutputArray results, int flags) const;
+    CV_WRAP virtual void getVotes(InputArray samples, OutputArray results, int flags) const = 0;
 
     /** Creates the empty model.
     Use StatModel::train to train the model, StatModel::train to create and train the model,
@@ -1514,33 +1514,33 @@ class CV_EXPORTS_W ANN_MLP : public StatModel
     /** ANNEAL: Update initial temperature.
     It must be \>=0. Default value is 10.*/
     /** @see setAnnealInitialT */
-    CV_WRAP double getAnnealInitialT() const;
+    CV_WRAP virtual double getAnnealInitialT() const = 0;
     /** @copybrief getAnnealInitialT @see getAnnealInitialT */
-    CV_WRAP void setAnnealInitialT(double val);
+    CV_WRAP virtual void setAnnealInitialT(double val) = 0;
 
     /** ANNEAL: Update final temperature.
     It must be \>=0 and less than initialT. Default value is 0.1.*/
     /** @see setAnnealFinalT */
-    CV_WRAP double getAnnealFinalT() const;
+    CV_WRAP virtual double getAnnealFinalT() const = 0;
     /** @copybrief getAnnealFinalT @see getAnnealFinalT */
-    CV_WRAP void setAnnealFinalT(double val);
+    CV_WRAP virtual void setAnnealFinalT(double val) = 0;
 
     /** ANNEAL: Update cooling ratio.
     It must be \>0 and less than 1. Default value is 0.95.*/
     /** @see setAnnealCoolingRatio */
-    CV_WRAP double getAnnealCoolingRatio() const;
+    CV_WRAP virtual double getAnnealCoolingRatio() const = 0;
     /** @copybrief getAnnealCoolingRatio @see getAnnealCoolingRatio */
-    CV_WRAP void setAnnealCoolingRatio(double val);
+    CV_WRAP virtual void setAnnealCoolingRatio(double val) = 0;
 
     /** ANNEAL: Update iteration per step.
     It must be \>0 . Default value is 10.*/
     /** @see setAnnealItePerStep */
-    CV_WRAP int getAnnealItePerStep() const;
+    CV_WRAP virtual int getAnnealItePerStep() const = 0;
     /** @copybrief getAnnealItePerStep @see getAnnealItePerStep */
-    CV_WRAP void setAnnealItePerStep(int val);
+    CV_WRAP virtual void setAnnealItePerStep(int val) = 0;
 
     /** @brief Set/initialize anneal RNG */
-    void setAnnealEnergyRNG(const RNG& rng);
+    virtual void setAnnealEnergyRNG(const RNG& rng) = 0;
 
     /** possible activation functions */
     enum ActivationFunctions {
@@ -1597,6 +1597,10 @@ class CV_EXPORTS_W ANN_MLP : public StatModel
 
 };
 
+#ifndef DISABLE_OPENCV_3_COMPATIBILITY
+typedef ANN_MLP ANN_MLP_ANNEAL;
+#endif
+
 /****************************************************************************************\
 *                           Logistic Regression                                          *
 \****************************************************************************************/
@@ -1881,43 +1885,6 @@ CV_EXPORTS void randMVNormal( InputArray mean, InputArray cov, int nsamples, Out
 CV_EXPORTS void createConcentricSpheresTestSet( int nsamples, int nfeatures, int nclasses,
                                                 OutputArray samples, OutputArray responses);
 
-/** @brief Artificial Neural Networks - Multi-Layer Perceptrons.
-
-@sa @ref ml_intro_ann
-*/
-class CV_EXPORTS_W ANN_MLP_ANNEAL : public ANN_MLP
-{
-public:
-    /** @see setAnnealInitialT */
-    CV_WRAP virtual double getAnnealInitialT() const = 0;
-    /** @copybrief getAnnealInitialT @see getAnnealInitialT */
-    CV_WRAP virtual void setAnnealInitialT(double val) = 0;
-
-    /** ANNEAL: Update final temperature.
-    It must be \>=0 and less than initialT. Default value is 0.1.*/
-    /** @see setAnnealFinalT */
-    CV_WRAP  virtual double getAnnealFinalT() const = 0;
-    /** @copybrief getAnnealFinalT @see getAnnealFinalT */
-    CV_WRAP  virtual void setAnnealFinalT(double val) = 0;
-
-    /** ANNEAL: Update cooling ratio.
-    It must be \>0 and less than 1. Default value is 0.95.*/
-    /** @see setAnnealCoolingRatio */
-    CV_WRAP  virtual double getAnnealCoolingRatio() const = 0;
-    /** @copybrief getAnnealCoolingRatio @see getAnnealCoolingRatio */
-    CV_WRAP  virtual void setAnnealCoolingRatio(double val) = 0;
-
-    /** ANNEAL: Update iteration per step.
-    It must be \>0 . Default value is 10.*/
-    /** @see setAnnealItePerStep */
-    CV_WRAP virtual int getAnnealItePerStep() const = 0;
-    /** @copybrief getAnnealItePerStep @see getAnnealItePerStep */
-    CV_WRAP virtual void setAnnealItePerStep(int val) = 0;
-
-    /** @brief Set/initialize anneal RNG */
-    virtual void setAnnealEnergyRNG(const RNG& rng) = 0;
-};
-
 
 /****************************************************************************************\
 *                                   Simulated annealing solver                             *
diff --git a/modules/ml/src/ann_mlp.cpp b/modules/ml/src/ann_mlp.cpp
index 1e4691e69d1..569aefa43a1 100644
--- a/modules/ml/src/ann_mlp.cpp
+++ b/modules/ml/src/ann_mlp.cpp
@@ -141,79 +141,7 @@ class SimulatedAnnealingANN_MLP
 
 };
 
-double ANN_MLP::getAnnealInitialT() const
-{
-    const ANN_MLP_ANNEAL* this_ = dynamic_cast<const ANN_MLP_ANNEAL*>(this);
-    if (!this_)
-        CV_Error(Error::StsNotImplemented, "the class is not ANN_MLP_ANNEAL");
-    return this_->getAnnealInitialT();
-}
-
-void ANN_MLP::setAnnealInitialT(double val)
-{
-    ANN_MLP_ANNEAL* this_ = dynamic_cast<ANN_MLP_ANNEAL*>(this);
-    if (!this_)
-        CV_Error(Error::StsNotImplemented, "the class is not ANN_MLP_ANNEAL");
-    this_->setAnnealInitialT(val);
-}
-
-double ANN_MLP::getAnnealFinalT() const
-{
-    const ANN_MLP_ANNEAL* this_ = dynamic_cast<const ANN_MLP_ANNEAL*>(this);
-    if (!this_)
-        CV_Error(Error::StsNotImplemented, "the class is not ANN_MLP_ANNEAL");
-    return this_->getAnnealFinalT();
-}
-
-void ANN_MLP::setAnnealFinalT(double val)
-{
-    ANN_MLP_ANNEAL* this_ = dynamic_cast<ANN_MLP_ANNEAL*>(this);
-    if (!this_)
-        CV_Error(Error::StsNotImplemented, "the class is not ANN_MLP_ANNEAL");
-    this_->setAnnealFinalT(val);
-}
-
-double ANN_MLP::getAnnealCoolingRatio() const
-{
-    const ANN_MLP_ANNEAL* this_ = dynamic_cast<const ANN_MLP_ANNEAL*>(this);
-    if (!this_)
-        CV_Error(Error::StsNotImplemented, "the class is not ANN_MLP_ANNEAL");
-    return this_->getAnnealCoolingRatio();
-}
-
-void ANN_MLP::setAnnealCoolingRatio(double val)
-{
-    ANN_MLP_ANNEAL* this_ = dynamic_cast<ANN_MLP_ANNEAL*>(this);
-    if (!this_)
-        CV_Error(Error::StsNotImplemented, "the class is not ANN_MLP_ANNEAL");
-    this_->setAnnealCoolingRatio(val);
-}
-
-int ANN_MLP::getAnnealItePerStep() const
-{
-    const ANN_MLP_ANNEAL* this_ = dynamic_cast<const ANN_MLP_ANNEAL*>(this);
-    if (!this_)
-        CV_Error(Error::StsNotImplemented, "the class is not ANN_MLP_ANNEAL");
-    return this_->getAnnealItePerStep();
-}
-
-void ANN_MLP::setAnnealItePerStep(int val)
-{
-    ANN_MLP_ANNEAL* this_ = dynamic_cast<ANN_MLP_ANNEAL*>(this);
-    if (!this_)
-        CV_Error(Error::StsNotImplemented, "the class is not ANN_MLP_ANNEAL");
-    this_->setAnnealItePerStep(val);
-}
-
-void ANN_MLP::setAnnealEnergyRNG(const RNG& rng)
-{
-    ANN_MLP_ANNEAL* this_ = dynamic_cast<ANN_MLP_ANNEAL*>(this);
-    if (!this_)
-        CV_Error(Error::StsNotImplemented, "the class is not ANN_MLP_ANNEAL");
-    this_->setAnnealEnergyRNG(rng);
-}
-
-class ANN_MLPImpl CV_FINAL : public ANN_MLP_ANNEAL
+class ANN_MLPImpl CV_FINAL : public ANN_MLP
 {
 public:
     ANN_MLPImpl()
@@ -224,7 +152,7 @@ class ANN_MLPImpl CV_FINAL : public ANN_MLP_ANNEAL
         setTrainMethod(ANN_MLP::RPROP, 0.1, FLT_EPSILON);
     }
 
-    virtual ~ANN_MLPImpl() {}
+    virtual ~ANN_MLPImpl() CV_OVERRIDE {}
 
     inline TermCriteria getTermCriteria() const CV_OVERRIDE { return params.termCrit; }
     inline void setTermCriteria(TermCriteria val) CV_OVERRIDE { params.termCrit = val; }
diff --git a/modules/ml/src/data.cpp b/modules/ml/src/data.cpp
index a5dd101f1d0..daf39b9a330 100644
--- a/modules/ml/src/data.cpp
+++ b/modules/ml/src/data.cpp
@@ -52,13 +52,6 @@ static const int VAR_MISSED = VAR_ORDERED;
 
 TrainData::~TrainData() {}
 
-Mat TrainData::getTestSamples() const
-{
-    Mat idx = getTestSampleIdx();
-    Mat samples = getSamples();
-    return idx.empty() ? Mat() : getSubMatrix(samples, idx, getLayout());
-}
-
 Mat TrainData::getSubVector(const Mat& vec, const Mat& idx)
 {
     if (!(vec.cols == 1 || vec.rows == 1))
@@ -117,6 +110,7 @@ Mat TrainData::getSubMatrix(const Mat& m, const Mat& idx, int layout)
     CV_Error(Error::StsInternal, "");
 }
 
+
 class TrainDataImpl CV_FINAL : public TrainData
 {
 public:
@@ -153,6 +147,12 @@ class TrainDataImpl CV_FINAL : public TrainData
         return layout == ROW_SAMPLE ? samples.cols : samples.rows;
     }
 
+    Mat getTestSamples() const CV_OVERRIDE
+    {
+        Mat idx = getTestSampleIdx();
+        return idx.empty() ? Mat() : getSubMatrix(samples, idx, getLayout());
+    }
+
     Mat getSamples() const CV_OVERRIDE { return samples; }
     Mat getResponses() const CV_OVERRIDE { return responses; }
     Mat getMissing() const CV_OVERRIDE { return missing; }
@@ -985,6 +985,27 @@ class TrainDataImpl CV_FINAL : public TrainData
         }
     }
 
+    void getNames(std::vector<String>& names) const CV_OVERRIDE
+    {
+        size_t n = nameMap.size();
+        TrainDataImpl::MapType::const_iterator it = nameMap.begin(),
+                                               it_end = nameMap.end();
+        names.resize(n+1);
+        names[0] = "?";
+        for( ; it != it_end; ++it )
+        {
+            String s = it->first;
+            int label = it->second;
+            CV_Assert( label > 0 && label <= (int)n );
+            names[label] = s;
+        }
+    }
+
+    Mat getVarSymbolFlags() const CV_OVERRIDE
+    {
+        return varSymbolFlags;
+    }
+
     FILE* file;
     int layout;
     Mat samples, missing, varType, varIdx, varSymbolFlags, responses, missingSubst;
@@ -994,30 +1015,6 @@ class TrainDataImpl CV_FINAL : public TrainData
     MapType nameMap;
 };
 
-void TrainData::getNames(std::vector<String>& names) const
-{
-    const TrainDataImpl* impl = dynamic_cast<const TrainDataImpl*>(this);
-    CV_Assert(impl != 0);
-    size_t n = impl->nameMap.size();
-    TrainDataImpl::MapType::const_iterator it = impl->nameMap.begin(),
-                                           it_end = impl->nameMap.end();
-    names.resize(n+1);
-    names[0] = "?";
-    for( ; it != it_end; ++it )
-    {
-        String s = it->first;
-        int label = it->second;
-        CV_Assert( label > 0 && label <= (int)n );
-        names[label] = s;
-    }
-}
-
-Mat TrainData::getVarSymbolFlags() const
-{
-    const TrainDataImpl* impl = dynamic_cast<const TrainDataImpl*>(this);
-    CV_Assert(impl != 0);
-    return impl->varSymbolFlags;
-}
 
 Ptr<TrainData> TrainData::loadFromCSV(const String& filename,
                                       int headerLines,
diff --git a/modules/ml/src/rtrees.cpp b/modules/ml/src/rtrees.cpp
index e10ef9bc42e..b7e32b92b00 100644
--- a/modules/ml/src/rtrees.cpp
+++ b/modules/ml/src/rtrees.cpp
@@ -454,6 +454,7 @@ class RTreesImpl CV_FINAL : public RTrees
     inline void setRegressionAccuracy(float val) CV_OVERRIDE { impl.params.setRegressionAccuracy(val); }
     inline cv::Mat getPriors() const CV_OVERRIDE { return impl.params.getPriors(); }
     inline void setPriors(const cv::Mat& val) CV_OVERRIDE { impl.params.setPriors(val); }
+    inline void getVotes(InputArray input, OutputArray output, int flags) const CV_OVERRIDE {return impl.getVotes(input,output,flags);}
 
     RTreesImpl() {}
     virtual ~RTreesImpl() CV_OVERRIDE {}
@@ -486,12 +487,6 @@ class RTreesImpl CV_FINAL : public RTrees
         impl.read(fn);
     }
 
-    void getVotes_( InputArray samples, OutputArray results, int flags ) const
-    {
-        CV_TRACE_FUNCTION();
-        impl.getVotes(samples, results, flags);
-    }
-
     Mat getVarImportance() const CV_OVERRIDE { return Mat_<float>(impl.varImportance, true); }
     int getVarCount() const CV_OVERRIDE { return impl.getVarCount(); }
 
@@ -520,15 +515,6 @@ Ptr<RTrees> RTrees::load(const String& filepath, const String& nodeName)
     return Algorithm::load<RTrees>(filepath, nodeName);
 }
 
-void RTrees::getVotes(InputArray input, OutputArray output, int flags) const
-{
-    CV_TRACE_FUNCTION();
-    const RTreesImpl* this_ = dynamic_cast<const RTreesImpl*>(this);
-    if(!this_)
-        CV_Error(Error::StsNotImplemented, "the class is not RTreesImpl");
-    return this_->getVotes_(input, output, flags);
-}
-
 }}
 
 // End of file.
diff --git a/modules/ml/src/svm.cpp b/modules/ml/src/svm.cpp
index 6aff6ff7d82..02043ac9298 100644
--- a/modules/ml/src/svm.cpp
+++ b/modules/ml/src/svm.cpp
@@ -1250,7 +1250,7 @@ class SVMImpl CV_FINAL : public SVM
         uncompressed_sv.release();
     }
 
-    Mat getUncompressedSupportVectors_() const
+    Mat getUncompressedSupportVectors() const CV_OVERRIDE
     {
         return uncompressed_sv;
     }
@@ -1982,10 +1982,10 @@ class SVMImpl CV_FINAL : public SVM
         bool returnDFVal;
     };
 
-    bool trainAuto_(InputArray samples, int layout,
+    bool trainAuto(InputArray samples, int layout,
             InputArray responses, int kfold, Ptr<ParamGrid> Cgrid,
             Ptr<ParamGrid> gammaGrid, Ptr<ParamGrid> pGrid, Ptr<ParamGrid> nuGrid,
-            Ptr<ParamGrid> coeffGrid, Ptr<ParamGrid> degreeGrid, bool balanced)
+            Ptr<ParamGrid> coeffGrid, Ptr<ParamGrid> degreeGrid, bool balanced) CV_OVERRIDE
     {
         Ptr<TrainData> data = TrainData::create(samples, layout, responses);
         return this->trainAuto(
@@ -2353,26 +2353,6 @@ Ptr<SVM> SVM::load(const String& filepath)
     return svm;
 }
 
-Mat SVM::getUncompressedSupportVectors() const
-{
-    const SVMImpl* this_ = dynamic_cast<const SVMImpl*>(this);
-    if(!this_)
-        CV_Error(Error::StsNotImplemented, "the class is not SVMImpl");
-    return this_->getUncompressedSupportVectors_();
-}
-
-bool SVM::trainAuto(InputArray samples, int layout,
-            InputArray responses, int kfold, Ptr<ParamGrid> Cgrid,
-            Ptr<ParamGrid> gammaGrid, Ptr<ParamGrid> pGrid, Ptr<ParamGrid> nuGrid,
-            Ptr<ParamGrid> coeffGrid, Ptr<ParamGrid> degreeGrid, bool balanced)
-{
-  SVMImpl* this_ = dynamic_cast<SVMImpl*>(this);
-  if (!this_) {
-    CV_Error(Error::StsNotImplemented, "the class is not SVMImpl");
-  }
-  return this_->trainAuto_(samples, layout, responses,
-    kfold, Cgrid, gammaGrid, pGrid, nuGrid, coeffGrid, degreeGrid, balanced);
-}
 
 }
 }
diff --git a/modules/ml/test/test_main.cpp b/modules/ml/test/test_main.cpp
index a78a031c367..aab717ee519 100644
--- a/modules/ml/test/test_main.cpp
+++ b/modules/ml/test/test_main.cpp
@@ -3,4 +3,8 @@
 // of this distribution and at http://opencv.org/license.html.
 #include "test_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_TEST_MAIN("ml")
diff --git a/modules/ml/test/test_mltests2.cpp b/modules/ml/test/test_mltests2.cpp
index 616a527bfe2..1b1c21cfeb3 100644
--- a/modules/ml/test/test_mltests2.cpp
+++ b/modules/ml/test/test_mltests2.cpp
@@ -279,7 +279,7 @@ TEST_P(ML_ANN_METHOD, Test)
 
 #ifdef GENERATE_TESTDATA
     {
-    Ptr<ml::ANN_MLP> xx = ml::ANN_MLP_ANNEAL::create();
+    Ptr<ml::ANN_MLP> xx = ml::ANN_MLP::create();
     Mat_<int> layerSizesXX(1, 4);
     layerSizesXX(0, 0) = tdata->getNVars();
     layerSizesXX(0, 1) = 30;
@@ -299,7 +299,7 @@ TEST_P(ML_ANN_METHOD, Test)
     {
         FileStorage fs;
         fs.open(dataname + "_init_weight.yml.gz", FileStorage::READ);
-        Ptr<ml::ANN_MLP> x = ml::ANN_MLP_ANNEAL::create();
+        Ptr<ml::ANN_MLP> x = ml::ANN_MLP::create();
         x->read(fs.root());
         x->setTrainMethod(methodType);
         if (methodType == ml::ANN_MLP::ANNEAL)
diff --git a/modules/objdetect/include/opencv2/objdetect.hpp b/modules/objdetect/include/opencv2/objdetect.hpp
index fa9b8bb4665..21eef2341fa 100644
--- a/modules/objdetect/include/opencv2/objdetect.hpp
+++ b/modules/objdetect/include/opencv2/objdetect.hpp
@@ -91,7 +91,7 @@ compensate for the differences in the size of areas. The sums of pixel values ov
 regions are calculated rapidly using integral images (see below and the integral description).
 
 To see the object detector at work, have a look at the facedetect demo:
-<https://github.com/opencv/opencv/tree/3.4/samples/cpp/dbt_face_detection.cpp>
+<https://github.com/opencv/opencv/tree/master/samples/cpp/dbt_face_detection.cpp>
 
 The following reference is for the detection part only. There is a separate application called
 opencv_traincascade that can train a cascade of boosted classifiers from a set of samples.
@@ -699,8 +699,4 @@ CV_EXPORTS bool detectQRCode(InputArray in, std::vector<Point> &points, double e
 
 #include "opencv2/objdetect/detection_based_tracker.hpp"
 
-#ifndef DISABLE_OPENCV_24_COMPATIBILITY
-#include "opencv2/objdetect/objdetect_c.h"
-#endif
-
 #endif
diff --git a/modules/objdetect/include/opencv2/objdetect/detection_based_tracker.hpp b/modules/objdetect/include/opencv2/objdetect/detection_based_tracker.hpp
index 07dd5874910..18cde13eabe 100644
--- a/modules/objdetect/include/opencv2/objdetect/detection_based_tracker.hpp
+++ b/modules/objdetect/include/opencv2/objdetect/detection_based_tracker.hpp
@@ -46,10 +46,6 @@
 
 #include <opencv2/core.hpp>
 
-// After this condition removal update blacklist for bindings: modules/python/common.cmake
-#if defined(__linux__) || defined(LINUX) || defined(__APPLE__) || defined(__ANDROID__) || \
-  defined(CV_CXX11)
-
 #include <vector>
 
 namespace cv
@@ -222,6 +218,5 @@ class CV_EXPORTS DetectionBasedTracker
 //! @} objdetect
 
 } //end of cv namespace
-#endif
 
 #endif
diff --git a/modules/objdetect/perf/opencl/perf_hogdetect.cpp b/modules/objdetect/perf/opencl/perf_hogdetect.cpp
index 43c63d8cca7..e7ca8c232a3 100644
--- a/modules/objdetect/perf/opencl/perf_hogdetect.cpp
+++ b/modules/objdetect/perf/opencl/perf_hogdetect.cpp
@@ -53,11 +53,7 @@ namespace opencv_test {
 namespace ocl {
 ///////////// HOG////////////////////////
 
-#ifdef CV_CXX11
 struct RectLess
-#else
-struct RectLess : public std::binary_function<cv::Rect, cv::Rect, bool>
-#endif
 {
     bool operator()(const cv::Rect& a,
         const cv::Rect& b) const
diff --git a/modules/objdetect/perf/perf_main.cpp b/modules/objdetect/perf/perf_main.cpp
index 69b8ecac5b8..154b6cc2afa 100644
--- a/modules/objdetect/perf/perf_main.cpp
+++ b/modules/objdetect/perf/perf_main.cpp
@@ -1,3 +1,7 @@
 #include "perf_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_PERF_TEST_MAIN(objdetect)
diff --git a/modules/objdetect/src/cascadedetect.cpp b/modules/objdetect/src/cascadedetect.cpp
index 6d76ba5e4e6..8f00c7bd996 100644
--- a/modules/objdetect/src/cascadedetect.cpp
+++ b/modules/objdetect/src/cascadedetect.cpp
@@ -969,10 +969,6 @@ Ptr<CascadeClassifierImpl::MaskGenerator> CascadeClassifierImpl::getMaskGenerato
 
 Ptr<BaseCascadeClassifier::MaskGenerator> createFaceDetectionMaskGenerator()
 {
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    if (tegra::useTegra())
-        return tegra::getCascadeClassifierMaskGenerator();
-#endif
     return Ptr<BaseCascadeClassifier::MaskGenerator>();
 }
 
diff --git a/modules/objdetect/src/detection_based_tracker.cpp b/modules/objdetect/src/detection_based_tracker.cpp
index 0cdcafaceee..431c289a006 100644
--- a/modules/objdetect/src/detection_based_tracker.cpp
+++ b/modules/objdetect/src/detection_based_tracker.cpp
@@ -42,23 +42,12 @@
 //M*/
 
 #include "precomp.hpp"
-#include <cassert>
-
-#ifdef CV_CXX11
-#define USE_STD_THREADS
-#endif
-
-#if defined(__linux__) || defined(LINUX) || defined(__APPLE__) || defined(__ANDROID__) || defined(USE_STD_THREADS)
 
 #include "opencv2/core/utility.hpp"
 
-#ifdef USE_STD_THREADS
 #include <thread>
 #include <mutex>
 #include <condition_variable>
-#else //USE_STD_THREADS
-#include <pthread.h>
-#endif //USE_STD_THREADS
 
 #if defined(DEBUG) || defined(_DEBUG)
 #undef DEBUGLOGS
@@ -139,49 +128,26 @@ class cv::DetectionBasedTracker::SeparateDetectionWork
         }
         void setParameters(const cv::DetectionBasedTracker::Parameters& params)
         {
-#ifdef USE_STD_THREADS
             std::unique_lock<std::mutex> mtx_lock(mtx);
-#else
-            pthread_mutex_lock(&mutex);
-#endif
             parameters = params;
-#ifndef USE_STD_THREADS
-            pthread_mutex_unlock(&mutex);
-#endif
         }
 
         inline void init()
         {
-#ifdef USE_STD_THREADS
             std::unique_lock<std::mutex> mtx_lock(mtx);
-#else
-            pthread_mutex_lock(&mutex);
-#endif
             stateThread = STATE_THREAD_STOPPED;
             isObjectDetectingReady = false;
             shouldObjectDetectingResultsBeForgot = false;
-#ifdef USE_STD_THREADS
             objectDetectorThreadStartStop.notify_one();
-#else
-            pthread_cond_signal(&(objectDetectorThreadStartStop));
-            pthread_mutex_unlock(&mutex);
-#endif
         }
     protected:
 
         DetectionBasedTracker& detectionBasedTracker;
         cv::Ptr<DetectionBasedTracker::IDetector> cascadeInThread;
-#ifdef USE_STD_THREADS
         std::thread second_workthread;
         std::mutex mtx;
         std::condition_variable objectDetectorRun;
         std::condition_variable objectDetectorThreadStartStop;
-#else
-        pthread_t second_workthread;
-        pthread_mutex_t mutex;
-        pthread_cond_t objectDetectorRun;
-        pthread_cond_t objectDetectorThreadStartStop;
-#endif
         std::vector<cv::Rect> resultDetect;
         volatile bool isObjectDetectingReady;
         volatile bool shouldObjectDetectingResultsBeForgot;
@@ -217,28 +183,6 @@ cv::DetectionBasedTracker::SeparateDetectionWork::SeparateDetectionWork(Detectio
     CV_Assert(_detector);
 
     cascadeInThread = _detector;
-#ifndef USE_STD_THREADS
-    second_workthread = 0;
-    int res=0;
-    res=pthread_mutex_init(&mutex, NULL);//TODO: should be attributes?
-    if (res) {
-        LOGE("ERROR in DetectionBasedTracker::SeparateDetectionWork::SeparateDetectionWork in pthread_mutex_init(&mutex, NULL) is %d", res);
-        throw(std::exception());
-    }
-    res=pthread_cond_init (&objectDetectorRun, NULL);
-    if (res) {
-        LOGE("ERROR in DetectionBasedTracker::SeparateDetectionWork::SeparateDetectionWork in pthread_cond_init(&objectDetectorRun,, NULL) is %d", res);
-        pthread_mutex_destroy(&mutex);
-        throw(std::exception());
-    }
-    res=pthread_cond_init (&objectDetectorThreadStartStop, NULL);
-    if (res) {
-        LOGE("ERROR in DetectionBasedTracker::SeparateDetectionWork::SeparateDetectionWork in pthread_cond_init(&objectDetectorThreadStartStop,, NULL) is %d", res);
-        pthread_cond_destroy(&objectDetectorRun);
-        pthread_mutex_destroy(&mutex);
-        throw(std::exception());
-    }
-#endif
 }
 
 cv::DetectionBasedTracker::SeparateDetectionWork::~SeparateDetectionWork()
@@ -246,39 +190,20 @@ cv::DetectionBasedTracker::SeparateDetectionWork::~SeparateDetectionWork()
     if(stateThread!=STATE_THREAD_STOPPED) {
         LOGE("\n\n\nATTENTION!!! dangerous algorithm error: destructor DetectionBasedTracker::DetectionBasedTracker::~SeparateDetectionWork is called before stopping the workthread");
     }
-#ifndef USE_STD_THREADS
-    pthread_cond_destroy(&objectDetectorThreadStartStop);
-    pthread_cond_destroy(&objectDetectorRun);
-    pthread_mutex_destroy(&mutex);
-#else
     second_workthread.join();
-#endif
 }
 bool cv::DetectionBasedTracker::SeparateDetectionWork::run()
 {
     LOGD("DetectionBasedTracker::SeparateDetectionWork::run() --- start");
-#ifdef USE_STD_THREADS
     std::unique_lock<std::mutex> mtx_lock(mtx);
     // unlocked when leaving scope
-#else
-    pthread_mutex_lock(&mutex);
-#endif
     if (stateThread != STATE_THREAD_STOPPED) {
         LOGE("DetectionBasedTracker::SeparateDetectionWork::run is called while the previous run is not stopped");
-#ifndef USE_STD_THREADS
-        pthread_mutex_unlock(&mutex);
-#endif
         return false;
     }
     stateThread=STATE_THREAD_WORKING_SLEEPING;
-#ifdef USE_STD_THREADS
     second_workthread = std::thread(workcycleObjectDetectorFunction, (void*)this); //TODO: add attributes?
     objectDetectorThreadStartStop.wait(mtx_lock);
-#else
-    pthread_create(&second_workthread, NULL, workcycleObjectDetectorFunction, (void*)this); //TODO: add attributes?
-    pthread_cond_wait(&objectDetectorThreadStartStop, &mutex);
-    pthread_mutex_unlock(&mutex);
-#endif
     LOGD("DetectionBasedTracker::SeparateDetectionWork::run --- end");
     return true;
 }
@@ -313,34 +238,18 @@ void cv::DetectionBasedTracker::SeparateDetectionWork::workcycleObjectDetector()
     std::vector<Rect> objects;
 
     CV_Assert(stateThread==STATE_THREAD_WORKING_SLEEPING);
-#ifdef USE_STD_THREADS
     std::unique_lock<std::mutex> mtx_lock(mtx);
-#else
-    pthread_mutex_lock(&mutex);
-#endif
     {
-#ifdef USE_STD_THREADS
         objectDetectorThreadStartStop.notify_one();
-#else
-        pthread_cond_signal(&objectDetectorThreadStartStop);
-#endif
         LOGD("DetectionBasedTracker::SeparateDetectionWork::workcycleObjectDetector() --- before waiting");
         CV_Assert(stateThread==STATE_THREAD_WORKING_SLEEPING);
-#ifdef USE_STD_THREADS
         objectDetectorRun.wait(mtx_lock);
-#else
-        pthread_cond_wait(&objectDetectorRun, &mutex);
-#endif
         if (isWorking()) {
             stateThread=STATE_THREAD_WORKING_WITH_IMAGE;
         }
         LOGD("DetectionBasedTracker::SeparateDetectionWork::workcycleObjectDetector() --- after waiting");
     }
-#ifdef USE_STD_THREADS
     mtx_lock.unlock();
-#else
-    pthread_mutex_unlock(&mutex);
-#endif
 
     bool isFirstStep=true;
 
@@ -353,34 +262,18 @@ void cv::DetectionBasedTracker::SeparateDetectionWork::workcycleObjectDetector()
         if (! isFirstStep) {
             LOGD("DetectionBasedTracker::SeparateDetectionWork::workcycleObjectDetector() --- before waiting");
             CV_Assert(stateThread==STATE_THREAD_WORKING_SLEEPING);
-#ifdef USE_STD_THREADS
             mtx_lock.lock();
-#else
-            pthread_mutex_lock(&mutex);
-#endif
             if (!isWorking()) {//it is a rare case, but may cause a crash
                 LOGD("DetectionBasedTracker::SeparateDetectionWork::workcycleObjectDetector() --- go out from the workcycle from inner part of lock just before waiting");
-#ifdef USE_STD_THREADS
                 mtx_lock.unlock();
-#else
-                pthread_mutex_unlock(&mutex);
-#endif
                 break;
             }
             CV_Assert(stateThread==STATE_THREAD_WORKING_SLEEPING);
-#ifdef USE_STD_THREADS
             objectDetectorRun.wait(mtx_lock);
-#else
-            pthread_cond_wait(&objectDetectorRun, &mutex);
-#endif
             if (isWorking()) {
                 stateThread=STATE_THREAD_WORKING_WITH_IMAGE;
             }
-#ifdef USE_STD_THREADS
             mtx_lock.unlock();
-#else
-            pthread_mutex_unlock(&mutex);
-#endif
 
             LOGD("DetectionBasedTracker::SeparateDetectionWork::workcycleObjectDetector() --- after waiting");
         } else {
@@ -427,11 +320,7 @@ void cv::DetectionBasedTracker::SeparateDetectionWork::workcycleObjectDetector()
         (void)(dt_detect_ms);
 
         LOGI("DetectionBasedTracker::SeparateDetectionWork::workcycleObjectDetector() --- objects num==%d, t_ms=%.4f", (int)objects.size(), dt_detect_ms);
-#ifdef USE_STD_THREADS
         mtx_lock.lock();
-#else
-        pthread_mutex_lock(&mutex);
-#endif
         if (!shouldObjectDetectingResultsBeForgot) {
             resultDetect=objects;
             isObjectDetectingReady=true;
@@ -443,11 +332,7 @@ void cv::DetectionBasedTracker::SeparateDetectionWork::workcycleObjectDetector()
         if(isWorking()) {
             stateThread=STATE_THREAD_WORKING_SLEEPING;
         }
-#ifdef USE_STD_THREADS
         mtx_lock.unlock();
-#else
-        pthread_mutex_unlock(&mutex);
-#endif
 
         objects.clear();
     }// while(isWorking())
@@ -458,44 +343,25 @@ void cv::DetectionBasedTracker::SeparateDetectionWork::workcycleObjectDetector()
 void cv::DetectionBasedTracker::SeparateDetectionWork::stop()
 {
     //FIXME: TODO: should add quickStop functionality
-#ifdef USE_STD_THREADS
   std::unique_lock<std::mutex> mtx_lock(mtx);
-#else
-    pthread_mutex_lock(&mutex);
-#endif
     if (!isWorking()) {
-#ifdef USE_STD_THREADS
         mtx_lock.unlock();
-#else
-        pthread_mutex_unlock(&mutex);
-#endif
         LOGE("SimpleHighguiDemoCore::stop is called but the SimpleHighguiDemoCore pthread is not active");
         stateThread = STATE_THREAD_STOPPING;
         return;
     }
     stateThread=STATE_THREAD_STOPPING;
     LOGD("DetectionBasedTracker::SeparateDetectionWork::stop: before going to sleep to wait for the signal from the workthread");
-#ifdef USE_STD_THREADS
     objectDetectorRun.notify_one();
     objectDetectorThreadStartStop.wait(mtx_lock);
     LOGD("DetectionBasedTracker::SeparateDetectionWork::stop: after receiving the signal from the workthread, stateThread=%d", (int)stateThread);
     mtx_lock.unlock();
-#else
-    pthread_cond_signal(&objectDetectorRun);
-    pthread_cond_wait(&objectDetectorThreadStartStop, &mutex);
-    LOGD("DetectionBasedTracker::SeparateDetectionWork::stop: after receiving the signal from the workthread, stateThread=%d", (int)stateThread);
-    pthread_mutex_unlock(&mutex);
-#endif
 }
 
 void cv::DetectionBasedTracker::SeparateDetectionWork::resetTracking()
 {
     LOGD("DetectionBasedTracker::SeparateDetectionWork::resetTracking");
-#ifdef USE_STD_THREADS
     std::unique_lock<std::mutex> mtx_lock(mtx);
-#else
-    pthread_mutex_lock(&mutex);
-#endif
 
     if (stateThread == STATE_THREAD_WORKING_WITH_IMAGE) {
         LOGD("DetectionBasedTracker::SeparateDetectionWork::resetTracking: since workthread is detecting objects at the moment, we should make cascadeInThread stop detecting and forget the detecting results");
@@ -508,12 +374,7 @@ void cv::DetectionBasedTracker::SeparateDetectionWork::resetTracking()
     resultDetect.clear();
     isObjectDetectingReady=false;
 
-#ifdef USE_STD_THREADS
     mtx_lock.unlock();
-#else
-    pthread_mutex_unlock(&mutex);
-#endif
-
 }
 
 bool cv::DetectionBasedTracker::SeparateDetectionWork::communicateWithDetectingThread(const Mat& imageGray, std::vector<Rect>& rectsWhereRegions)
@@ -529,11 +390,7 @@ bool cv::DetectionBasedTracker::SeparateDetectionWork::communicateWithDetectingT
 
     bool shouldHandleResult = false;
 
-#ifdef USE_STD_THREADS
     std::unique_lock<std::mutex> mtx_lock(mtx);
-#else
-    pthread_mutex_lock(&mutex);
-#endif
 
     if (isObjectDetectingReady) {
         shouldHandleResult=true;
@@ -562,18 +419,10 @@ bool cv::DetectionBasedTracker::SeparateDetectionWork::communicateWithDetectingT
 
         timeWhenDetectingThreadStartedWork = getTickCount() ;
 
-#ifdef USE_STD_THREADS
         objectDetectorRun.notify_one();
-#else
-        pthread_cond_signal(&objectDetectorRun);
-#endif
     }
 
-#ifdef USE_STD_THREADS
     mtx_lock.unlock();
-#else
-    pthread_mutex_unlock(&mutex);
-#endif
     LOGD("DetectionBasedTracker::SeparateDetectionWork::communicateWithDetectingThread: result: shouldHandleResult=%d", (shouldHandleResult?1:0));
 
     return shouldHandleResult;
@@ -1034,5 +883,3 @@ const cv::DetectionBasedTracker::Parameters& DetectionBasedTracker::getParameter
 {
     return parameters;
 }
-
-#endif //defined(__linux__) || defined(LINUX) || defined(__APPLE__) || defined(__ANDROID__) || defined(USE_STD_THREADS)
diff --git a/modules/objdetect/src/precomp.hpp b/modules/objdetect/src/precomp.hpp
index 448d8b19b70..cbefc396be9 100644
--- a/modules/objdetect/src/precomp.hpp
+++ b/modules/objdetect/src/precomp.hpp
@@ -50,8 +50,4 @@
 #include "opencv2/core/ocl.hpp"
 #include "opencv2/core/private.hpp"
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-#include "opencv2/objdetect/objdetect_tegra.hpp"
-#endif
-
 #endif
diff --git a/modules/objdetect/test/test_main.cpp b/modules/objdetect/test/test_main.cpp
index 0e51ddfd050..93e4d2860eb 100644
--- a/modules/objdetect/test/test_main.cpp
+++ b/modules/objdetect/test/test_main.cpp
@@ -3,4 +3,8 @@
 // of this distribution and at http://opencv.org/license.html.
 #include "test_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_TEST_MAIN("cv")
diff --git a/modules/photo/include/opencv2/photo.hpp b/modules/photo/include/opencv2/photo.hpp
index 4fdeef90fa0..083811971ed 100644
--- a/modules/photo/include/opencv2/photo.hpp
+++ b/modules/photo/include/opencv2/photo.hpp
@@ -869,8 +869,4 @@ CV_EXPORTS_W void stylization(InputArray src, OutputArray dst, float sigma_s = 6
 
 } // cv
 
-#ifndef DISABLE_OPENCV_24_COMPATIBILITY
-#include "opencv2/photo/photo_c.h"
-#endif
-
 #endif
diff --git a/modules/photo/misc/java/test/PhotoTest.java b/modules/photo/misc/java/test/PhotoTest.java
index 27bac6380ed..45d92203d55 100644
--- a/modules/photo/misc/java/test/PhotoTest.java
+++ b/modules/photo/misc/java/test/PhotoTest.java
@@ -11,8 +11,8 @@
 
     public void testInpaint() {
         Point p = new Point(matSize / 2, matSize / 2);
-        Imgproc.circle(gray255, p, 2, colorBlack, Core.FILLED);
-        Imgproc.circle(gray0,   p, 2, colorWhite, Core.FILLED);
+        Imgproc.circle(gray255, p, 2, colorBlack, Imgproc.FILLED);
+        Imgproc.circle(gray0,   p, 2, colorWhite, Imgproc.FILLED);
 
         Photo.inpaint(gray255, gray0, dst, 3, Photo.INPAINT_TELEA);
 
diff --git a/modules/photo/perf/perf_main.cpp b/modules/photo/perf/perf_main.cpp
index 9bbb8392a1c..b579308a33f 100644
--- a/modules/photo/perf/perf_main.cpp
+++ b/modules/photo/perf/perf_main.cpp
@@ -8,4 +8,8 @@ static const char * impls[] = {
     "plain"
 };
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_PERF_TEST_MAIN_WITH_IMPLS(photo, impls, perf::printCudaInfo())
diff --git a/modules/photo/src/denoising.cpp b/modules/photo/src/denoising.cpp
index ee9e57331e3..e81a53ba55a 100644
--- a/modules/photo/src/denoising.cpp
+++ b/modules/photo/src/denoising.cpp
@@ -131,11 +131,6 @@ void cv::fastNlMeansDenoising( InputArray _src, OutputArray _dst, const std::vec
 
     switch (normType) {
         case NORM_L2:
-#ifdef HAVE_TEGRA_OPTIMIZATION
-            if(hn == 1 && tegra::useTegra() &&
-               tegra::fastNlMeansDenoising(src, dst, h[0], templateWindowSize, searchWindowSize))
-                return;
-#endif
             switch (depth) {
                 case CV_8U:
                     fastNlMeansDenoising_<uchar, int, unsigned, DistSquared>(src, dst, h,
diff --git a/modules/photo/src/precomp.hpp b/modules/photo/src/precomp.hpp
index 4355f13c004..18348819e75 100644
--- a/modules/photo/src/precomp.hpp
+++ b/modules/photo/src/precomp.hpp
@@ -49,8 +49,4 @@
 #include "opencv2/core/ocl.hpp"
 #include "opencv2/imgproc.hpp"
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-#include "opencv2/photo/photo_tegra.hpp"
-#endif
-
 #endif
diff --git a/modules/photo/test/test_main.cpp b/modules/photo/test/test_main.cpp
index 0e51ddfd050..93e4d2860eb 100644
--- a/modules/photo/test/test_main.cpp
+++ b/modules/photo/test/test_main.cpp
@@ -3,4 +3,8 @@
 // of this distribution and at http://opencv.org/license.html.
 #include "test_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_TEST_MAIN("cv")
diff --git a/modules/python/bindings/CMakeLists.txt b/modules/python/bindings/CMakeLists.txt
index 9d0346d5fc6..dd9caacbf87 100644
--- a/modules/python/bindings/CMakeLists.txt
+++ b/modules/python/bindings/CMakeLists.txt
@@ -26,15 +26,15 @@ foreach(m ${OPENCV_PYTHON_MODULES})
       list(APPEND opencv_hdrs "${hdr}")
     endif()
   endforeach()
+  file(GLOB hdr ${OPENCV_MODULE_${m}_LOCATION}/misc/python/shadow*.hpp)
+  list(APPEND opencv_hdrs ${hdr})
   file(GLOB userdef_hdrs ${OPENCV_MODULE_${m}_LOCATION}/misc/python/pyopencv*.hpp)
   list(APPEND opencv_userdef_hdrs ${userdef_hdrs})
 endforeach(m)
 
 # header blacklist
 ocv_list_filterout(opencv_hdrs "modules/.*\\\\.h$")
-ocv_list_filterout(opencv_hdrs "modules/core/.*/cuda")
-ocv_list_filterout(opencv_hdrs "modules/cuda.*")
-ocv_list_filterout(opencv_hdrs "modules/cudev")
+ocv_list_filterout(opencv_hdrs "modules/core/.*/cuda/")
 ocv_list_filterout(opencv_hdrs "modules/core/.*/hal/")
 ocv_list_filterout(opencv_hdrs "modules/core/.*/opencl/")
 ocv_list_filterout(opencv_hdrs "modules/.+/utils/.*")
@@ -43,6 +43,10 @@ ocv_list_filterout(opencv_hdrs "modules/.*_inl\\\\.h*")
 ocv_list_filterout(opencv_hdrs "modules/.*\\\\.details\\\\.h*")
 ocv_list_filterout(opencv_hdrs "modules/.*\\\\.private\\\\.h*")
 ocv_list_filterout(opencv_hdrs "modules/.*/detection_based_tracker\\\\.hpp") # Conditional compilation
+if(NOT HAVE_CUDA)
+  ocv_list_filterout(opencv_hdrs "modules/cuda.*")
+  ocv_list_filterout(opencv_hdrs "modules/cudev")
+endif()
 
 set(cv2_generated_files
     "${CMAKE_CURRENT_BINARY_DIR}/pyopencv_generated_include.h"
diff --git a/modules/python/src2/cv2.cpp b/modules/python/src2/cv2.cpp
index 5a49ef7d8e4..89d0aa31f18 100644
--- a/modules/python/src2/cv2.cpp
+++ b/modules/python/src2/cv2.cpp
@@ -27,6 +27,80 @@
 #  define CV_PYTHON_TYPE_HEAD_INIT() PyObject_HEAD_INIT(&PyType_Type) 0,
 #endif
 
+#define CV_PY_TO_CLASS(TYPE)                                                                          \
+template<> bool pyopencv_to(PyObject* dst, Ptr<TYPE>& src, const char* name);                         \
+                                                                                                      \
+template<>                                                                                            \
+bool pyopencv_to(PyObject* dst, TYPE& src, const char* name)                                          \
+{                                                                                                     \
+    if (!dst || dst == Py_None)                                                                       \
+        return true;                                                                                  \
+    Ptr<TYPE> ptr;                                                                                    \
+                                                                                                      \
+    if (!pyopencv_to(dst, ptr, name)) return false;                                                   \
+    src = *ptr;                                                                                       \
+    return true;                                                                                      \
+}
+
+#define CV_PY_FROM_CLASS(TYPE)                                                                        \
+template<> PyObject* pyopencv_from(const Ptr<TYPE>& src);                                             \
+                                                                                                      \
+template<>                                                                                            \
+PyObject* pyopencv_from(const TYPE& src)                                                              \
+{                                                                                                     \
+    Ptr<TYPE> ptr(new TYPE());                                                                        \
+                                                                                                      \
+    *ptr = src;                                                                                       \
+    return pyopencv_from(ptr);                                                                        \
+}
+
+#define CV_PY_TO_CLASS_PTR(TYPE)                                                                      \
+template<> bool pyopencv_to(PyObject* dst, Ptr<TYPE>& src, const char* name);                         \
+                                                                                                      \
+template<>                                                                                            \
+bool pyopencv_to(PyObject* dst, TYPE*& src, const char* name)                                         \
+{                                                                                                     \
+    if (!dst || dst == Py_None)                                                                       \
+        return true;                                                                                  \
+    Ptr<TYPE> ptr;                                                                                    \
+                                                                                                      \
+    if (!pyopencv_to(dst, ptr, name)) return false;                                                   \
+    src = ptr;                                                                                        \
+    return true;                                                                                      \
+}
+
+#define CV_PY_FROM_CLASS_PTR(TYPE)                                                                    \
+template<> PyObject* pyopencv_from(const Ptr<TYPE>& src);                                             \
+                                                                                                      \
+static PyObject* pyopencv_from(TYPE*& src)                                                            \
+{                                                                                                     \
+    return pyopencv_from(Ptr<TYPE>(src));                                                             \
+}
+
+#define CV_PY_TO_ENUM(TYPE)                                                                           \
+template<> bool pyopencv_to(PyObject* dst, std::underlying_type<TYPE>::type& src, const char* name);  \
+                                                                                                      \
+template<>                                                                                            \
+bool pyopencv_to(PyObject* dst, TYPE& src, const char* name)                                          \
+{                                                                                                     \
+    if (!dst || dst == Py_None)                                                                       \
+        return true;                                                                                  \
+    std::underlying_type<TYPE>::type underlying;                                                      \
+                                                                                                      \
+    if (!pyopencv_to(dst, underlying, name)) return false;                                            \
+    src = static_cast<TYPE>(underlying);                                                              \
+    return true;                                                                                      \
+}
+
+#define CV_PY_FROM_ENUM(TYPE)                                                                         \
+template<> PyObject* pyopencv_from(const std::underlying_type<TYPE>::type& src);                      \
+                                                                                                      \
+template<>                                                                                            \
+PyObject* pyopencv_from(const TYPE& src)                                                              \
+{                                                                                                     \
+    return pyopencv_from(static_cast<std::underlying_type<TYPE>::type>(src));                         \
+}
+
 #include "pyopencv_generated_include.h"
 #include "opencv2/core/types_c.h"
 
@@ -36,7 +110,7 @@
 
 #include <map>
 
-static PyObject* opencv_error = 0;
+static PyObject* opencv_error = NULL;
 
 static int failmsg(const char *fmt, ...)
 {
@@ -97,6 +171,12 @@ try \
 } \
 catch (const cv::Exception &e) \
 { \
+    PyObject_SetAttrString(opencv_error, "file", PyString_FromString(e.file.c_str())); \
+    PyObject_SetAttrString(opencv_error, "func", PyString_FromString(e.func.c_str())); \
+    PyObject_SetAttrString(opencv_error, "line", PyInt_FromLong(e.line)); \
+    PyObject_SetAttrString(opencv_error, "code", PyInt_FromLong(e.code)); \
+    PyObject_SetAttrString(opencv_error, "msg", PyString_FromString(e.msg.c_str())); \
+    PyObject_SetAttrString(opencv_error, "err", PyString_FromString(e.err.c_str())); \
     PyErr_SetString(opencv_error, e.what()); \
     return 0; \
 }
@@ -474,272 +554,22 @@ PyObject* pyopencv_from(const cv::Ptr<T>& p)
     return pyopencv_from(*p);
 }
 
-typedef struct {
-    PyObject_HEAD
-    UMat* um;
-} cv2_UMatWrapperObject;
-
-static bool PyObject_IsUMat(PyObject *o);
-
-// UMatWrapper init - try to map arguments from python to UMat constructors
-static int UMatWrapper_init(PyObject* self_, PyObject *args, PyObject *kwds)
-{
-    cv2_UMatWrapperObject* self = (cv2_UMatWrapperObject*)self_;
-    if (self == NULL)
-    {
-        PyErr_SetString(PyExc_TypeError, "Internal error");
-        return -1;
-    }
-    self->um = NULL;
-    {
-        // constructor ()
-        const char *kwlist[] = {NULL};
-        if (PyArg_ParseTupleAndKeywords(args, kwds, "", (char**) kwlist)) {
-            self->um = new UMat();
-            return 0;
-        }
-        PyErr_Clear();
-    }
-    {
-        // constructor (rows, cols, type)
-        const char *kwlist[] = {"rows", "cols", "type", NULL};
-        int rows, cols, type;
-        if (PyArg_ParseTupleAndKeywords(args, kwds, "iii", (char**) kwlist, &rows, &cols, &type)) {
-            self->um = new UMat(rows, cols, type);
-            return 0;
-        }
-        PyErr_Clear();
-    }
-    {
-        // constructor (m, rowRange, colRange)
-        const char *kwlist[] = {"m", "rowRange", "colRange", NULL};
-        PyObject *obj = NULL;
-        int y0 = -1, y1 = -1, x0 = -1, x1 = -1;
-        if (PyArg_ParseTupleAndKeywords(args, kwds, "O(ii)|(ii)", (char**) kwlist, &obj, &y0, &y1, &x0, &x1) && PyObject_IsUMat(obj)) {
-            UMat *um_other = ((cv2_UMatWrapperObject *) obj)->um;
-            Range rowRange(y0, y1);
-            Range colRange = (x0 >= 0 && x1 >= 0) ? Range(x0, x1) : Range::all();
-            self->um = new UMat(*um_other, rowRange, colRange);
-            return 0;
-        }
-        PyErr_Clear();
-    }
-    {
-        // constructor (m)
-        const char *kwlist[] = {"m", NULL};
-        PyObject *obj = NULL;
-        if (PyArg_ParseTupleAndKeywords(args, kwds, "O", (char**) kwlist, &obj)) {
-            // constructor (UMat m)
-            if (PyObject_IsUMat(obj)) {
-                UMat *um_other = ((cv2_UMatWrapperObject *) obj)->um;
-                self->um = new UMat(*um_other);
-                return 0;
-            }
-            // python specific constructor from array like object
-            Mat m;
-            if (pyopencv_to(obj, m, ArgInfo("UMatWrapper.np_mat", 0))) {
-                self->um = new UMat();
-                m.copyTo(*self->um);
-                return 0;
-            }
-        }
-        PyErr_Clear();
-    }
-    PyErr_SetString(PyExc_TypeError, "no matching UMat constructor found/supported");
-    return -1;
-}
-
-static void UMatWrapper_dealloc(cv2_UMatWrapperObject* self)
-{
-    if (self->um)
-        delete self->um;
-#if PY_MAJOR_VERSION >= 3
-    Py_TYPE(self)->tp_free((PyObject*)self);
-#else
-    self->ob_type->tp_free((PyObject*)self);
-#endif
-}
-
-// UMatWrapper.get() - returns numpy array by transferring UMat data to Mat and than wrapping it to numpy array
-// (using numpy allocator - and so without unnecessary copy)
-static PyObject * UMatWrapper_get(PyObject* self_, PyObject * /*args*/)
-{
-    cv2_UMatWrapperObject* self = (cv2_UMatWrapperObject*)self_;
-    if (self == NULL)
-        return failmsgp("Incorrect type of self (must be 'cv2_UMatWrapperObject')");
-    Mat m;
-    m.allocator = &g_numpyAllocator;
-    self->um->copyTo(m);
-
-    return pyopencv_from(m);
-}
-
-// UMatWrapper.handle() - returns the OpenCL handle of the UMat object
-static PyObject * UMatWrapper_handle(PyObject* self_, PyObject *args, PyObject *kwds)
-{
-    cv2_UMatWrapperObject* self = (cv2_UMatWrapperObject*)self_;
-    if (self == NULL)
-        return failmsgp("Incorrect type of self (must be 'cv2_UMatWrapperObject')");
-    const char *kwlist[] = {"accessFlags", NULL};
-    int accessFlags;
-    if (!PyArg_ParseTupleAndKeywords(args, kwds, "i", (char**) kwlist, &accessFlags))
-        return 0;
-    return PyLong_FromVoidPtr(self->um->handle(accessFlags));
-}
-
-// UMatWrapper.isContinuous() - returns true if the matrix data is continuous
-static PyObject * UMatWrapper_isContinuous(PyObject* self_, PyObject * /*args*/)
-{
-    cv2_UMatWrapperObject* self = (cv2_UMatWrapperObject*)self_;
-    if (self == NULL)
-        return failmsgp("Incorrect type of self (must be 'cv2_UMatWrapperObject')");
-    return PyBool_FromLong(self->um->isContinuous());
-}
-
-// UMatWrapper.isContinuous() - returns true if the matrix is a submatrix of another matrix
-static PyObject * UMatWrapper_isSubmatrix(PyObject* self_, PyObject * /*args*/)
-{
-    cv2_UMatWrapperObject* self = (cv2_UMatWrapperObject*)self_;
-    if (self == NULL)
-        return failmsgp("Incorrect type of self (must be 'cv2_UMatWrapperObject')");
-    return PyBool_FromLong(self->um->isSubmatrix());
-}
-
-// UMatWrapper.context() - returns the OpenCL context used by OpenCV UMat
-static PyObject * UMatWrapper_context(PyObject* /*self_*/, PyObject * /*args*/)
-{
-    return PyLong_FromVoidPtr(cv::ocl::Context::getDefault().ptr());
-}
-
-// UMatWrapper.context() - returns the OpenCL queue used by OpenCV UMat
-static PyObject * UMatWrapper_queue(PyObject* /*self_*/, PyObject * /*args*/)
-{
-    return PyLong_FromVoidPtr(cv::ocl::Queue::getDefault().ptr());
-}
-
-static PyObject * UMatWrapper_offset_getter(PyObject* self_, void*)
+template<>
+bool pyopencv_to(PyObject* obj, void*& ptr, const char* name)
 {
-    cv2_UMatWrapperObject* self = (cv2_UMatWrapperObject*)self_;
-    if (self == NULL)
-        return failmsgp("Incorrect type of self (must be 'cv2_UMatWrapperObject')");
-    return PyLong_FromSsize_t(self->um->offset);
-}
-
-static PyMethodDef UMatWrapper_methods[] = {
-        {"get", CV_PY_FN_NOARGS(UMatWrapper_get),
-                "Returns numpy array"
-        },
-        {"handle", CV_PY_FN_WITH_KW(UMatWrapper_handle),
-                "Returns UMat native handle"
-        },
-        {"isContinuous", CV_PY_FN_NOARGS(UMatWrapper_isContinuous),
-                "Returns true if the matrix data is continuous"
-        },
-        {"isSubmatrix", CV_PY_FN_NOARGS(UMatWrapper_isSubmatrix),
-                "Returns true if the matrix is a submatrix of another matrix"
-        },
-        {"context", CV_PY_FN_NOARGS_(UMatWrapper_context, METH_STATIC),
-                "Returns OpenCL context handle"
-        },
-        {"queue", CV_PY_FN_NOARGS_(UMatWrapper_queue, METH_STATIC),
-                "Returns OpenCL queue handle"
-        },
-        {NULL, NULL, 0, NULL}  /* Sentinel */
-};
-
-static PyGetSetDef UMatWrapper_getset[] = {
-        {(char*) "offset", (getter) UMatWrapper_offset_getter, NULL, NULL, NULL},
-        {NULL, NULL, NULL, NULL, NULL}  /* Sentinel */
-};
-
-static PyTypeObject cv2_UMatWrapperType = {
-#if PY_MAJOR_VERSION >= 3
-        PyVarObject_HEAD_INIT(NULL, 0)
-#else
-        PyObject_HEAD_INIT(NULL)
-        0,                             /*ob_size*/
-#endif
-        "cv2.UMat",                    /* tp_name */
-        sizeof(cv2_UMatWrapperObject), /* tp_basicsize */
-        0,                             /* tp_itemsize */
-      (destructor)UMatWrapper_dealloc, /* tp_dealloc */
-        0,                             /* tp_print */
-        0,                             /* tp_getattr */
-        0,                             /* tp_setattr */
-        0,                             /* tp_reserved */
-        0,                             /* tp_repr */
-        0,                             /* tp_as_number */
-        0,                             /* tp_as_sequence */
-        0,                             /* tp_as_mapping */
-        0,                             /* tp_hash  */
-        0,                             /* tp_call */
-        0,                             /* tp_str */
-        0,                             /* tp_getattro */
-        0,                             /* tp_setattro */
-        0,                             /* tp_as_buffer */
-        Py_TPFLAGS_DEFAULT,            /* tp_flags */
-        "OpenCV 3 UMat wrapper. Used for T-API support.", /* tp_doc */
-        0,                             /* tp_traverse */
-        0,                             /* tp_clear */
-        0,                             /* tp_richcompare */
-        0,                             /* tp_weaklistoffset */
-        0,                             /* tp_iter */
-        0,                             /* tp_iternext */
-        UMatWrapper_methods,           /* tp_methods */
-        0,                             /* tp_members */
-        UMatWrapper_getset,            /* tp_getset */
-        0,                             /* tp_base */
-        0,                             /* tp_dict */
-        0,                             /* tp_descr_get */
-        0,                             /* tp_descr_set */
-        0,                             /* tp_dictoffset */
-        (initproc)UMatWrapper_init,    /* tp_init */
-        0,                             /* tp_alloc */
-        PyType_GenericNew,             /* tp_new */
-        0,                             /* tp_free */
-        0,                             /* tp_is_gc */
-        0,                             /* tp_bases */
-        0,                             /* tp_mro */
-        0,                             /* tp_cache */
-        0,                             /* tp_subclasses */
-        0,                             /* tp_weaklist */
-        0,                             /* tp_del */
-        0,                             /* tp_version_tag */
-#if PY_MAJOR_VERSION >= 3
-        0,                             /* tp_finalize */
-#endif
-};
-
-static bool PyObject_IsUMat(PyObject *o) {
-    return (o != NULL) && PyObject_TypeCheck(o, &cv2_UMatWrapperType);
-}
-
-static bool pyopencv_to(PyObject* o, UMat& um, const ArgInfo info) {
-    if (PyObject_IsUMat(o)) {
-        um = *((cv2_UMatWrapperObject *) o)->um;
+    (void)name;
+    if (!obj || obj == Py_None)
         return true;
-    }
 
-    Mat m;
-    if (!pyopencv_to(o, m, info)) {
+    if (!PyLong_Check(obj))
         return false;
-    }
-
-    m.copyTo(um);
-    return true;
+    ptr = PyLong_AsVoidPtr(obj);
+    return ptr != NULL && !PyErr_Occurred();
 }
 
-template<>
-bool pyopencv_to(PyObject* o, UMat& um, const char* name)
+static PyObject* pyopencv_from(void*& ptr)
 {
-    return pyopencv_to(o, um, ArgInfo(name, 0));
-}
-
-template<>
-PyObject* pyopencv_from(const UMat& m) {
-    PyObject *o = PyObject_CallObject((PyObject *) &cv2_UMatWrapperType, NULL);
-    *((cv2_UMatWrapperObject *) o)->um = m;
-    return o;
+    return PyLong_FromVoidPtr(ptr);
 }
 
 static bool pyopencv_to(PyObject *o, Scalar& s, const ArgInfo info)
@@ -844,6 +674,30 @@ bool pyopencv_to(PyObject* obj, int& value, const char* name)
     return value != -1 || !PyErr_Occurred();
 }
 
+#if defined (_M_AMD64) || defined (__x86_64__)
+template<>
+PyObject* pyopencv_from(const unsigned int& value)
+{
+    return PyLong_FromUnsignedLong(value);
+}
+
+template<>
+
+bool pyopencv_to(PyObject* obj, unsigned int& value, const char* name)
+{
+    (void)name;
+    if(!obj || obj == Py_None)
+        return true;
+    if(PyInt_Check(obj))
+        value = (unsigned int)PyInt_AsLong(obj);
+    else if(PyLong_Check(obj))
+        value = (unsigned int)PyLong_AsLong(obj);
+    else
+        return false;
+    return value != (unsigned int)-1 || !PyErr_Occurred();
+}
+#endif
+
 template<>
 PyObject* pyopencv_from(const uchar& value)
 {
@@ -1926,18 +1780,17 @@ void initcv2()
 
   PyDict_SetItemString(d, "__version__", PyString_FromString(CV_VERSION));
 
-  opencv_error = PyErr_NewException((char*)MODULESTR".error", NULL, NULL);
+  PyObject *opencv_error_dict = PyDict_New();
+  PyDict_SetItemString(opencv_error_dict, "file", Py_None);
+  PyDict_SetItemString(opencv_error_dict, "func", Py_None);
+  PyDict_SetItemString(opencv_error_dict, "line", Py_None);
+  PyDict_SetItemString(opencv_error_dict, "code", Py_None);
+  PyDict_SetItemString(opencv_error_dict, "msg", Py_None);
+  PyDict_SetItemString(opencv_error_dict, "err", Py_None);
+  opencv_error = PyErr_NewException((char*)MODULESTR".error", NULL, opencv_error_dict);
+  Py_DECREF(opencv_error_dict);
   PyDict_SetItemString(d, "error", opencv_error);
 
-//Registering UMatWrapper python class in cv2 module:
-  if (PyType_Ready(&cv2_UMatWrapperType) < 0)
-#if PY_MAJOR_VERSION >= 3
-    return NULL;
-#else
-    return;
-#endif
-
-
 #if PY_MAJOR_VERSION >= 3
 #define PUBLISH_OBJECT(name, type) Py_INCREF(&type);\
   PyModule_AddObject(m, name, (PyObject *)&type);
@@ -1948,8 +1801,6 @@ void initcv2()
   PyModule_AddObject(m, name, (PyObject *)&type);
 #endif
 
-  PUBLISH_OBJECT("UMat", cv2_UMatWrapperType);
-
 #include "pyopencv_generated_type_publish.h"
 
 #define PUBLISH(I) PyDict_SetItemString(d, #I, PyInt_FromLong(I))
diff --git a/modules/python/src2/gen2.py b/modules/python/src2/gen2.py
index 6995e23651e..8dcce91ed76 100755
--- a/modules/python/src2/gen2.py
+++ b/modules/python/src2/gen2.py
@@ -12,17 +12,19 @@
 
 ignored_arg_types = ["RNG*"]
 
+pass_by_val_types = ["Point*", "Point2f*", "Rect*", "String*", "double*", "float*", "int*"]
+
 gen_template_check_self = Template("""    $cname* _self_ = NULL;
     if(PyObject_TypeCheck(self, &pyopencv_${name}_Type))
         _self_ = ${amp}((pyopencv_${name}_t*)self)->v${get};
-    if (_self_ == NULL)
+    if (!_self_)
         return failmsgp("Incorrect type of self (must be '${name}' or its derivative)");
 """)
 
 gen_template_check_self_algo = Template("""    $cname* _self_ = NULL;
     if(PyObject_TypeCheck(self, &pyopencv_${name}_Type))
         _self_ = dynamic_cast<$cname*>(${amp}((pyopencv_${name}_t*)self)->v.get());
-    if (_self_ == NULL)
+    if (!_self_)
         return failmsgp("Incorrect type of self (must be '${name}' or its derivative)");
 """)
 
@@ -77,18 +79,27 @@
 
 template<> bool pyopencv_to(PyObject* src, ${cname}& dst, const char* name)
 {
-    if( src == NULL || src == Py_None )
+    if(!src || src == Py_None)
         return true;
-    if(!PyObject_TypeCheck(src, &pyopencv_${name}_Type))
+    if(PyObject_TypeCheck(src, &pyopencv_${name}_Type))
     {
-        failmsg("Expected ${cname} for argument '%%s'", name);
-        return false;
+        dst = ((pyopencv_${name}_t*)src)->v;
+        return true;
     }
-    dst = ((pyopencv_${name}_t*)src)->v;
-    return true;
+    failmsg("Expected ${cname} for argument '%%s'", name);
+    return false;
 }
 """ % head_init_str)
 
+gen_template_mappable = Template("""
+    {
+        ${mappable} _src;
+        if (pyopencv_to(src, _src, name))
+        {
+            return cv_mappable_to(_src, dst);
+        }
+    }
+""")
 
 gen_template_type_decl = Template("""
 struct pyopencv_${name}_t
@@ -120,15 +131,16 @@
 
 template<> bool pyopencv_to(PyObject* src, Ptr<${cname}>& dst, const char* name)
 {
-    if( src == NULL || src == Py_None )
+    if(!src || src == Py_None)
         return true;
-    if(!PyObject_TypeCheck(src, &pyopencv_${name}_Type))
+    if(PyObject_TypeCheck(src, &pyopencv_${name}_Type))
     {
-        failmsg("Expected ${cname} for argument '%%s'", name);
-        return false;
+        dst = ((pyopencv_${name}_t*)src)->v.dynamicCast<${cname}>();
+        return true;
     }
-    dst = ((pyopencv_${name}_t*)src)->v.dynamicCast<${cname}>();
-    return true;
+    ${mappable_code}
+    failmsg("Expected ${cname} for argument '%%s'", name);
+    return false;
 }
 
 """ % head_init_str)
@@ -192,7 +204,7 @@
 static PyObject* pyopencv_${name}_get_${member}(pyopencv_${name}_t* p, void *closure)
 {
     $cname* _self_ = dynamic_cast<$cname*>(p->v.get());
-    if (_self_ == NULL)
+    if (!_self_)
         return failmsgp("Incorrect type of object (must be '${name}' or its derivative)");
     return pyopencv_from(_self_${access}${member});
 }
@@ -201,7 +213,7 @@
 gen_template_set_prop = Template("""
 static int pyopencv_${name}_set_${member}(pyopencv_${name}_t* p, PyObject *value, void *closure)
 {
-    if (value == NULL)
+    if (!value)
     {
         PyErr_SetString(PyExc_TypeError, "Cannot delete the ${member} attribute");
         return -1;
@@ -213,13 +225,13 @@
 gen_template_set_prop_algo = Template("""
 static int pyopencv_${name}_set_${member}(pyopencv_${name}_t* p, PyObject *value, void *closure)
 {
-    if (value == NULL)
+    if (!value)
     {
         PyErr_SetString(PyExc_TypeError, "Cannot delete the ${member} attribute");
         return -1;
     }
     $cname* _self_ = dynamic_cast<$cname*>(p->v.get());
-    if (_self_ == NULL)
+    if (!_self_)
     {
         failmsgp("Incorrect type of object (must be '${name}' or its derivative)");
         return -1;
@@ -265,6 +277,7 @@ def __init__(self, name, decl=None):
         self.isalgorithm = False
         self.methods = {}
         self.props = []
+        self.mappables = []
         self.consts = {}
         self.base = None
         self.constructor = None
@@ -402,7 +415,7 @@ def __init__(self, arg_tuple):
         self.py_outputarg = False
 
     def isbig(self):
-        return self.tp == "Mat" or self.tp == "vector_Mat"\
+        return self.tp == "Mat" or self.tp == "vector_Mat" or self.tp == "cuda::GpuMat"\
                or self.tp == "UMat" or self.tp == "vector_UMat" # or self.tp.startswith("vector")
 
     def crepr(self):
@@ -410,10 +423,11 @@ def crepr(self):
 
 
 class FuncVariant(object):
-    def __init__(self, classname, name, decl, isconstructor):
+    def __init__(self, classname, name, decl, isconstructor, isphantom=False):
         self.classname = classname
         self.name = self.wname = name
         self.isconstructor = isconstructor
+        self.isphantom = isphantom
 
         self.docstring = decl[5]
 
@@ -520,17 +534,17 @@ def init_pyproto(self):
 
 
 class FuncInfo(object):
-    def __init__(self, classname, name, cname, isconstructor, namespace, isclassmethod):
+    def __init__(self, classname, name, cname, isconstructor, namespace, is_static):
         self.classname = classname
         self.name = name
         self.cname = cname
         self.isconstructor = isconstructor
         self.namespace = namespace
-        self.isclassmethod = isclassmethod
+        self.is_static = is_static
         self.variants = []
 
-    def add_variant(self, decl):
-        self.variants.append(FuncVariant(self.classname, self.name, decl, self.isconstructor))
+    def add_variant(self, decl, isphantom=False):
+        self.variants.append(FuncVariant(self.classname, self.name, decl, self.isconstructor, isphantom))
 
     def get_wrapper_name(self):
         name = self.name
@@ -541,8 +555,8 @@ def get_wrapper_name(self):
         else:
             classname = ""
 
-        if self.isclassmethod:
-            name += "_cls"
+        if self.is_static:
+            name += "_static"
 
         return "pyopencv_" + self.namespace.replace('.','_') + '_' + classname + name
 
@@ -601,7 +615,7 @@ def get_tab_entry(self):
 
         return Template('    {"$py_funcname", CV_PY_FN_WITH_KW_($wrap_funcname, $flags), "$py_docstring"},\n'
                         ).substitute(py_funcname = self.variants[0].wname, wrap_funcname=self.get_wrapper_name(),
-                                     flags = 'METH_CLASS' if self.isclassmethod else '0', py_docstring = full_docstring)
+                                     flags = 'METH_STATIC' if self.is_static else '0', py_docstring = full_docstring)
 
     def gen_code(self, codegen):
         all_classes = codegen.classes
@@ -618,7 +632,7 @@ def gen_code(self, codegen):
             selfinfo = all_classes[self.classname]
             if not self.isconstructor:
                 amp = "&" if selfinfo.issimple else ""
-                if self.isclassmethod:
+                if self.is_static:
                     pass
                 elif selfinfo.isalgorithm:
                     code += gen_template_check_self_algo.substitute(name=selfinfo.name, cname=selfinfo.cname, amp=amp)
@@ -638,6 +652,9 @@ def gen_code(self, codegen):
             all_cargs = []
             parse_arglist = []
 
+            if v.isphantom and ismethod and not self.is_static:
+                code_args += "_self_"
+
             # declare all the C function arguments,
             # add necessary conversions from Python objects to code_cvt_list,
             # form the function/method call,
@@ -656,15 +673,15 @@ def gen_code(self, codegen):
                 tp1 = tp = a.tp
                 amp = ""
                 defval0 = ""
-                if tp.endswith("*"):
+                if tp in pass_by_val_types:
                     tp = tp1 = tp[:-1]
                     amp = "&"
                     if tp.endswith("*"):
                         defval0 = "0"
                         tp1 = tp.replace("*", "_ptr")
-                if tp1.endswith("*"):
-                    print("Error: type with star: a.tp=%s, tp=%s, tp1=%s" % (a.tp, tp, tp1))
-                    sys.exit(-1)
+                tp_candidates = [a.tp, normalize_class_name(self.namespace + "." + a.tp)]
+                if any(tp in codegen.enumTypes for tp in tp_candidates):
+                    defval0 = "static_cast<%s>(%d)" % (a.tp, 0)
 
                 amapping = simple_argtype_mapping.get(tp, (tp, "O", defval0))
                 parse_name = a.name
@@ -686,6 +703,9 @@ def gen_code(self, codegen):
                     if "UMat" in tp:
                         if "Mat" in defval and "UMat" not in defval:
                             defval = defval.replace("Mat", "UMat")
+                    if "cuda::GpuMat" in tp:
+                        if "Mat" in defval and "GpuMat" not in defval:
+                            defval = defval.replace("Mat", "cuda::GpuMat")
                 # "tp arg = tp();" is equivalent to "tp arg;" in the case of complex types
                 if defval == tp + "()" and amapping[1] == "O":
                     defval = ""
@@ -712,13 +732,15 @@ def gen_code(self, codegen):
 
                 code_prelude = templ_prelude.substitute(name=selfinfo.name, cname=selfinfo.cname)
                 code_fcall = templ.substitute(name=selfinfo.name, cname=selfinfo.cname, args=code_args)
+                if v.isphantom:
+                    code_fcall = code_fcall.replace("new " + selfinfo.cname, self.cname.replace("::", "_"))
             else:
                 code_prelude = ""
                 code_fcall = ""
                 if v.rettype:
                     code_decl += "    " + v.rettype + " retval;\n"
                     code_fcall += "retval = "
-                if ismethod and not self.isclassmethod:
+                if not v.isphantom and ismethod and not self.is_static:
                     code_fcall += "_self_->" + self.cname
                 else:
                     code_fcall += self.cname
@@ -754,7 +776,7 @@ def gen_code(self, codegen):
                     parse_arglist = ", ".join(["&" + all_cargs[argno][1] for aname, argno in v.py_arglist]),
                     code_cvt = " &&\n        ".join(code_cvt_list))
             else:
-                code_parse = "if(PyObject_Size(args) == 0 && (kw == NULL || PyObject_Size(kw) == 0))"
+                code_parse = "if(PyObject_Size(args) == 0 && (!kw || PyObject_Size(kw) == 0))"
 
             if len(v.py_outlist) == 0:
                 code_ret = "Py_RETURN_NONE"
@@ -799,7 +821,7 @@ def gen_code(self, codegen):
             #if dump: pprint(vars(classinfo))
             if self.isconstructor:
                 py_name = 'cv.' + classinfo.wname
-            elif self.isclassmethod:
+            elif self.is_static:
                 py_name = '.'.join([self.namespace, classinfo.sname + '_' + self.variants[0].wname])
             else:
                 cname = classinfo.cname + '::' + cname
@@ -833,6 +855,7 @@ def clear(self):
         self.classes = {}
         self.namespaces = {}
         self.consts = {}
+        self.enumTypes = []
         self.code_include = StringIO()
         self.code_types = StringIO()
         self.code_funcs = StringIO()
@@ -890,6 +913,18 @@ def add_const(self, name, decl):
         py_signatures.append(dict(name=py_name, value=value))
         #print(cname + ' => ' + str(py_name) + ' (value=' + value + ')')
 
+    def add_enum(self, name, decl):
+        enumType = normalize_class_name(name)
+        if enumType.endswith("<unnamed>"):
+            enumType = None
+        else:
+            self.enumTypes.append(enumType)
+        const_decls = decl[3]
+
+        for decl in const_decls:
+            name = decl[0]
+            self.add_const(name.replace("const ", "").strip(), decl)
+
     def add_func(self, decl):
         namespace, classes, barename = self.split_decl_name(decl[0])
         cname = "::".join(namespace+classes+[barename])
@@ -902,35 +937,46 @@ def add_func(self, decl):
         namespace = '.'.join(namespace)
 
         isconstructor = name == bareclassname
-        isclassmethod = False
+        is_static = False
+        isphantom = False
+        mappable = None
         for m in decl[2]:
             if m == "/S":
-                isclassmethod = True
+                is_static = True
+            elif m == "/phantom":
+                isphantom = True
+                cname = cname.replace("::", "_")
             elif m.startswith("="):
                 name = m[1:]
+            elif m.startswith("/mappable="):
+                mappable = m[10:]
+                self.classes[classname].mappables.append(mappable)
+                return
+
         if isconstructor:
             name = "_".join(classes[:-1]+[name])
 
-        if isclassmethod:
+        if is_static:
             # Add it as a method to the class
             func_map = self.classes[classname].methods
-            func = func_map.setdefault(name, FuncInfo(classname, name, cname, isconstructor, namespace, isclassmethod))
-            func.add_variant(decl)
+            func = func_map.setdefault(name, FuncInfo(classname, name, cname, isconstructor, namespace, is_static))
+            func.add_variant(decl, isphantom)
 
             # Add it as global function
             g_name = "_".join(classes+[name])
             func_map = self.namespaces.setdefault(namespace, Namespace()).funcs
             func = func_map.setdefault(g_name, FuncInfo("", g_name, cname, isconstructor, namespace, False))
-            func.add_variant(decl)
+            func.add_variant(decl, isphantom)
         else:
             if classname and not isconstructor:
-                cname = barename
+                if not isphantom:
+                    cname = barename
                 func_map = self.classes[classname].methods
             else:
                 func_map = self.namespaces.setdefault(namespace, Namespace()).funcs
 
-            func = func_map.setdefault(name, FuncInfo(classname, name, cname, isconstructor, namespace, isclassmethod))
-            func.add_variant(decl)
+            func = func_map.setdefault(name, FuncInfo(classname, name, cname, isconstructor, namespace, is_static))
+            func.add_variant(decl, isphantom)
 
         if classname and isconstructor:
             self.classes[classname].constructor = func
@@ -949,10 +995,10 @@ def gen_namespace(self, ns_name):
 
         self.code_ns_reg.write('static ConstDef consts_%s[] = {\n'%wname)
         for name, cname in sorted(ns.consts.items()):
-            self.code_ns_reg.write('    {"%s", %s},\n'%(name, cname))
+            self.code_ns_reg.write('    {"%s", static_cast<long>(%s)},\n'%(name, cname))
             compat_name = re.sub(r"([a-z])([A-Z])", r"\1_\2", name).upper()
             if name != compat_name:
-                self.code_ns_reg.write('    {"%s", %s},\n'%(compat_name, cname))
+                self.code_ns_reg.write('    {"%s", static_cast<long>(%s)},\n'%(compat_name, cname))
         self.code_ns_reg.write('    {NULL, 0}\n};\n\n')
 
     def gen_namespaces_reg(self):
@@ -975,14 +1021,15 @@ def save_json(self, path, name, value):
 
     def gen(self, srcfiles, output_path):
         self.clear()
-        self.parser = hdr_parser.CppHeaderParser(generate_umat_decls=True)
+        self.parser = hdr_parser.CppHeaderParser(generate_umat_decls=True, generate_gpumat_decls=True)
 
         # step 1: scan the headers and build more descriptive maps of classes, consts, functions
         for hdr in srcfiles:
             decls = self.parser.parse(hdr)
             if len(decls) == 0:
                 continue
-            self.code_include.write( '#include "{0}"\n'.format(hdr[hdr.rindex('opencv2/'):]) )
+            if hdr.find('opencv2/') >= 0: #Avoid including the shadow files
+                self.code_include.write( '#include "{0}"\n'.format(hdr[hdr.rindex('opencv2/'):]) )
             for decl in decls:
                 name = decl[0]
                 if name.startswith("struct") or name.startswith("class"):
@@ -994,6 +1041,9 @@ def gen(self, srcfiles, output_path):
                 elif name.startswith("const"):
                     # constant
                     self.add_const(name.replace("const ", "").strip(), decl)
+                elif name.startswith("enum"):
+                    # enum
+                    self.add_enum(name.rsplit(" ", 1)[1], decl)
                 else:
                     # function
                     self.add_func(decl)
@@ -1043,8 +1093,11 @@ def process_isalgorithm(classinfo):
                     templ = gen_template_simple_type_decl
                 else:
                     templ = gen_template_type_decl
+                mappable_code = "\n".join([
+                                      gen_template_mappable.substitute(cname=classinfo.cname, mappable=mappable)
+                                          for mappable in classinfo.mappables])
                 self.code_types.write(templ.substitute(name=name, wname=classinfo.wname, cname=classinfo.cname, sname=classinfo.sname,
-                                      cname1=("cv::Algorithm" if classinfo.isalgorithm else classinfo.cname)))
+                                      cname1=("cv::Algorithm" if classinfo.isalgorithm else classinfo.cname), mappable_code=mappable_code))
 
         # register classes in the same order as they have been declared.
         # this way, base classes will be registered in Python before their derivatives.
diff --git a/modules/python/src2/hdr_parser.py b/modules/python/src2/hdr_parser.py
index c49036a2666..f5364fc46aa 100755
--- a/modules/python/src2/hdr_parser.py
+++ b/modules/python/src2/hdr_parser.py
@@ -6,6 +6,7 @@
 # the list only for debugging. The real list, used in the real OpenCV build, is specified in CMakeLists.txt
 opencv_hdr_list = [
 "../../core/include/opencv2/core.hpp",
+"../../core/include/opencv2/core/mat.hpp",
 "../../core/include/opencv2/core/ocl.hpp",
 "../../flann/include/opencv2/flann/miniflann.hpp",
 "../../ml/include/opencv2/ml.hpp",
@@ -32,8 +33,9 @@
 
 class CppHeaderParser(object):
 
-    def __init__(self, generate_umat_decls=False):
+    def __init__(self, generate_umat_decls=False, generate_gpumat_decls=False):
         self._generate_umat_decls = generate_umat_decls
+        self._generate_gpumat_decls = generate_gpumat_decls
 
         self.BLOCK_TYPE = 0
         self.BLOCK_NAME = 1
@@ -375,11 +377,9 @@ def parse_func_decl_no_wrap(self, decl_str, static_method=False, docstring=""):
             decl[2].append("/A")
         if bool(re.match(r".*\)\s*const(\s*=\s*0)?", decl_str)):
             decl[2].append("/C")
-        if "virtual" in decl_str:
-            print(decl_str)
         return decl
 
-    def parse_func_decl(self, decl_str, use_umat=False, docstring=""):
+    def parse_func_decl(self, decl_str, mat="Mat", docstring=""):
         """
         Parses the function or method declaration in the form:
         [([CV_EXPORTS] <rettype>) | CVAPI(rettype)]
@@ -392,8 +392,7 @@ def parse_func_decl(self, decl_str, use_umat=False, docstring=""):
         """
 
         if self.wrap_mode:
-            if not (("CV_EXPORTS_AS" in decl_str) or ("CV_EXPORTS_W" in decl_str) or \
-                ("CV_WRAP" in decl_str) or ("CV_WRAP_AS" in decl_str)):
+            if not (("CV_EXPORTS_AS" in decl_str) or ("CV_EXPORTS_W" in decl_str) or ("CV_WRAP" in decl_str)):
                 return []
 
         # ignore old API in the documentation check (for now)
@@ -413,6 +412,16 @@ def parse_func_decl(self, decl_str, use_umat=False, docstring=""):
             arg, npos3 = self.get_macro_arg(decl_str, npos)
             func_modlist.append("="+arg)
             decl_str = decl_str[:npos] + decl_str[npos3+1:]
+        npos = decl_str.find("CV_WRAP_PHANTOM")
+        if npos >= 0:
+            decl_str, _ = self.get_macro_arg(decl_str, npos)
+            func_modlist.append("/phantom")
+        npos = decl_str.find("CV_WRAP_MAPPABLE")
+        if npos >= 0:
+            mappable, npos3 = self.get_macro_arg(decl_str, npos)
+            func_modlist.append("/mappable="+mappable)
+            classname = top[1]
+            return ['.'.join([classname, classname]), None, func_modlist, [], None, None]
 
         virtual_method = False
         pure_virtual_method = False
@@ -526,8 +535,6 @@ def parse_func_decl(self, decl_str, use_umat=False, docstring=""):
             t, npos = self.find_next_token(decl_str, ["(", ")", ",", "<", ">"], npos)
             if not t:
                 print("Error: no closing ')' at %d" % (self.lineno,))
-                print(decl_str)
-                print(decl_str[arg_start:])
                 sys.exit(-1)
             if t == "<":
                 angle_balance += 1
@@ -563,8 +570,6 @@ def parse_func_decl(self, decl_str, use_umat=False, docstring=""):
                         a = a[:eqpos].strip()
                     arg_type, arg_name, modlist, argno = self.parse_arg(a, argno)
                     if self.wrap_mode:
-                        mat = "UMat" if use_umat else "Mat"
-
                         # TODO: Vectors should contain UMat, but this is not very easy to support and not very needed
                         vector_mat = "vector_{}".format("Mat")
                         vector_mat_template = "vector<{}>".format("Mat")
@@ -629,8 +634,8 @@ class A {
             block_type, block_name = b[self.BLOCK_TYPE], b[self.BLOCK_NAME]
             if block_type in ["file", "enum"]:
                 continue
-            if block_type not in ["struct", "class", "namespace"]:
-                print("Error at %d: there are non-valid entries in the current block stack " % (self.lineno, self.block_stack))
+            if block_type not in ["struct", "class", "namespace", "enum struct", "enum class"]:
+                print("Error at %d: there are non-valid entries in the current block stack %s" % (self.lineno, self.block_stack))
                 sys.exit(-1)
             if block_name and (block_type == "namespace" or not qualified_name):
                 n += block_name + "."
@@ -639,7 +644,7 @@ class A {
             n = "cv.Algorithm"
         return n
 
-    def parse_stmt(self, stmt, end_token, use_umat=False, docstring=""):
+    def parse_stmt(self, stmt, end_token, mat="Mat", docstring=""):
         """
         parses the statement (ending with ';' or '}') or a block head (ending with '{')
 
@@ -706,20 +711,19 @@ def parse_stmt(self, stmt, end_token, use_umat=False, docstring=""):
                             decl[1] = ": " + ", ".join([self.get_dotted_name(b).replace(".","::") for b in bases])
                     return stmt_type, classname, True, decl
 
-            if stmt.startswith("enum"):
-                return "enum", "", True, None
-
-            if stmt.startswith("namespace"):
-                stmt_list = stmt.split()
+            if stmt.startswith("enum") or stmt.startswith("namespace"):
+                stmt_list = stmt.rsplit(" ", 1)
                 if len(stmt_list) < 2:
                     stmt_list.append("<unnamed>")
                 return stmt_list[0], stmt_list[1], True, None
+
             if stmt.startswith("extern") and "\"C\"" in stmt:
                 return "namespace", "", True, None
 
-        if end_token == "}" and context == "enum":
+        if end_token == "}" and context.startswith("enum"):
             decl = self.parse_enum(stmt)
-            return "enum", "", False, decl
+            name = stack_top[self.BLOCK_NAME]
+            return context, name, False, decl
 
         if end_token == ";" and stmt.startswith("typedef"):
             # TODO: handle typedef's more intelligently
@@ -731,7 +735,7 @@ def parse_stmt(self, stmt, end_token, use_umat=False, docstring=""):
             # since we filtered off the other places where '(' can normally occur:
             #   - code blocks
             #   - function pointer typedef's
-            decl = self.parse_func_decl(stmt, use_umat=use_umat, docstring=docstring)
+            decl = self.parse_func_decl(stmt, mat=mat, docstring=docstring)
             # we return parse_flag == False to prevent the parser to look inside function/method bodies
             # (except for tracking the nested blocks)
             return stmt_type, "", False, decl
@@ -896,20 +900,29 @@ def parse(self, hname, wmode=True):
                     docstring = docstring.strip()
                     stmt_type, name, parse_flag, decl = self.parse_stmt(stmt, token, docstring=docstring)
                     if decl:
-                        if stmt_type == "enum":
-                            for d in decl:
-                                decls.append(d)
+                        if stmt_type.startswith("enum"):
+                            decls.append([stmt_type + " " + self.get_dotted_name(name), "", [], decl, None, ""])
                         else:
                             decls.append(decl)
 
+                            if self._generate_gpumat_decls and "cv.cuda." in decl[0]:
+                                # If function takes as one of arguments Mat or vector<Mat> - we want to create the
+                                # same declaration working with GpuMat (this is important for T-Api access)
+                                args = decl[3]
+                                has_mat = len(list(filter(lambda x: x[0] in {"Mat", "vector_Mat"}, args))) > 0
+                                if has_mat:
+                                    _, _, _, gpumat_decl = self.parse_stmt(stmt, token, mat="cuda::GpuMat", docstring=docstring)
+                                    decls.append(gpumat_decl)
+
                             if self._generate_umat_decls:
                                 # If function takes as one of arguments Mat or vector<Mat> - we want to create the
                                 # same declaration working with UMat (this is important for T-Api access)
                                 args = decl[3]
                                 has_mat = len(list(filter(lambda x: x[0] in {"Mat", "vector_Mat"}, args))) > 0
                                 if has_mat:
-                                    _, _, _, umat_decl = self.parse_stmt(stmt, token, use_umat=True, docstring=docstring)
+                                    _, _, _, umat_decl = self.parse_stmt(stmt, token, mat="UMat", docstring=docstring)
                                     decls.append(umat_decl)
+
                         docstring = ""
                     if stmt_type == "namespace":
                         chunks = [block[1] for block in self.block_stack if block[0] == 'namespace'] + [name]
@@ -952,7 +965,7 @@ def print_decls(self, decls):
                     print()
 
 if __name__ == '__main__':
-    parser = CppHeaderParser(generate_umat_decls=True)
+    parser = CppHeaderParser(generate_umat_decls=True, generate_gpumat_decls=True)
     decls = []
     for hname in opencv_hdr_list:
         decls += parser.parse(hname)
diff --git a/modules/python/test/test_cuda.py b/modules/python/test/test_cuda.py
new file mode 100644
index 00000000000..ea816645093
--- /dev/null
+++ b/modules/python/test/test_cuda.py
@@ -0,0 +1,248 @@
+#!/usr/bin/env python
+
+'''
+CUDA-accelerated Computer Vision functions
+'''
+
+# Python 2/3 compatibility
+from __future__ import print_function
+
+import numpy as np
+import cv2 as cv
+
+from tests_common import NewOpenCVTests
+
+class cuda_test(NewOpenCVTests):
+    def setUp(self):
+        super(cuda_test, self).setUp()
+        if not cv.cuda.getCudaEnabledDeviceCount():
+            self.skipTest("No CUDA-capable device is detected")
+
+    def test_cuda_upload_download(self):
+        npMat = (np.random.random((128, 128, 3)) * 255).astype(np.uint8)
+        cuMat = cv.cuda_GpuMat()
+        cuMat.upload(npMat)
+
+        self.assertTrue(np.allclose(cuMat.download(), npMat))
+
+    def test_cudaarithm_arithmetic(self):
+        npMat1 = np.random.random((128, 128, 3)) - 0.5
+        npMat2 = np.random.random((128, 128, 3)) - 0.5
+
+        cuMat1 = cv.cuda_GpuMat()
+        cuMat2 = cv.cuda_GpuMat()
+        cuMat1.upload(npMat1)
+        cuMat2.upload(npMat2)
+
+        self.assertTrue(np.allclose(cv.cuda.add(cuMat1, cuMat2).download(),
+                                         cv.add(npMat1, npMat2)))
+
+        self.assertTrue(np.allclose(cv.cuda.subtract(cuMat1, cuMat2).download(),
+                                         cv.subtract(npMat1, npMat2)))
+
+        self.assertTrue(np.allclose(cv.cuda.multiply(cuMat1, cuMat2).download(),
+                                         cv.multiply(npMat1, npMat2)))
+
+        self.assertTrue(np.allclose(cv.cuda.divide(cuMat1, cuMat2).download(),
+                                         cv.divide(npMat1, npMat2)))
+
+        self.assertTrue(np.allclose(cv.cuda.absdiff(cuMat1, cuMat2).download(),
+                                         cv.absdiff(npMat1, npMat2)))
+
+        self.assertTrue(np.allclose(cv.cuda.compare(cuMat1, cuMat2, cv.CMP_GE).download(),
+                                         cv.compare(npMat1, npMat2, cv.CMP_GE)))
+
+        self.assertTrue(np.allclose(cv.cuda.abs(cuMat1).download(),
+                                         np.abs(npMat1)))
+
+        self.assertTrue(np.allclose(cv.cuda.sqrt(cv.cuda.sqr(cuMat1)).download(),
+                                    cv.cuda.abs(cuMat1).download()))
+
+
+        self.assertTrue(np.allclose(cv.cuda.log(cv.cuda.exp(cuMat1)).download(),
+                                                            npMat1))
+
+        self.assertTrue(np.allclose(cv.cuda.pow(cuMat1, 2).download(),
+                                         cv.pow(npMat1, 2)))
+
+    def test_cudaarithm_logical(self):
+        npMat1 = (np.random.random((128, 128)) * 255).astype(np.uint8)
+        npMat2 = (np.random.random((128, 128)) * 255).astype(np.uint8)
+
+        cuMat1 = cv.cuda_GpuMat()
+        cuMat2 = cv.cuda_GpuMat()
+        cuMat1.upload(npMat1)
+        cuMat2.upload(npMat2)
+
+        self.assertTrue(np.allclose(cv.cuda.bitwise_or(cuMat1, cuMat2).download(),
+                                         cv.bitwise_or(npMat1, npMat2)))
+
+        self.assertTrue(np.allclose(cv.cuda.bitwise_and(cuMat1, cuMat2).download(),
+                                         cv.bitwise_and(npMat1, npMat2)))
+
+        self.assertTrue(np.allclose(cv.cuda.bitwise_xor(cuMat1, cuMat2).download(),
+                                         cv.bitwise_xor(npMat1, npMat2)))
+
+        self.assertTrue(np.allclose(cv.cuda.bitwise_not(cuMat1).download(),
+                                         cv.bitwise_not(npMat1)))
+
+        self.assertTrue(np.allclose(cv.cuda.min(cuMat1, cuMat2).download(),
+                                         cv.min(npMat1, npMat2)))
+
+        self.assertTrue(np.allclose(cv.cuda.max(cuMat1, cuMat2).download(),
+                                         cv.max(npMat1, npMat2)))
+
+    def test_cudabgsegm_existence(self):
+        #Test at least the existence of wrapped functions for now
+
+        bgsub = cv.cuda.createBackgroundSubtractorMOG()
+        bgsub = cv.cuda.createBackgroundSubtractorMOG2()
+
+        self.assertTrue(True) #It is sufficient that no exceptions have been there
+
+    def test_cudacodec_existence(self):
+        #Test at least the existence of wrapped functions for now
+
+        try:
+            writer = cv.cudacodec.createVideoWriter("tmp", (128, 128), 30)
+            reader = cv.cudacodec.createVideoReader("tmp")
+        except cv.error as e:
+            self.assertEqual(e.code, cv.Error.StsNotImplemented)
+            self.skipTest("NVCUVENC is not installed")
+
+        self.assertTrue(True) #It is sufficient that no exceptions have been there
+
+    def test_cudafeatures2d(self):
+        npMat1 = self.get_sample("samples/data/right01.jpg")
+        npMat2 = self.get_sample("samples/data/right02.jpg")
+
+        cuMat1 = cv.cuda_GpuMat()
+        cuMat2 = cv.cuda_GpuMat()
+        cuMat1.upload(npMat1)
+        cuMat2.upload(npMat2)
+
+        cuMat1 = cv.cuda.cvtColor(cuMat1, cv.COLOR_RGB2GRAY)
+        cuMat2 = cv.cuda.cvtColor(cuMat2, cv.COLOR_RGB2GRAY)
+
+        fast = cv.cuda_FastFeatureDetector.create()
+        kps = fast.detectAsync(cuMat1)
+
+        orb = cv.cuda_ORB.create()
+        kps1, descs1 = orb.detectAndComputeAsync(cuMat1, None)
+        kps2, descs2 = orb.detectAndComputeAsync(cuMat2, None)
+
+        bf = cv.cuda_DescriptorMatcher.createBFMatcher(cv.NORM_HAMMING)
+        matches = bf.match(descs1, descs2)
+        self.assertGreater(len(matches), 0)
+        matches = bf.knnMatch(descs1, descs2, 2)
+        self.assertGreater(len(matches), 0)
+        matches = bf.radiusMatch(descs1, descs2, 0.1)
+        self.assertGreater(len(matches), 0)
+
+        self.assertTrue(True) #It is sufficient that no exceptions have been there
+
+    def test_cudafilters_existence(self):
+        #Test at least the existence of wrapped functions for now
+
+        filter = cv.cuda.createBoxFilter(cv.CV_8UC1, -1, (3, 3))
+        filter = cv.cuda.createLinearFilter(cv.CV_8UC4, -1, np.eye(3))
+        filter = cv.cuda.createLaplacianFilter(cv.CV_16UC1, -1, ksize=3)
+        filter = cv.cuda.createSeparableLinearFilter(cv.CV_8UC1, -1, np.eye(3), np.eye(3))
+        filter = cv.cuda.createDerivFilter(cv.CV_8UC1, -1, 1, 1, 3)
+        filter = cv.cuda.createSobelFilter(cv.CV_8UC1, -1, 1, 1)
+        filter = cv.cuda.createScharrFilter(cv.CV_8UC1, -1, 1, 0)
+        filter = cv.cuda.createGaussianFilter(cv.CV_8UC1, -1, (3, 3), 16)
+        filter = cv.cuda.createMorphologyFilter(cv.MORPH_DILATE, cv.CV_32FC1, np.eye(3))
+        filter = cv.cuda.createBoxMaxFilter(cv.CV_8UC1, (3, 3))
+        filter = cv.cuda.createBoxMinFilter(cv.CV_8UC1, (3, 3))
+        filter = cv.cuda.createRowSumFilter(cv.CV_8UC1, cv.CV_32FC1, 3)
+        filter = cv.cuda.createColumnSumFilter(cv.CV_8UC1, cv.CV_32FC1, 3)
+        filter = cv.cuda.createMedianFilter(cv.CV_8UC1, 3)
+
+        self.assertTrue(True) #It is sufficient that no exceptions have been there
+
+    def test_cudafilters_laplacian(self):
+        npMat = (np.random.random((128, 128)) * 255).astype(np.uint16)
+        cuMat = cv.cuda_GpuMat()
+        cuMat.upload(npMat)
+
+        self.assertTrue(np.allclose(cv.cuda.createLaplacianFilter(cv.CV_16UC1, -1, ksize=3).apply(cuMat).download(),
+                                         cv.Laplacian(npMat, cv.CV_16UC1, ksize=3)))
+
+    def test_cudaimgproc(self):
+        npC1 = (np.random.random((128, 128)) * 255).astype(np.uint8)
+        npC3 = (np.random.random((128, 128, 3)) * 255).astype(np.uint8)
+        npC4 = (np.random.random((128, 128, 4)) * 255).astype(np.uint8)
+        cuC1 = cv.cuda_GpuMat()
+        cuC3 = cv.cuda_GpuMat()
+        cuC4 = cv.cuda_GpuMat()
+        cuC1.upload(npC1)
+        cuC3.upload(npC3)
+        cuC4.upload(npC4)
+
+        cv.cuda.cvtColor(cuC3, cv.COLOR_RGB2HSV)
+        cv.cuda.demosaicing(cuC1, cv.cuda.COLOR_BayerGR2BGR_MHT)
+        cv.cuda.gammaCorrection(cuC3)
+        cv.cuda.alphaComp(cuC4, cuC4, cv.cuda.ALPHA_XOR)
+        cv.cuda.calcHist(cuC1)
+        cv.cuda.equalizeHist(cuC1)
+        cv.cuda.evenLevels(3, 0, 255)
+        cv.cuda.meanShiftFiltering(cuC4, 10, 5)
+        cv.cuda.meanShiftProc(cuC4, 10, 5)
+        cv.cuda.bilateralFilter(cuC3, 3, 16, 3)
+        cv.cuda.blendLinear
+
+        cv.cuda.meanShiftSegmentation(cuC4, 10, 5, 5).download()
+
+        clahe = cv.cuda.createCLAHE()
+        clahe.apply(cuC1, cv.cuda_Stream.Null());
+
+        histLevels = cv.cuda.histEven(cuC3, 20, 0, 255)
+        cv.cuda.histRange(cuC1, histLevels)
+
+        detector = cv.cuda.createCannyEdgeDetector(0, 100)
+        detector.detect(cuC1)
+
+        detector = cv.cuda.createHoughLinesDetector(3, np.pi / 180, 20)
+        detector.detect(cuC1)
+
+        detector = cv.cuda.createHoughSegmentDetector(3, np.pi / 180, 20, 5)
+        detector.detect(cuC1)
+
+        detector = cv.cuda.createHoughCirclesDetector(3, 20, 10, 10, 20, 100)
+        detector.detect(cuC1)
+
+        detector = cv.cuda.createGeneralizedHoughBallard()
+        #BUG: detect accept only Mat!
+        #Even if generate_gpumat_decls is set to True, it only wraps overload CUDA functions.
+        #The problem is that Mat and GpuMat are not fully compatible to enable system-wide overloading
+        #detector.detect(cuC1, cuC1, cuC1)
+
+        detector = cv.cuda.createGeneralizedHoughGuil()
+        #BUG: same as above..
+        #detector.detect(cuC1, cuC1, cuC1)
+
+        detector = cv.cuda.createHarrisCorner(cv.CV_8UC1, 15, 5, 1)
+        detector.compute(cuC1)
+
+        detector = cv.cuda.createMinEigenValCorner(cv.CV_8UC1, 15, 5, 1)
+        detector.compute(cuC1)
+
+        detector = cv.cuda.createGoodFeaturesToTrackDetector(cv.CV_8UC1)
+        detector.detect(cuC1)
+
+        matcher = cv.cuda.createTemplateMatching(cv.CV_8UC1, cv.TM_CCOEFF_NORMED)
+        matcher.match(cuC3, cuC3)
+
+        self.assertTrue(True) #It is sufficient that no exceptions have been there
+
+    def test_cudaimgproc_cvtColor(self):
+        npMat = (np.random.random((128, 128, 3)) * 255).astype(np.uint8)
+        cuMat = cv.cuda_GpuMat()
+        cuMat.upload(npMat)
+
+        self.assertTrue(np.allclose(cv.cuda.cvtColor(cuMat, cv.COLOR_BGR2HSV).download(),
+                                         cv.cvtColor(npMat, cv.COLOR_BGR2HSV)))
+
+if __name__ == '__main__':
+    NewOpenCVTests.bootstrap()
diff --git a/modules/python/test/test_persistence.py b/modules/python/test/test_persistence.py
index dcfce6e9757..4c1ec8ee0ae 100644
--- a/modules/python/test/test_persistence.py
+++ b/modules/python/test/test_persistence.py
@@ -14,14 +14,17 @@ def test_yml_rw(self):
 
         # Writing ...
         expected = np.array([[[0, 1, 2, 3, 4]]])
+        expected_str = ("Hello", "World", "!")
         fs = cv.FileStorage(fname, cv.FILE_STORAGE_WRITE)
         fs.write("test", expected)
+        fs.write("strings", expected_str)
         fs.release()
 
         # Reading ...
         fs = cv.FileStorage(fname, cv.FILE_STORAGE_READ)
         root = fs.getFirstTopLevelNode()
         self.assertEqual(root.name(), "test")
+
         test = fs.getNode("test")
         self.assertEqual(test.empty(), False)
         self.assertEqual(test.name(), "test")
@@ -30,6 +33,12 @@ def test_yml_rw(self):
         actual = test.mat()
         self.assertEqual(actual.shape, expected.shape)
         self.assertEqual(np.array_equal(expected, actual), True)
+
+        strings = fs.getNode("strings")
+        self.assertEqual(strings.isSeq(), True)
+        self.assertEqual(strings.size(), len(expected_str))
+        self.assertEqual(all(strings.at(i).isString() for i in range(strings.size())), True)
+        self.assertSequenceEqual([strings.at(i).string() for i in range(strings.size())], expected_str)
         fs.release()
 
         os.remove(fname)
diff --git a/modules/python/test/test_umat.py b/modules/python/test/test_umat.py
index c76ddd44aae..102bb12bfb6 100644
--- a/modules/python/test/test_umat.py
+++ b/modules/python/test/test_umat.py
@@ -12,7 +12,7 @@ def test_umat_construct(self):
         data = np.random.random([512, 512])
         # UMat constructors
         data_um = cv.UMat(data)  # from ndarray
-        data_sub_um = cv.UMat(data_um, [128, 256], [128, 256])  # from UMat
+        data_sub_um = cv.UMat(data_um, (128, 256), (128, 256))  # from UMat
         data_dst_um = cv.UMat(128, 128, cv.CV_64F)  # from size/type
         # test continuous and submatrix flags
         assert data_um.isContinuous() and not data_um.isSubmatrix()
@@ -73,14 +73,17 @@ def test_umat_optical_flow(self):
 
         _p1_mask_err = cv.calcOpticalFlowPyrLK(img1, img2, p0, None)
 
-        _p1_mask_err_umat0 = map(cv.UMat.get, cv.calcOpticalFlowPyrLK(img1, img2, p0_umat, None))
-        _p1_mask_err_umat1 = map(cv.UMat.get, cv.calcOpticalFlowPyrLK(cv.UMat(img1), img2, p0_umat, None))
-        _p1_mask_err_umat2 = map(cv.UMat.get, cv.calcOpticalFlowPyrLK(img1, cv.UMat(img2), p0_umat, None))
-
-        # # results of OCL optical flow differs from CPU implementation, so result can not be easily compared
-        # for p1_mask_err_umat in [p1_mask_err_umat0, p1_mask_err_umat1, p1_mask_err_umat2]:
-        #     for data, data_umat in zip(p1_mask_err, p1_mask_err_umat):
-        #         self.assertTrue(np.allclose(data, data_umat))
+        _p1_mask_err_umat0 = list(map(lambda umat: umat.get(), cv.calcOpticalFlowPyrLK(img1, img2, p0_umat, None)))
+        _p1_mask_err_umat1 = list(map(lambda umat: umat.get(), cv.calcOpticalFlowPyrLK(cv.UMat(img1), img2, p0_umat, None)))
+        _p1_mask_err_umat2 = list(map(lambda umat: umat.get(), cv.calcOpticalFlowPyrLK(img1, cv.UMat(img2), p0_umat, None)))
+
+        for _p1_mask_err_umat in [_p1_mask_err_umat0, _p1_mask_err_umat1, _p1_mask_err_umat2]:
+            for data, data_umat in zip(_p1_mask_err, _p1_mask_err_umat):
+                self.assertEqual(data.shape, data_umat.shape)
+                self.assertEqual(data.dtype, data_umat.dtype)
+        for _p1_mask_err_umat in [_p1_mask_err_umat1, _p1_mask_err_umat2]:
+            for data_umat0, data_umat in zip(_p1_mask_err_umat0[:2], _p1_mask_err_umat[:2]):
+                self.assertTrue(np.allclose(data_umat0, data_umat))
 
 if __name__ == '__main__':
     NewOpenCVTests.bootstrap()
diff --git a/modules/shape/CMakeLists.txt b/modules/shape/CMakeLists.txt
index 527a0c2f713..61beeb66078 100644
--- a/modules/shape/CMakeLists.txt
+++ b/modules/shape/CMakeLists.txt
@@ -1,2 +1,2 @@
 set(the_description "Shape descriptors and matchers")
-ocv_define_module(shape opencv_core opencv_imgproc opencv_video WRAP python)
+ocv_define_module(shape opencv_core opencv_imgproc opencv_calib3d WRAP python)
diff --git a/modules/shape/src/aff_trans.cpp b/modules/shape/src/aff_trans.cpp
index a4490f474f1..3d59f5127db 100644
--- a/modules/shape/src/aff_trans.cpp
+++ b/modules/shape/src/aff_trans.cpp
@@ -222,12 +222,18 @@ void AffineTransformerImpl::estimateTransformation(InputArray _pts1, InputArray
         shape2.push_back(pt2);
     }
 
-    // estimateRigidTransform //
     Mat affine;
-    estimateRigidTransform(shape1, shape2, fullAffine).convertTo(affine, CV_32F);
+    if (fullAffine)
+    {
+        estimateAffine2D(shape1, shape2).convertTo(affine, CV_32F);
+    } else
+    {
+        estimateAffinePartial2D(shape1, shape2).convertTo(affine, CV_32F);
+    }
 
     if (affine.empty())
-        affine=_localAffineEstimate(shape1, shape2, fullAffine); //In case there is not good solution, just give a LLS based one
+        //In case there is not good solution, just give a LLS based one
+        affine = _localAffineEstimate(shape1, shape2, fullAffine);
 
     affineMat = affine;
 }
diff --git a/modules/shape/src/precomp.hpp b/modules/shape/src/precomp.hpp
index bc00e5993df..a059b97b5a0 100644
--- a/modules/shape/src/precomp.hpp
+++ b/modules/shape/src/precomp.hpp
@@ -47,7 +47,7 @@
 #include <cmath>
 #include <iostream>
 
-#include "opencv2/video/tracking.hpp"
+#include "opencv2/calib3d.hpp"
 #include "opencv2/imgproc.hpp"
 #include "opencv2/shape.hpp"
 
diff --git a/modules/shape/test/test_main.cpp b/modules/shape/test/test_main.cpp
index 0e51ddfd050..93e4d2860eb 100644
--- a/modules/shape/test/test_main.cpp
+++ b/modules/shape/test/test_main.cpp
@@ -3,4 +3,8 @@
 // of this distribution and at http://opencv.org/license.html.
 #include "test_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_TEST_MAIN("cv")
diff --git a/modules/stitching/perf/perf_main.cpp b/modules/stitching/perf/perf_main.cpp
index 079785685ea..4bc151554bf 100644
--- a/modules/stitching/perf/perf_main.cpp
+++ b/modules/stitching/perf/perf_main.cpp
@@ -1,3 +1,7 @@
 #include "perf_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_PERF_TEST_MAIN(stitching)
diff --git a/modules/stitching/src/blenders.cpp b/modules/stitching/src/blenders.cpp
index 0417a4c927b..64bea1f5eaa 100644
--- a/modules/stitching/src/blenders.cpp
+++ b/modules/stitching/src/blenders.cpp
@@ -720,12 +720,6 @@ void normalizeUsingWeightMap(InputArray _weight, InputOutputArray _src)
 {
     Mat src;
     Mat weight;
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    src = _src.getMat();
-    weight = _weight.getMat();
-    if(tegra::useTegra() && tegra::normalizeUsingWeightMap(weight, src))
-        return;
-#endif
 
 #ifdef HAVE_OPENCL
     if ( !cv::ocl::isOpenCLActivated() ||
@@ -792,12 +786,6 @@ void createWeightMap(InputArray mask, float sharpness, InputOutputArray weight)
 
 void createLaplacePyr(InputArray img, int num_levels, std::vector<UMat> &pyr)
 {
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    cv::Mat imgMat = img.getMat();
-    if(tegra::useTegra() && tegra::createLaplacePyr(imgMat, num_levels, pyr))
-        return;
-#endif
-
     pyr.resize(num_levels + 1);
 
     if(img.depth() == CV_8U)
diff --git a/modules/stitching/src/matchers.cpp b/modules/stitching/src/matchers.cpp
index 46dda51da41..3d82acf484a 100644
--- a/modules/stitching/src/matchers.cpp
+++ b/modules/stitching/src/matchers.cpp
@@ -188,11 +188,6 @@ void CpuMatcher::match(const ImageFeatures &features1, const ImageFeatures &feat
     CV_Assert(features1.descriptors.type() == features2.descriptors.type());
     CV_Assert(features2.descriptors.depth() == CV_8U || features2.descriptors.depth() == CV_32F);
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    if (tegra::useTegra() && tegra::match2nearest(features1, features2, matches_info, match_conf_))
-        return;
-#endif
-
     matches_info.matches.clear();
 
     Ptr<cv::DescriptorMatcher> matcher;
diff --git a/modules/stitching/src/precomp.hpp b/modules/stitching/src/precomp.hpp
index eff78cf5855..ef3740ed763 100644
--- a/modules/stitching/src/precomp.hpp
+++ b/modules/stitching/src/precomp.hpp
@@ -95,10 +95,6 @@
 
 #include "opencv2/core/private.hpp"
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-# include "opencv2/stitching/stitching_tegra.hpp"
-#endif
-
 #include "util_log.hpp"
 
 #endif
diff --git a/modules/stitching/test/test_main.cpp b/modules/stitching/test/test_main.cpp
index b10d0d7a39e..f31f6570b32 100644
--- a/modules/stitching/test/test_main.cpp
+++ b/modules/stitching/test/test_main.cpp
@@ -3,4 +3,8 @@
 // of this distribution and at http://opencv.org/license.html.
 #include "test_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_TEST_MAIN(".")
diff --git a/modules/superres/perf/perf_main.cpp b/modules/superres/perf/perf_main.cpp
index 0a8ab5deaa1..af1ff2fdb94 100644
--- a/modules/superres/perf/perf_main.cpp
+++ b/modules/superres/perf/perf_main.cpp
@@ -51,4 +51,8 @@ static const char * impls[] = {
     "plain"
 };
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_PERF_TEST_MAIN_WITH_IMPLS(superres, impls, printCudaInfo())
diff --git a/modules/superres/test/test_main.cpp b/modules/superres/test/test_main.cpp
index b1998b93208..e9724d80967 100644
--- a/modules/superres/test/test_main.cpp
+++ b/modules/superres/test/test_main.cpp
@@ -42,4 +42,8 @@
 
 #include "test_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_TEST_MAIN("superres")
diff --git a/modules/ts/include/opencv2/ts/ts_perf.hpp b/modules/ts/include/opencv2/ts/ts_perf.hpp
index 3a5f6846d6e..83988c2b862 100644
--- a/modules/ts/include/opencv2/ts/ts_perf.hpp
+++ b/modules/ts/include/opencv2/ts/ts_perf.hpp
@@ -686,11 +686,7 @@ namespace comparators
 {
 
 template<typename T>
-#ifdef CV_CXX11
 struct RectLess_
-#else
-struct RectLess_ : public std::binary_function<cv::Rect_<T>, cv::Rect_<T>, bool>
-#endif
 {
   bool operator()(const cv::Rect_<T>& r1, const cv::Rect_<T>& r2) const
   {
@@ -703,11 +699,7 @@ struct RectLess_ : public std::binary_function<cv::Rect_<T>, cv::Rect_<T>, bool>
 
 typedef RectLess_<int> RectLess;
 
-#ifdef CV_CXX11
 struct KeypointGreater
-#else
-struct KeypointGreater : public std::binary_function<cv::KeyPoint, cv::KeyPoint, bool>
-#endif
 {
     bool operator()(const cv::KeyPoint& kp1, const cv::KeyPoint& kp2) const
     {
diff --git a/modules/ts/src/cuda_test.cpp b/modules/ts/src/cuda_test.cpp
index 307e1296a22..ca48d0631ed 100644
--- a/modules/ts/src/cuda_test.cpp
+++ b/modules/ts/src/cuda_test.cpp
@@ -462,11 +462,7 @@ namespace cvtest
             return false;
         }
 
-#ifdef CV_CXX11
         struct KeyPointLess
-#else
-        struct KeyPointLess : std::binary_function<cv::KeyPoint, cv::KeyPoint, bool>
-#endif
         {
             bool operator()(const cv::KeyPoint& kp1, const cv::KeyPoint& kp2) const
             {
diff --git a/modules/video/CMakeLists.txt b/modules/video/CMakeLists.txt
index df5e49b828f..015c95ca96a 100644
--- a/modules/video/CMakeLists.txt
+++ b/modules/video/CMakeLists.txt
@@ -1,2 +1,2 @@
 set(the_description "Video Analysis")
-ocv_define_module(video opencv_imgproc WRAP java python js)
+ocv_define_module(video opencv_imgproc OPTIONAL opencv_calib3d WRAP java python js)
diff --git a/modules/video/include/opencv2/video.hpp b/modules/video/include/opencv2/video.hpp
index aa644a937a7..a3dde603992 100644
--- a/modules/video/include/opencv2/video.hpp
+++ b/modules/video/include/opencv2/video.hpp
@@ -56,8 +56,4 @@
 #include "opencv2/video/tracking.hpp"
 #include "opencv2/video/background_segm.hpp"
 
-#ifndef DISABLE_OPENCV_24_COMPATIBILITY
-#include "opencv2/video/tracking_c.h"
-#endif
-
 #endif //OPENCV_VIDEO_HPP
diff --git a/modules/video/include/opencv2/video/tracking.hpp b/modules/video/include/opencv2/video/tracking.hpp
index e757b0fa910..228548924b0 100644
--- a/modules/video/include/opencv2/video/tracking.hpp
+++ b/modules/video/include/opencv2/video/tracking.hpp
@@ -249,13 +249,13 @@ where src[i] and dst[i] are the i-th points in src and dst, respectively
 \f[\begin{bmatrix} a_{11} & a_{12} & b_1  \\ -a_{12} & a_{11} & b_2  \end{bmatrix}\f]
 when fullAffine=false.
 
+@deprecated Use cv::estimateAffine2D, cv::estimateAffinePartial2D instead. If you are using this fuction
+with images, extract points using cv::calcOpticalFlowPyrLK and then use the estimation fuctions.
+
 @sa
 estimateAffine2D, estimateAffinePartial2D, getAffineTransform, getPerspectiveTransform, findHomography
  */
-CV_EXPORTS_W Mat estimateRigidTransform( InputArray src, InputArray dst, bool fullAffine);
-CV_EXPORTS_W Mat estimateRigidTransform( InputArray src, InputArray dst, bool fullAffine, int ransacMaxIters, double ransacGoodRatio,
-                                         int ransacSize0);
-
+CV_DEPRECATED CV_EXPORTS Mat estimateRigidTransform( InputArray src, InputArray dst, bool fullAffine );
 
 enum
 {
diff --git a/modules/video/include/opencv2/video/tracking_c.h b/modules/video/include/opencv2/video/tracking_c.h
index 3e32fbd0c0b..740a9fae126 100644
--- a/modules/video/include/opencv2/video/tracking_c.h
+++ b/modules/video/include/opencv2/video/tracking_c.h
@@ -94,10 +94,6 @@ CVAPI(void)  cvCalcAffineFlowPyrLK( const CvArr*  prev, const CvArr*  curr,
                                     char* status, float* track_error,
                                     CvTermCriteria criteria, int flags );
 
-/* Estimate rigid transformation between 2 images or 2 point sets */
-CVAPI(int)  cvEstimateRigidTransform( const CvArr* A, const CvArr* B,
-                                      CvMat* M, int full_affine );
-
 /* Estimate optical flow for each pixel using the two-frame G. Farneback algorithm */
 CVAPI(void) cvCalcOpticalFlowFarneback( const CvArr* prev, const CvArr* next,
                                         CvArr* flow, double pyr_scale, int levels,
diff --git a/modules/video/misc/java/test/BackgroundSubtractorMOGTest.java b/modules/video/misc/java/test/BackgroundSubtractorMOGTest.java
index 9d6f71d1a2f..05c12f1dfaf 100644
--- a/modules/video/misc/java/test/BackgroundSubtractorMOGTest.java
+++ b/modules/video/misc/java/test/BackgroundSubtractorMOGTest.java
@@ -14,12 +14,12 @@ public void testApplyMatMat() {
         Scalar color = new Scalar(128);
         Mat mask = new Mat(rgbLena.size(), CvType.CV_16UC3, new Scalar(1));
 
-        Imgproc.rectangle(rgbLena, bottomRight, topLeft, color, Core.FILLED);
+        Imgproc.rectangle(rgbLena, bottomRight, topLeft, color, Imgproc.FILLED);
 
         backGroundSubtract.apply(rgbLena, mask);
 
         Mat truth = new Mat(rgbLena.size(), rgbLena.type(), new Scalar(0));
-        Imgproc.rectangle(truth, bottomRight, topLeft, color, Core.FILLED);
+        Imgproc.rectangle(truth, bottomRight, topLeft, color, Imgproc.FILLED);
         assertMatEqual(truth, rgbLena);
         */
     }
diff --git a/modules/video/perf/perf_main.cpp b/modules/video/perf/perf_main.cpp
index 2aeb9080478..b6fd57a32db 100644
--- a/modules/video/perf/perf_main.cpp
+++ b/modules/video/perf/perf_main.cpp
@@ -1,3 +1,7 @@
 #include "perf_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_PERF_TEST_MAIN(video)
diff --git a/modules/video/src/compat_video.cpp b/modules/video/src/compat_video.cpp
index 34006b9548a..9e01f925e64 100644
--- a/modules/video/src/compat_video.cpp
+++ b/modules/video/src/compat_video.cpp
@@ -299,21 +299,3 @@ CV_IMPL void cvCalcOpticalFlowFarneback(
     cv::calcOpticalFlowFarneback( prev, next, flow, pyr_scale, levels,
         winsize, iterations, poly_n, poly_sigma, flags );
 }
-
-
-CV_IMPL int
-cvEstimateRigidTransform( const CvArr* arrA, const CvArr* arrB, CvMat* arrM, int full_affine )
-{
-    cv::Mat matA = cv::cvarrToMat(arrA), matB = cv::cvarrToMat(arrB);
-    const cv::Mat matM0 = cv::cvarrToMat(arrM);
-
-    cv::Mat matM = cv::estimateRigidTransform(matA, matB, full_affine != 0);
-    if( matM.empty() )
-    {
-        matM = cv::cvarrToMat(arrM);
-        matM.setTo(cv::Scalar::all(0));
-        return 0;
-    }
-    matM.convertTo(matM0, matM0.type());
-    return 1;
-}
diff --git a/modules/video/src/lkpyramid.cpp b/modules/video/src/lkpyramid.cpp
index 94704681efd..0ec39761522 100644
--- a/modules/video/src/lkpyramid.cpp
+++ b/modules/video/src/lkpyramid.cpp
@@ -45,6 +45,9 @@
 #include "lkpyramid.hpp"
 #include "opencl_kernels_video.hpp"
 #include "opencv2/core/hal/intrin.hpp"
+#ifdef HAVE_OPENCV_CALIB3D
+#include "opencv2/calib3d.hpp"
+#endif
 
 #include "opencv2/core/openvx/ovx_defs.hpp"
 
@@ -60,11 +63,6 @@ static void calcSharrDeriv(const cv::Mat& src, cv::Mat& dst)
     CV_Assert(depth == CV_8U);
     dst.create(rows, cols, CV_MAKETYPE(DataType<deriv_type>::depth, cn*2));
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-    if (tegra::useTegra() && tegra::calcSharrDeriv(src, dst))
-        return;
-#endif
-
     int x, y, delta = (int)alignSize((cols + 2)*cn, 16);
     AutoBuffer<deriv_type> _tempBuf(delta*2 + 64);
     deriv_type *trow0 = alignPtr(_tempBuf.data() + cn, 16), *trow1 = alignPtr(trow0 + delta, 16);
@@ -1378,12 +1376,7 @@ void SparsePyrLKOpticalFlowImpl::calc( InputArray _prevImg, InputArray _nextImg,
         CV_Assert(prevPyr[level * lvlStep1].size() == nextPyr[level * lvlStep2].size());
         CV_Assert(prevPyr[level * lvlStep1].type() == nextPyr[level * lvlStep2].type());
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-        typedef tegra::LKTrackerInvoker<cv::detail::LKTrackerInvoker> LKTrackerInvoker;
-#else
         typedef cv::detail::LKTrackerInvoker LKTrackerInvoker;
-#endif
-
         parallel_for_(Range(0, npoints), LKTrackerInvoker(prevPyr[level * lvlStep1], derivI,
                                                           nextPyr[level * lvlStep2], prevPts, nextPts,
                                                           status, err,
@@ -1408,115 +1401,23 @@ void cv::calcOpticalFlowPyrLK( InputArray _prevImg, InputArray _nextImg,
     optflow->calc(_prevImg,_nextImg,_prevPts,_nextPts,_status,_err);
 }
 
-namespace cv
-{
-
-static void
-getRTMatrix( const std::vector<Point2f> a, const std::vector<Point2f> b,
-             int count, Mat& M, bool fullAffine )
-{
-    CV_Assert( M.isContinuous() );
-
-    if( fullAffine )
-    {
-        double sa[6][6]={{0.}}, sb[6]={0.};
-        Mat A( 6, 6, CV_64F, &sa[0][0] ), B( 6, 1, CV_64F, sb );
-        Mat MM = M.reshape(1, 6);
-
-        for( int i = 0; i < count; i++ )
-        {
-            sa[0][0] += a[i].x*a[i].x;
-            sa[0][1] += a[i].y*a[i].x;
-            sa[0][2] += a[i].x;
-
-            sa[1][1] += a[i].y*a[i].y;
-            sa[1][2] += a[i].y;
-
-            sb[0] += a[i].x*b[i].x;
-            sb[1] += a[i].y*b[i].x;
-            sb[2] += b[i].x;
-            sb[3] += a[i].x*b[i].y;
-            sb[4] += a[i].y*b[i].y;
-            sb[5] += b[i].y;
-        }
-
-        sa[3][4] = sa[4][3] = sa[1][0] = sa[0][1];
-        sa[3][5] = sa[5][3] = sa[2][0] = sa[0][2];
-        sa[4][5] = sa[5][4] = sa[2][1] = sa[1][2];
-
-        sa[3][3] = sa[0][0];
-        sa[4][4] = sa[1][1];
-        sa[5][5] = sa[2][2] = count;
-
-        solve( A, B, MM, DECOMP_EIG );
-    }
-    else
-    {
-        double sa[4][4]={{0.}}, sb[4]={0.}, m[4] = {0};
-        Mat A( 4, 4, CV_64F, sa ), B( 4, 1, CV_64F, sb );
-        Mat MM( 4, 1, CV_64F, m );
-
-        for( int i = 0; i < count; i++ )
-        {
-            sa[0][0] += a[i].x*a[i].x + a[i].y*a[i].y;
-            sa[0][2] += a[i].x;
-            sa[0][3] += a[i].y;
-
-            sb[0] += a[i].x*b[i].x + a[i].y*b[i].y;
-            sb[1] += a[i].x*b[i].y - a[i].y*b[i].x;
-            sb[2] += b[i].x;
-            sb[3] += b[i].y;
-        }
-
-        sa[1][1] = sa[0][0];
-        sa[2][1] = sa[1][2] = -sa[0][3];
-        sa[3][1] = sa[1][3] = sa[2][0] = sa[0][2];
-        sa[2][2] = sa[3][3] = count;
-        sa[3][0] = sa[0][3];
-
-        solve( A, B, MM, DECOMP_EIG );
-
-        double* om = M.ptr<double>();
-        om[0] = om[4] = m[0];
-        om[1] = -m[1];
-        om[3] = m[1];
-        om[2] = m[2];
-        om[5] = m[3];
-    }
-}
-
-}
-
 cv::Mat cv::estimateRigidTransform( InputArray src1, InputArray src2, bool fullAffine )
-{
-    return estimateRigidTransform(src1, src2, fullAffine, 500, 0.5, 3);
-}
-
-cv::Mat cv::estimateRigidTransform( InputArray src1, InputArray src2, bool fullAffine, int ransacMaxIters, double ransacGoodRatio,
-                                    const int ransacSize0)
 {
     CV_INSTRUMENT_REGION()
-
-    Mat M(2, 3, CV_64F), A = src1.getMat(), B = src2.getMat();
+#ifndef HAVE_OPENCV_CALIB3D
+    CV_UNUSED(src1); CV_UNUSED(src2); CV_UNUSED(fullAffine);
+    CV_Error(Error::StsError, "estimateRigidTransform requires calib3d module");
+#else
+    Mat A = src1.getMat(), B = src2.getMat();
 
     const int COUNT = 15;
     const int WIDTH = 160, HEIGHT = 120;
 
     std::vector<Point2f> pA, pB;
-    std::vector<int> good_idx;
     std::vector<uchar> status;
 
     double scale = 1.;
-    int i, j, k, k1;
-
-    RNG rng((uint64)-1);
-    int good_count = 0;
-
-    if( ransacSize0 < 3 )
-        CV_Error( Error::StsBadArg, "ransacSize0 should have value bigger than 2.");
-
-    if( ransacGoodRatio > 1 || ransacGoodRatio < 0)
-        CV_Error( Error::StsBadArg, "ransacGoodRatio should have value between 0 and 1");
+    int i, j, k;
 
     if( A.size() != B.size() )
         CV_Error( Error::StsUnmatchedSizes, "Both input images must have the same size" );
@@ -1528,11 +1429,13 @@ cv::Mat cv::estimateRigidTransform( InputArray src1, InputArray src2, bool fullA
 
     if( count > 0 )
     {
+        // inputs are points
         A.reshape(2, count).convertTo(pA, CV_32F);
         B.reshape(2, count).convertTo(pB, CV_32F);
     }
     else if( A.depth() == CV_8U )
     {
+        // inputs are images
         int cn = A.channels();
         CV_Assert( cn == 1 || cn == 3 || cn == 4 );
         Size sz0 = A.size();
@@ -1604,108 +1507,13 @@ cv::Mat cv::estimateRigidTransform( InputArray src1, InputArray src2, bool fullA
     else
         CV_Error( Error::StsUnsupportedFormat, "Both input images must have either 8uC1 or 8uC3 type" );
 
-    good_idx.resize(count);
-
-    if( count < ransacSize0 )
-        return Mat();
-
-    Rect brect = boundingRect(pB);
-
-    std::vector<Point2f> a(ransacSize0);
-    std::vector<Point2f> b(ransacSize0);
-
-    // RANSAC stuff:
-    // 1. find the consensus
-    for( k = 0; k < ransacMaxIters; k++ )
+    if (fullAffine)
     {
-        std::vector<int> idx(ransacSize0);
-        // choose random 3 non-complanar points from A & B
-        for( i = 0; i < ransacSize0; i++ )
-        {
-            for( k1 = 0; k1 < ransacMaxIters; k1++ )
-            {
-                idx[i] = rng.uniform(0, count);
-
-                for( j = 0; j < i; j++ )
-                {
-                    if( idx[j] == idx[i] )
-                        break;
-                    // check that the points are not very close one each other
-                    if( fabs(pA[idx[i]].x - pA[idx[j]].x) +
-                        fabs(pA[idx[i]].y - pA[idx[j]].y) < FLT_EPSILON )
-                        break;
-                    if( fabs(pB[idx[i]].x - pB[idx[j]].x) +
-                        fabs(pB[idx[i]].y - pB[idx[j]].y) < FLT_EPSILON )
-                        break;
-                }
-
-                if( j < i )
-                    continue;
-
-                if( i+1 == ransacSize0 )
-                {
-                    // additional check for non-complanar vectors
-                    a[0] = pA[idx[0]];
-                    a[1] = pA[idx[1]];
-                    a[2] = pA[idx[2]];
-
-                    b[0] = pB[idx[0]];
-                    b[1] = pB[idx[1]];
-                    b[2] = pB[idx[2]];
-
-                    double dax1 = a[1].x - a[0].x, day1 = a[1].y - a[0].y;
-                    double dax2 = a[2].x - a[0].x, day2 = a[2].y - a[0].y;
-                    double dbx1 = b[1].x - b[0].x, dby1 = b[1].y - b[0].y;
-                    double dbx2 = b[2].x - b[0].x, dby2 = b[2].y - b[0].y;
-                    const double eps = 0.01;
-
-                    if( fabs(dax1*day2 - day1*dax2) < eps*std::sqrt(dax1*dax1+day1*day1)*std::sqrt(dax2*dax2+day2*day2) ||
-                        fabs(dbx1*dby2 - dby1*dbx2) < eps*std::sqrt(dbx1*dbx1+dby1*dby1)*std::sqrt(dbx2*dbx2+dby2*dby2) )
-                        continue;
-                }
-                break;
-            }
-
-            if( k1 >= ransacMaxIters )
-                break;
-        }
-
-        if( i < ransacSize0 )
-            continue;
-
-        // estimate the transformation using 3 points
-        getRTMatrix( a, b, 3, M, fullAffine );
-
-        const double* m = M.ptr<double>();
-        for( i = 0, good_count = 0; i < count; i++ )
-        {
-            if( std::abs( m[0]*pA[i].x + m[1]*pA[i].y + m[2] - pB[i].x ) +
-                std::abs( m[3]*pA[i].x + m[4]*pA[i].y + m[5] - pB[i].y ) < std::max(brect.width,brect.height)*0.05 )
-                good_idx[good_count++] = i;
-        }
-
-        if( good_count >= count*ransacGoodRatio )
-            break;
+        return estimateAffine2D(pA, pB);
     }
-
-    if( k >= ransacMaxIters )
-        return Mat();
-
-    if( good_count < count )
+    else
     {
-        for( i = 0; i < good_count; i++ )
-        {
-            j = good_idx[i];
-            pA[i] = pA[j];
-            pB[i] = pB[j];
-        }
+        return estimateAffinePartial2D(pA, pB);
     }
-
-    getRTMatrix( pA, pB, good_count, M, fullAffine );
-    M.at<double>(0, 2) /= scale;
-    M.at<double>(1, 2) /= scale;
-
-    return M;
+#endif
 }
-
-/* End of file. */
diff --git a/modules/video/src/precomp.hpp b/modules/video/src/precomp.hpp
index 5f1bbf827dd..aac0c5734f7 100644
--- a/modules/video/src/precomp.hpp
+++ b/modules/video/src/precomp.hpp
@@ -49,8 +49,4 @@
 #include "opencv2/core/ocl.hpp"
 #include "opencv2/core.hpp"
 
-#ifdef HAVE_TEGRA_OPTIMIZATION
-#include "opencv2/video/video_tegra.hpp"
-#endif
-
 #endif
diff --git a/modules/video/test/test_estimaterigid.cpp b/modules/video/test/test_estimaterigid.cpp
index 5fed70465fa..0b4179732f6 100644
--- a/modules/video/test/test_estimaterigid.cpp
+++ b/modules/video/test/test_estimaterigid.cpp
@@ -42,6 +42,15 @@
 
 #include "test_precomp.hpp"
 
+// this is test for a deprecated function. let's ignore deprecated warnings in this file
+#if defined(__clang__)
+    #pragma clang diagnostic ignored "-Wdeprecated-declarations"
+#elif defined(__GNUC__)
+    #pragma GCC diagnostic ignored "-Wdeprecated-declarations"
+#elif defined(_MSC_VER)
+    #pragma warning( disable : 4996)
+#endif
+
 namespace opencv_test { namespace {
 
 class CV_RigidTransform_Test : public cvtest::BaseTest
diff --git a/modules/video/test/test_main.cpp b/modules/video/test/test_main.cpp
index 0e51ddfd050..93e4d2860eb 100644
--- a/modules/video/test/test_main.cpp
+++ b/modules/video/test/test_main.cpp
@@ -3,4 +3,8 @@
 // of this distribution and at http://opencv.org/license.html.
 #include "test_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_TEST_MAIN("cv")
diff --git a/modules/videoio/CMakeLists.txt b/modules/videoio/CMakeLists.txt
index f5eba046c54..dc3e0233eda 100644
--- a/modules/videoio/CMakeLists.txt
+++ b/modules/videoio/CMakeLists.txt
@@ -220,6 +220,12 @@ if(HAVE_INTELPERC)
   list(APPEND VIDEOIO_LIBRARIES ${INTELPERC_LIBRARIES})
 endif(HAVE_INTELPERC)
 
+if(HAVE_LIBREALSENSE)
+  list(APPEND videoio_srcs ${CMAKE_CURRENT_LIST_DIR}/src/cap_librealsense.cpp)
+  ocv_include_directories(${LIBREALSENSE_INCLUDE_DIR})
+  list(APPEND VIDEOIO_LIBRARIES ${LIBREALSENSE_LIBRARIES})
+endif(HAVE_LIBREALSENSE)
+
 if(HAVE_GPHOTO2)
   list(APPEND videoio_srcs ${CMAKE_CURRENT_LIST_DIR}/src/cap_gphoto2.cpp)
 endif(HAVE_GPHOTO2)
diff --git a/modules/videoio/perf/perf_main.cpp b/modules/videoio/perf/perf_main.cpp
index 70a7a47f999..433209a5951 100644
--- a/modules/videoio/perf/perf_main.cpp
+++ b/modules/videoio/perf/perf_main.cpp
@@ -3,4 +3,8 @@
 // of this distribution and at http://opencv.org/license.html
 #include "perf_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_PERF_TEST_MAIN(videoio)
diff --git a/modules/videoio/src/cap_librealsense.cpp b/modules/videoio/src/cap_librealsense.cpp
new file mode 100644
index 00000000000..4ef1c76f71a
--- /dev/null
+++ b/modules/videoio/src/cap_librealsense.cpp
@@ -0,0 +1,111 @@
+// This file is part of OpenCV project.
+// It is subject to the license terms in the LICENSE file found in the top-level directory
+// of this distribution and at http://opencv.org/license.html.
+
+#include "precomp.hpp"
+
+#ifdef HAVE_LIBREALSENSE
+#include "cap_librealsense.hpp"
+
+namespace cv
+{
+
+VideoCapture_LibRealsense::VideoCapture_LibRealsense(int) : mAlign(RS2_STREAM_COLOR)
+{
+    try
+    {
+        rs2::config config;
+        // Configure all streams to run at VGA resolution at default fps
+        config.enable_stream(RS2_STREAM_DEPTH, 640, 480, RS2_FORMAT_Z16);
+        config.enable_stream(RS2_STREAM_COLOR, 640, 480, RS2_FORMAT_BGR8);
+        config.enable_stream(RS2_STREAM_INFRARED, 640, 480, RS2_FORMAT_Y8);
+        mPipe.start();
+    }
+    catch (const rs2::error&)
+    {
+    }
+}
+VideoCapture_LibRealsense::~VideoCapture_LibRealsense(){}
+
+double VideoCapture_LibRealsense::getProperty(int prop) const
+{
+    double propValue = 0;
+
+    if (prop == CAP_PROP_INTELPERC_DEPTH_SATURATION_VALUE)
+        return mPipe.get_active_profile().get_device().first<rs2::depth_sensor>().get_depth_scale();
+
+    return propValue;
+}
+bool VideoCapture_LibRealsense::setProperty(int, double)
+{
+    bool isSet = false;
+    return isSet;
+}
+
+bool VideoCapture_LibRealsense::grabFrame()
+{
+    if (!isOpened())
+        return false;
+
+    try
+    {
+        mData = mAlign.process(mPipe.wait_for_frames());
+    }
+    catch (const rs2::error&)
+    {
+        return false;
+    }
+
+    return true;
+}
+bool VideoCapture_LibRealsense::retrieveFrame(int outputType, cv::OutputArray frame)
+{
+    rs2::video_frame _frame(nullptr);
+    int type;
+    switch (outputType)
+    {
+    case CAP_INTELPERC_DEPTH_MAP:
+        _frame = mData.get_depth_frame().as<rs2::video_frame>();
+        type = CV_16UC1;
+        break;
+    case CAP_INTELPERC_IR_MAP:
+        _frame = mData.get_infrared_frame();
+        type = CV_8UC1;
+        break;
+    case CAP_INTELPERC_IMAGE:
+        _frame = mData.get_color_frame();
+        type = CV_8UC3;
+        break;
+    default:
+        return false;
+    }
+
+    try
+    {
+        // we copy the data straight away, so const_cast should be fine
+        void* data = const_cast<void*>(_frame.get_data());
+        Mat(_frame.get_height(), _frame.get_width(), type, data, _frame.get_stride_in_bytes()).copyTo(frame);
+
+        if(_frame.get_profile().format() == RS2_FORMAT_RGB8)
+            cvtColor(frame, frame, COLOR_RGB2BGR);
+    }
+    catch (const rs2::error&)
+    {
+        return false;
+    }
+
+    return true;
+}
+int VideoCapture_LibRealsense::getCaptureDomain()
+{
+    return CAP_INTELPERC;
+}
+
+bool VideoCapture_LibRealsense::isOpened() const
+{
+    return bool(std::shared_ptr<rs2_pipeline>(mPipe));
+}
+
+}
+
+#endif
diff --git a/modules/videoio/src/cap_librealsense.hpp b/modules/videoio/src/cap_librealsense.hpp
new file mode 100644
index 00000000000..81d17e23604
--- /dev/null
+++ b/modules/videoio/src/cap_librealsense.hpp
@@ -0,0 +1,37 @@
+// This file is part of OpenCV project.
+// It is subject to the license terms in the LICENSE file found in the top-level directory
+// of this distribution and at http://opencv.org/license.html.
+
+#ifndef _CAP_LIBREALSENE_HPP_
+#define _CAP_LIBREALSENE_HPP_
+
+#ifdef HAVE_LIBREALSENSE
+
+#include <librealsense2/rs.hpp>
+
+namespace cv
+{
+
+class VideoCapture_LibRealsense : public IVideoCapture
+{
+public:
+    VideoCapture_LibRealsense(int index);
+    virtual ~VideoCapture_LibRealsense();
+
+    virtual double getProperty(int propIdx) const CV_OVERRIDE;
+    virtual bool setProperty(int propIdx, double propVal) CV_OVERRIDE;
+
+    virtual bool grabFrame() CV_OVERRIDE;
+    virtual bool retrieveFrame(int outputType, OutputArray frame) CV_OVERRIDE;
+    virtual int getCaptureDomain() CV_OVERRIDE;
+    virtual bool isOpened() const CV_OVERRIDE;
+protected:
+    rs2::pipeline mPipe;
+    rs2::frameset mData;
+    rs2::align    mAlign;
+};
+
+}
+
+#endif
+#endif
diff --git a/modules/videoio/src/cap_v4l.cpp b/modules/videoio/src/cap_v4l.cpp
index 0416231f65e..524fc0d35eb 100644
--- a/modules/videoio/src/cap_v4l.cpp
+++ b/modules/videoio/src/cap_v4l.cpp
@@ -442,7 +442,8 @@ static int autosetup_capture_mode_v4l2(CvCaptureCAM_V4L* capture) {
             V4L2_PIX_FMT_MJPEG,
             V4L2_PIX_FMT_JPEG,
 #endif
-            V4L2_PIX_FMT_Y16
+            V4L2_PIX_FMT_Y16,
+            V4L2_PIX_FMT_GREY
     };
 
     for (size_t i = 0; i < sizeof(try_order) / sizeof(__u32); i++) {
@@ -536,6 +537,7 @@ static int v4l2_num_channels(__u32 palette) {
     case V4L2_PIX_FMT_MJPEG:
     case V4L2_PIX_FMT_JPEG:
     case V4L2_PIX_FMT_Y16:
+    case V4L2_PIX_FMT_GREY:
         return 1;
     case V4L2_PIX_FMT_YUYV:
     case V4L2_PIX_FMT_UYVY:
@@ -1090,6 +1092,13 @@ y16_to_rgb24 (int width, int height, unsigned char* src, unsigned char* dst)
     cvtColor(gray8,Mat(height, width, CV_8UC3, dst),COLOR_GRAY2BGR);
 }
 
+static inline void
+y8_to_rgb24 (int width, int height, unsigned char* src, unsigned char* dst)
+{
+    Mat gray8(height, width, CV_8UC1, src);
+    cvtColor(gray8,Mat(height, width, CV_8UC3, dst),COLOR_GRAY2BGR);
+}
+
 #ifdef HAVE_JPEG
 
 /* convert from mjpeg to rgb24 */
@@ -1561,6 +1570,18 @@ static IplImage* icvRetrieveFrameCAM_V4L( CvCaptureCAM_V4L* capture, int) {
                     capture->frame.imageSize);
         }
         break;
+    case V4L2_PIX_FMT_GREY:
+        if(capture->convert_rgb){
+            y8_to_rgb24(capture->form.fmt.pix.width,
+                    capture->form.fmt.pix.height,
+                    (unsigned char*)capture->buffers[capture->bufferIndex].start,
+                    (unsigned char*)capture->frame.imageData);
+        }else{
+            memcpy((char *)capture->frame.imageData,
+                    (char *)capture->buffers[capture->bufferIndex].start,
+                    capture->frame.imageSize);
+        }
+        break;
     }
 
     if (capture->returnFrame)
diff --git a/modules/videoio/src/videoio_registry.cpp b/modules/videoio/src/videoio_registry.cpp
index 85fc239ad95..e3d0bcab951 100644
--- a/modules/videoio/src/videoio_registry.cpp
+++ b/modules/videoio/src/videoio_registry.cpp
@@ -9,6 +9,7 @@
 #include "opencv2/videoio/registry.hpp"
 
 #include "cap_intelperc.hpp"
+#include "cap_librealsense.hpp"
 #include "cap_dshow.hpp"
 
 #ifdef HAVE_MFX
@@ -101,6 +102,8 @@ static const struct VideoBackendInfo builtin_backends[] =
 #endif
 #ifdef HAVE_INTELPERC
     DECLARE_BACKEND(CAP_INTELPERC, "INTEL_PERC", MODE_CAPTURE_BY_INDEX),
+#elif defined(HAVE_LIBREALSENSE)
+    DECLARE_BACKEND(CAP_INTELPERC, "INTEL_REALSENSE", MODE_CAPTURE_BY_INDEX),
 #endif
 
     // OpenCV file-based only
@@ -425,6 +428,10 @@ void VideoCapture_create(CvCapture*& capture, Ptr<IVideoCapture>& icap, VideoCap
     case CAP_INTELPERC:
         TRY_OPEN(makePtr<VideoCapture_IntelPerC>());
         break;
+#elif defined(HAVE_LIBREALSENSE)
+    case CAP_INTELPERC:
+        TRY_OPEN(makePtr<VideoCapture_LibRealsense>(index));
+        break;
 #endif
 #ifdef WINRT_VIDEO
     case CAP_WINRT:
diff --git a/modules/videoio/test/test_main.cpp b/modules/videoio/test/test_main.cpp
index 4eb2abd8f87..d2483270466 100644
--- a/modules/videoio/test/test_main.cpp
+++ b/modules/videoio/test/test_main.cpp
@@ -3,4 +3,8 @@
 // of this distribution and at http://opencv.org/license.html.
 #include "test_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_TEST_MAIN("highgui")
diff --git a/modules/videostab/src/inpainting.cpp b/modules/videostab/src/inpainting.cpp
index 3fad005318f..1cd2e2391f5 100644
--- a/modules/videostab/src/inpainting.cpp
+++ b/modules/videostab/src/inpainting.cpp
@@ -325,6 +325,9 @@ class MotionInpaintBody
 };
 
 
+#ifdef _MSC_VER
+#pragma warning(disable: 4702)  // unreachable code
+#endif
 MotionInpainter::MotionInpainter()
 {
 #ifdef HAVE_OPENCV_CUDAOPTFLOW
diff --git a/modules/videostab/test/test_main.cpp b/modules/videostab/test/test_main.cpp
index bbe14318988..1eff6818990 100644
--- a/modules/videostab/test/test_main.cpp
+++ b/modules/videostab/test/test_main.cpp
@@ -4,4 +4,8 @@
 
 #include "test_precomp.hpp"
 
+#if defined(HAVE_HPX)
+    #include <hpx/hpx_main.hpp>
+#endif
+
 CV_TEST_MAIN("cv")
diff --git a/modules/viz/include/opencv2/viz/viz3d.hpp b/modules/viz/include/opencv2/viz/viz3d.hpp
index 226c9e90c4b..b761224a00b 100644
--- a/modules/viz/include/opencv2/viz/viz3d.hpp
+++ b/modules/viz/include/opencv2/viz/viz3d.hpp
@@ -144,7 +144,7 @@ namespace cv
 
             /** @brief Returns the current pose of the viewer.
             */
-            Affine3d getViewerPose();
+            Affine3d getViewerPose() const;
 
             /** @brief Sets pose of the viewer.
 
diff --git a/modules/viz/include/opencv2/viz/widgets.hpp b/modules/viz/include/opencv2/viz/widgets.hpp
index 1b73110b587..4e2a4565d0f 100644
--- a/modules/viz/include/opencv2/viz/widgets.hpp
+++ b/modules/viz/include/opencv2/viz/widgets.hpp
@@ -95,7 +95,7 @@ namespace cv
             Widget();
             Widget(const Widget& other);
             Widget& operator=(const Widget& other);
-            ~Widget();
+            virtual ~Widget();
 
             /** @brief Creates a widget from ply file.
 
diff --git a/modules/viz/src/viz3d.cpp b/modules/viz/src/viz3d.cpp
index 7f201222a47..98ccca47f1c 100644
--- a/modules/viz/src/viz3d.cpp
+++ b/modules/viz/src/viz3d.cpp
@@ -127,7 +127,7 @@ cv::Affine3d cv::viz::Viz3d::getWidgetPose(const String &id) const { return impl
 void cv::viz::Viz3d::setCamera(const Camera &camera) { impl_->setCamera(camera); }
 cv::viz::Camera cv::viz::Viz3d::getCamera() const { return impl_->getCamera(); }
 void cv::viz::Viz3d::setViewerPose(const Affine3d &pose) { impl_->setViewerPose(pose); }
-cv::Affine3d cv::viz::Viz3d::getViewerPose() { return impl_->getViewerPose(); }
+cv::Affine3d cv::viz::Viz3d::getViewerPose() const { return impl_->getViewerPose(); }
 
 void cv::viz::Viz3d::resetCameraViewpoint(const String &id) { impl_->resetCameraViewpoint(id); }
 void cv::viz::Viz3d::resetCamera() { impl_->resetCamera(); }
diff --git a/platforms/android/build-tests/test_cmake_build.py b/platforms/android/build-tests/test_cmake_build.py
index f02915c611d..eb4d43512ab 100644
--- a/platforms/android/build-tests/test_cmake_build.py
+++ b/platforms/android/build-tests/test_cmake_build.py
@@ -8,12 +8,17 @@
 
 CMAKE_TEMPLATE='''\
 CMAKE_MINIMUM_REQUIRED(VERSION 2.8)
+
+# Enable C++11
+set(CMAKE_CXX_STANDARD 11)
+set(CMAKE_CXX_STANDARD_REQUIRED TRUE)
+
 SET(PROJECT_NAME hello-android)
 PROJECT(${PROJECT_NAME})
+
 FIND_PACKAGE(OpenCV REQUIRED %(libset)s)
-INCLUDE_DIRECTORIES(${CMAKE_CURRENT_SOURCE_DIR})
-INCLUDE_DIRECTORIES(${OpenCV_INCLUDE_DIRS})
 FILE(GLOB srcs "*.cpp")
+
 ADD_EXECUTABLE(${PROJECT_NAME} ${srcs})
 TARGET_LINK_LIBRARIES(${PROJECT_NAME} ${OpenCV_LIBS} dl z)
 '''
@@ -28,9 +33,9 @@
 {
   (void)argc; (void)argv;
   printf("%s\\n", message);
-  Size textsize = getTextSize(message, CV_FONT_HERSHEY_COMPLEX, 3, 5, 0);
+  Size textsize = getTextSize(message, FONT_HERSHEY_COMPLEX, 3, 5, 0);
   Mat img(textsize.height + 20, textsize.width + 20, CV_32FC1, Scalar(230,230,230));
-  putText(img, message, Point(10, img.rows - 10), CV_FONT_HERSHEY_COMPLEX, 3, Scalar(0, 0, 0), 5);
+  putText(img, message, Point(10, img.rows - 10), FONT_HERSHEY_COMPLEX, 3, Scalar(0, 0, 0), 5);
   imwrite("/mnt/sdcard/HelloAndroid.png", img);
   return 0;
 }
diff --git a/platforms/android/build-tests/test_ndk_build.py b/platforms/android/build-tests/test_ndk_build.py
index cbc2b7c6aba..cc1dbc01026 100644
--- a/platforms/android/build-tests/test_ndk_build.py
+++ b/platforms/android/build-tests/test_ndk_build.py
@@ -22,7 +22,7 @@
 
 TEMPLATE_APPLICATION_MK = '''\
 APP_STL := gnustl_static
-APP_CPPFLAGS := -frtti -fexceptions
+APP_CPPFLAGS := -frtti -fexceptions -std=c++11
 APP_ABI := {abi}
 APP_PLATFORM := android-9
 '''
diff --git a/platforms/js/build_js.py b/platforms/js/build_js.py
index 3ff69c05e54..c3df51b79b0 100644
--- a/platforms/js/build_js.py
+++ b/platforms/js/build_js.py
@@ -129,7 +129,7 @@ def get_cmake_cmd(self):
                "-DWITH_ITT=OFF",
                "-DBUILD_ZLIB=ON",
                "-DBUILD_opencv_apps=OFF",
-               "-DBUILD_opencv_calib3d=OFF",
+               "-DBUILD_opencv_calib3d=ON",
                "-DBUILD_opencv_dnn=ON",
                "-DBUILD_opencv_features2d=OFF",
                "-DBUILD_opencv_flann=OFF",
diff --git a/samples/CMakeLists.txt b/samples/CMakeLists.txt
index 5daa941df0a..15aff36c39f 100644
--- a/samples/CMakeLists.txt
+++ b/samples/CMakeLists.txt
@@ -79,7 +79,11 @@ else()
 #  Standalone mode
 #
 #===================================================================================================
-cmake_minimum_required(VERSION 2.8)
+cmake_minimum_required(VERSION 3.1)
+
+# Enable C++11
+set(CMAKE_CXX_STANDARD 11)
+set(CMAKE_CXX_STANDARD_REQUIRED TRUE)
 
 project(samples C CXX)
 option(BUILD_EXAMPLES "Build samples" ON)
diff --git a/samples/android/camera-calibration/src/org/opencv/samples/cameracalibration/CameraCalibrator.java b/samples/android/camera-calibration/src/org/opencv/samples/cameracalibration/CameraCalibrator.java
index 47ebeb89f5a..5927b967d57 100644
--- a/samples/android/camera-calibration/src/org/opencv/samples/cameracalibration/CameraCalibrator.java
+++ b/samples/android/camera-calibration/src/org/opencv/samples/cameracalibration/CameraCalibrator.java
@@ -141,7 +141,7 @@ private void renderFrame(Mat rgbaFrame) {
         drawPoints(rgbaFrame);
 
         Imgproc.putText(rgbaFrame, "Captured: " + mCornersBuffer.size(), new Point(rgbaFrame.cols() / 3 * 2, rgbaFrame.rows() * 0.1),
-                Core.FONT_HERSHEY_SIMPLEX, 1.0, new Scalar(255, 255, 0));
+                Imgproc.FONT_HERSHEY_SIMPLEX, 1.0, new Scalar(255, 255, 0));
     }
 
     public Mat getCameraMatrix() {
diff --git a/samples/android/camera-calibration/src/org/opencv/samples/cameracalibration/OnCameraFrameRender.java b/samples/android/camera-calibration/src/org/opencv/samples/cameracalibration/OnCameraFrameRender.java
index 85a85040c02..311f4d5cae1 100644
--- a/samples/android/camera-calibration/src/org/opencv/samples/cameracalibration/OnCameraFrameRender.java
+++ b/samples/android/camera-calibration/src/org/opencv/samples/cameracalibration/OnCameraFrameRender.java
@@ -83,9 +83,9 @@ public Mat render(CvCameraViewFrame inputFrame) {
         Imgproc.fillPoly(comparisonFrame, border, new Scalar(255, 255, 255));
 
         Imgproc.putText(comparisonFrame, mResources.getString(R.string.original), new Point(mWidth * 0.1, mHeight * 0.1),
-                Core.FONT_HERSHEY_SIMPLEX, 1.0, new Scalar(255, 255, 0));
+                Imgproc.FONT_HERSHEY_SIMPLEX, 1.0, new Scalar(255, 255, 0));
         Imgproc.putText(comparisonFrame, mResources.getString(R.string.undistorted), new Point(mWidth * 0.6, mHeight * 0.1),
-                Core.FONT_HERSHEY_SIMPLEX, 1.0, new Scalar(255, 255, 0));
+                Imgproc.FONT_HERSHEY_SIMPLEX, 1.0, new Scalar(255, 255, 0));
 
         return comparisonFrame;
     }
diff --git a/samples/android/mobilenet-objdetect/src/org/opencv/samples/opencv_mobilenet/MainActivity.java b/samples/android/mobilenet-objdetect/src/org/opencv/samples/opencv_mobilenet/MainActivity.java
index 31440e2c853..3b62cc1e1a1 100644
--- a/samples/android/mobilenet-objdetect/src/org/opencv/samples/opencv_mobilenet/MainActivity.java
+++ b/samples/android/mobilenet-objdetect/src/org/opencv/samples/opencv_mobilenet/MainActivity.java
@@ -127,16 +127,16 @@ public Mat onCameraFrame(CvCameraViewFrame inputFrame) {
                         new Scalar(0, 255, 0));
                 String label = classNames[classId] + ": " + confidence;
                 int[] baseLine = new int[1];
-                Size labelSize = Imgproc.getTextSize(label, Core.FONT_HERSHEY_SIMPLEX, 0.5, 1, baseLine);
+                Size labelSize = Imgproc.getTextSize(label, Imgproc.FONT_HERSHEY_SIMPLEX, 0.5, 1, baseLine);
 
                 // Draw background for label.
                 Imgproc.rectangle(subFrame, new Point(xLeftBottom, yLeftBottom - labelSize.height),
                         new Point(xLeftBottom + labelSize.width, yLeftBottom + baseLine[0]),
-                        new Scalar(255, 255, 255), Core.FILLED);
+                        new Scalar(255, 255, 255), Imgproc.FILLED);
 
                 // Write class name and confidence.
                 Imgproc.putText(subFrame, label, new Point(xLeftBottom, yLeftBottom),
-                        Core.FONT_HERSHEY_SIMPLEX, 0.5, new Scalar(0, 0, 0));
+                        Imgproc.FONT_HERSHEY_SIMPLEX, 0.5, new Scalar(0, 0, 0));
             }
         }
         return frame;
diff --git a/samples/android/tutorial-4-opencl/src/org/opencv/samples/tutorial4/NativePart.java b/samples/android/tutorial-4-opencl/src/org/opencv/samples/tutorial4/NativePart.java
index e5f11ba3aef..e3d11709a9e 100644
--- a/samples/android/tutorial-4-opencl/src/org/opencv/samples/tutorial4/NativePart.java
+++ b/samples/android/tutorial-4-opencl/src/org/opencv/samples/tutorial4/NativePart.java
@@ -3,7 +3,7 @@
 public class NativePart {
     static
     {
-        System.loadLibrary("opencv_java3");
+        System.loadLibrary("opencv_java4");
         System.loadLibrary("JNIpart");
     }
 
diff --git a/samples/cpp/ela.cpp b/samples/cpp/ela.cpp
new file mode 100644
index 00000000000..ca98bf9f85e
--- /dev/null
+++ b/samples/cpp/ela.cpp
@@ -0,0 +1,79 @@
+/**
+  @file ela.cpp
+  @author Alessandro de Oliveira Faria (A.K.A. CABELO)
+  @brief Error Level Analysis (ELA) permits identifying areas within an image that are at different compression levels. With JPEG images, the entire picture should be at roughly the same level. If a section of the image is at a significantly different error level, then it likely indicates a digital modification. This example allows to see visually the changes made in a JPG image based in it's compression error analysis. Questions and suggestions email to: Alessandro de Oliveira Faria cabelo[at]opensuse[dot]org or OpenCV Team.
+  @date Jun 24, 2018
+*/
+
+#include <opencv2/highgui/highgui.hpp>
+#include <iostream>
+#include <vector>
+
+const char* keys =
+    "{ help h      | | Print help message. }"
+    "{ input i     | | Input image to calc ELA algorithm. }";
+
+using namespace cv;
+
+int scale_value = 7;
+int quality = 95;
+Mat image;
+Mat compressed_img;
+const char* decodedwin = "the recompressed image";
+const char* diffwin = "scaled difference between the original and recompressed images";
+
+static void processImage(int , void*)
+{
+    Mat Ela;
+
+    // Compression jpeg
+    std::vector<int> compressing_factor;
+    std::vector<uchar> buf;
+
+    compressing_factor.push_back(IMWRITE_JPEG_QUALITY);
+    compressing_factor.push_back(quality);
+
+    imencode(".jpg", image, buf, compressing_factor);
+
+    compressed_img = imdecode(buf, 1);
+
+    Mat output;
+    absdiff(image,compressed_img,output);
+    output.convertTo(Ela, CV_8UC3, scale_value);
+
+    // Shows processed image
+    imshow(decodedwin, compressed_img);
+    imshow(diffwin, Ela);
+}
+
+int main (int argc, char* argv[])
+{
+
+    CommandLineParser parser(argc, argv, keys);
+    if(argc == 1 || parser.has("help"))
+    {
+        parser.printMessage();
+        std::cout << "\nJpeg Recompression Example:\n\t" << argv[0] << " --input=../../data/ela_modified.jpg\n";
+        return 0;
+    }
+
+    if(parser.has("input"))
+    {
+        // Read the new image
+        image = imread(parser.get<String>("input"));
+    }
+    // Check image
+    if (!image.empty())
+    {
+        processImage(0, 0);
+        createTrackbar("Scale", diffwin, &scale_value, 100, processImage);
+        createTrackbar("Quality", diffwin, &quality, 100, processImage);
+        waitKey(0);
+    }
+    else
+    {
+        std::cout << "> Error in load image\n";
+    }
+
+    return 0;
+}
diff --git a/samples/cpp/example_cmake/CMakeLists.txt b/samples/cpp/example_cmake/CMakeLists.txt
index 00c1687fa02..f7c5b6bbd6e 100644
--- a/samples/cpp/example_cmake/CMakeLists.txt
+++ b/samples/cpp/example_cmake/CMakeLists.txt
@@ -1,5 +1,9 @@
 # cmake needs this line
-cmake_minimum_required(VERSION 2.8)
+cmake_minimum_required(VERSION 3.1)
+
+# Enable C++11
+set(CMAKE_CXX_STANDARD 11)
+set(CMAKE_CXX_STANDARD_REQUIRED TRUE)
 
 # Define project name
 project(opencv_example_project)
@@ -18,11 +22,6 @@ message(STATUS "    version: ${OpenCV_VERSION}")
 message(STATUS "    libraries: ${OpenCV_LIBS}")
 message(STATUS "    include path: ${OpenCV_INCLUDE_DIRS}")
 
-if(CMAKE_VERSION VERSION_LESS "2.8.11")
-  # Add OpenCV headers location to your include paths
-  include_directories(${OpenCV_INCLUDE_DIRS})
-endif()
-
 # Declare the executable target built from your sources
 add_executable(opencv_example example.cpp)
 
diff --git a/samples/cpp/facial_features.cpp b/samples/cpp/facial_features.cpp
index 4fdfcb74d84..6dbef75c49d 100644
--- a/samples/cpp/facial_features.cpp
+++ b/samples/cpp/facial_features.cpp
@@ -89,7 +89,7 @@ static void help()
         "\tThis will detect only the face in image.jpg.\n";
 
     cout << " \n\nThe classifiers for face and eyes can be downloaded from : "
-        " \nhttps://github.com/opencv/opencv/tree/3.4/data/haarcascades";
+        " \nhttps://github.com/opencv/opencv/tree/master/data/haarcascades";
 
     cout << "\n\nThe classifiers for nose and mouth can be downloaded from : "
         " \nhttps://github.com/opencv/opencv_contrib/tree/master/modules/face/data/cascades\n";
diff --git a/samples/data/ela_modified.jpg b/samples/data/ela_modified.jpg
new file mode 100644
index 00000000000..7b4be661ace
Binary files /dev/null and b/samples/data/ela_modified.jpg differ
diff --git a/samples/data/ela_original.jpg b/samples/data/ela_original.jpg
new file mode 100644
index 00000000000..6790ad47315
Binary files /dev/null and b/samples/data/ela_original.jpg differ
diff --git a/samples/dnn/README.md b/samples/dnn/README.md
index 94460b3c0c8..9072ddb2a8e 100644
--- a/samples/dnn/README.md
+++ b/samples/dnn/README.md
@@ -7,7 +7,7 @@
 |    Model | Scale |   Size WxH|   Mean subtraction | Channels order |
 |---------------|-------|-----------|--------------------|-------|
 | [MobileNet-SSD, Caffe](https://github.com/chuanqi305/MobileNet-SSD/) | `0.00784 (2/255)` | `300x300` | `127.5 127.5 127.5` | BGR |
-| [OpenCV face detector](https://github.com/opencv/opencv/tree/3.4/samples/dnn/face_detector) | `1.0` | `300x300` | `104 177 123` | BGR |
+| [OpenCV face detector](https://github.com/opencv/opencv/tree/master/samples/dnn/face_detector) | `1.0` | `300x300` | `104 177 123` | BGR |
 | [SSDs from TensorFlow](https://github.com/tensorflow/models/tree/master/research/object_detection/) | `0.00784 (2/255)` | `300x300` | `127.5 127.5 127.5` | RGB |
 | [YOLO](https://pjreddie.com/darknet/yolo/) | `0.00392 (1/255)` | `416x416` | `0 0 0` | RGB |
 | [VGG16-SSD](https://github.com/weiliu89/caffe/tree/ssd) | `1.0` | `300x300` | `104 117 123` | BGR |
@@ -17,14 +17,14 @@
 | [Faster-RCNN, InceptionV2 backbone](https://github.com/tensorflow/models/tree/master/research/object_detection/) | `0.00784 (2/255)` | `300x300` | `127.5 127.5 127.5` | RGB |
 
 #### Face detection
-[An origin model](https://github.com/opencv/opencv/tree/3.4/samples/dnn/face_detector)
+[An origin model](https://github.com/opencv/opencv/tree/master/samples/dnn/face_detector)
 with single precision floating point weights has been quantized using [TensorFlow framework](https://www.tensorflow.org/).
 To achieve the best accuracy run the model on BGR images resized to `300x300` applying mean subtraction
 of values `(104, 177, 123)` for each blue, green and red channels correspondingly.
 
 The following are accuracy metrics obtained using [COCO object detection evaluation
 tool](http://cocodataset.org/#detections-eval) on [FDDB dataset](http://vis-www.cs.umass.edu/fddb/)
-(see [script](https://github.com/opencv/opencv/blob/3.4/modules/dnn/misc/face_detector_accuracy.py))
+(see [script](https://github.com/opencv/opencv/blob/master/modules/dnn/misc/face_detector_accuracy.py))
 applying resize to `300x300` and keeping an origin images' sizes.
 ```
 AP - Average Precision                            | FP32/FP16 | UINT8          | FP32/FP16 | UINT8          |
@@ -60,4 +60,4 @@ AR @[ IoU=0.50:0.95 | area= large | maxDets=100 ] | 0.528     | 0.528          |
 * [Models downloading script](https://github.com/opencv/opencv_extra/blob/master/testdata/dnn/download_models.py)
 * [Configuration files adopted for OpenCV](https://github.com/opencv/opencv_extra/tree/master/testdata/dnn)
 * [How to import models from TensorFlow Object Detection API](https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API)
-* [Names of classes from different datasets](https://github.com/opencv/opencv/tree/3.4/samples/data/dnn)
+* [Names of classes from different datasets](https://github.com/opencv/opencv/tree/master/samples/data/dnn)
diff --git a/samples/dnn/js_face_recognition.html b/samples/dnn/js_face_recognition.html
index bc94783c902..887f5f1bd86 100644
--- a/samples/dnn/js_face_recognition.html
+++ b/samples/dnn/js_face_recognition.html
@@ -69,7 +69,7 @@
 
 function loadModels(callback) {
   var utils = new Utils('');
-  var proto = 'https://raw.githubusercontent.com/opencv/opencv/3.4/samples/dnn/face_detector/deploy.prototxt';
+  var proto = 'https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt';
   var weights = 'https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20180205_fp16/res10_300x300_ssd_iter_140000_fp16.caffemodel';
   var recognModel = 'https://raw.githubusercontent.com/pyannote/pyannote-data/master/openface.nn4.small2.v1.t7';
   utils.createFileFromUrl('face_detector.prototxt', proto, () => {
diff --git a/samples/java/tutorial_code/Histograms_Matching/back_projection/CalcBackProjectDemo1.java b/samples/java/tutorial_code/Histograms_Matching/back_projection/CalcBackProjectDemo1.java
index c5b5f8d2495..d2e03c88f85 100644
--- a/samples/java/tutorial_code/Histograms_Matching/back_projection/CalcBackProjectDemo1.java
+++ b/samples/java/tutorial_code/Histograms_Matching/back_projection/CalcBackProjectDemo1.java
@@ -145,7 +145,7 @@ private void update() {
         hist.get(0, 0, histData);
         for (int i = 0; i < bins; i++) {
             Imgproc.rectangle(histImg, new Point(i * binW, h),
-                    new Point((i + 1) * binW, h - Math.round(histData[i] * h / 255.0)), new Scalar(0, 0, 255), Core.FILLED);
+                    new Point((i + 1) * binW, h - Math.round(histData[i] * h / 255.0)), new Scalar(0, 0, 255), Imgproc.FILLED);
         }
         Image histImage = HighGui.toBufferedImage(histImg);
         histImgLabel.setIcon(new ImageIcon(histImage));
diff --git a/samples/java/tutorial_code/ImgProc/Smoothing/Smoothing.java b/samples/java/tutorial_code/ImgProc/Smoothing/Smoothing.java
index b4d96307c9b..8b5a8330ef0 100644
--- a/samples/java/tutorial_code/ImgProc/Smoothing/Smoothing.java
+++ b/samples/java/tutorial_code/ImgProc/Smoothing/Smoothing.java
@@ -79,7 +79,7 @@ int displayCaption(String caption) {
         dst = Mat.zeros(src.size(), src.type());
         Imgproc.putText(dst, caption,
                 new Point(src.cols() / 4, src.rows() / 2),
-                Core.FONT_HERSHEY_COMPLEX, 1, new Scalar(255, 255, 255));
+                Imgproc.FONT_HERSHEY_COMPLEX, 1, new Scalar(255, 255, 255));
 
         return displayDst(DELAY_CAPTION);
     }
diff --git a/samples/java/tutorial_code/ShapeDescriptors/find_contours/FindContoursDemo.java b/samples/java/tutorial_code/ShapeDescriptors/find_contours/FindContoursDemo.java
index 5eec4f878a5..af6a1c8b226 100644
--- a/samples/java/tutorial_code/ShapeDescriptors/find_contours/FindContoursDemo.java
+++ b/samples/java/tutorial_code/ShapeDescriptors/find_contours/FindContoursDemo.java
@@ -112,7 +112,7 @@ private void update() {
         Mat drawing = Mat.zeros(cannyOutput.size(), CvType.CV_8UC3);
         for (int i = 0; i < contours.size(); i++) {
             Scalar color = new Scalar(rng.nextInt(256), rng.nextInt(256), rng.nextInt(256));
-            Imgproc.drawContours(drawing, contours, i, color, 2, Core.LINE_8, hierarchy, 0, new Point());
+            Imgproc.drawContours(drawing, contours, i, color, 2, Imgproc.LINE_8, hierarchy, 0, new Point());
         }
 
         imgContoursLabel.setIcon(new ImageIcon(HighGui.toBufferedImage(drawing)));
diff --git a/samples/java/tutorial_code/TrackingMotion/corner_subpixels/CornerSubPixDemo.java b/samples/java/tutorial_code/TrackingMotion/corner_subpixels/CornerSubPixDemo.java
index 3be2e580569..cb1888c08a0 100644
--- a/samples/java/tutorial_code/TrackingMotion/corner_subpixels/CornerSubPixDemo.java
+++ b/samples/java/tutorial_code/TrackingMotion/corner_subpixels/CornerSubPixDemo.java
@@ -115,7 +115,7 @@ private void update() {
         matCorners.get(0, 0, matCornersData);
         for (int i = 0; i < corners.rows(); i++) {
             Imgproc.circle(copy, new Point(cornersData[i * 2], cornersData[i * 2 + 1]), radius,
-                    new Scalar(rng.nextInt(256), rng.nextInt(256), rng.nextInt(256)), Core.FILLED);
+                    new Scalar(rng.nextInt(256), rng.nextInt(256), rng.nextInt(256)), Imgproc.FILLED);
             matCornersData[i * 2] = cornersData[i * 2];
             matCornersData[i * 2 + 1] = cornersData[i * 2 + 1];
         }
diff --git a/samples/java/tutorial_code/TrackingMotion/generic_corner_detector/CornerDetectorDemo.java b/samples/java/tutorial_code/TrackingMotion/generic_corner_detector/CornerDetectorDemo.java
index 30450f8db10..f7743f5d3e3 100644
--- a/samples/java/tutorial_code/TrackingMotion/generic_corner_detector/CornerDetectorDemo.java
+++ b/samples/java/tutorial_code/TrackingMotion/generic_corner_detector/CornerDetectorDemo.java
@@ -147,7 +147,7 @@ private void update() {
                 if (McData[i * srcGray.cols() + j] > harrisMinVal
                         + (harrisMaxVal - harrisMinVal) * qualityLevelVal / MAX_QUALITY_LEVEL) {
                     Imgproc.circle(harrisCopy, new Point(j, i), 4,
-                            new Scalar(rng.nextInt(256), rng.nextInt(256), rng.nextInt(256)), Core.FILLED);
+                            new Scalar(rng.nextInt(256), rng.nextInt(256), rng.nextInt(256)), Imgproc.FILLED);
                 }
             }
         }
@@ -162,7 +162,7 @@ private void update() {
                 if (shiTomasiData[i * srcGray.cols() + j] > shiTomasiMinVal
                         + (shiTomasiMaxVal - shiTomasiMinVal) * qualityLevelVal / MAX_QUALITY_LEVEL) {
                     Imgproc.circle(shiTomasiCopy, new Point(j, i), 4,
-                            new Scalar(rng.nextInt(256), rng.nextInt(256), rng.nextInt(256)), Core.FILLED);
+                            new Scalar(rng.nextInt(256), rng.nextInt(256), rng.nextInt(256)), Imgproc.FILLED);
                 }
             }
         }
diff --git a/samples/java/tutorial_code/TrackingMotion/good_features_to_track/GoodFeaturesToTrackDemo.java b/samples/java/tutorial_code/TrackingMotion/good_features_to_track/GoodFeaturesToTrackDemo.java
index b5ee732e84d..2033cd57277 100644
--- a/samples/java/tutorial_code/TrackingMotion/good_features_to_track/GoodFeaturesToTrackDemo.java
+++ b/samples/java/tutorial_code/TrackingMotion/good_features_to_track/GoodFeaturesToTrackDemo.java
@@ -109,7 +109,7 @@ private void update() {
         int radius = 4;
         for (int i = 0; i < corners.rows(); i++) {
             Imgproc.circle(copy, new Point(cornersData[i * 2], cornersData[i * 2 + 1]), radius,
-                    new Scalar(rng.nextInt(256), rng.nextInt(256), rng.nextInt(256)), Core.FILLED);
+                    new Scalar(rng.nextInt(256), rng.nextInt(256), rng.nextInt(256)), Imgproc.FILLED);
         }
 
         imgLabel.setIcon(new ImageIcon(HighGui.toBufferedImage(copy)));
diff --git a/samples/java/tutorial_code/ml/introduction_to_pca/IntroductionToPCADemo.java b/samples/java/tutorial_code/ml/introduction_to_pca/IntroductionToPCADemo.java
index 5dfef53efa6..8f07675a681 100644
--- a/samples/java/tutorial_code/ml/introduction_to_pca/IntroductionToPCADemo.java
+++ b/samples/java/tutorial_code/ml/introduction_to_pca/IntroductionToPCADemo.java
@@ -23,16 +23,16 @@ private void drawAxis(Mat img, Point p_, Point q_, Scalar colour, float scale) {
         // Here we lengthen the arrow by a factor of scale
         q.x = (int) (p.x - scale * hypotenuse * Math.cos(angle));
         q.y = (int) (p.y - scale * hypotenuse * Math.sin(angle));
-        Imgproc.line(img, p, q, colour, 1, Core.LINE_AA, 0);
+        Imgproc.line(img, p, q, colour, 1, Imgproc.LINE_AA, 0);
 
         // create the arrow hooks
         p.x = (int) (q.x + 9 * Math.cos(angle + Math.PI / 4));
         p.y = (int) (q.y + 9 * Math.sin(angle + Math.PI / 4));
-        Imgproc.line(img, p, q, colour, 1, Core.LINE_AA, 0);
+        Imgproc.line(img, p, q, colour, 1, Imgproc.LINE_AA, 0);
 
         p.x = (int) (q.x + 9 * Math.cos(angle - Math.PI / 4));
         p.y = (int) (q.y + 9 * Math.sin(angle - Math.PI / 4));
-        Imgproc.line(img, p, q, colour, 1, Core.LINE_AA, 0);
+        Imgproc.line(img, p, q, colour, 1, Imgproc.LINE_AA, 0);
         //! [visualization1]
     }
 
diff --git a/samples/java/tutorial_code/ml/introduction_to_svm/IntroductionToSVMDemo.java b/samples/java/tutorial_code/ml/introduction_to_svm/IntroductionToSVMDemo.java
index c44483f2cf6..dcff5ff7884 100644
--- a/samples/java/tutorial_code/ml/introduction_to_svm/IntroductionToSVMDemo.java
+++ b/samples/java/tutorial_code/ml/introduction_to_svm/IntroductionToSVMDemo.java
@@ -71,7 +71,7 @@ public static void main(String[] args) {
         // Show the training data
         //! [show_data]
         int thickness = -1;
-        int lineType = Core.LINE_8;
+        int lineType = Imgproc.LINE_8;
         Imgproc.circle(image, new Point(501, 10), 5, new Scalar(0, 0, 0), thickness, lineType, 0);
         Imgproc.circle(image, new Point(255, 10), 5, new Scalar(255, 255, 255), thickness, lineType, 0);
         Imgproc.circle(image, new Point(501, 255), 5, new Scalar(255, 255, 255), thickness, lineType, 0);
diff --git a/samples/java/tutorial_code/ml/non_linear_svms/NonLinearSVMsDemo.java b/samples/java/tutorial_code/ml/non_linear_svms/NonLinearSVMsDemo.java
index 798c1fc3efc..b2b40d1513e 100644
--- a/samples/java/tutorial_code/ml/non_linear_svms/NonLinearSVMsDemo.java
+++ b/samples/java/tutorial_code/ml/non_linear_svms/NonLinearSVMsDemo.java
@@ -148,7 +148,7 @@ public static void main(String[] args) {
         // ----------------------- 5. Show the training data--------------------------------------------
         //! [show_data]
         int thick = -1;
-        int lineType = Core.LINE_8;
+        int lineType = Imgproc.LINE_8;
         float px, py;
         // Class 1
         float[] trainDataData = new float[(int) (trainData.total() * trainData.channels())];
