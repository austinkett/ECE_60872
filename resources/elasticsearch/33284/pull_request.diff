diff --git a/docs/reference/rollup/apis/put-job.asciidoc b/docs/reference/rollup/apis/put-job.asciidoc
index 6834ef7ebeb8..79e30ae8dc99 100644
--- a/docs/reference/rollup/apis/put-job.asciidoc
+++ b/docs/reference/rollup/apis/put-job.asciidoc
@@ -44,6 +44,8 @@ started with the <<rollup-start-job,Start Job API>>.
 `metrics`::
    (object) Defines the metrics that should be collected for each grouping tuple. See <<rollup-job-config,rollup job config>>.
 
+For more details about the job configuration, see <<rollup-job-config>>.
+
 ==== Authorization
 
 You must have `manage` or `manage_rollup` cluster privileges to use this API.
diff --git a/docs/reference/rollup/apis/rollup-job-config.asciidoc b/docs/reference/rollup/apis/rollup-job-config.asciidoc
index e0f522e6b4bf..4eb85564a5cb 100644
--- a/docs/reference/rollup/apis/rollup-job-config.asciidoc
+++ b/docs/reference/rollup/apis/rollup-job-config.asciidoc
@@ -24,7 +24,7 @@ PUT _xpack/rollup/job/sensor
     "groups" : {
       "date_histogram": {
         "field": "timestamp",
-        "interval": "1h",
+        "interval": "60m",
         "delay": "7d"
       },
       "terms": {
@@ -94,7 +94,7 @@ fields will then be available later for aggregating into buckets.  For example,
 "groups" : {
   "date_histogram": {
     "field": "timestamp",
-    "interval": "1h",
+    "interval": "60m",
     "delay": "7d"
   },
   "terms": {
@@ -128,9 +128,9 @@ The `date_histogram` group has several parameters:
   The date field that is to be rolled up.
 
 `interval` (required)::
-  The interval of time buckets to be generated when rolling up.  E.g. `"1h"` will produce hourly rollups.  This follows standard time formatting
-  syntax as used elsewhere in Elasticsearch.  The `interval` defines the _minimum_ interval that can be aggregated only.  If hourly (`"1h"`)
-  intervals are configured, <<rollup-search,Rollup Search>> can execute aggregations with 1hr or greater (weekly, monthly, etc) intervals.
+  The interval of time buckets to be generated when rolling up.  E.g. `"60m"` will produce 60 minute (hourly) rollups.  This follows standard time formatting
+  syntax as used elsewhere in Elasticsearch.  The `interval` defines the _minimum_ interval that can be aggregated only.  If hourly (`"60m"`)
+  intervals are configured, <<rollup-search,Rollup Search>> can execute aggregations with 60m or greater (weekly, monthly, etc) intervals.
   So define the interval as the smallest unit that you wish to later query.
 
   Note: smaller, more granular intervals take up proportionally more space.
@@ -149,6 +149,46 @@ The `date_histogram` group has several parameters:
   to be stored with a specific timezone.  By default, rollup documents are stored in `UTC`, but this can be changed with the `time_zone`
   parameter.
 
+.Calendar vs Fixed time intervals
+**********************************
+Elasticsearch understands both "calendar" and "fixed" time intervals.  Fixed time intervals are fairly easy to understand;
+`"60s"` means sixty seconds.  But what does `"1M` mean?  One month of time depends on which month we are talking about,
+some months are longer or shorter than others.  This is an example of "calendar" time, and the duration of that unit
+depends on context.  Calendar units are also affected by leap-seconds, leap-years, etc.
+
+This is important because the buckets generated by Rollup will be in either calendar or fixed intervals, and will limit
+how you can query them later (see <<rollup-search-limitations-intervals, Requests must be multiples of the config>>.
+
+We recommend sticking with "fixed" time intervals, since they are easier to understand and are more flexible at query
+time.  It will introduce some drift in your data during leap-events, and you will have to think about months in a fixed
+quantity (30 days) instead of the actual calendar length... but it is often easier than dealing with calendar units
+at query time.
+
+Multiples of units are always "fixed" (e.g. `"2h"` is always the fixed quantity `7200` seconds.  Single units can be
+fixed or calendar depending on the unit:
+
+[options="header"]
+|=======
+|Unit |Calendar |Fixed
+|millisecond |NA |`1ms`, `10ms`, etc
+|second |NA |`1s`, `10s`, etc
+|minute |`1m` |`2m`, `10m`, etc
+|hour |`1h` |`2h`, `10h`, etc
+|day |`1d` |`2d`, `10d`, etc
+|week |`1w` |NA
+|month |`1M` |NA
+|quarter |`1q` |NA
+|year |`1y` |NA
+|=======
+
+For some units where there are both fixed and calendar, you may need to express the quantity in terms of the next
+smaller unit.  For example, if you want a fixed day (not a calendar day), you should specify `24h` instead of `1d`.
+Similarly, if you want fixed hours, specify `60m` instead of `1h`.  This is because the single quantity entails
+calendar time, and limits you to querying by calendar time in the future.
+
+
+**********************************
+
 ===== Terms
 
 The `terms` group can be used on `keyword` or numeric fields, to allow bucketing via the `terms` aggregation at a later point.  The `terms`
diff --git a/docs/reference/rollup/rollup-getting-started.asciidoc b/docs/reference/rollup/rollup-getting-started.asciidoc
index 931c26747f4d..8f99bc2c010c 100644
--- a/docs/reference/rollup/rollup-getting-started.asciidoc
+++ b/docs/reference/rollup/rollup-getting-started.asciidoc
@@ -39,8 +39,7 @@ PUT _xpack/rollup/job/sensor
     "groups" : {
       "date_histogram": {
         "field": "timestamp",
-        "interval": "1h",
-        "delay": "7d"
+        "interval": "60m"
       },
       "terms": {
         "fields": ["node"]
@@ -68,7 +67,7 @@ The `cron` parameter controls when and how often the job activates.  When a roll
 from where it left off after the last activation.  So if you configure the cron to run every 30 seconds, the job will process the last 30
 seconds worth of data that was indexed into the `sensor-*` indices.
 
-If instead the cron was configured to run once a day at midnight, the job would process the last 24hours worth of data.  The choice is largely
+If instead the cron was configured to run once a day at midnight, the job would process the last 24 hours worth of data.  The choice is largely
 preference, based on how "realtime" you want the rollups, and if you wish to process continuously or move it to off-peak hours.
 
 Next, we define a set of `groups` and `metrics`.  The metrics are fairly straightforward: we want to save the min/max/sum of the `temperature`
@@ -81,7 +80,7 @@ It also allows us to run terms aggregations on the `node` field.
 .Date histogram interval vs cron schedule
 **********************************
 You'll note that the job's cron is configured to run every 30 seconds, but the date_histogram is configured to
-rollup at hourly intervals.  How do these relate?
+rollup at 60 minute intervals.  How do these relate?
 
 The date_histogram controls the granularity of the saved data.  Data will be rolled up into hourly intervals, and you will be unable
 to query with finer granularity.  The cron simply controls when the process looks for new data to rollup.  Every 30 seconds it will see
@@ -225,70 +224,71 @@ Which returns a corresponding response:
 [source,js]
 ----
 {
-  "took" : 93,
-  "timed_out" : false,
-  "terminated_early" : false,
-  "_shards" : ... ,
-  "hits" : {
-    "total" : 0,
-    "max_score" : 0.0,
-    "hits" : [ ]
-  },
-  "aggregations" : {
-    "timeline" : {
-      "meta" : { },
-      "buckets" : [
-        {
-          "key_as_string" : "2018-01-18T00:00:00.000Z",
-          "key" : 1516233600000,
-          "doc_count" : 6,
-          "nodes" : {
-            "doc_count_error_upper_bound" : 0,
-            "sum_other_doc_count" : 0,
-            "buckets" : [
-              {
-                "key" : "a",
-                "doc_count" : 2,
-                "max_temperature" : {
-                  "value" : 202.0
-                },
-                "avg_voltage" : {
-                  "value" : 5.1499998569488525
-                }
-              },
-              {
-                "key" : "b",
-                "doc_count" : 2,
-                "max_temperature" : {
-                  "value" : 201.0
-                },
-                "avg_voltage" : {
-                  "value" : 5.700000047683716
-                }
-              },
-              {
-                "key" : "c",
-                "doc_count" : 2,
-                "max_temperature" : {
-                  "value" : 202.0
-                },
-                "avg_voltage" : {
-                  "value" : 4.099999904632568
-                }
-              }
-            ]
-          }
-        }
-      ]
-    }
-  }
+   "took" : 93,
+   "timed_out" : false,
+   "terminated_early" : false,
+   "_shards" : ... ,
+   "hits" : {
+     "total" : 0,
+     "max_score" : 0.0,
+     "hits" : [ ]
+   },
+   "aggregations" : {
+     "timeline" : {
+       "meta" : { },
+       "buckets" : [
+         {
+           "key_as_string" : "2018-01-18T00:00:00.000Z",
+           "key" : 1516233600000,
+           "doc_count" : 6,
+           "nodes" : {
+             "doc_count_error_upper_bound" : 0,
+             "sum_other_doc_count" : 0,
+             "buckets" : [
+               {
+                 "key" : "a",
+                 "doc_count" : 2,
+                 "max_temperature" : {
+                   "value" : 202.0
+                 },
+                 "avg_voltage" : {
+                   "value" : 5.1499998569488525
+                 }
+               },
+               {
+                 "key" : "b",
+                 "doc_count" : 2,
+                 "max_temperature" : {
+                   "value" : 201.0
+                 },
+                 "avg_voltage" : {
+                   "value" : 5.700000047683716
+                 }
+               },
+               {
+                 "key" : "c",
+                 "doc_count" : 2,
+                 "max_temperature" : {
+                   "value" : 202.0
+                 },
+                 "avg_voltage" : {
+                   "value" : 4.099999904632568
+                 }
+               }
+             ]
+           }
+         }
+       ]
+     }
+   }
 }
+
 ----
 // TESTRESPONSE[s/"took" : 93/"took" : $body.$_path/]
 // TESTRESPONSE[s/"_shards" : \.\.\. /"_shards" : $body.$_path/]
 
 In addition to being more complicated (date histogram and a terms aggregation, plus an additional average metric), you'll notice
-the date_histogram uses a `7d` interval instead of `1h`.
+the date_histogram uses a `7d` interval instead of `60m`.
 
 [float]
 === Conclusion
diff --git a/docs/reference/rollup/rollup-search-limitations.asciidoc b/docs/reference/rollup/rollup-search-limitations.asciidoc
index ce8c216576b1..43feeab9a2ee 100644
--- a/docs/reference/rollup/rollup-search-limitations.asciidoc
+++ b/docs/reference/rollup/rollup-search-limitations.asciidoc
@@ -82,9 +82,25 @@ The response will tell you that the field and aggregation were not possible, bec
 [float]
 === Interval Granularity
 
-Rollups are stored at a certain granularity, as defined by the `date_histogram` group in the configuration.  If data is rolled up at hourly
-intervals, the <<rollup-search>> API can aggregate on any time interval hourly or greater.  Intervals that are less than an hour will throw
-an exception, since the data simply doesn't exist for finer granularities.
+Rollups are stored at a certain granularity, as defined by the `date_histogram` group in the configuration.  This means you
+can only search/aggregate the rollup data with an interval that is greater-than or equal to the configured rollup interval.
+
+For example, if data is rolled up at hourly intervals, the <<rollup-search>> API can aggregate on any time interval
+hourly or greater.  Intervals that are less than an hour will throw an exception, since the data simply doesn't
+exist for finer granularities.
+
+[[rollup-search-limitations-intervals]]
+.Requests must be multiples of the config
+**********************************
+Perhaps not immediately apparent, but the interval specified in an aggregation request must be a whole
+multiple of the configured interval.  If the job was configured to rollup on `3d` intervals, you can only
+query and aggregate on multiples of three (`3d`, `6d`, `9d`, etc).
+
+A non-multiple wouldn't work, since the rolled up data wouldn't cleanly "overlap" with the buckets generated
+by the aggregation, leading to incorrect results.
+
+For that reason, an error is thrown if a whole multiple of the configured interval isn't found.
+**********************************
 
 Because the RollupSearch endpoint can "upsample" intervals, there is no need to configure jobs with multiple intervals (hourly, daily, etc).
 It's recommended to just configure a single job with the smallest granularity that is needed, and allow the search endpoint to upsample
diff --git a/x-pack/docs/build.gradle b/x-pack/docs/build.gradle
index 201f0186b303..9968a3b93735 100644
--- a/x-pack/docs/build.gradle
+++ b/x-pack/docs/build.gradle
@@ -674,9 +674,8 @@ setups['sensor_prefab_data'] = '''
                     page_size: 1000
                     groups:
                       date_histogram:
-                        delay: "7d"
                         field: "timestamp"
-                        interval: "1h"
+                        interval: "7d"
                         time_zone: "UTC"
                       terms:
                         fields:
diff --git a/x-pack/plugin/rollup/src/main/java/org/elasticsearch/xpack/rollup/RollupJobIdentifierUtils.java b/x-pack/plugin/rollup/src/main/java/org/elasticsearch/xpack/rollup/RollupJobIdentifierUtils.java
index a54c93a521db..c3d2fc3c5336 100644
--- a/x-pack/plugin/rollup/src/main/java/org/elasticsearch/xpack/rollup/RollupJobIdentifierUtils.java
+++ b/x-pack/plugin/rollup/src/main/java/org/elasticsearch/xpack/rollup/RollupJobIdentifierUtils.java
@@ -5,6 +5,8 @@
  */
 package org.elasticsearch.xpack.rollup;
 
+import org.elasticsearch.common.logging.DeprecationLogger;
+import org.elasticsearch.common.logging.Loggers;
 import org.elasticsearch.common.rounding.DateTimeUnit;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.search.aggregations.AggregationBuilder;
@@ -32,6 +34,7 @@
  */
 public class RollupJobIdentifierUtils {
 
+    private static final DeprecationLogger DEPRECATION_LOGGER = new DeprecationLogger(Loggers.getLogger(RollupJobIdentifierUtils.class));
     static final Comparator<RollupJobCaps> COMPARATOR = RollupJobIdentifierUtils.getComparator();
 
     /**
@@ -90,12 +93,19 @@ private static void doFindBestJobs(AggregationBuilder source, List<RollupJobCaps
     private static void checkDateHisto(DateHistogramAggregationBuilder source, List<RollupJobCaps> jobCaps,
                                        Set<RollupJobCaps> bestCaps) {
         ArrayList<RollupJobCaps> localCaps = new ArrayList<>();
+
+        // These represent rollup caps where the configured cap time type (fixed vs calendar) doesn't match the query.
+        // These are disallowed in 6.5+, but for bwc we accept them in 6.4 and log a deprecation warning.
+        // Note that we only use these if we can't find a better matching cap
+        ArrayList<RollupJobCaps> mixedIntervalCaps = new ArrayList<>();
+
         for (RollupJobCaps cap : jobCaps) {
             RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field());
             if (fieldCaps != null) {
                 for (Map<String, Object> agg : fieldCaps.getAggs()) {
                     if (agg.get(RollupField.AGG).equals(DateHistogramAggregationBuilder.NAME)) {
-                        TimeValue interval = TimeValue.parseTimeValue((String)agg.get(RollupField.INTERVAL), "date_histogram.interval");
+                        DateHistogramInterval interval = new DateHistogramInterval((String)agg.get(RollupField.INTERVAL));
+
                         String thisTimezone  = (String)agg.get(DateHistoGroupConfig.TIME_ZONE.getPreferredName());
                         String sourceTimeZone = source.timeZone() == null ? DateTimeZone.UTC.toString() : source.timeZone().toString();
 
@@ -104,23 +114,37 @@ private static void checkDateHisto(DateHistogramAggregationBuilder source, List<
                             continue;
                         }
                         if (source.dateHistogramInterval() != null) {
-                            TimeValue sourceInterval = TimeValue.parseTimeValue(source.dateHistogramInterval().toString(),
-                                    "source.date_histogram.interval");
-                            //TODO should be divisor of interval
-                            if (interval.compareTo(sourceInterval) <= 0) {
+                            // Check if both are calendar and validate if they are.
+                            // If not, check if both are fixed and validate
+                            if (validateCalendarInterval(source.dateHistogramInterval(), interval)) {
+                                localCaps.add(cap);
+                            } else if (validateFixedInterval(source.dateHistogramInterval(), interval)) {
                                 localCaps.add(cap);
+                            } else if (validateMixedInterval(source.dateHistogramInterval(), interval)) {
+                                // In 6.4 we accept mixed caps
+                                mixedIntervalCaps.add(cap);
                             }
                         } else {
-                            if (interval.getMillis() <= source.interval()) {
+                            // check if config is fixed and validate if it is
+                            if (validateFixedInterval(source.interval(), interval)) {
                                 localCaps.add(cap);
+                            } else if (validateMixedInterval(source.interval(), interval)) {
+                                // In 6.4 we accept mixed caps
+                                mixedIntervalCaps.add(cap);
                             }
                         }
+                        // not a candidate if we get here
                         break;
                     }
                 }
             }
         }
 
+        // If we don't have any "matching" caps, fall back to using mixed time unit caps
+        if (localCaps.isEmpty()) {
+            localCaps.addAll(mixedIntervalCaps);
+        }
+
         if (localCaps.isEmpty()) {
             throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg on field [" +
                     source.field() + "] which also satisfies all requirements of query.");
@@ -165,13 +189,17 @@ static boolean validateFixedInterval(DateHistogramInterval requestInterval,
         }
 
         // Both are fixed, good to convert to millis now
-        long configIntervalMillis = TimeValue.parseTimeValue(configInterval.toString(),
-            "date_histo.config.interval").getMillis();
-        long requestIntervalMillis = TimeValue.parseTimeValue(requestInterval.toString(),
-            "date_histo.request.interval").getMillis();
+        long configIntervalMillis = TimeValue.parseTimeValue(configInterval.toString(), "date_histo.config.interval").getMillis();
+        long requestIntervalMillis = TimeValue.parseTimeValue(requestInterval.toString(), "date_histo.request.interval").getMillis();
 
-        // Must be a multiple and gte the config
-        return requestIntervalMillis >= configIntervalMillis && requestIntervalMillis % configIntervalMillis == 0;
+        // Must be a multiple and gte the config, but in 6.4 we only enforce `gte` and log about multiple
+        if (requestIntervalMillis >= configIntervalMillis) {
+            if (requestIntervalMillis % configIntervalMillis != 0) {
+                DEPRECATION_LOGGER.deprecated("Starting in 6.5.0, query intervals must be a multiple of configured intervals.");
+            }
+            return true;
+        }
+        return false;
     }
 
     static boolean validateFixedInterval(long requestInterval, DateHistogramInterval configInterval) {
@@ -179,11 +207,67 @@ static boolean validateFixedInterval(long requestInterval, DateHistogramInterval
         if (isCalendarInterval(configInterval)) {
             return false;
         }
-        long configIntervalMillis = TimeValue.parseTimeValue(configInterval.toString(),
-            "date_histo.config.interval").getMillis();
+        long configIntervalMillis = TimeValue.parseTimeValue(configInterval.toString(), "date_histo.config.interval").getMillis();
+
+        // Must be a multiple and gte the config, but in 6.4 we only enforce `gte` and log about multiple
+        if (requestInterval >= configIntervalMillis) {
+            if (requestInterval % configIntervalMillis != 0) {
+                DEPRECATION_LOGGER.deprecated("Starting in 6.5.0, query intervals must be a multiple of configured intervals.");
+            }
+            return true;
+        }
+        return false;
+    }
+
+    /**
+     * If intervals are mixed (one calendar, one fixed), this attempts to compare the two and make sure they are roughly
+     * in the right arrangement (request >= config).  This always logs a deprecation warning because the behavior is gone
+     * in 6.5
+     */
+    static boolean validateMixedInterval(DateHistogramInterval requestInterval, DateHistogramInterval configInterval) {
+        long configIntervalMillis;
+        long requestIntervalMillis;
+
+        if (isCalendarInterval(requestInterval) && isCalendarInterval(configInterval) == false) {
+            configIntervalMillis= TimeValue.parseTimeValue(configInterval.toString(), "date_histo.config.interval").getMillis();
+            DateTimeUnit requestUnit = DateHistogramAggregationBuilder.DATE_FIELD_UNITS.get(requestInterval.toString());
+            requestIntervalMillis = requestUnit.field(DateTimeZone.UTC).getDurationField().getUnitMillis();
+
+        } else if (isCalendarInterval(requestInterval) == false && isCalendarInterval(configInterval)) {
+            DateTimeUnit configUnit = DateHistogramAggregationBuilder.DATE_FIELD_UNITS.get(configInterval.toString());
+            configIntervalMillis = configUnit.field(DateTimeZone.UTC).getDurationField().getUnitMillis();
+            requestIntervalMillis = TimeValue.parseTimeValue(requestInterval.toString(), "date_histo.config.interval").getMillis();
+
+        } else {
+           return false;
+        }
+        if (requestIntervalMillis >= configIntervalMillis) {
+            DEPRECATION_LOGGER.deprecated("Starting in 6.5.0, query and config interval types must match (e.g. fixed-time config " +
+                "can only be queried with fixed-time aggregations, and calendar-time config can only be queried with calendar-time" +
+                "aggregations).");
+            return true;
+        }
+        return false;
+    }
 
-        // Must be a multiple and gte the config
-        return requestInterval >= configIntervalMillis && requestInterval % configIntervalMillis == 0;
+    /**
+     * If intervals are mixed (one calendar, one fixed), this attempts to compare the two and make sure they are roughly
+     * in the right arrangement (request >= config).  This always logs a deprecation warning because the behavior is gone
+     * in 6.5
+     */
+    static boolean validateMixedInterval(long requestInterval, DateHistogramInterval configInterval) {
+        if (isCalendarInterval(configInterval)) {
+            DateTimeUnit configUnit = DateHistogramAggregationBuilder.DATE_FIELD_UNITS.get(configInterval.toString());
+            long configIntervalMillis = configUnit.field(DateTimeZone.UTC).getDurationField().getUnitMillis();
+            if (requestInterval >= configIntervalMillis) {
+                DEPRECATION_LOGGER.deprecated("Starting in 6.5.0, query and config interval types must match (e.g. fixed-time config " +
+                    "can only be queried with fixed-time aggregations, and calendar-time config can only be queried with calendar-time" +
+                    "aggregations).");
+                return true;
+            }
+            return false;
+        }
+        return false;
     }
 
     /**
@@ -197,8 +281,12 @@ private static void checkHisto(HistogramAggregationBuilder source, List<RollupJo
                 for (Map<String, Object> agg : fieldCaps.getAggs()) {
                     if (agg.get(RollupField.AGG).equals(HistogramAggregationBuilder.NAME)) {
                         Long interval = (long)agg.get(RollupField.INTERVAL);
-                        // TODO should be divisor of interval
+                        // query interval must be gte the configured interval
                         if (interval <= source.interval()) {
+                            if (source.interval() % interval != 0) {
+                                DEPRECATION_LOGGER.deprecated("Starting in 6.5.0, query intervals must be a " +
+                                    "multiple of configured intervals.");
+                            }
                             localCaps.add(cap);
                         }
                         break;
@@ -208,8 +296,8 @@ private static void checkHisto(HistogramAggregationBuilder source, List<RollupJo
         }
 
         if (localCaps.isEmpty()) {
-            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg on field [" +
-                    source.field() + "] which also satisfies all requirements of query.");
+            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName()
+                + "] agg on field [" + source.field() + "] which also satisfies all requirements of query.");
         }
 
         // We are a leaf, save our best caps
diff --git a/x-pack/plugin/rollup/src/test/java/org/elasticsearch/xpack/rollup/RollupJobIdentifierUtilTests.java b/x-pack/plugin/rollup/src/test/java/org/elasticsearch/xpack/rollup/RollupJobIdentifierUtilTests.java
index 6ba599188816..99301cfbb904 100644
--- a/x-pack/plugin/rollup/src/test/java/org/elasticsearch/xpack/rollup/RollupJobIdentifierUtilTests.java
+++ b/x-pack/plugin/rollup/src/test/java/org/elasticsearch/xpack/rollup/RollupJobIdentifierUtilTests.java
@@ -70,6 +70,52 @@ public void testBiggerButCompatibleInterval() {
         assertThat(bestCaps.size(), equalTo(1));
     }
 
+    public void testBiggerButCompatibleFixedInterval() {
+        RollupJobConfig.Builder job = ConfigTestHelpers.getRollupJob("foo");
+        GroupConfig.Builder group = ConfigTestHelpers.getGroupConfig();
+        group.setDateHisto(new DateHistoGroupConfig.Builder().setField("foo").setInterval(new DateHistogramInterval("100s")).build());
+        job.setGroupConfig(group.build());
+        RollupJobCaps cap = new RollupJobCaps(job.build());
+        Set<RollupJobCaps> caps = singletonSet(cap);
+
+        DateHistogramAggregationBuilder builder = new DateHistogramAggregationBuilder("foo").field("foo")
+            .dateHistogramInterval(new DateHistogramInterval("1000s"));
+
+        Set<RollupJobCaps> bestCaps = RollupJobIdentifierUtils.findBestJobs(builder, caps);
+        assertThat(bestCaps.size(), equalTo(1));
+    }
+
+    public void testBiggerButCompatibleFixedIntervalNotMultiple() {
+        RollupJobConfig.Builder job = ConfigTestHelpers.getRollupJob("foo");
+        GroupConfig.Builder group = ConfigTestHelpers.getGroupConfig();
+        group.setDateHisto(new DateHistoGroupConfig.Builder().setField("foo").setInterval(new DateHistogramInterval("300s")).build());
+        job.setGroupConfig(group.build());
+        RollupJobCaps cap = new RollupJobCaps(job.build());
+        Set<RollupJobCaps> caps = singletonSet(cap);
+
+        DateHistogramAggregationBuilder builder = new DateHistogramAggregationBuilder("foo").field("foo")
+            .dateHistogramInterval(new DateHistogramInterval("1000s"));
+
+        Set<RollupJobCaps> bestCaps = RollupJobIdentifierUtils.findBestJobs(builder, caps);
+        assertWarnings("Starting in 6.5.0, query intervals must be a multiple of configured intervals.");
+        assertThat(bestCaps.size(), equalTo(1));
+    }
+
+    public void testBiggerButCompatibleFixedMillisInterval() {
+        RollupJobConfig.Builder job = ConfigTestHelpers.getRollupJob("foo");
+        GroupConfig.Builder group = ConfigTestHelpers.getGroupConfig();
+        group.setDateHisto(new DateHistoGroupConfig.Builder().setField("foo").setInterval(new DateHistogramInterval("100ms")).build());
+        job.setGroupConfig(group.build());
+        RollupJobCaps cap = new RollupJobCaps(job.build());
+        Set<RollupJobCaps> caps = singletonSet(cap);
+
+        DateHistogramAggregationBuilder builder = new DateHistogramAggregationBuilder("foo").field("foo")
+            .interval(1000);
+
+        Set<RollupJobCaps> bestCaps = RollupJobIdentifierUtils.findBestJobs(builder, caps);
+        assertThat(bestCaps.size(), equalTo(1));
+    }
+
     public void testIncompatibleInterval() {
         RollupJobConfig.Builder job = ConfigTestHelpers.getRollupJob("foo");
         GroupConfig.Builder group = ConfigTestHelpers.getGroupConfig();
@@ -86,6 +132,84 @@ public void testIncompatibleInterval() {
                 "[foo] which also satisfies all requirements of query."));
     }
 
+    public void testIncompatibleFixedCalendarInterval() {
+        RollupJobConfig.Builder job = ConfigTestHelpers.getRollupJob("foo");
+        GroupConfig.Builder group = ConfigTestHelpers.getGroupConfig();
+        group.setDateHisto(new DateHistoGroupConfig.Builder().setField("foo").setInterval(new DateHistogramInterval("5d")).build());
+        job.setGroupConfig(group.build());
+        RollupJobCaps cap = new RollupJobCaps(job.build());
+        Set<RollupJobCaps> caps = singletonSet(cap);
+
+
+        DateHistogramAggregationBuilder builder = new DateHistogramAggregationBuilder("foo").field("foo")
+            .dateHistogramInterval(new DateHistogramInterval("day"));
+
+        RuntimeException e = expectThrows(RuntimeException.class, () -> RollupJobIdentifierUtils.findBestJobs(builder, caps));
+        assertThat(e.getMessage(), equalTo("There is not a rollup job that has a [date_histogram] agg on field " +
+            "[foo] which also satisfies all requirements of query."));
+    }
+
+    public void testRequestFixedConfigCalendarInterval() {
+        RollupJobConfig.Builder job = ConfigTestHelpers.getRollupJob("foo");
+        GroupConfig.Builder group = ConfigTestHelpers.getGroupConfig();
+        group.setDateHisto(new DateHistoGroupConfig.Builder().setField("foo").setInterval(new DateHistogramInterval("1d")).build());
+        job.setGroupConfig(group.build());
+        RollupJobCaps cap = new RollupJobCaps(job.build());
+        Set<RollupJobCaps> caps = singletonSet(cap);
+
+
+        DateHistogramAggregationBuilder builder = new DateHistogramAggregationBuilder("foo").field("foo")
+            .dateHistogramInterval(new DateHistogramInterval("5d"));
+
+        Set<RollupJobCaps> bestCaps = RollupJobIdentifierUtils.findBestJobs(builder, caps);
+        assertWarnings("Starting in 6.5.0, query and config interval " +
+            "types must match (e.g. fixed-time config can only be queried with fixed-time aggregations, " +
+            "and calendar-time config can only be queried with calendar-timeaggregations).");
+
+        assertThat(bestCaps.size(), equalTo(1));
+    }
+
+    public void testRequestCalendarConfigFixedInterval() {
+        RollupJobConfig.Builder job = ConfigTestHelpers.getRollupJob("foo");
+        GroupConfig.Builder group = ConfigTestHelpers.getGroupConfig();
+        group.setDateHisto(new DateHistoGroupConfig.Builder().setField("foo").setInterval(new DateHistogramInterval("60m")).build());
+        job.setGroupConfig(group.build());
+        RollupJobCaps cap = new RollupJobCaps(job.build());
+        Set<RollupJobCaps> caps = singletonSet(cap);
+
+
+        DateHistogramAggregationBuilder builder = new DateHistogramAggregationBuilder("foo").field("foo")
+            .dateHistogramInterval(new DateHistogramInterval("1d"));
+
+        Set<RollupJobCaps> bestCaps = RollupJobIdentifierUtils.findBestJobs(builder, caps);
+        assertWarnings("Starting in 6.5.0, query and config interval " +
+            "types must match (e.g. fixed-time config can only be queried with fixed-time aggregations, " +
+            "and calendar-time config can only be queried with calendar-timeaggregations).");
+
+        assertThat(bestCaps.size(), equalTo(1));
+    }
+
+    public void testRequestMonthCalendarConfigFixedInterval() {
+        RollupJobConfig.Builder job = ConfigTestHelpers.getRollupJob("foo");
+        GroupConfig.Builder group = ConfigTestHelpers.getGroupConfig();
+        group.setDateHisto(new DateHistoGroupConfig.Builder().setField("foo").setInterval(new DateHistogramInterval("24h")).build());
+        job.setGroupConfig(group.build());
+        RollupJobCaps cap = new RollupJobCaps(job.build());
+        Set<RollupJobCaps> caps = singletonSet(cap);
+
+
+        DateHistogramAggregationBuilder builder = new DateHistogramAggregationBuilder("foo").field("foo")
+            .dateHistogramInterval(new DateHistogramInterval("1M"));
+
+        Set<RollupJobCaps> bestCaps = RollupJobIdentifierUtils.findBestJobs(builder, caps);
+        assertWarnings("Starting in 6.5.0, query and config interval " +
+            "types must match (e.g. fixed-time config can only be queried with fixed-time aggregations, " +
+            "and calendar-time config can only be queried with calendar-timeaggregations).");
+
+        assertThat(bestCaps.size(), equalTo(1));
+    }
+
+
     public void testBadTimeZone() {
         RollupJobConfig.Builder job = ConfigTestHelpers.getRollupJob("foo");
         GroupConfig.Builder group = ConfigTestHelpers.getGroupConfig();
@@ -474,7 +598,7 @@ public void testNoMatchingHistoInterval() {
                 .field("bar")
                 .subAggregation(new MaxAggregationBuilder("the_max").field("max_field"))
                 .subAggregation(new AvgAggregationBuilder("the_avg").field("avg_field"));
-        
+
         RollupJobConfig job = ConfigTestHelpers.getRollupJob("foo")
                 .setGroupConfig(ConfigTestHelpers.getGroupConfig()
                         .setDateHisto(new DateHistoGroupConfig.Builder()
@@ -496,6 +620,25 @@ public void testNoMatchingHistoInterval() {
                 "[bar] which also satisfies all requirements of query."));
     }
 
+    public void testHistoIntervalNotMultiple() {
+        HistogramAggregationBuilder histo = new HistogramAggregationBuilder("test_histo");
+        histo.interval(10)  // <--- interval is not a multiple of 3
+            .field("bar");
+
+        RollupJobConfig.Builder job = ConfigTestHelpers.getRollupJob("foo");
+        GroupConfig.Builder group = ConfigTestHelpers.getGroupConfig();
+        group.setDateHisto(new DateHistoGroupConfig.Builder().setField("foo").setInterval(new DateHistogramInterval("1d")).build());
+        group.setHisto(new HistoGroupConfig.Builder().setFields(Collections.singletonList("bar")).setInterval(3L).build());
+        job.setGroupConfig(group.build());
+        RollupJobCaps cap = new RollupJobCaps(job.build());
+        Set<RollupJobCaps> caps = singletonSet(cap);
+
+        Set<RollupJobCaps> bestCaps = RollupJobIdentifierUtils.findBestJobs(histo, caps);
+
+        assertThat(bestCaps.size(), equalTo(1));
+        assertWarnings("Starting in 6.5.0, query intervals must be a multiple of configured intervals.");
+    }
+
     public void testMissingMetric() {
         int i = ESTestCase.randomIntBetween(0, 3);
 
@@ -622,12 +765,73 @@ public void testValidateCalendarInterval() {
             new DateHistogramInterval("1m"));
         assertFalse(valid);
 
+        valid = RollupJobIdentifierUtils.validateCalendarInterval(new DateHistogramInterval("1M"),
+            new DateHistogramInterval("minute"));
+        assertTrue(valid);
+
         // Fails because both are actually fixed
         valid = RollupJobIdentifierUtils.validateCalendarInterval(new DateHistogramInterval("100ms"),
             new DateHistogramInterval("100ms"));
         assertFalse(valid);
     }
 
+    public void testMixedIntervals() {
+        boolean valid = RollupJobIdentifierUtils.validateMixedInterval(60 * 1000, new DateHistogramInterval("1m"));
+        assertTrue(valid);
+
+        valid = RollupJobIdentifierUtils.validateMixedInterval(10 * 60 * 1000, new DateHistogramInterval("1m"));
+        assertTrue(valid);
+
+        valid = RollupJobIdentifierUtils.validateMixedInterval(100, new DateHistogramInterval("1d"));
+        assertFalse(valid);
+
+        valid = RollupJobIdentifierUtils.validateMixedInterval(1000 * 60 * 60 * 24, new DateHistogramInterval("1d"));
+        assertTrue(valid);
+
+        valid = RollupJobIdentifierUtils.validateMixedInterval(100, new DateHistogramInterval("minute"));
+        assertFalse(valid);
+
+        valid = RollupJobIdentifierUtils.validateMixedInterval(1000 * 60 * 60, new DateHistogramInterval("minute"));
+        assertTrue(valid);
+
+        valid = RollupJobIdentifierUtils.validateMixedInterval(100, new DateHistogramInterval("second"));
+        assertFalse(valid);
+
+        valid = RollupJobIdentifierUtils.validateMixedInterval(1000, new DateHistogramInterval("second"));
+        assertTrue(valid);
+
+        // -----------
+        // Same tests, with both being DateHistoIntervals
+        // -----------
+        valid = RollupJobIdentifierUtils.validateMixedInterval(new DateHistogramInterval("60s"), new DateHistogramInterval("1m"));
+        assertTrue(valid);
+
+        valid = RollupJobIdentifierUtils.validateMixedInterval(new DateHistogramInterval("10m"), new DateHistogramInterval("1m"));
+        assertTrue(valid);
+
+        valid = RollupJobIdentifierUtils.validateMixedInterval(new DateHistogramInterval("100ms"), new DateHistogramInterval("1d"));
+        assertFalse(valid);
+
+        valid = RollupJobIdentifierUtils.validateMixedInterval(new DateHistogramInterval("24h"), new DateHistogramInterval("1d"));
+        assertTrue(valid);
+
+        valid = RollupJobIdentifierUtils.validateMixedInterval(new DateHistogramInterval("10s"), new DateHistogramInterval("minute"));
+        assertFalse(valid);
+
+        valid = RollupJobIdentifierUtils.validateMixedInterval(new DateHistogramInterval("2m"), new DateHistogramInterval("minute"));
+        assertTrue(valid);
+
+        valid = RollupJobIdentifierUtils.validateMixedInterval(new DateHistogramInterval("100ms"), new DateHistogramInterval("second"));
+        assertFalse(valid);
+
+        valid = RollupJobIdentifierUtils.validateMixedInterval(new DateHistogramInterval("60s"), new DateHistogramInterval("second"));
+        assertTrue(valid);
+
+        assertWarnings("Starting in 6.5.0, query and config interval " +
+            "types must match (e.g. fixed-time config can only be queried with fixed-time aggregations, " +
+            "and calendar-time config can only be queried with calendar-timeaggregations).");
+    }
+
     public void testComparatorMixed() {
         int numCaps = randomIntBetween(1, 10);
         List<RollupJobCaps> caps = new ArrayList<>(numCaps);
diff --git a/x-pack/qa/multi-node/src/test/java/org/elasticsearch/multi_node/RollupIT.java b/x-pack/qa/multi-node/src/test/java/org/elasticsearch/multi_node/RollupIT.java
index 43ad4dc0a45a..fb9c665b2bf1 100644
--- a/x-pack/qa/multi-node/src/test/java/org/elasticsearch/multi_node/RollupIT.java
+++ b/x-pack/qa/multi-node/src/test/java/org/elasticsearch/multi_node/RollupIT.java
@@ -173,7 +173,7 @@ public void testBigRollup() throws Exception {
             "    \"date_histo\": {\n" +
             "      \"date_histogram\": {\n" +
             "        \"field\": \"timestamp\",\n" +
-            "        \"interval\": \"1h\",\n" +
+            "        \"interval\": \"60m\",\n" +
             "        \"format\": \"date_time\"\n" +
             "      },\n" +
             "      \"aggs\": {\n" +
