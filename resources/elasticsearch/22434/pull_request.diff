diff --git a/core/src/main/java/org/elasticsearch/indices/recovery/RecoveriesCollection.java b/core/src/main/java/org/elasticsearch/indices/recovery/RecoveriesCollection.java
index 3bee3febf3f6..aed232561087 100644
--- a/core/src/main/java/org/elasticsearch/indices/recovery/RecoveriesCollection.java
+++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoveriesCollection.java
@@ -107,25 +107,17 @@ public RecoveryTarget resetRecovery(final long recoveryId, TimeValue activityTim
             }
 
             // Closes the current recovery target
-            final AtomicBoolean successfulReset = new AtomicBoolean();
-            try {
-                final RecoveryTarget finalOldRecoveryTarget = oldRecoveryTarget;
-                newRecoveryTarget.CancellableThreads().executeIO(() -> successfulReset.set(finalOldRecoveryTarget.resetRecovery()));
-            } catch (CancellableThreads.ExecutionCancelledException e) {
-                // new recovery target is already cancelled (probably due to shard closing or recovery source changing)
-                assert onGoingRecoveries.containsKey(newRecoveryTarget.recoveryId()) == false;
-                logger.trace("{} recovery reset cancelled, recovery from {}, id [{}], previous id [{}]", newRecoveryTarget.shardId(),
-                    newRecoveryTarget.sourceNode(), newRecoveryTarget.recoveryId(), oldRecoveryTarget.recoveryId());
-                oldRecoveryTarget.cancel("recovery reset cancelled"); // if finalOldRecoveryTarget.resetRecovery did not even get to execute
-                return null;
-            }
-            if (successfulReset.get() == false) {
-                cancelRecovery(newRecoveryTarget.recoveryId(), "failed to reset recovery");
-                return null;
-            } else {
+            boolean successfulReset = oldRecoveryTarget.resetRecovery(newRecoveryTarget.CancellableThreads());
+            if (successfulReset) {
                 logger.trace("{} restarted recovery from {}, id [{}], previous id [{}]", newRecoveryTarget.shardId(),
                     newRecoveryTarget.sourceNode(), newRecoveryTarget.recoveryId(), oldRecoveryTarget.recoveryId());
                 return newRecoveryTarget;
+            } else {
+                logger.trace("{} recovery could not be reset as it is already cancelled, recovery from {}, id [{}], previous id [{}]",
+                    newRecoveryTarget.shardId(), newRecoveryTarget.sourceNode(), newRecoveryTarget.recoveryId(),
+                    oldRecoveryTarget.recoveryId());
+                cancelRecovery(newRecoveryTarget.recoveryId(), "recovery cancelled during reset");
+                return null;
             }
         } catch (Exception e) {
             // fail shard to be safe
diff --git a/core/src/main/java/org/elasticsearch/indices/recovery/RecoveryTarget.java b/core/src/main/java/org/elasticsearch/indices/recovery/RecoveryTarget.java
index 4311d3b2ab1d..00dd019aac47 100644
--- a/core/src/main/java/org/elasticsearch/indices/recovery/RecoveryTarget.java
+++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoveryTarget.java
@@ -36,6 +36,7 @@
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.logging.Loggers;
 import org.elasticsearch.common.lucene.Lucene;
+import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.common.util.Callback;
 import org.elasticsearch.common.util.CancellableThreads;
 import org.elasticsearch.common.util.concurrent.AbstractRefCounted;
@@ -56,6 +57,8 @@
 import java.util.Map.Entry;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.TimeoutException;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicLong;
 
@@ -182,17 +185,21 @@ public void renameAllTempFiles() throws IOException {
      * Closes the current recovery target and waits up to a certain timeout for resources to be freed.
      * Returns true if resetting the recovery was successful, false if the recovery target is already cancelled / failed or marked as done.
      */
-    boolean resetRecovery() throws InterruptedException, IOException {
+    boolean resetRecovery(CancellableThreads newTargetCancellableThreads) throws IOException {
         if (finished.compareAndSet(false, true)) {
             try {
-                // yes, this is just a logger call in a try-finally block. The reason for this is that resetRecovery is called from
-                // CancellableThreads and we have to make sure that all references to IndexShard are cleaned up before exiting this method
                 logger.debug("reset of recovery with shard {} and id [{}]", shardId, recoveryId);
             } finally {
                 // release the initial reference. recovery files will be cleaned as soon as ref count goes to zero, potentially now.
                 decRef();
             }
-            closedLatch.await();
+            try {
+                newTargetCancellableThreads.execute(closedLatch::await);
+            } catch (CancellableThreads.ExecutionCancelledException e) {
+                logger.trace("new recovery target cancelled for shard {} while waiting on old recovery target with id [{}] to close",
+                    shardId, recoveryId);
+                return false;
+            }
             RecoveryState.Stage stage = indexShard.recoveryState().getStage();
             if (indexShard.recoveryState().getPrimary() && (stage == RecoveryState.Stage.FINALIZE || stage == RecoveryState.Stage.DONE)) {
                 // once primary relocation has moved past the finalization step, the relocation source can be moved to RELOCATED state
