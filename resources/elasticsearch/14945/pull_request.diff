diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/settings/TransportClusterUpdateSettingsAction.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/settings/TransportClusterUpdateSettingsAction.java
index b0934781dcd7..7485a209b9b6 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/settings/TransportClusterUpdateSettingsAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/settings/TransportClusterUpdateSettingsAction.java
@@ -189,10 +189,10 @@ public ClusterState execute(final ClusterState currentState) {
                             transientUpdates.put(entry.getKey(), entry.getValue());
                             changed = true;
                         } else {
-                            logger.warn("ignoring transient setting [{}], [{}]", entry.getKey(), error);
+                            logger.warn("ignoring transient setting [{}], [{}]", null, entry.getKey(), error);
                         }
                     } else {
-                        logger.warn("ignoring transient setting [{}], not dynamically updateable", entry.getKey());
+                        logger.warn("ignoring transient setting [{}], not dynamically updateable", null, entry.getKey());
                     }
                 }
 
@@ -206,10 +206,10 @@ public ClusterState execute(final ClusterState currentState) {
                             persistentUpdates.put(entry.getKey(), entry.getValue());
                             changed = true;
                         } else {
-                            logger.warn("ignoring persistent setting [{}], [{}]", entry.getKey(), error);
+                            logger.warn("ignoring persistent setting [{}], [{}]", null, entry.getKey(), error);
                         }
                     } else {
-                        logger.warn("ignoring persistent setting [{}], not dynamically updateable", entry.getKey());
+                        logger.warn("ignoring persistent setting [{}], not dynamically updateable", null, entry.getKey());
                     }
                 }
 
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportNodesSnapshotsStatus.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportNodesSnapshotsStatus.java
index 8c856beaf65b..e4352fa093d4 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportNodesSnapshotsStatus.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportNodesSnapshotsStatus.java
@@ -96,8 +96,10 @@ protected NodesSnapshotStatus newResponse(Request request, AtomicReferenceArray
                 nodesList.add((NodeSnapshotStatus) resp);
             } else if (resp instanceof FailedNodeException) {
                 failures.add((FailedNodeException) resp);
+            } else if (resp instanceof Throwable) {
+                logger.warn("unknown response type, expected NodeSnapshotStatus or FailedNodeException", (Throwable) resp);
             } else {
-                logger.warn("unknown response type [{}], expected NodeSnapshotStatus or FailedNodeException", resp);
+                logger.warn("unknown response type [{}], expected NodeSnapshotStatus or FailedNodeException", null, resp);
             }
         }
         return new NodesSnapshotStatus(clusterName, nodesList.toArray(new NodeSnapshotStatus[nodesList.size()]),
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java
index 5e87e91b2557..bff0e70840be 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java
@@ -109,7 +109,7 @@ protected UpgradeResponse newResponse(UpgradeRequest request, int totalShards, i
             if (primaryCount == metaData.index(index).getNumberOfShards()) {
                 updatedVersions.put(index, new Tuple<>(versionEntry.getValue().v1(), versionEntry.getValue().v2().toString()));
             } else {
-                logger.warn("Not updating settings for the index [{}] because upgraded of some primary shards failed - expected[{}], received[{}]", index,
+                logger.warn("Not updating settings for the index [{}] because upgraded of some primary shards failed - expected[{}], received[{}]", null, index,
                         expectedPrimaryCount, primaryCount == null ? 0 : primaryCount);
             }
         }
diff --git a/core/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java b/core/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java
index 805778ccdebc..db08c9125469 100644
--- a/core/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java
+++ b/core/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java
@@ -296,7 +296,7 @@ public void onTimeout(TimeValue timeout) {
                 try {
                     failReplicaIfNeeded(request.internalShardId.getIndex(), request.internalShardId.id(), t, request);
                 } catch (Throwable unexpected) {
-                    logger.error("{} unexpected error while failing replica", request.internalShardId.id(), unexpected);
+                    logger.error("{} unexpected error while failing replica", unexpected, request.internalShardId.id());
                 } finally {
                     responseWithFailure(t);
                 }
@@ -383,7 +383,7 @@ protected void doRun() {
                 return;
             }
             if (observer.observedState().nodes().nodeExists(primary.currentNodeId()) == false) {
-                logger.trace("primary shard [{}] is assigned to anode we do not know the node, scheduling a retry.", primary.shardId(), primary.currentNodeId());
+                logger.trace("primary shard [{}] is assigned to a node we do not know the node [{}], scheduling a retry.", primary.shardId(), primary.currentNodeId());
                 retryBecauseUnavailable(shardIt.shardId(), "Primary shard is not active or isn't assigned to a known node.");
                 return;
             }
diff --git a/core/src/main/java/org/elasticsearch/action/support/single/shard/TransportSingleShardAction.java b/core/src/main/java/org/elasticsearch/action/support/single/shard/TransportSingleShardAction.java
index 6b419abece18..160cdf01ae71 100644
--- a/core/src/main/java/org/elasticsearch/action/support/single/shard/TransportSingleShardAction.java
+++ b/core/src/main/java/org/elasticsearch/action/support/single/shard/TransportSingleShardAction.java
@@ -201,7 +201,7 @@ private void perform(@Nullable final Throwable currentFailure) {
                     failure = new NoShardAvailableActionException(null, LoggerMessageFormat.format("No shard available for [{}]", internalRequest.request()), failure);
                 } else {
                     if (logger.isDebugEnabled()) {
-                        logger.debug("{}: failed to execute [{}]", failure, null, internalRequest.request());
+                        logger.debug("failed to execute [{}]", failure, internalRequest.request());
                     }
                 }
                 listener.onFailure(failure);
diff --git a/core/src/main/java/org/elasticsearch/action/update/UpdateHelper.java b/core/src/main/java/org/elasticsearch/action/update/UpdateHelper.java
index 010142b0b4c1..dc12fc480245 100644
--- a/core/src/main/java/org/elasticsearch/action/update/UpdateHelper.java
+++ b/core/src/main/java/org/elasticsearch/action/update/UpdateHelper.java
@@ -110,7 +110,7 @@ protected Result prepare(UpdateRequest request, final GetResult getResult) {
                 // (the default) or "none", meaning abort upsert
                 if (!"create".equals(scriptOpChoice)) {
                     if (!"none".equals(scriptOpChoice)) {
-                        logger.warn("Used upsert operation [{}] for script [{}], doing nothing...", scriptOpChoice,
+                        logger.warn("Used upsert operation [{}] for script [{}], doing nothing...", null, scriptOpChoice,
                                 request.script.getScript());
                     }
                     UpdateResponse update = new UpdateResponse(getResult.getIndex(), getResult.getType(), getResult.getId(),
@@ -235,7 +235,7 @@ protected Result prepare(UpdateRequest request, final GetResult getResult) {
             update.setGetResult(extractGetResult(request, request.index(), getResult.getVersion(), updatedSourceAsMap, updateSourceContentType, getResult.internalSourceRef()));
             return new Result(update, Operation.NONE, updatedSourceAsMap, updateSourceContentType);
         } else {
-            logger.warn("Used update operation [{}] for script [{}], doing nothing...", operation, request.script.getScript());
+            logger.warn("Used update operation [{}] for script [{}], doing nothing...", null, operation, request.script.getScript());
             UpdateResponse update = new UpdateResponse(getResult.getIndex(), getResult.getType(), getResult.getId(), getResult.getVersion(), false);
             return new Result(update, Operation.NONE, updatedSourceAsMap, updateSourceContentType);
         }
diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java
index 3a0ddf1c050d..fa3b9022924d 100644
--- a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java
+++ b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java
@@ -88,7 +88,7 @@ public static void initializeNatives(Path tmpFile, boolean mlockAll, boolean sec
         // check if the user is running as root, and bail
         if (Natives.definitelyRunningAsRoot()) {
             if (Boolean.parseBoolean(System.getProperty("es.insecure.allow.root"))) {
-                logger.warn("running as ROOT user. this is a bad idea!");
+                logger.warn("running as ROOT user. this is a bad idea!", null);
             } else {
                 throw new RuntimeException("don't run elasticsearch as root.");
             }
@@ -278,7 +278,7 @@ static void init(String[] args) throws Throwable {
         // warn if running using the client VM
         if (JvmInfo.jvmInfo().getVmName().toLowerCase(Locale.ROOT).contains("client")) {
             ESLogger logger = Loggers.getLogger(Bootstrap.class);
-            logger.warn("jvm uses the client vm, make sure to run `java` with the server vm for best performance by adding `-server` to the command line");
+            logger.warn("jvm uses the client vm, make sure to run `java` with the server vm for best performance by adding `-server` to the command line", null);
         }
 
         try {
@@ -313,7 +313,7 @@ static void init(String[] args) throws Throwable {
                 PrintStream ps = new PrintStream(os, false, "UTF-8");
                 new StartupError(e).printStackTrace(ps);
                 ps.flush();
-                logger.error("Guice Exception: {}", os.toString("UTF-8"));
+                logger.error("Guice Exception: {}", null, os.toString("UTF-8"));
             } else {
                 // full exception
                 logger.error("Exception", e);
diff --git a/core/src/main/java/org/elasticsearch/bootstrap/JNAKernel32Library.java b/core/src/main/java/org/elasticsearch/bootstrap/JNAKernel32Library.java
index 8924812e6d61..00d28de7b673 100644
--- a/core/src/main/java/org/elasticsearch/bootstrap/JNAKernel32Library.java
+++ b/core/src/main/java/org/elasticsearch/bootstrap/JNAKernel32Library.java
@@ -54,9 +54,9 @@ private JNAKernel32Library() {
                 Native.register("kernel32");
                 logger.debug("windows/Kernel32 library loaded");
             } catch (NoClassDefFoundError e) {
-                logger.warn("JNA not found. native methods and handlers will be disabled.");
+                logger.warn("JNA not found. native methods and handlers will be disabled.", e);
             } catch (UnsatisfiedLinkError e) {
-                logger.warn("unable to link Windows/Kernel32 library. native methods and handlers will be disabled.");
+                logger.warn("unable to link Windows/Kernel32 library. native methods and handlers will be disabled.", e);
             }
         }
     }
diff --git a/core/src/main/java/org/elasticsearch/bootstrap/JNANatives.java b/core/src/main/java/org/elasticsearch/bootstrap/JNANatives.java
index 5356d33bb8e8..5aff7da9031a 100644
--- a/core/src/main/java/org/elasticsearch/bootstrap/JNANatives.java
+++ b/core/src/main/java/org/elasticsearch/bootstrap/JNANatives.java
@@ -74,7 +74,7 @@ static void tryMlockall() {
                     softLimit = rlimit.rlim_cur.longValue();
                     hardLimit = rlimit.rlim_max.longValue();
                 } else {
-                    logger.warn("Unable to retrieve resource limits: " + JNACLibrary.strerror(Native.getLastError()));
+                    logger.warn("Unable to retrieve resource limits: " + JNACLibrary.strerror(Native.getLastError()), null);
                 }
             }
         } catch (UnsatisfiedLinkError e) {
@@ -83,23 +83,23 @@ static void tryMlockall() {
         }
 
         // mlockall failed for some reason
-        logger.warn("Unable to lock JVM Memory: error=" + errno + ",reason=" + errMsg);
-        logger.warn("This can result in part of the JVM being swapped out.");
+        logger.warn("Unable to lock JVM Memory: error=" + errno + ",reason=" + errMsg, null);
+        logger.warn("This can result in part of the JVM being swapped out.", null);
         if (errno == JNACLibrary.ENOMEM) {
             if (rlimitSuccess) {
-                logger.warn("Increase RLIMIT_MEMLOCK, soft limit: " + rlimitToString(softLimit) + ", hard limit: " + rlimitToString(hardLimit));
+                logger.warn("Increase RLIMIT_MEMLOCK, soft limit: " + rlimitToString(softLimit) + ", hard limit: " + rlimitToString(hardLimit), null);
                 if (Constants.LINUX) {
                     // give specific instructions for the linux case to make it easy
                     String user = System.getProperty("user.name");
                     logger.warn("These can be adjusted by modifying /etc/security/limits.conf, for example: \n" +
                                 "\t# allow user '" + user + "' mlockall\n" +
                                 "\t" + user + " soft memlock unlimited\n" +
-                                "\t" + user + " hard memlock unlimited"
+                                "\t" + user + " hard memlock unlimited", null
                                );
-                    logger.warn("If you are logged in interactively, you will have to re-login for the new limits to take effect.");
+                    logger.warn("If you are logged in interactively, you will have to re-login for the new limits to take effect.", null);
                 }
             } else {
-                logger.warn("Increase RLIMIT_MEMLOCK (ulimit).");
+                logger.warn("Increase RLIMIT_MEMLOCK (ulimit).", null);
             }
         }
     }
@@ -137,7 +137,7 @@ static void tryVirtualLock() {
             // the amount of memory we wish to lock, plus a small overhead (1MB).
             SizeT size = new SizeT(JvmInfo.jvmInfo().getMem().getHeapInit().getBytes() + (1024 * 1024));
             if (!kernel.SetProcessWorkingSetSize(process, size, size)) {
-                logger.warn("Unable to lock JVM memory. Failed to set working set size. Error code " + Native.getLastError());
+                logger.warn("Unable to lock JVM memory. Failed to set working set size. Error code " + Native.getLastError(), null);
             } else {
                 JNAKernel32Library.MemoryBasicInformation memInfo = new JNAKernel32Library.MemoryBasicInformation();
                 long address = 0;
@@ -170,7 +170,7 @@ static void addConsoleCtrlHandler(ConsoleCtrlHandler handler) {
                 if (result) {
                     logger.debug("console ctrl handler correctly set");
                 } else {
-                    logger.warn("unknown error " + Native.getLastError() + " when adding console ctrl handler:");
+                    logger.warn("unknown error " + Native.getLastError() + " when adding console ctrl handler:", null);
                 }
             } catch (UnsatisfiedLinkError e) {
                 // this will have already been logged by Kernel32Library, no need to repeat it
@@ -186,11 +186,6 @@ static void trySeccomp(Path tmpFile) {
                 LOCAL_SECCOMP_ALL = true;
             }
         } catch (Throwable t) {
-            // this is likely to happen unless the kernel is newish, its a best effort at the moment
-            // so we log stacktrace at debug for now...
-            if (logger.isDebugEnabled()) {
-                logger.debug("unable to install syscall filter", t);
-            }
             logger.warn("unable to install syscall filter: ", t);
         }
     }
diff --git a/core/src/main/java/org/elasticsearch/bootstrap/JVMCheck.java b/core/src/main/java/org/elasticsearch/bootstrap/JVMCheck.java
index 5c402bd83ce5..99d9ccd8db55 100644
--- a/core/src/main/java/org/elasticsearch/bootstrap/JVMCheck.java
+++ b/core/src/main/java/org/elasticsearch/bootstrap/JVMCheck.java
@@ -113,12 +113,12 @@ String getWarningMessage() {
      */
     static void check() {
         if (Boolean.parseBoolean(System.getProperty(JVM_BYPASS))) {
-            Loggers.getLogger(JVMCheck.class).warn("bypassing jvm version check for version [{}], this can result in data corruption!", fullVersion());
+            Loggers.getLogger(JVMCheck.class).warn("bypassing jvm version check for version [{}], this can result in data corruption!", null, fullVersion());
         } else if ("Oracle Corporation".equals(Constants.JVM_VENDOR)) {
             HotspotBug bug = JVM_BROKEN_HOTSPOT_VERSIONS.get(Constants.JVM_VERSION);
             if (bug != null) {
                 if (bug.workAround != null && ManagementFactory.getRuntimeMXBean().getInputArguments().contains(bug.workAround)) {
-                    Loggers.getLogger(JVMCheck.class).warn(bug.getWarningMessage());
+                    Loggers.getLogger(JVMCheck.class).warn(bug.getWarningMessage(), null);
                 } else {
                     throw new RuntimeException(bug.getErrorMessage());
                 }
diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Natives.java b/core/src/main/java/org/elasticsearch/bootstrap/Natives.java
index a9935d8530c1..ab390176561a 100644
--- a/core/src/main/java/org/elasticsearch/bootstrap/Natives.java
+++ b/core/src/main/java/org/elasticsearch/bootstrap/Natives.java
@@ -54,7 +54,7 @@ private Natives() {}
 
     static void tryMlockall() {
         if (!JNA_AVAILABLE) {
-            logger.warn("cannot mlockall because JNA is not available");
+            logger.warn("cannot mlockall because JNA is not available", null);
             return;
         }
         JNANatives.tryMlockall();
@@ -62,7 +62,7 @@ static void tryMlockall() {
 
     static boolean definitelyRunningAsRoot() {
         if (!JNA_AVAILABLE) {
-            logger.warn("cannot check if running as root because JNA is not available");
+            logger.warn("cannot check if running as root because JNA is not available", null);
             return false;
         }
         return JNANatives.definitelyRunningAsRoot();
@@ -70,7 +70,7 @@ static boolean definitelyRunningAsRoot() {
 
     static void tryVirtualLock() {
         if (!JNA_AVAILABLE) {
-            logger.warn("cannot mlockall because JNA is not available");
+            logger.warn("cannot mlockall because JNA is not available", null);
             return;
         }
         JNANatives.tryVirtualLock();
@@ -78,7 +78,7 @@ static void tryVirtualLock() {
 
     static void addConsoleCtrlHandler(ConsoleCtrlHandler handler) {
         if (!JNA_AVAILABLE) {
-            logger.warn("cannot register console handler because JNA is not available");
+            logger.warn("cannot register console handler because JNA is not available", null);
             return;
         }
         JNANatives.addConsoleCtrlHandler(handler);
@@ -93,7 +93,7 @@ static boolean isMemoryLocked() {
     
     static void trySeccomp(Path tmpFile) {
         if (!JNA_AVAILABLE) {
-            logger.warn("cannot install syscall filters because JNA is not available");
+            logger.warn("cannot install syscall filters because JNA is not available", null);
             return;
         }
         JNANatives.trySeccomp(tmpFile);
diff --git a/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java b/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java
index 56befbb9b841..e7b07862db3f 100644
--- a/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java
+++ b/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java
@@ -367,7 +367,7 @@ public LivenessResponse newInstance() {
                                 }
                             }).txGet();
                     if (!ignoreClusterName && !clusterName.equals(livenessResponse.getClusterName())) {
-                        logger.warn("node {} not part of the cluster {}, ignoring...", listedNode, clusterName);
+                        logger.warn("node {} not part of the cluster {}, ignoring...", null, listedNode, clusterName);
                         newFilteredNodes.add(listedNode);
                     } else if (livenessResponse.getDiscoveryNode() != null) {
                         // use discovered information but do keep the original transport address, so people can control which address is exactly used.
@@ -475,7 +475,7 @@ public void handleException(TransportException e) {
             HashSet<DiscoveryNode> newFilteredNodes = new HashSet<>();
             for (Map.Entry<DiscoveryNode, ClusterStateResponse> entry : clusterStateResponses.entrySet()) {
                 if (!ignoreClusterName && !clusterName.equals(entry.getValue().getClusterName())) {
-                    logger.warn("node {} not part of the cluster {}, ignoring...", entry.getValue().getState().nodes().localNode(), clusterName);
+                    logger.warn("node {} not part of the cluster {}, ignoring...", null, entry.getValue().getState().nodes().localNode(), clusterName);
                     newFilteredNodes.add(entry.getKey());
                     continue;
                 }
diff --git a/core/src/main/java/org/elasticsearch/cluster/ClusterModule.java b/core/src/main/java/org/elasticsearch/cluster/ClusterModule.java
index f2797e3b2675..836f1e3ba4a6 100644
--- a/core/src/main/java/org/elasticsearch/cluster/ClusterModule.java
+++ b/core/src/main/java/org/elasticsearch/cluster/ClusterModule.java
@@ -302,7 +302,7 @@ protected void configure() {
         String shardsAllocatorType = shardsAllocators.bindType(binder(), settings, ClusterModule.SHARDS_ALLOCATOR_TYPE_KEY, ClusterModule.BALANCED_ALLOCATOR);
         if (shardsAllocatorType.equals(ClusterModule.EVEN_SHARD_COUNT_ALLOCATOR)) {
             final ESLogger logger = Loggers.getLogger(getClass(), settings);
-            logger.warn("{} allocator has been removed in 2.0 using {} instead", ClusterModule.EVEN_SHARD_COUNT_ALLOCATOR, ClusterModule.BALANCED_ALLOCATOR);
+            logger.warn("{} allocator has been removed in 2.0 using {} instead", null, ClusterModule.EVEN_SHARD_COUNT_ALLOCATOR, ClusterModule.BALANCED_ALLOCATOR);
         }
         allocationDeciders.bind(binder());
         indexTemplateFilters.bind(binder());
diff --git a/core/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java b/core/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java
index 039868d16c41..07db62551393 100644
--- a/core/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java
@@ -115,7 +115,7 @@ public void onRefreshSettings(Settings settings) {
 
             if (newUpdateFrequency != null) {
                 if (newUpdateFrequency.getMillis() < TimeValue.timeValueSeconds(10).getMillis()) {
-                    logger.warn("[{}] set too low [{}] (< 10s)", INTERNAL_CLUSTER_INFO_UPDATE_INTERVAL, newUpdateFrequency);
+                    logger.warn("[{}] set too low [{}] (< 10s)", null, INTERNAL_CLUSTER_INFO_UPDATE_INTERVAL, newUpdateFrequency);
                     throw new IllegalStateException("Unable to set " + INTERNAL_CLUSTER_INFO_UPDATE_INTERVAL + " less than 10 seconds");
                 } else {
                     logger.info("updating [{}] from [{}] to [{}]", INTERNAL_CLUSTER_INFO_UPDATE_INTERVAL, updateFrequency, newUpdateFrequency);
@@ -317,7 +317,7 @@ public void onResponse(NodesStatsResponse nodeStatses) {
             @Override
             public void onFailure(Throwable e) {
                 if (e instanceof ReceiveTimeoutTransportException) {
-                    logger.error("NodeStatsAction timed out for ClusterInfoUpdateJob (reason [{}])", e.getMessage());
+                    logger.error("NodeStatsAction timed out for ClusterInfoUpdateJob", e);
                 } else {
                     if (e instanceof ClusterBlockException) {
                         if (logger.isTraceEnabled()) {
@@ -347,7 +347,7 @@ public void onResponse(IndicesStatsResponse indicesStatsResponse) {
             @Override
             public void onFailure(Throwable e) {
                 if (e instanceof ReceiveTimeoutTransportException) {
-                    logger.error("IndicesStatsAction timed out for ClusterInfoUpdateJob (reason [{}])", e.getMessage());
+                    logger.error("IndicesStatsAction timed out for ClusterInfoUpdateJob", e);
                 } else {
                     if (e instanceof ClusterBlockException) {
                         if (logger.isTraceEnabled()) {
@@ -367,14 +367,14 @@ public void onFailure(Throwable e) {
             nodeLatch.await(fetchTimeout.getMillis(), TimeUnit.MILLISECONDS);
         } catch (InterruptedException e) {
             Thread.currentThread().interrupt(); // restore interrupt status
-            logger.warn("Failed to update node information for ClusterInfoUpdateJob within {} timeout", fetchTimeout);
+            logger.warn("Failed to update node information for ClusterInfoUpdateJob within {} timeout", e, fetchTimeout);
         }
 
         try {
             indicesLatch.await(fetchTimeout.getMillis(), TimeUnit.MILLISECONDS);
         } catch (InterruptedException e) {
             Thread.currentThread().interrupt(); // restore interrupt status
-            logger.warn("Failed to update shard information for ClusterInfoUpdateJob within {} timeout", fetchTimeout);
+            logger.warn("Failed to update shard information for ClusterInfoUpdateJob within {} timeout", e, fetchTimeout);
         }
         ClusterInfo clusterInfo = getClusterInfo();
         for (Listener l : listeners) {
@@ -405,7 +405,7 @@ static void fillDiskUsagePerNode(ESLogger logger, NodeStats[] nodeStatsArray,
             ImmutableOpenMap.Builder<String, DiskUsage> newMostAvaiableUsages) {
         for (NodeStats nodeStats : nodeStatsArray) {
             if (nodeStats.getFs() == null) {
-                logger.warn("Unable to retrieve node FS stats for {}", nodeStats.getNode().name());
+                logger.warn("Unable to retrieve node FS stats for {}", null, nodeStats.getNode().name());
             } else {
                 FsInfo.Path leastAvailablePath = null;
                 FsInfo.Path mostAvailablePath = null;
diff --git a/core/src/main/java/org/elasticsearch/cluster/action/index/NodeIndexDeletedAction.java b/core/src/main/java/org/elasticsearch/cluster/action/index/NodeIndexDeletedAction.java
index 4079f14abc7b..bf036d1cf7f8 100644
--- a/core/src/main/java/org/elasticsearch/cluster/action/index/NodeIndexDeletedAction.java
+++ b/core/src/main/java/org/elasticsearch/cluster/action/index/NodeIndexDeletedAction.java
@@ -76,7 +76,7 @@ public void nodeIndexDeleted(final ClusterState clusterState, final String index
         transportService.sendRequest(clusterState.nodes().masterNode(),
                 INDEX_DELETED_ACTION_NAME, new NodeIndexDeletedMessage(index, nodeId), EmptyTransportResponseHandler.INSTANCE_SAME);
         if (nodes.localNode().isDataNode() == false) {
-            logger.trace("[{}] not acking store deletion (not a data node)");
+            logger.trace("[{}] not acking store deletion (not a data node)", nodeId);
             return;
         }
         threadPool.generic().execute(new AbstractRunnable() {
@@ -102,9 +102,9 @@ private void lockIndexAndAck(String index, DiscoveryNodes nodes, String nodeId,
             transportService.sendRequest(clusterState.nodes().masterNode(),
                     INDEX_STORE_DELETED_ACTION_NAME, new NodeIndexStoreDeletedMessage(index, nodeId), EmptyTransportResponseHandler.INSTANCE_SAME);
         } catch (LockObtainFailedException exc) {
-            logger.warn("[{}] failed to lock all shards for index - timed out after 30 seconds", index);
+            logger.warn("[{}] failed to lock all shards for index - timed out after 30 seconds", exc, index);
         } catch (InterruptedException e) {
-            logger.warn("[{}] failed to lock all shards for index - interrupted", index);
+            logger.warn("[{}] failed to lock all shards for index - interrupted", e, index);
         }
     }
 
@@ -191,4 +191,4 @@ public void readFrom(StreamInput in) throws IOException {
             nodeId = in.readString();
         }
     }
-}
\ No newline at end of file
+}
diff --git a/core/src/main/java/org/elasticsearch/cluster/action/index/NodeMappingRefreshAction.java b/core/src/main/java/org/elasticsearch/cluster/action/index/NodeMappingRefreshAction.java
index d0eb29d6b220..0ca23cc69590 100644
--- a/core/src/main/java/org/elasticsearch/cluster/action/index/NodeMappingRefreshAction.java
+++ b/core/src/main/java/org/elasticsearch/cluster/action/index/NodeMappingRefreshAction.java
@@ -57,7 +57,7 @@ public NodeMappingRefreshAction(Settings settings, TransportService transportSer
     public void nodeMappingRefresh(final ClusterState state, final NodeMappingRefreshRequest request) {
         final DiscoveryNodes nodes = state.nodes();
         if (nodes.masterNode() == null) {
-            logger.warn("can't send mapping refresh for [{}][{}], no master known.", request.index(), Strings.arrayToCommaDelimitedString(request.types()));
+            logger.warn("can't send mapping refresh for [{}][{}], no master known.", null, request.index(), Strings.arrayToCommaDelimitedString(request.types()));
             return;
         }
         transportService.sendRequest(nodes.masterNode(), ACTION_NAME, request, EmptyTransportResponseHandler.INSTANCE_SAME);
diff --git a/core/src/main/java/org/elasticsearch/cluster/action/shard/ShardStateAction.java b/core/src/main/java/org/elasticsearch/cluster/action/shard/ShardStateAction.java
index 83897baa50df..cabbce54f5ea 100644
--- a/core/src/main/java/org/elasticsearch/cluster/action/shard/ShardStateAction.java
+++ b/core/src/main/java/org/elasticsearch/cluster/action/shard/ShardStateAction.java
@@ -86,7 +86,7 @@ public void shardFailed(final ShardRouting shardRouting, final String indexUUID,
     public void shardFailed(final ShardRouting shardRouting, final String indexUUID, final String message, @Nullable final Throwable failure, TimeValue timeout, Listener listener) {
         DiscoveryNode masterNode = clusterService.state().nodes().masterNode();
         if (masterNode == null) {
-            logger.warn("can't send shard failed for {}, no master known.", shardRouting);
+            logger.warn("can't send shard failed for {}, no master known.", null, shardRouting);
             listener.onShardFailedNoMaster();
             return;
         }
@@ -122,7 +122,7 @@ public void handleException(TransportException exp) {
     public void shardStarted(final ShardRouting shardRouting, String indexUUID, final String reason) {
         DiscoveryNode masterNode = clusterService.state().nodes().masterNode();
         if (masterNode == null) {
-            logger.warn("{} can't send shard started for {}, no master known.", shardRouting.shardId(), shardRouting);
+            logger.warn("{} can't send shard started for {}, no master known.", null, shardRouting.shardId(), shardRouting);
             return;
         }
         shardStarted(shardRouting, indexUUID, reason, masterNode);
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java
index 9945de1f8d39..abbb1b6588f8 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java
@@ -780,7 +780,7 @@ public static MetaData addDefaultUnitsIfNeeded(ESLogger logger, MetaData metaDat
                     continue;
                 }
                 // It's a naked number that previously would be interpreted as default unit (bytes); now we add it:
-                logger.warn("byte-sized cluster setting [{}] with value [{}] is missing units; assuming default units (b) but in future versions this will be a hard error", settingName, settingValue);
+                logger.warn("byte-sized cluster setting [{}] with value [{}] is missing units; assuming default units (b) but in future versions this will be a hard error", null, settingName, settingValue);
                 if (newPersistentSettings == null) {
                     newPersistentSettings = Settings.builder();
                     newPersistentSettings.put(metaData.persistentSettings());
@@ -794,7 +794,7 @@ public static MetaData addDefaultUnitsIfNeeded(ESLogger logger, MetaData metaDat
                     continue;
                 }
                 // It's a naked number that previously would be interpreted as default unit (ms); now we add it:
-                logger.warn("time cluster setting [{}] with value [{}] is missing units; assuming default units (ms) but in future versions this will be a hard error", settingName, settingValue);
+                logger.warn("time cluster setting [{}] with value [{}] is missing units; assuming default units (ms) but in future versions this will be a hard error", null, settingName, settingValue);
                 if (newPersistentSettings == null) {
                     newPersistentSettings = Settings.builder();
                     newPersistentSettings.put(metaData.persistentSettings());
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java
index 2d89857f60d9..84a4a6d7be1e 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java
@@ -172,7 +172,7 @@ private IndexMetaData addDefaultUnitsIfNeeded(IndexMetaData indexMetaData) {
                         continue;
                     }
                     // It's a naked number that previously would be interpreted as default unit (bytes); now we add it:
-                    logger.warn("byte-sized index setting [{}] with value [{}] is missing units; assuming default units (b) but in future versions this will be a hard error", byteSizeSetting, value);
+                    logger.warn("byte-sized index setting [{}] with value [{}] is missing units; assuming default units (b) but in future versions this will be a hard error", null, byteSizeSetting, value);
                     if (newSettings == null) {
                         newSettings = Settings.builder();
                         newSettings.put(settings);
@@ -189,7 +189,7 @@ private IndexMetaData addDefaultUnitsIfNeeded(IndexMetaData indexMetaData) {
                         continue;
                     }
                     // It's a naked number that previously would be interpreted as default unit (ms); now we add it:
-                    logger.warn("time index setting [{}] with value [{}] is missing units; assuming default units (ms) but in future versions this will be a hard error", timeSetting, value);
+                    logger.warn("time index setting [{}] with value [{}] is missing units; assuming default units (ms) but in future versions this will be a hard error", null, timeSetting, value);
                     if (newSettings == null) {
                         newSettings = Settings.builder();
                         newSettings.put(settings);
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java
index 725f06d9fae6..369582e46f00 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java
@@ -243,10 +243,10 @@ private boolean processIndexMappingTasks(List<MappingTask> tasks, IndexService i
                         continue;
                     }
 
-                    logger.warn("[{}] re-syncing mappings with cluster state for types [{}]", index, updatedTypes);
+                    logger.warn("[{}] re-syncing mappings with cluster state for types [{}]", null, index, updatedTypes);
                     dirty = true;
                 } catch (Throwable t) {
-                    logger.warn("[{}] failed to refresh-mapping in cluster state, types [{}]", index, refreshTask.types);
+                    logger.warn("[{}] failed to refresh-mapping in cluster state, types [{}]", t, index, refreshTask.types);
                 }
             } else if (task instanceof UpdateTask) {
                 UpdateTask updateTask = (UpdateTask) task;
@@ -279,10 +279,10 @@ private boolean processIndexMappingTasks(List<MappingTask> tasks, IndexService i
                     builder.putMapping(new MappingMetaData(updatedMapper));
                     dirty = true;
                 } catch (Throwable t) {
-                    logger.warn("[{}] failed to update-mapping in cluster state, type [{}]", index, updateTask.type);
+                    logger.warn("[{}] failed to update-mapping in cluster state, type [{}]", t, index, updateTask.type);
                 }
             } else {
-                logger.warn("illegal state, got wrong mapping task type [{}]", task);
+                logger.warn("illegal state, got wrong mapping task type [{}]", null, task);
             }
         }
         return dirty;
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java
index 1a928dd41ea4..28d291cf8a76 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java
@@ -102,7 +102,7 @@ public void clusterChanged(ClusterChangedEvent event) {
                     final int dash = autoExpandReplicas.indexOf('-');
                     if (-1 == dash) {
                         logger.warn("failed to set [{}] for index [{}], it should be dash delimited [{}]",
-                                IndexMetaData.SETTING_AUTO_EXPAND_REPLICAS, indexMetaData.getIndex(), autoExpandReplicas);
+                                null, IndexMetaData.SETTING_AUTO_EXPAND_REPLICAS, indexMetaData.getIndex(), autoExpandReplicas);
                         continue;
                     }
                     final String sMin = autoExpandReplicas.substring(0, dash);
@@ -173,7 +173,7 @@ public void onResponse(ClusterStateUpdateResponse response) {
                     @Override
                     public void onFailure(Throwable t) {
                         for (String index : indices) {
-                            logger.warn("[{}] fail to auto expand replicas to [{}]", index, fNumberOfReplicas);
+                            logger.warn("[{}] fail to auto expand replicas to [{}]", null, index, fNumberOfReplicas);
                         }
                     }
                 });
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/ClusterRebalanceAllocationDecider.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/ClusterRebalanceAllocationDecider.java
index 7638c7aeee88..bbf65ea9113a 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/ClusterRebalanceAllocationDecider.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/ClusterRebalanceAllocationDecider.java
@@ -98,7 +98,7 @@ public ClusterRebalanceAllocationDecider(Settings settings, NodeSettingsService
         try {
             type = ClusterRebalanceType.parseString(allowRebalance);
         } catch (IllegalStateException e) {
-            logger.warn("[{}] has a wrong value {}, defaulting to 'indices_all_active'", CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE, allowRebalance);
+            logger.warn("[{}] has a wrong value {}, defaulting to 'indices_all_active'", e, CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE, allowRebalance);
             type = ClusterRebalanceType.INDICES_ALL_ACTIVE;
         }
         logger.debug("using [{}] with [{}]", CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE, type.toString().toLowerCase(Locale.ROOT));
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java
index a02c72c57458..70dda1dda342 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java
@@ -150,7 +150,7 @@ private void warnAboutDiskIfNeeded(DiskUsage usage) {
             // Check absolute disk values
             if (usage.getFreeBytes() < DiskThresholdDecider.this.freeBytesThresholdHigh.bytes()) {
                 logger.warn("high disk watermark [{}] exceeded on {}, shards will be relocated away from this node",
-                        DiskThresholdDecider.this.freeBytesThresholdHigh, usage);
+                        null, DiskThresholdDecider.this.freeBytesThresholdHigh, usage);
             } else if (usage.getFreeBytes() < DiskThresholdDecider.this.freeBytesThresholdLow.bytes()) {
                 logger.info("low disk watermark [{}] exceeded on {}, replicas will not be assigned to this node",
                         DiskThresholdDecider.this.freeBytesThresholdLow, usage);
@@ -159,7 +159,7 @@ private void warnAboutDiskIfNeeded(DiskUsage usage) {
             // Check percentage disk values
             if (usage.getFreeDiskAsPercentage() < DiskThresholdDecider.this.freeDiskThresholdHigh) {
                 logger.warn("high disk watermark [{}] exceeded on {}, shards will be relocated away from this node",
-                        Strings.format1Decimals(100.0 - DiskThresholdDecider.this.freeDiskThresholdHigh, "%"), usage);
+                        null, Strings.format1Decimals(100.0 - DiskThresholdDecider.this.freeDiskThresholdHigh, "%"), usage);
             } else if (usage.getFreeDiskAsPercentage() < DiskThresholdDecider.this.freeDiskThresholdLow) {
                 logger.info("low disk watermark [{}] exceeded on {}, replicas will not be assigned to this node",
                         Strings.format1Decimals(100.0 - DiskThresholdDecider.this.freeDiskThresholdLow, "%"), usage);
@@ -435,13 +435,13 @@ public Decision canAllocate(ShardRouting shardRouting, RoutingNode node, Routing
         long freeBytesAfterShard = freeBytes - shardSize;
         if (freeBytesAfterShard < freeBytesThresholdHigh.bytes()) {
             logger.warn("after allocating, node [{}] would have less than the required {} free bytes threshold ({} bytes free), preventing allocation",
-                    node.nodeId(), freeBytesThresholdHigh, freeBytesAfterShard);
+                    null, node.nodeId(), freeBytesThresholdHigh, freeBytesAfterShard);
             return allocation.decision(Decision.NO, NAME, "after allocation less than required [%s] free on node, free: [%s]",
                     freeBytesThresholdLow, new ByteSizeValue(freeBytesAfterShard));
         }
         if (freeSpaceAfterShard < freeDiskThresholdHigh) {
             logger.warn("after allocating, node [{}] would have more than the allowed {} free disk threshold ({} free), preventing allocation",
-                    node.nodeId(), Strings.format1Decimals(freeDiskThresholdHigh, "%"), Strings.format1Decimals(freeSpaceAfterShard, "%"));
+                    null, node.nodeId(), Strings.format1Decimals(freeDiskThresholdHigh, "%"), Strings.format1Decimals(freeSpaceAfterShard, "%"));
             return allocation.decision(Decision.NO, NAME, "after allocation more than allowed [%s%%] used disk on node, free: [%s%%]",
                     usedDiskThresholdLow, freeSpaceAfterShard);
         }
diff --git a/core/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java b/core/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java
index c2300739a7dc..be614d0651f2 100644
--- a/core/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java
@@ -566,7 +566,7 @@ public void run() {
 
     private void warnAboutSlowTaskIfNeeded(TimeValue executionTime, String source) {
         if (executionTime.getMillis() > slowTaskLoggingThreshold.getMillis()) {
-            logger.warn("cluster state update task [{}] took {} above the warn threshold of {}", source, executionTime, slowTaskLoggingThreshold);
+            logger.warn("cluster state update task [{}] took {} above the warn threshold of {}", null, source, executionTime, slowTaskLoggingThreshold);
         }
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/MacAddressProvider.java b/core/src/main/java/org/elasticsearch/common/MacAddressProvider.java
index 7952cbe2892e..03a4dd05ba17 100644
--- a/core/src/main/java/org/elasticsearch/common/MacAddressProvider.java
+++ b/core/src/main/java/org/elasticsearch/common/MacAddressProvider.java
@@ -71,7 +71,7 @@ private static boolean isValidAddress(byte[] address) {
         }
 
         if (!isValidAddress(address)) {
-            logger.warn("Unable to get a valid mac address, will use a dummy address");
+            logger.warn("Unable to get a valid mac address, will use a dummy address", null);
             address = constructDummyMulticastAddress();
         }
 
diff --git a/core/src/main/java/org/elasticsearch/common/breaker/ChildMemoryCircuitBreaker.java b/core/src/main/java/org/elasticsearch/common/breaker/ChildMemoryCircuitBreaker.java
index 9284b7b50a24..5b4abd118b7d 100644
--- a/core/src/main/java/org/elasticsearch/common/breaker/ChildMemoryCircuitBreaker.java
+++ b/core/src/main/java/org/elasticsearch/common/breaker/ChildMemoryCircuitBreaker.java
@@ -141,6 +141,7 @@ public double addEstimateBytesAndMaybeBreak(long bytes, String label) throws Cir
                 }
                 if (memoryBytesLimit > 0 && newUsedWithOverhead > memoryBytesLimit) {
                     logger.warn("[{}] New used memory {} [{}] for data of [{}] would be larger than configured breaker: {} [{}], breaking",
+                            null,
                             this.name,
                             newUsedWithOverhead, new ByteSizeValue(newUsedWithOverhead), label,
                             memoryBytesLimit, new ByteSizeValue(memoryBytesLimit));
diff --git a/core/src/main/java/org/elasticsearch/common/breaker/MemoryCircuitBreaker.java b/core/src/main/java/org/elasticsearch/common/breaker/MemoryCircuitBreaker.java
index b069456b5d47..72b59150bc14 100644
--- a/core/src/main/java/org/elasticsearch/common/breaker/MemoryCircuitBreaker.java
+++ b/core/src/main/java/org/elasticsearch/common/breaker/MemoryCircuitBreaker.java
@@ -129,7 +129,7 @@ public double addEstimateBytesAndMaybeBreak(long bytes, String label) throws Cir
             }
             if (memoryBytesLimit > 0 && newUsedWithOverhead > memoryBytesLimit) {
                 logger.warn("New used memory {} [{}] from field [{}] would be larger than configured breaker: {} [{}], breaking",
-                        newUsedWithOverhead, new ByteSizeValue(newUsedWithOverhead), label,
+                        null, newUsedWithOverhead, new ByteSizeValue(newUsedWithOverhead), label,
                         memoryBytesLimit, new ByteSizeValue(memoryBytesLimit));
                 circuitBreak(label, newUsedWithOverhead);
             }
diff --git a/core/src/main/java/org/elasticsearch/common/logging/ESLogger.java b/core/src/main/java/org/elasticsearch/common/logging/ESLogger.java
index 06cce146b323..3f3ed1836752 100644
--- a/core/src/main/java/org/elasticsearch/common/logging/ESLogger.java
+++ b/core/src/main/java/org/elasticsearch/common/logging/ESLogger.java
@@ -101,21 +101,19 @@
 
     /**
      * Logs a WARN level message.
-     */
-    void warn(String msg, Object... params);
-
-    /**
-     * Logs a WARN level message.
+     *
+     * @param cause exception that caused this warning. If you are certain no exception caused it, pass {@code null}. It's intentional
+     *        that there isn't an overload of this method without this parameter: we want to make logging a warning without the exception
+     *        inconvenient because logging exceptions is often vital for debugging.
      */
     void warn(String msg, Throwable cause, Object... params);
 
     /**
      * Logs an ERROR level message.
-     */
-    void error(String msg, Object... params);
-
-    /**
-     * Logs an ERROR level message.
+     *
+     * @param cause exception that caused this error. If you are certain no exception caused it, pass {@code null}. It's intentional
+     *        that there isn't an overload of this method without this parameter: we want to make logging an error without the exception
+     *        inconvenient because logging exceptions is often vital for debugging.
      */
     void error(String msg, Throwable cause, Object... params);
 
diff --git a/core/src/main/java/org/elasticsearch/common/logging/jdk/JdkESLogger.java b/core/src/main/java/org/elasticsearch/common/logging/jdk/JdkESLogger.java
index 2db16983e1ad..0b12c8844a1a 100644
--- a/core/src/main/java/org/elasticsearch/common/logging/jdk/JdkESLogger.java
+++ b/core/src/main/java/org/elasticsearch/common/logging/jdk/JdkESLogger.java
@@ -131,12 +131,6 @@ protected void internalInfo(String msg, Throwable cause) {
         logger.log(record);
     }
 
-    @Override
-    protected void internalWarn(String msg) {
-        LogRecord record = new ESLogRecord(Level.WARNING, msg);
-        logger.log(record);
-    }
-
     @Override
     protected void internalWarn(String msg, Throwable cause) {
         LogRecord record = new ESLogRecord(Level.WARNING, msg);
@@ -144,12 +138,6 @@ protected void internalWarn(String msg, Throwable cause) {
         logger.log(record);
     }
 
-    @Override
-    protected void internalError(String msg) {
-        LogRecord record = new ESLogRecord(Level.SEVERE, msg);
-        logger.log(record);
-    }
-
     @Override
     protected void internalError(String msg, Throwable cause) {
         LogRecord record = new ESLogRecord(Level.SEVERE, msg);
diff --git a/core/src/main/java/org/elasticsearch/common/logging/log4j/Log4jESLogger.java b/core/src/main/java/org/elasticsearch/common/logging/log4j/Log4jESLogger.java
index e74307f8a4d5..ec3e8b974421 100644
--- a/core/src/main/java/org/elasticsearch/common/logging/log4j/Log4jESLogger.java
+++ b/core/src/main/java/org/elasticsearch/common/logging/log4j/Log4jESLogger.java
@@ -125,21 +125,11 @@ protected void internalInfo(String msg, Throwable cause) {
         logger.log(FQCN, Level.INFO, msg, cause);
     }
 
-    @Override
-    protected void internalWarn(String msg) {
-        logger.log(FQCN, Level.WARN, msg, null);
-    }
-
     @Override
     protected void internalWarn(String msg, Throwable cause) {
         logger.log(FQCN, Level.WARN, msg, cause);
     }
 
-    @Override
-    protected void internalError(String msg) {
-        logger.log(FQCN, Level.ERROR, msg, null);
-    }
-
     @Override
     protected void internalError(String msg, Throwable cause) {
         logger.log(FQCN, Level.ERROR, msg, cause);
diff --git a/core/src/main/java/org/elasticsearch/common/logging/slf4j/Slf4jESLogger.java b/core/src/main/java/org/elasticsearch/common/logging/slf4j/Slf4jESLogger.java
index fc40ec00b018..bc0d1855eb13 100644
--- a/core/src/main/java/org/elasticsearch/common/logging/slf4j/Slf4jESLogger.java
+++ b/core/src/main/java/org/elasticsearch/common/logging/slf4j/Slf4jESLogger.java
@@ -137,15 +137,6 @@ protected void internalInfo(String msg, Throwable cause) {
         }
     }
 
-    @Override
-    protected void internalWarn(String msg) {
-        if (lALogger != null) {
-            lALogger.log(null, FQCN, LocationAwareLogger.WARN_INT, msg, null, null);
-        } else {
-            logger.warn(msg);
-        }
-    }
-
     @Override
     protected void internalWarn(String msg, Throwable cause) {
         if (lALogger != null) {
@@ -155,15 +146,6 @@ protected void internalWarn(String msg, Throwable cause) {
         }
     }
 
-    @Override
-    protected void internalError(String msg) {
-        if (lALogger != null) {
-            lALogger.log(null, FQCN, LocationAwareLogger.ERROR_INT, msg, null, null);
-        } else {
-            logger.error(msg);
-        }
-    }
-
     @Override
     protected void internalError(String msg, Throwable cause) {
         if (lALogger != null) {
diff --git a/core/src/main/java/org/elasticsearch/common/logging/support/AbstractESLogger.java b/core/src/main/java/org/elasticsearch/common/logging/support/AbstractESLogger.java
index 441e2418e6cc..e3e23e4951aa 100644
--- a/core/src/main/java/org/elasticsearch/common/logging/support/AbstractESLogger.java
+++ b/core/src/main/java/org/elasticsearch/common/logging/support/AbstractESLogger.java
@@ -94,15 +94,6 @@ public void info(String msg, Throwable cause, Object... params) {
     protected abstract void internalInfo(String msg, Throwable cause);
 
 
-    @Override
-    public void warn(String msg, Object... params) {
-        if (isWarnEnabled()) {
-            internalWarn(LoggerMessageFormat.format(prefix, msg, params));
-        }
-    }
-
-    protected abstract void internalWarn(String msg);
-
     @Override
     public void warn(String msg, Throwable cause, Object... params) {
         if (isWarnEnabled()) {
@@ -113,15 +104,6 @@ public void warn(String msg, Throwable cause, Object... params) {
     protected abstract void internalWarn(String msg, Throwable cause);
 
 
-    @Override
-    public void error(String msg, Object... params) {
-        if (isErrorEnabled()) {
-            internalError(LoggerMessageFormat.format(prefix, msg, params));
-        }
-    }
-
-    protected abstract void internalError(String msg);
-
     @Override
     public void error(String msg, Throwable cause, Object... params) {
         if (isErrorEnabled()) {
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java b/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java
index 16a9796d8b6d..c79a1e97c2b9 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java
@@ -86,7 +86,7 @@ public static Version parseVersion(@Nullable String version, Version defaultVers
         try {
             return Version.parse(version);
         } catch (ParseException e) {
-            logger.warn("no version match {}, default to {}", version, defaultVersion, e);
+            logger.warn("no version match {}, default to {}", e, version, defaultVersion);
             return defaultVersion;
         }
     }
diff --git a/core/src/main/java/org/elasticsearch/common/network/NetworkService.java b/core/src/main/java/org/elasticsearch/common/network/NetworkService.java
index 6a280519c55d..2cb00bf54e74 100644
--- a/core/src/main/java/org/elasticsearch/common/network/NetworkService.java
+++ b/core/src/main/java/org/elasticsearch/common/network/NetworkService.java
@@ -194,7 +194,7 @@ public InetAddress resolvePublishHostAddresses(String publishHosts[]) throws IOE
             NetworkUtils.sortAddresses(sorted);
             addresses = new InetAddress[] { sorted.get(0) };
             logger.warn("publish host: {} resolves to multiple addresses, auto-selecting {{}} as single publish address", 
-                    Arrays.toString(publishHosts), NetworkAddress.format(addresses[0]));
+                    null, Arrays.toString(publishHosts), NetworkAddress.format(addresses[0]));
         }
         return addresses[0];
     }
diff --git a/core/src/main/java/org/elasticsearch/common/util/MultiDataPathUpgrader.java b/core/src/main/java/org/elasticsearch/common/util/MultiDataPathUpgrader.java
index 2cbc8cbdf995..d6612b874334 100644
--- a/core/src/main/java/org/elasticsearch/common/util/MultiDataPathUpgrader.java
+++ b/core/src/main/java/org/elasticsearch/common/util/MultiDataPathUpgrader.java
@@ -125,7 +125,7 @@ public void checkIndex(ShardPath targetPath) throws IOException {
             CheckIndex.Status status = checkIndex.checkIndex();
             out.flush();
             if (!status.clean) {
-                logger.warn("check index [failure]\n{}", new String(os.bytes().toBytes(), StandardCharsets.UTF_8));
+                logger.warn("check index [failure]\n{}", null, new String(os.bytes().toBytes(), StandardCharsets.UTF_8));
                 throw new IllegalStateException("index check failure");
             }
         }
@@ -334,7 +334,7 @@ public static void upgradeMultiDataPath(NodeEnvironment nodeEnv, ESLogger logger
                                 upgrader.checkIndex(shardPath);
                             }
                         } else {
-                            logger.debug("{} no upgrade needed - already upgraded");
+                            logger.debug("{} no upgrade needed - already upgraded", shardId);
                         }
                     }
                 }
diff --git a/core/src/main/java/org/elasticsearch/discovery/DiscoveryService.java b/core/src/main/java/org/elasticsearch/discovery/DiscoveryService.java
index eeba9baa32a7..751d85e9884a 100644
--- a/core/src/main/java/org/elasticsearch/discovery/DiscoveryService.java
+++ b/core/src/main/java/org/elasticsearch/discovery/DiscoveryService.java
@@ -89,7 +89,7 @@ protected void doStart() {
     public void waitForInitialState() {
         try {
             if (!initialStateListener.waitForInitialState(initialStateTimeout)) {
-                logger.warn("waited for {} and no initial state was set by the discovery", initialStateTimeout);
+                logger.warn("waited for {} and no initial state was set by the discovery", null, initialStateTimeout);
             }
         } catch (InterruptedException e) {
             Thread.currentThread().interrupt();
diff --git a/core/src/main/java/org/elasticsearch/discovery/local/LocalDiscovery.java b/core/src/main/java/org/elasticsearch/discovery/local/LocalDiscovery.java
index 947bf6099f80..e08c94a2ece9 100644
--- a/core/src/main/java/org/elasticsearch/discovery/local/LocalDiscovery.java
+++ b/core/src/main/java/org/elasticsearch/discovery/local/LocalDiscovery.java
@@ -216,7 +216,7 @@ protected void doStop() {
         synchronized (clusterGroups) {
             ClusterGroup clusterGroup = clusterGroups.get(clusterName);
             if (clusterGroup == null) {
-                logger.warn("Illegal state, should not have an empty cluster group when stopping, I should be there at teh very least...");
+                logger.warn("Illegal state, should not have an empty cluster group when stopping, I should be there at teh very least...", null);
                 return;
             }
             clusterGroup.members().remove(this);
@@ -257,7 +257,7 @@ public ClusterState execute(ClusterState currentState) {
                         DiscoveryNodes newNodes = currentState.nodes().removeDeadMembers(newMembers, master.localNode.id());
                         DiscoveryNodes.Delta delta = newNodes.delta(currentState.nodes());
                         if (delta.added()) {
-                            logger.warn("No new nodes should be created when a new discovery view is accepted");
+                            logger.warn("No new nodes should be created when a new discovery view is accepted", null);
                         }
                         // reroute here, so we eagerly remove dead nodes from the routing
                         ClusterState updatedState = ClusterState.builder(currentState).nodes(newNodes).build();
@@ -433,7 +433,7 @@ public void clusterStateProcessed(String source, ClusterState oldState, ClusterS
                         DiscoveryNode[] pendingNodes = publishResponseHandler.pendingNodes();
                         // everyone may have just responded
                         if (pendingNodes.length > 0) {
-                            logger.warn("timed out waiting for all nodes to process published state [{}] (timeout [{}], pending nodes: {})", clusterState.version(), publishTimeout, pendingNodes);
+                            logger.warn("timed out waiting for all nodes to process published state [{}] (timeout [{}], pending nodes: {})", null, clusterState.version(), publishTimeout, pendingNodes);
                         }
                     }
                 } catch (InterruptedException e) {
diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/NodeJoinController.java b/core/src/main/java/org/elasticsearch/discovery/zen/NodeJoinController.java
index 78df4e21a031..303e27b37663 100644
--- a/core/src/main/java/org/elasticsearch/discovery/zen/NodeJoinController.java
+++ b/core/src/main/java/org/elasticsearch/discovery/zen/NodeJoinController.java
@@ -379,7 +379,7 @@ public ClusterState execute(ClusterState currentState) {
                         for (DiscoveryNode existingNode : currentState.nodes()) {
                             if (node.address().equals(existingNode.address())) {
                                 nodesBuilder.remove(existingNode.id());
-                                logger.warn("received join request from node [{}], but found existing node {} with same address, removing existing node", node, existingNode);
+                                logger.warn("received join request from node [{}], but found existing node {} with same address, removing existing node", null, node, existingNode);
                             }
                         }
                     }
diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java b/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java
index e5ec230fd665..edbf07a31487 100644
--- a/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java
+++ b/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java
@@ -819,7 +819,7 @@ public static void validateStateIsFromCurrentMaster(ESLogger logger, DiscoveryNo
             return;
         }
         if (!currentNodes.masterNodeId().equals(newClusterState.nodes().masterNodeId())) {
-            logger.warn("received a cluster state from a different master than the current one, rejecting (received {}, current {})", newClusterState.nodes().masterNode(), currentNodes.masterNode());
+            logger.warn("received a cluster state from a different master than the current one, rejecting (received {}, current {})", null, newClusterState.nodes().masterNode(), currentNodes.masterNode());
             throw new IllegalStateException("cluster state from a different master than the current one, rejecting (received " + newClusterState.nodes().masterNode() + ", current " + currentNodes.masterNode() + ")");
         }
     }
@@ -828,7 +828,7 @@ void handleJoinRequest(final DiscoveryNode node, final MembershipAction.JoinCall
 
         if (!transportService.addressSupported(node.address().getClass())) {
             // TODO, what should we do now? Maybe inform that node that its crap?
-            logger.warn("received a wrong address type from [{}], ignoring...", node);
+            logger.warn("received a wrong address type from [{}], ignoring...", null, node);
         } else if (nodeJoinController == null) {
             throw new IllegalStateException("discovery module is not yet started");
         } else {
@@ -955,7 +955,7 @@ protected ClusterState rejoin(ClusterState clusterState, String reason) {
         // *** called from within an cluster state update task *** //
         assert Thread.currentThread().getName().contains(InternalClusterService.UPDATE_THREAD_NAME);
 
-        logger.warn(reason + ", current nodes: {}", clusterState.nodes());
+        logger.warn(reason + ", current nodes: {}", null, clusterState.nodes());
         nodesFD.stop();
         masterFD.stop(reason);
 
@@ -988,7 +988,7 @@ private ClusterState handleAnotherMaster(ClusterState localClusterState, final D
         if (otherClusterStateVersion > localClusterState.version()) {
             return rejoin(localClusterState, "zen-disco-discovered another master with a new cluster_state [" + otherMaster + "][" + reason + "]");
         } else {
-            logger.warn("discovered [{}] which is also master but with an older cluster_state, telling [{}] to rejoin the cluster ([{}])", otherMaster, otherMaster, reason);
+            logger.warn("discovered [{}] which is also master but with an older cluster_state, telling [{}] to rejoin the cluster ([{}])", null, otherMaster, otherMaster, reason);
             try {
                 // make sure we're connected to this node (connect to node does nothing if we're already connected)
                 // since the network connections are asymmetric, it may be that we received a state but have disconnected from the node
diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/elect/ElectMasterService.java b/core/src/main/java/org/elasticsearch/discovery/zen/elect/ElectMasterService.java
index 9164a85388a9..37f8b0c2485e 100644
--- a/core/src/main/java/org/elasticsearch/discovery/zen/elect/ElectMasterService.java
+++ b/core/src/main/java/org/elasticsearch/discovery/zen/elect/ElectMasterService.java
@@ -136,7 +136,7 @@ public DiscoveryNode electMaster(Iterable<DiscoveryNode> nodes) {
         DiscoveryNode masterNode = sortedNodes.get(0);
         // Sanity check: maybe we don't end up here, because serialization may have failed.
         if (masterNode.getVersion().before(minMasterVersion)) {
-            logger.warn("ignoring master [{}], because the version [{}] is lower than the minimum compatible version [{}]", masterNode, masterNode.getVersion(), minMasterVersion);
+            logger.warn("ignoring master [{}], because the version [{}] is lower than the minimum compatible version [{}]", null, masterNode, masterNode.getVersion(), minMasterVersion);
             return null;
         } else {
             return masterNode;
diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPing.java b/core/src/main/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPing.java
index 99feb4b7f726..f6d33782bf68 100644
--- a/core/src/main/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPing.java
+++ b/core/src/main/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPing.java
@@ -468,7 +468,7 @@ public void handleResponse(UnicastPingResponse response) {
                         if (sendPingsHandler == null) {
                             if (!closed) {
                                 // Only log when we're not closing the node. Having no send ping handler is then expected
-                                logger.warn("received ping response {} with no matching handler id [{}]", pingResponse, response.id);
+                                logger.warn("received ping response {} with no matching handler id [{}]", null, pingResponse, response.id);
                             }
                         } else {
                             sendPingsHandler.pingCollection().addPing(pingResponse);
diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/publish/PendingClusterStatesQueue.java b/core/src/main/java/org/elasticsearch/discovery/zen/publish/PendingClusterStatesQueue.java
index 2f444f50288f..5729648df1c6 100644
--- a/core/src/main/java/org/elasticsearch/discovery/zen/publish/PendingClusterStatesQueue.java
+++ b/core/src/main/java/org/elasticsearch/discovery/zen/publish/PendingClusterStatesQueue.java
@@ -68,7 +68,7 @@ public synchronized void addPending(ClusterState state) {
         pendingStates.add(new ClusterStateContext(state));
         if (pendingStates.size() > maxQueueSize) {
             ClusterStateContext context = pendingStates.remove(0);
-            logger.warn("dropping pending state [{}]. more than [{}] pending states.", context, maxQueueSize);
+            logger.warn("dropping pending state [{}]. more than [{}] pending states.", null, context, maxQueueSize);
             if (context.committed()) {
                 context.listener.onNewClusterStateFailed(new ElasticsearchException("too many pending states ([{}] pending)", maxQueueSize));
             }
@@ -153,7 +153,7 @@ public synchronized void markAsProcessed(ClusterState state) {
                 if (pendingContext.committed()) {
                     // this is a committed state , warn
                     logger.warn("received a cluster state (uuid[{}]/v[{}]) from a different master than the current one, rejecting (received {}, current {})",
-                            pendingState.stateUUID(), pendingState.version(),
+                            null, pendingState.stateUUID(), pendingState.version(),
                             pendingMasterNode, currentMaster);
                     pendingContext.listener.onNewClusterStateFailed(
                             new IllegalStateException("cluster state from a different master than the current one, rejecting (received " + pendingMasterNode + ", current " + currentMaster + ")")
diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java b/core/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java
index 91fd622023fc..4bc534a05383 100644
--- a/core/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java
+++ b/core/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java
@@ -180,7 +180,7 @@ private void innerPublish(final ClusterChangedEvent clusterChangedEvent, final S
                 DiscoveryNode[] pendingNodes = publishResponseHandler.pendingNodes();
                 // everyone may have just responded
                 if (pendingNodes.length > 0) {
-                    logger.warn("timed out waiting for all nodes to process published state [{}] (timeout [{}], pending nodes: {})", clusterState.version(), publishTimeout, pendingNodes);
+                    logger.warn("timed out waiting for all nodes to process published state [{}] (timeout [{}], pending nodes: {})", null, clusterState.version(), publishTimeout, pendingNodes);
                 }
             }
         } catch (InterruptedException e) {
@@ -375,13 +375,13 @@ protected void handleIncomingClusterStateRequest(BytesTransportRequest request,
     void validateIncomingState(ClusterState incomingState, ClusterState lastSeenClusterState) {
         final ClusterName incomingClusterName = incomingState.getClusterName();
         if (!incomingClusterName.equals(this.clusterName)) {
-            logger.warn("received cluster state from [{}] which is also master but with a different cluster name [{}]", incomingState.nodes().masterNode(), incomingClusterName);
+            logger.warn("received cluster state from [{}] which is also master but with a different cluster name [{}]", null, incomingState.nodes().masterNode(), incomingClusterName);
             throw new IllegalStateException("received state from a node that is not part of the cluster");
         }
         final DiscoveryNodes currentNodes = nodesProvider.nodes();
 
         if (currentNodes.localNode().equals(incomingState.nodes().localNode()) == false) {
-            logger.warn("received a cluster state from [{}] and not part of the cluster, should not happen", incomingState.nodes().masterNode());
+            logger.warn("received a cluster state from [{}] and not part of the cluster, should not happen", null, incomingState.nodes().masterNode());
             throw new IllegalStateException("received state from a node that is not part of the cluster");
         }
 
diff --git a/core/src/main/java/org/elasticsearch/gateway/Gateway.java b/core/src/main/java/org/elasticsearch/gateway/Gateway.java
index e89cd6c8577a..e75402d0ba2c 100644
--- a/core/src/main/java/org/elasticsearch/gateway/Gateway.java
+++ b/core/src/main/java/org/elasticsearch/gateway/Gateway.java
@@ -163,7 +163,7 @@ protected int calcRequiredAllocations(final String setting, final int nodeCount)
                 requiredAllocation = Integer.parseInt(setting);
             }
         } catch (Exception e) {
-            logger.warn("failed to derived initial_meta from value {}", setting);
+            logger.warn("failed to derived initial_meta from value {}", e, setting);
         }
         return requiredAllocation;
     }
diff --git a/core/src/main/java/org/elasticsearch/gateway/LocalAllocateDangledIndices.java b/core/src/main/java/org/elasticsearch/gateway/LocalAllocateDangledIndices.java
index 0e151cec5e5f..db7e02406962 100644
--- a/core/src/main/java/org/elasticsearch/gateway/LocalAllocateDangledIndices.java
+++ b/core/src/main/java/org/elasticsearch/gateway/LocalAllocateDangledIndices.java
@@ -136,7 +136,7 @@ public ClusterState execute(ClusterState currentState) {
                         }
                         if (currentState.metaData().hasAlias(indexMetaData.getIndex())) {
                             logger.warn("ignoring dangled index [{}] on node [{}] due to an existing alias with the same name",
-                                    indexMetaData.getIndex(), request.fromNode);
+                                    null, indexMetaData.getIndex(), request.fromNode);
                             continue;
                         }
                         importNeeded = true;
diff --git a/core/src/main/java/org/elasticsearch/gateway/PrimaryShardAllocator.java b/core/src/main/java/org/elasticsearch/gateway/PrimaryShardAllocator.java
index e560b4458b73..3a1c69e21166 100644
--- a/core/src/main/java/org/elasticsearch/gateway/PrimaryShardAllocator.java
+++ b/core/src/main/java/org/elasticsearch/gateway/PrimaryShardAllocator.java
@@ -151,7 +151,7 @@ private boolean isEnoughAllocationsFound(ShardRouting shard, IndexMetaData index
                     requiredAllocation = Integer.parseInt(initialShards);
                 }
             } catch (Exception e) {
-                logger.warn("[{}][{}] failed to derived initial_shards from value {}, ignore allocation for {}", shard.index(), shard.id(), initialShards, shard);
+                logger.warn("[{}][{}] failed to derived initial_shards from value {}, ignore allocation for {}", e, shard.index(), shard.id(), initialShards, shard);
             }
         }
 
diff --git a/core/src/main/java/org/elasticsearch/gateway/TransportNodesListGatewayMetaState.java b/core/src/main/java/org/elasticsearch/gateway/TransportNodesListGatewayMetaState.java
index a117eb709afb..44498f5742f6 100644
--- a/core/src/main/java/org/elasticsearch/gateway/TransportNodesListGatewayMetaState.java
+++ b/core/src/main/java/org/elasticsearch/gateway/TransportNodesListGatewayMetaState.java
@@ -99,7 +99,7 @@ protected NodesGatewayMetaState newResponse(Request request, AtomicReferenceArra
             } else if (resp instanceof FailedNodeException) {
                 failures.add((FailedNodeException) resp);
             } else {
-                logger.warn("unknown response type [{}], expected NodeLocalGatewayMetaState or FailedNodeException", resp);
+                logger.warn("unknown response type [{}], expected NodeLocalGatewayMetaState or FailedNodeException", null, resp);
             }
         }
         return new NodesGatewayMetaState(clusterName, nodesList.toArray(new NodeGatewayMetaState[nodesList.size()]),
diff --git a/core/src/main/java/org/elasticsearch/gateway/TransportNodesListGatewayStartedShards.java b/core/src/main/java/org/elasticsearch/gateway/TransportNodesListGatewayStartedShards.java
index bfc078a6679f..09927795cdaa 100644
--- a/core/src/main/java/org/elasticsearch/gateway/TransportNodesListGatewayStartedShards.java
+++ b/core/src/main/java/org/elasticsearch/gateway/TransportNodesListGatewayStartedShards.java
@@ -112,7 +112,7 @@ protected NodesGatewayStartedShards newResponse(Request request, AtomicReference
             } else if (resp instanceof FailedNodeException) {
                 failures.add((FailedNodeException) resp);
             } else {
-                logger.warn("unknown response type [{}], expected NodeLocalGatewayStartedShards or FailedNodeException", resp);
+                logger.warn("unknown response type [{}], expected NodeLocalGatewayStartedShards or FailedNodeException", null, resp);
             }
         }
         return new NodesGatewayStartedShards(clusterName, nodesList.toArray(new NodeGatewayStartedShards[nodesList.size()]),
@@ -146,7 +146,7 @@ protected NodeGatewayStartedShards nodeOperation(NodeRequest request) {
                 // is equal to IndexMetaData.INDEX_UUID_NA_VALUE otherwise this shard doesn't belong to the requested index.
                 if (indexUUID.equals(shardStateMetaData.indexUUID) == false
                         && IndexMetaData.INDEX_UUID_NA_VALUE.equals(shardStateMetaData.indexUUID) == false) {
-                    logger.warn("{} shard state info found but indexUUID didn't match expected [{}] actual [{}]", shardId, indexUUID, shardStateMetaData.indexUUID);
+                    logger.warn("{} shard state info found but indexUUID didn't match expected [{}] actual [{}]", null, shardId, indexUUID, shardStateMetaData.indexUUID);
                 } else {
                     logger.debug("{} shard state info found: [{}]", shardId, shardStateMetaData);
                     return new NodeGatewayStartedShards(clusterService.localNode(), shardStateMetaData.version);
diff --git a/core/src/main/java/org/elasticsearch/http/netty/NettyHttpServerTransport.java b/core/src/main/java/org/elasticsearch/http/netty/NettyHttpServerTransport.java
index ebc655ae4a52..00d1919f4ed8 100644
--- a/core/src/main/java/org/elasticsearch/http/netty/NettyHttpServerTransport.java
+++ b/core/src/main/java/org/elasticsearch/http/netty/NettyHttpServerTransport.java
@@ -195,7 +195,7 @@ public NettyHttpServerTransport(Settings settings, NetworkService networkService
 
         // validate max content length
         if (maxContentLength.bytes() > Integer.MAX_VALUE) {
-            logger.warn("maxContentLength[" + maxContentLength + "] set to high value, resetting it to [100mb]");
+            logger.warn("maxContentLength[" + maxContentLength + "] set to high value, resetting it to [100mb]", null);
             maxContentLength = new ByteSizeValue(100, ByteSizeUnit.MB);
         }
         this.maxContentLength = maxContentLength;
diff --git a/core/src/main/java/org/elasticsearch/index/IndexService.java b/core/src/main/java/org/elasticsearch/index/IndexService.java
index 92ca00231b53..5107d1340ae3 100644
--- a/core/src/main/java/org/elasticsearch/index/IndexService.java
+++ b/core/src/main/java/org/elasticsearch/index/IndexService.java
@@ -240,7 +240,7 @@ public synchronized IndexShard createShard(ShardRouting routing) throws IOExcept
             try {
                 path = ShardPath.loadShardPath(logger, nodeEnv, shardId, this.indexSettings);
             } catch (IllegalStateException ex) {
-                logger.warn("{} failed to load shard path, trying to remove leftover", shardId);
+                logger.warn("{} failed to load shard path, trying to remove leftover", ex, shardId);
                 try {
                     ShardPath.deleteLeftoverShardDirectory(logger, nodeEnv, lock, this.indexSettings);
                     path = ShardPath.loadShardPath(logger, nodeEnv, shardId, this.indexSettings);
diff --git a/core/src/main/java/org/elasticsearch/index/codec/PerFieldMappingPostingFormatCodec.java b/core/src/main/java/org/elasticsearch/index/codec/PerFieldMappingPostingFormatCodec.java
index 2c23f9474752..26da988bde1d 100644
--- a/core/src/main/java/org/elasticsearch/index/codec/PerFieldMappingPostingFormatCodec.java
+++ b/core/src/main/java/org/elasticsearch/index/codec/PerFieldMappingPostingFormatCodec.java
@@ -56,7 +56,7 @@ public PerFieldMappingPostingFormatCodec(Lucene50StoredFieldsFormat.Mode compres
     public PostingsFormat getPostingsFormatForField(String field) {
         final MappedFieldType indexName = mapperService.indexName(field);
         if (indexName == null) {
-            logger.warn("no index mapper found for field: [{}] returning default postings format", field);
+            logger.warn("no index mapper found for field: [{}] returning default postings format", null, field);
         } else if (indexName instanceof CompletionFieldMapper.CompletionFieldType) {
             return CompletionFieldMapper.CompletionFieldType.postingsFormat();
         }
diff --git a/core/src/main/java/org/elasticsearch/index/engine/Engine.java b/core/src/main/java/org/elasticsearch/index/engine/Engine.java
index 0504fdfa9969..482c5ddce406 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/Engine.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/Engine.java
@@ -530,7 +530,7 @@ public void failEngine(String reason, @Nullable Throwable failure) {
                     closeNoLock("engine failed on: [" + reason + "]");
                 } finally {
                     if (failedEngine != null) {
-                        logger.debug("tried to fail engine but engine is already failed. ignoring. [{}]", reason, failure);
+                        logger.debug("tried to fail engine but engine is already failed. ignoring. [{}]", failure, reason);
                         return;
                     }
                     logger.warn("failed engine [{}]", failure, reason);
@@ -556,7 +556,7 @@ public void failEngine(String reason, @Nullable Throwable failure) {
                 store.decRef();
             }
         } else {
-            logger.debug("tried to fail engine but could not acquire lock - engine should be failed by now [{}]", reason, failure);
+            logger.debug("tried to fail engine but could not acquire lock - engine should be failed by now [{}]", failure, reason);
         }
     }
 
diff --git a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
index 1404b61b8ec8..6ea6d7bc65a3 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
@@ -1083,7 +1083,7 @@ public synchronized void afterMerge(OnGoingMerge merge) {
                     @Override
                     public void onFailure(Throwable t) {
                         if (isClosed.get() == false) {
-                            logger.warn("failed to flush after merge has finished");
+                            logger.warn("failed to flush after merge has finished", t);
                         }
                     }
 
diff --git a/core/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataService.java b/core/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataService.java
index 809472604427..97b3b2303d0f 100644
--- a/core/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataService.java
+++ b/core/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataService.java
@@ -204,13 +204,13 @@ public synchronized void clearField(final String fieldName) {
         IndexFieldData.Builder builder = null;
         String format = type.getFormat(indexSettings.getSettings());
         if (format != null && FieldDataType.DOC_VALUES_FORMAT_VALUE.equals(format) && !docValues) {
-            logger.warn("field [" + fieldNames.fullName() + "] has no doc values, will use default field data format");
+            logger.warn("field [" + fieldNames.fullName() + "] has no doc values, will use default field data format", null);
             format = null;
         }
         if (format != null) {
             builder = buildersByTypeAndFormat.get(Tuple.tuple(type.getType(), format));
             if (builder == null) {
-                logger.warn("failed to find format [" + format + "] for field [" + fieldNames.fullName() + "], will use default");
+                logger.warn("failed to find format [" + format + "] for field [" + fieldNames.fullName() + "], will use default", null);
             }
         }
         if (builder == null && docValues) {
diff --git a/core/src/main/java/org/elasticsearch/index/indexing/IndexingSlowLog.java b/core/src/main/java/org/elasticsearch/index/indexing/IndexingSlowLog.java
index 292c2a16e911..8534df331b40 100644
--- a/core/src/main/java/org/elasticsearch/index/indexing/IndexingSlowLog.java
+++ b/core/src/main/java/org/elasticsearch/index/indexing/IndexingSlowLog.java
@@ -145,7 +145,7 @@ private int readSourceToLog(Settings settings) {
 
     private void postIndexing(ParsedDocument doc, long tookInNanos) {
         if (indexWarnThreshold >= 0 && tookInNanos > indexWarnThreshold) {
-            indexLogger.warn("{}", new SlowLogParsedDocumentPrinter(doc, tookInNanos, reformat, maxSourceCharsToLog));
+            indexLogger.warn("{}", null, new SlowLogParsedDocumentPrinter(doc, tookInNanos, reformat, maxSourceCharsToLog));
         } else if (indexInfoThreshold >= 0 && tookInNanos > indexInfoThreshold) {
             indexLogger.info("{}", new SlowLogParsedDocumentPrinter(doc, tookInNanos, reformat, maxSourceCharsToLog));
         } else if (indexDebugThreshold >= 0 && tookInNanos > indexDebugThreshold) {
@@ -192,4 +192,4 @@ public String toString() {
             return sb.toString();
         }
     }
-}
\ No newline at end of file
+}
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java b/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java
index f617dd5c6f03..b62defaf57a7 100755
--- a/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java
@@ -241,7 +241,7 @@ private DocumentMapper merge(DocumentMapper mapper, boolean updateAllTypes) {
                 if (indexSettings.getIndexVersionCreated().onOrAfter(Version.V_2_0_0_beta1)) {
                     throw new IllegalArgumentException("mapping type name [" + mapper.type() + "] must not start with a '.'");
                 } else {
-                    logger.warn("Type [{}] starts with a '.', it is recommended not to start a type name with a '.'", mapper.type());
+                    logger.warn("Type [{}] starts with a '.', it is recommended not to start a type name with a '.'", null, mapper.type());
                 }
             }
             // we can add new field/object mappers while the old ones are there
diff --git a/core/src/main/java/org/elasticsearch/index/percolator/QueriesLoaderCollector.java b/core/src/main/java/org/elasticsearch/index/percolator/QueriesLoaderCollector.java
index 26b52f773e94..6425787311ad 100644
--- a/core/src/main/java/org/elasticsearch/index/percolator/QueriesLoaderCollector.java
+++ b/core/src/main/java/org/elasticsearch/index/percolator/QueriesLoaderCollector.java
@@ -80,7 +80,7 @@ public void collect(int doc) throws IOException {
                 if (parseQuery != null) {
                     queries.put(BytesRef.deepCopyOf(id), parseQuery);
                 } else {
-                    logger.warn("failed to add query [{}] - parser returned null", id);
+                    logger.warn("failed to add query [{}] - parser returned null", null, id);
                 }
 
             } catch (Exception e) {
diff --git a/core/src/main/java/org/elasticsearch/index/search/stats/SearchSlowLog.java b/core/src/main/java/org/elasticsearch/index/search/stats/SearchSlowLog.java
index 108dab449a3d..5e9f4c4e5694 100644
--- a/core/src/main/java/org/elasticsearch/index/search/stats/SearchSlowLog.java
+++ b/core/src/main/java/org/elasticsearch/index/search/stats/SearchSlowLog.java
@@ -89,7 +89,7 @@
 
     void onQueryPhase(SearchContext context, long tookInNanos) {
         if (queryWarnThreshold >= 0 && tookInNanos > queryWarnThreshold) {
-            queryLogger.warn("{}", new SlowLogSearchContextPrinter(context, tookInNanos, reformat));
+            queryLogger.warn("{}", null, new SlowLogSearchContextPrinter(context, tookInNanos, reformat));
         } else if (queryInfoThreshold >= 0 && tookInNanos > queryInfoThreshold) {
             queryLogger.info("{}", new SlowLogSearchContextPrinter(context, tookInNanos, reformat));
         } else if (queryDebugThreshold >= 0 && tookInNanos > queryDebugThreshold) {
@@ -101,7 +101,7 @@ void onQueryPhase(SearchContext context, long tookInNanos) {
 
     void onFetchPhase(SearchContext context, long tookInNanos) {
         if (fetchWarnThreshold >= 0 && tookInNanos > fetchWarnThreshold) {
-            fetchLogger.warn("{}", new SlowLogSearchContextPrinter(context, tookInNanos, reformat));
+            fetchLogger.warn("{}", null, new SlowLogSearchContextPrinter(context, tookInNanos, reformat));
         } else if (fetchInfoThreshold >= 0 && tookInNanos > fetchInfoThreshold) {
             fetchLogger.info("{}", new SlowLogSearchContextPrinter(context, tookInNanos, reformat));
         } else if (fetchDebugThreshold >= 0 && tookInNanos > fetchDebugThreshold) {
diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
index b8bbb65c4959..f1208a1c45fc 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
@@ -346,7 +346,7 @@ public void updateRoutingEntry(final ShardRouting newRouting, final boolean pers
         try {
             if (currentRouting != null) {
                 if (!newRouting.primary() && currentRouting.primary()) {
-                    logger.warn("suspect illegal state: trying to move shard from primary mode to replica mode");
+                    logger.warn("suspect illegal state: trying to move shard from primary mode to replica mode", null);
                 }
                 // if its the same routing except for some metadata info, return
                 if (currentRouting.equalsIgnoringMetaData(newRouting)) {
@@ -670,7 +670,7 @@ public void forceMerge(ForceMergeRequest forceMerge) throws IOException {
                 false, true, upgrade.upgradeOnlyAncientSegments());
         org.apache.lucene.util.Version version = minimumCompatibleVersion();
         if (logger.isTraceEnabled()) {
-            logger.trace("upgraded segment {} from version {} to version {}", previousVersion, version);
+            logger.trace("upgraded segments from version {} to version {}, onlyAncientSegments {}", previousVersion, version, upgrade.upgradeOnlyAncientSegments());
         }
 
         return version;
@@ -1322,7 +1322,7 @@ private void doCheckIndex() throws IOException {
             }
             out.flush();
             if (corrupt != null) {
-                logger.warn("check index [failure]\n{}", new String(os.bytes().toBytes(), StandardCharsets.UTF_8));
+                logger.warn("check index [failure]\n{}", corrupt, new String(os.bytes().toBytes(), StandardCharsets.UTF_8));
                 throw corrupt;
             }
         } else {
@@ -1337,7 +1337,9 @@ private void doCheckIndex() throws IOException {
                         // ignore if closed....
                         return;
                     }
-                    logger.warn("check index [failure]\n{}", new String(os.bytes().toBytes(), StandardCharsets.UTF_8));
+                    // We pass null as the cause here because the root cause exception will be included in CheckIndex's output which we log
+                    // in full:
+                    logger.warn("check index [failure]\n{}", null, new String(os.bytes().toBytes(), StandardCharsets.UTF_8));
                     if ("fix".equalsIgnoreCase(checkIndexOnStartup)) {
                         if (logger.isDebugEnabled()) {
                             logger.debug("fixing index, writing new segments file ...");
@@ -1525,7 +1527,7 @@ public void sync(Translog.Location location) {
         try {
             return Translog.Durabilty.valueOf(value.toUpperCase(Locale.ROOT));
         } catch (IllegalArgumentException ex) {
-            logger.warn("Can't apply {} illegal value: {} using {} instead, use one of: {}", TranslogConfig.INDEX_TRANSLOG_DURABILITY, value, defaultValue, Arrays.toString(Translog.Durabilty.values()));
+            logger.warn("Can't apply {} illegal value: {} using {} instead, use one of: {}", ex, TranslogConfig.INDEX_TRANSLOG_DURABILITY, value, defaultValue, Arrays.toString(Translog.Durabilty.values()));
             return defaultValue;
         }
     }
diff --git a/core/src/main/java/org/elasticsearch/index/shard/MergePolicyConfig.java b/core/src/main/java/org/elasticsearch/index/shard/MergePolicyConfig.java
index 0a9315dbc250..e12a92db5315 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/MergePolicyConfig.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/MergePolicyConfig.java
@@ -151,7 +151,7 @@ public MergePolicyConfig(ESLogger logger, Settings indexSettings) {
         double reclaimDeletesWeight = indexSettings.getAsDouble("index.merge.policy.reclaim_deletes_weight", DEFAULT_RECLAIM_DELETES_WEIGHT);
         this.mergesEnabled = indexSettings.getAsBoolean(INDEX_MERGE_ENABLED, true);
         if (mergesEnabled == false) {
-            logger.warn("[{}] is set to false, this should only be used in tests and can cause serious problems in production environments", INDEX_MERGE_ENABLED);
+            logger.warn("[{}] is set to false, this should only be used in tests and can cause serious problems in production environments", null, INDEX_MERGE_ENABLED);
         }
         maxMergeAtOnce = adjustMaxMergeAtOnceIfNeeded(maxMergeAtOnce, segmentsPerTier);
         mergePolicy.setNoCFSRatio(noCFSRatio);
diff --git a/core/src/main/java/org/elasticsearch/index/shard/ShardPath.java b/core/src/main/java/org/elasticsearch/index/shard/ShardPath.java
index d940d1a93cd9..4722e640c11a 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/ShardPath.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/ShardPath.java
@@ -122,7 +122,7 @@ public static ShardPath loadShardPath(ESLogger logger, NodeEnvironment env, Shar
             ShardStateMetaData load = ShardStateMetaData.FORMAT.loadLatestState(logger, path);
             if (load != null) {
                 if (load.indexUUID.equals(indexUUID) == false && IndexMetaData.INDEX_UUID_NA_VALUE.equals(load.indexUUID) == false) {
-                    logger.warn("{} found shard on path: [{}] with a different index UUID - this shard seems to be leftover from a different index with the same name. Remove the leftover shard in order to reuse the path with the current index", shardId, path);
+                    logger.warn("{} found shard on path: [{}] with a different index UUID - this shard seems to be leftover from a different index with the same name. Remove the leftover shard in order to reuse the path with the current index", null, shardId, path);
                     throw new IllegalStateException(shardId + " index UUID in shard state was: " + load.indexUUID + " expected: " + indexUUID + " on shard path: " + path);
                 }
                 if (loadedPath == null) {
@@ -159,7 +159,7 @@ public static void deleteLeftoverShardDirectory(ESLogger logger, NodeEnvironment
             ShardStateMetaData load = ShardStateMetaData.FORMAT.loadLatestState(logger, path);
             if (load != null) {
                 if (load.indexUUID.equals(indexUUID) == false && IndexMetaData.INDEX_UUID_NA_VALUE.equals(load.indexUUID) == false) {
-                    logger.warn("{} deleting leftover shard on path: [{}] with a different index UUID", lock.getShardId(), path);
+                    logger.warn("{} deleting leftover shard on path: [{}] with a different index UUID", null, lock.getShardId(), path);
                     assert Files.isDirectory(path) : path + " is not a directory";
                     NodeEnvironment.acquireFSLockForPaths(indexSettings, paths);
                     IOUtils.rm(path);
diff --git a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java
index 674d1085660e..268aa667d00d 100644
--- a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java
+++ b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java
@@ -431,7 +431,7 @@ protected long findLatestFileNameGeneration(Map<String, BlobMetaData> blobs) {
                         generation = currentGen;
                     }
                 } catch (NumberFormatException e) {
-                    logger.warn("file [{}] does not conform to the '{}' schema", name, DATA_BLOB_PREFIX);
+                    logger.warn("file [{}] does not conform to the '{}' schema", e, name, DATA_BLOB_PREFIX);
                 }
             }
             return generation;
@@ -453,7 +453,7 @@ protected long findLatestFileNameGeneration(Map<String, BlobMetaData> blobs) {
                             latest = gen;
                         }
                     } catch (NumberFormatException ex) {
-                        logger.warn("failed to parse index file name [{}]", name);
+                        logger.warn("failed to parse index file name [{}]", ex, name);
                     }
                 }
             }
@@ -890,11 +890,11 @@ public void restore() throws IOException {
                             store.deleteQuiet("restore", storeFile);
                             store.directory().deleteFile(storeFile);
                         } catch (IOException e) {
-                            logger.warn("[{}] failed to delete file [{}] during snapshot cleanup", snapshotId, storeFile);
+                            logger.warn("[{}] failed to delete file [{}] during snapshot cleanup", e, snapshotId, storeFile);
                         }
                     }
                 } catch (IOException e) {
-                    logger.warn("[{}] failed to list directory - some of files might not be deleted", snapshotId);
+                    logger.warn("[{}] failed to list directory - some of files might not be deleted", e, snapshotId);
                 }
             } finally {
                 store.decRef();
diff --git a/core/src/main/java/org/elasticsearch/indices/IndicesService.java b/core/src/main/java/org/elasticsearch/indices/IndicesService.java
index ca059fa25f00..0b0cdfb16aba 100644
--- a/core/src/main/java/org/elasticsearch/indices/IndicesService.java
+++ b/core/src/main/java/org/elasticsearch/indices/IndicesService.java
@@ -136,7 +136,7 @@ protected void doStop() {
         }
         try {
             if (latch.await(shardsClosedTimeout.seconds(), TimeUnit.SECONDS) == false) {
-              logger.warn("Not all shards are closed yet, waited {}sec - stopping service", shardsClosedTimeout.seconds());
+                logger.warn("Not all shards are closed yet, waited {} - stopping service", null, shardsClosedTimeout);
             }
         } catch (InterruptedException e) {
             // ignore
@@ -694,13 +694,13 @@ public void processPendingDeletes(Index index, IndexSettings indexSettings, Time
                                     logger.debug("{} retry pending delete", ex, shardLock.getShardId());
                                 }
                             } else {
-                                logger.warn("{} no shard lock for pending delete", delete.shardId);
+                                logger.warn("{} no shard lock for pending delete", null, delete.shardId);
                                 iterator.remove();
                             }
                         }
                     }
                     if (remove.isEmpty() == false) {
-                        logger.warn("{} still pending deletes present for shards {} - retrying", index, remove.toString());
+                        logger.warn("{} still pending deletes present for shards {} - retrying", null, index, remove.toString());
                         Thread.sleep(sleepTime);
                         sleepTime = Math.min(maxSleepTimeMs, sleepTime * 2); // increase the sleep time gradually
                         logger.debug("{} schedule pending delete retry after {} ms", index, sleepTime);
diff --git a/core/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java b/core/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java
index ad264c2ac057..a8195c06a103 100644
--- a/core/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java
+++ b/core/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java
@@ -308,7 +308,7 @@ void sendSyncRequests(final String syncId, final List<ShardRouting> shards, Clus
             }
             final Engine.CommitId expectedCommitId = expectedCommitIds.get(shard.currentNodeId());
             if (expectedCommitId == null) {
-                logger.trace("{} can't resolve expected commit id for {}, skipping for sync id [{}]. shard routing {}", shardId, syncId, shard);
+                logger.trace("{} can't resolve expected commit id for {}, skipping for sync id [{}]. shard routing {}", shardId, shard.currentNodeId(), syncId, shard);
                 results.put(shard, new SyncedFlushResponse("no commit id from pre-sync flush"));
                 contDownAndSendResponseIfDone(syncId, shards, shardId, totalShards, listener, countDown, results);
                 continue;
diff --git a/core/src/main/java/org/elasticsearch/indices/recovery/RecoveriesCollection.java b/core/src/main/java/org/elasticsearch/indices/recovery/RecoveriesCollection.java
index 4cd9d7d6dea1..47628364331e 100644
--- a/core/src/main/java/org/elasticsearch/indices/recovery/RecoveriesCollection.java
+++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoveriesCollection.java
@@ -238,7 +238,7 @@ protected void doRun() throws Exception {
                 return;
             }
             lastSeenAccessTime = accessTime;
-            logger.trace("[monitor] rescheduling check for [{}]. last access time is [{}]", lastSeenAccessTime);
+            logger.trace("[monitor] rescheduling check for [{}]. last access time is [{}]", checkInterval, lastSeenAccessTime);
             threadPool.schedule(checkInterval, ThreadPool.Names.GENERIC, this);
         }
     }
diff --git a/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySettings.java b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySettings.java
index 7ccba8439931..ef9a56a7bf30 100644
--- a/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySettings.java
+++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySettings.java
@@ -269,7 +269,7 @@ private TimeValue maybeUpdate(final TimeValue currentValue, final Settings setti
             if (value.equals(currentValue)) {
                 return currentValue;
             }
-            logger.info("updating [] from [{}] to [{}]", key, currentValue, value);
+            logger.info("updating [{}] from [{}] to [{}]", key, currentValue, value);
             return value;
         }
     }
diff --git a/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java
index 73193161d12d..c4a882738739 100644
--- a/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java
+++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java
@@ -286,7 +286,7 @@ public int compare(StoreFileMetaData o1, StoreFileMetaData o2) {
                                     logger.debug("{} checking integrity for file {} after remove corruption exception", shard.shardId(), md);
                                     if (store.checkIntegrityNoException(md) == false) { // we are corrupted on the primary -- fail!
                                         shard.failShard("recovery", corruptIndexException);
-                                        logger.warn("{} Corrupted file detected {} checksum mismatch", shard.shardId(), md);
+                                        logger.warn("{} Corrupted file detected {} checksum mismatch", corruptIndexException, shard.shardId(), md);
                                         throw corruptIndexException;
                                     }
                                 }
@@ -297,8 +297,9 @@ public int compare(StoreFileMetaData o1, StoreFileMetaData o2) {
                             // corruption has happened on the way to replica
                             RemoteTransportException exception = new RemoteTransportException("File corruption occurred on recovery but checksums are ok", null);
                             exception.addSuppressed(remoteException);
+
                             logger.warn("{} Remote file corruption during finalization on node {}, recovering {}. local checksum OK",
-                                    corruptIndexException, shard.shardId(), request.targetNode());
+                                    corruptIndexException, shard.shardId(), request.targetNode(), request.recoveryId());
                             throw exception;
                         } else {
                             throw remoteException;
@@ -618,7 +619,7 @@ private IOException handleExecutionException(Store store, IOException corruptedE
         final boolean checkIntegrity = corruptedEngine == null;
         if ((corruptIndexException = ExceptionsHelper.unwrapCorruption(t)) != null) {
             if (checkIntegrity && store.checkIntegrityNoException(md) == false) { // we are corrupted on the primary -- fail!
-                logger.warn("{} Corrupted file detected {} checksum mismatch", shardId, md);
+                logger.warn("{} Corrupted file detected {} checksum mismatch", corruptIndexException, shardId, md);
                 corruptedEngine = corruptIndexException;
             } else { // corruption has happened on the way to replica
                 RemoteTransportException exception = new RemoteTransportException("File corruption occurred on recovery but checksums are ok", null);
diff --git a/core/src/main/java/org/elasticsearch/indices/store/TransportNodesListShardStoreMetaData.java b/core/src/main/java/org/elasticsearch/indices/store/TransportNodesListShardStoreMetaData.java
index 44c9fbec0e07..5d916a430182 100644
--- a/core/src/main/java/org/elasticsearch/indices/store/TransportNodesListShardStoreMetaData.java
+++ b/core/src/main/java/org/elasticsearch/indices/store/TransportNodesListShardStoreMetaData.java
@@ -113,8 +113,10 @@ protected NodesStoreFilesMetaData newResponse(Request request, AtomicReferenceAr
                 nodeStoreFilesMetaDatas.add((NodeStoreFilesMetaData) resp);
             } else if (resp instanceof FailedNodeException) {
                 failures.add((FailedNodeException) resp);
+            } else if (resp instanceof Throwable) {
+                logger.warn("unknown response type, expected NodeStoreFilesMetaData or FailedNodeException", (Throwable) resp);
             } else {
-                logger.warn("unknown response type [{}], expected NodeStoreFilesMetaData or FailedNodeException", resp);
+                logger.warn("unknown response type [{}], expected NodeStoreFilesMetaData or FailedNodeException", null, resp);
             }
         }
         return new NodesStoreFilesMetaData(clusterName, nodeStoreFilesMetaDatas.toArray(new NodeStoreFilesMetaData[nodeStoreFilesMetaDatas.size()]),
diff --git a/core/src/main/java/org/elasticsearch/indices/ttl/IndicesTTLService.java b/core/src/main/java/org/elasticsearch/indices/ttl/IndicesTTLService.java
index f095cc355efc..1e15be3bde8e 100644
--- a/core/src/main/java/org/elasticsearch/indices/ttl/IndicesTTLService.java
+++ b/core/src/main/java/org/elasticsearch/indices/ttl/IndicesTTLService.java
@@ -286,7 +286,7 @@ public void onResponse(BulkResponse bulkResponse) {
                             if (logger.isTraceEnabled()) {
                                 logger.trace("bulk deletion failures for [{}]/[{}] items, failure message: [{}]", failedItems, bulkResponse.getItems().length, bulkResponse.buildFailureMessage());
                             } else {
-                                logger.error("bulk deletion failures for [{}]/[{}] items", failedItems, bulkResponse.getItems().length);
+                                logger.error("bulk deletion failures for [{}]/[{}] items", null, failedItems, bulkResponse.getItems().length);
                             }
                         } else {
                             logger.trace("bulk deletion took " + bulkResponse.getTookInMillis() + "ms");
@@ -298,7 +298,7 @@ public void onFailure(Throwable e) {
                         if (logger.isTraceEnabled()) {
                             logger.trace("failed to execute bulk", e);
                         } else {
-                            logger.warn("failed to execute bulk: [{}]", e.getMessage());
+                            logger.warn("failed to execute bulk", e);
                         }
                     }
                 });
diff --git a/core/src/main/java/org/elasticsearch/monitor/fs/FsService.java b/core/src/main/java/org/elasticsearch/monitor/fs/FsService.java
index c95a7bf8b3ab..3478b1b1973f 100644
--- a/core/src/main/java/org/elasticsearch/monitor/fs/FsService.java
+++ b/core/src/main/java/org/elasticsearch/monitor/fs/FsService.java
@@ -58,7 +58,7 @@ protected FsInfo refresh() {
             try {
                 return probe.stats();
             } catch (IOException ex) {
-                logger.warn("Failed to fetch fs stats - returning empty instance");
+                logger.warn("Failed to fetch fs stats - returning empty instance", ex);
                 return new FsInfo();
             }
         }
diff --git a/core/src/main/java/org/elasticsearch/monitor/jvm/JvmMonitorService.java b/core/src/main/java/org/elasticsearch/monitor/jvm/JvmMonitorService.java
index a11fc2957a44..a593b4147fb0 100644
--- a/core/src/main/java/org/elasticsearch/monitor/jvm/JvmMonitorService.java
+++ b/core/src/main/java/org/elasticsearch/monitor/jvm/JvmMonitorService.java
@@ -87,7 +87,7 @@ public JvmMonitorService(Settings settings, ThreadPool threadPool) {
             TimeValue info = entry.getValue().getAsTime("info", null);
             TimeValue debug = entry.getValue().getAsTime("debug", null);
             if (warn == null || info == null || debug == null) {
-                logger.warn("ignoring gc_threshold for [{}], missing warn/info/debug values", name);
+                logger.warn("ignoring gc_threshold for [{}], missing warn/info/debug values", null, name);
             } else {
                 gcThresholds.put(name, new GcThreshold(name, warn.millis(), info.millis(), debug.millis()));
             }
@@ -164,7 +164,7 @@ private synchronized void monitorLongGc() {
 
                 if (avgCollectionTime > gcThreshold.warnThreshold) {
                     logger.warn("[gc][{}][{}][{}] duration [{}], collections [{}]/[{}], total [{}]/[{}], memory [{}]->[{}]/[{}], all_pools {}",
-                            gc.getName(), seq, gc.getCollectionCount(), TimeValue.timeValueMillis(collectionTime), collections, TimeValue.timeValueMillis(currentJvmStats.getTimestamp() - lastJvmStats.getTimestamp()), TimeValue.timeValueMillis(collectionTime), gc.getCollectionTime(), lastJvmStats.getMem().getHeapUsed(), currentJvmStats.getMem().getHeapUsed(), JvmInfo.jvmInfo().getMem().getHeapMax(), buildPools(lastJvmStats, currentJvmStats));
+                            null, gc.getName(), seq, gc.getCollectionCount(), TimeValue.timeValueMillis(collectionTime), collections, TimeValue.timeValueMillis(currentJvmStats.getTimestamp() - lastJvmStats.getTimestamp()), TimeValue.timeValueMillis(collectionTime), gc.getCollectionTime(), lastJvmStats.getMem().getHeapUsed(), currentJvmStats.getMem().getHeapUsed(), JvmInfo.jvmInfo().getMem().getHeapMax(), buildPools(lastJvmStats, currentJvmStats));
                 } else if (avgCollectionTime > gcThreshold.infoThreshold) {
                     logger.info("[gc][{}][{}][{}] duration [{}], collections [{}]/[{}], total [{}]/[{}], memory [{}]->[{}]/[{}], all_pools {}",
                             gc.getName(), seq, gc.getCollectionCount(), TimeValue.timeValueMillis(collectionTime), collections, TimeValue.timeValueMillis(currentJvmStats.getTimestamp() - lastJvmStats.getTimestamp()), TimeValue.timeValueMillis(collectionTime), gc.getCollectionTime(), lastJvmStats.getMem().getHeapUsed(), currentJvmStats.getMem().getHeapUsed(), JvmInfo.jvmInfo().getMem().getHeapMax(), buildPools(lastJvmStats, currentJvmStats));
diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java
index 4fddf7ad8380..454e1c218e5a 100644
--- a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java
+++ b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java
@@ -161,12 +161,12 @@ public PluginsService(Settings settings, Path pluginsDirectory, Collection<Class
                     continue;
                 }
                 if (method.getParameterTypes().length == 0 || method.getParameterTypes().length > 1) {
-                    logger.warn("Plugin: {} implementing onModule with no parameters or more than one parameter", plugin.name());
+                    logger.warn("Plugin: {} implementing onModule with no parameters or more than one parameter", null, plugin.name());
                     continue;
                 }
                 Class moduleClass = method.getParameterTypes()[0];
                 if (!Module.class.isAssignableFrom(moduleClass)) {
-                    logger.warn("Plugin: {} implementing onModule by the type is not of Module type {}", plugin.name(), moduleClass);
+                    logger.warn("Plugin: {} implementing onModule by the type is not of Module type {}", null, plugin.name(), moduleClass);
                     continue;
                 }
                 list.add(new OnModuleReference(moduleClass, method));
diff --git a/core/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java b/core/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java
index 8c5088e757b1..af70045f3c91 100644
--- a/core/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java
+++ b/core/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java
@@ -481,7 +481,7 @@ private MetaData readSnapshotMetaData(SnapshotId snapshotId, Version snapshotVer
                 metaDataBuilder.put(indexMetaDataFormat(snapshotVersion).read(indexMetaDataBlobContainer, snapshotId.getSnapshot()), false);
             } catch (ElasticsearchParseException | IOException ex) {
                 if (ignoreIndexErrors) {
-                    logger.warn("[{}] [{}] failed to read metadata for index", snapshotId, index, ex);
+                    logger.warn("[{}] [{}] failed to read metadata for index", ex, snapshotId, index);
                 } else {
                     throw ex;
                 }
diff --git a/core/src/main/java/org/elasticsearch/repositories/fs/FsRepository.java b/core/src/main/java/org/elasticsearch/repositories/fs/FsRepository.java
index 478158282d68..2b2831a7b227 100644
--- a/core/src/main/java/org/elasticsearch/repositories/fs/FsRepository.java
+++ b/core/src/main/java/org/elasticsearch/repositories/fs/FsRepository.java
@@ -71,16 +71,16 @@ public FsRepository(RepositoryName name, RepositorySettings repositorySettings,
         Path locationFile;
         String location = repositorySettings.settings().get("location", settings.get("repositories.fs.location"));
         if (location == null) {
-            logger.warn("the repository location is missing, it should point to a shared file system location that is available on all master and data nodes");
+            logger.warn("the repository location is missing, it should point to a shared file system location that is available on all master and data nodes", null);
             throw new RepositoryException(name.name(), "missing location");
         }
         locationFile = environment.resolveRepoFile(location);
         if (locationFile == null) {
             if (environment.repoFiles().length > 0) {
-                logger.warn("The specified location [{}] doesn't start with any repository paths specified by the path.repo setting: [{}] ", location, environment.repoFiles());
+                logger.warn("The specified location [{}] doesn't start with any repository paths specified by the path.repo setting: [{}] ", null, location, environment.repoFiles());
                 throw new RepositoryException(name.name(), "location [" + location + "] doesn't match any of the locations specified by path.repo");
             } else {
-                logger.warn("The specified location [{}] should start with a repository path specified by the path.repo setting, but the path.repo setting was not set on this node", location);
+                logger.warn("The specified location [{}] should start with a repository path specified by the path.repo setting, but the path.repo setting was not set on this node", null, location);
                 throw new RepositoryException(name.name(), "location [" + location + "] doesn't match any of the locations specified by path.repo because this setting is empty");
             }
         }
diff --git a/core/src/main/java/org/elasticsearch/repositories/uri/URLRepository.java b/core/src/main/java/org/elasticsearch/repositories/uri/URLRepository.java
index 4d361683e5c1..031c127ff84d 100644
--- a/core/src/main/java/org/elasticsearch/repositories/uri/URLRepository.java
+++ b/core/src/main/java/org/elasticsearch/repositories/uri/URLRepository.java
@@ -19,6 +19,12 @@
 
 package org.elasticsearch.repositories.uri;
 
+import java.io.IOException;
+import java.net.URISyntaxException;
+import java.net.URL;
+import java.util.Arrays;
+import java.util.List;
+
 import org.elasticsearch.cluster.metadata.SnapshotId;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.blobstore.BlobPath;
@@ -33,11 +39,6 @@
 import org.elasticsearch.repositories.RepositorySettings;
 import org.elasticsearch.repositories.blobstore.BlobStoreRepository;
 
-import java.io.IOException;
-import java.net.URISyntaxException;
-import java.net.URL;
-import java.util.List;
-
 /**
  * Read-only URL-based implementation of the BlobStoreRepository
  * <p>
@@ -141,13 +142,14 @@ private URL checkURL(URL url) {
                         return url;
                     }
                 } catch (URISyntaxException ex) {
-                    logger.warn("cannot parse the specified url [{}]", url);
+                    logger.warn("cannot parse the specified url [{}]", ex, url);
                     throw new RepositoryException(repositoryName, "cannot parse the specified url [" + url + "]");
                 }
                 // We didn't match white list - try to resolve against path.repo
                 URL normalizedUrl = environment.resolveRepoURL(url);
                 if (normalizedUrl == null) {
-                    logger.warn("The specified url [{}] doesn't start with any repository paths specified by the path.repo setting: [{}] or by repositories.url.allowed_urls setting: [{}] ", url, environment.repoFiles());
+                    logger.warn("The specified url [{}] doesn't start with any repository paths specified by the path.repo setting: [{}] or by repositories.url.allowed_urls setting: [{}] ",
+                                null, url, environment.repoFiles(), urlWhiteList);
                     throw new RepositoryException(repositoryName, "file url [" + url + "] doesn't match any of the locations specified by path.repo or repositories.url.allowed_urls");
                 }
                 return normalizedUrl;
diff --git a/core/src/main/java/org/elasticsearch/script/ScriptService.java b/core/src/main/java/org/elasticsearch/script/ScriptService.java
index 3b91f2d31107..afb0a49251d5 100644
--- a/core/src/main/java/org/elasticsearch/script/ScriptService.java
+++ b/core/src/main/java/org/elasticsearch/script/ScriptService.java
@@ -372,7 +372,7 @@ private void validate(BytesReference scriptBytes, String scriptLang) {
                     } else {
                         logger.warn(
                                 "skipping compile of script [{}], lang [{}] as all scripted operations are disabled for indexed scripts",
-                                template.getScript(), scriptLang);
+                                null, template.getScript(), scriptLang);
                     }
                 } catch (Exception e) {
                     throw new IllegalArgumentException("Unable to parse [" + template.getScript() +
@@ -530,7 +530,7 @@ public void onFileInit(Path file) {
             if (scriptNameExt != null) {
                 ScriptEngineService engineService = getScriptEngineServiceForFileExt(scriptNameExt.v2());
                 if (engineService == null) {
-                    logger.warn("no script engine found for [{}]", scriptNameExt.v2());
+                    logger.warn("no script engine found for [{}]", null, scriptNameExt.v2());
                 } else {
                     try {
                         //we don't know yet what the script will be used for, but if all of the operations for this lang
@@ -544,7 +544,7 @@ public void onFileInit(Path file) {
                                 scriptMetrics.onCompilation();
                             }
                         } else {
-                            logger.warn("skipping compile of script file [{}] as all scripted operations are disabled for file scripts", file.toAbsolutePath());
+                            logger.warn("skipping compile of script file [{}] as all scripted operations are disabled for file scripts", null, file.toAbsolutePath());
                         }
                     } catch (Throwable e) {
                         logger.warn("failed to load/compile script [{}]", e, scriptNameExt.v1());
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/ScriptHeuristic.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/ScriptHeuristic.java
index 046ca717b9f0..c2b9fdb66883 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/ScriptHeuristic.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/ScriptHeuristic.java
@@ -105,7 +105,7 @@ public double getScore(long subsetFreq, long subsetSize, long supersetFreq, long
             // Now, for version before 1.5.0 the score is computed after streaming the response but for scripts the script does not exists yet.
             // assertSearchResponse() might therefore fail although there is no problem.
             // This should be replaced by an exception in 2.0.
-            ESLoggerFactory.getLogger("script heuristic").warn("cannot compute score - script has not been initialized yet.");
+            ESLoggerFactory.getLogger("script heuristic").warn("cannot compute score - script has not been initialized yet.", null);
             return 0;
         }
         subsetSizeHolder.value = subsetSize;
diff --git a/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java b/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java
index cd710d52cdc5..0db937d21c63 100644
--- a/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java
+++ b/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java
@@ -398,10 +398,10 @@ private void restoreGlobalStateIfRequested(MetaData.Builder mdBuilder) {
                                         persistentSettings.put(entry.getKey(), entry.getValue());
                                         changed = true;
                                     } else {
-                                        logger.warn("ignoring persistent setting [{}], [{}]", entry.getKey(), error);
+                                        logger.warn("ignoring persistent setting [{}], [{}]", null, entry.getKey(), error);
                                     }
                                 } else {
-                                    logger.warn("ignoring persistent setting [{}], not dynamically updateable", entry.getKey());
+                                    logger.warn("ignoring persistent setting [{}], not dynamically updateable", null, entry.getKey());
                                 }
                             }
                             if (changed) {
diff --git a/core/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java b/core/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java
index bf3af7394dd6..32e5c9d6cb5e 100644
--- a/core/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java
+++ b/core/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java
@@ -371,7 +371,7 @@ public void onFailure(String source, Throwable t) {
                         repositoriesService.repository(snapshot.snapshotId().getRepository()).finalizeSnapshot(
                                 snapshot.snapshotId(), snapshot.indices(), snapshot.startTime(), ExceptionsHelper.detailedMessage(t), 0, Collections.<SnapshotShardFailure>emptyList());
                     } catch (Throwable t2) {
-                        logger.warn("[{}] failed to close snapshot in repository", snapshot.snapshotId());
+                        logger.warn("[{}] failed to close snapshot in repository", t2, snapshot.snapshotId());
                     }
                     userCreateSnapshotListener.onFailure(t);
                 }
@@ -401,7 +401,7 @@ public void clusterStateProcessed(String source, ClusterState oldState, ClusterS
                     repositoriesService.repository(snapshot.snapshotId().getRepository()).finalizeSnapshot(snapshot.snapshotId(), snapshot.indices(), snapshot.startTime(),
                             ExceptionsHelper.detailedMessage(t), 0, Collections.<SnapshotShardFailure>emptyList());
                 } catch (Throwable t2) {
-                    logger.warn("[{}] failed to close snapshot in repository", snapshot.snapshotId());
+                    logger.warn("[{}] failed to close snapshot in repository", t2, snapshot.snapshotId());
                 }
             }
             userCreateSnapshotListener.onFailure(t);
@@ -564,7 +564,7 @@ public ClusterState execute(ClusterState currentState) throws Exception {
                                     } else {
                                         // TODO: Restart snapshot on another node?
                                         snapshotChanged = true;
-                                        logger.warn("failing snapshot of shard [{}] on closed node [{}]", shardEntry.key, shardStatus.nodeId());
+                                        logger.warn("failing snapshot of shard [{}] on closed node [{}]", null, shardEntry.key, shardStatus.nodeId());
                                         shards.put(shardEntry.key, new ShardSnapshotStatus(shardStatus.nodeId(), State.FAILED, "node shutdown"));
                                     }
                                 }
@@ -590,7 +590,7 @@ public void onResponse() {
 
                                 @Override
                                 public void onFailure(Throwable t) {
-                                    logger.warn("failed to clean up abandoned snapshot {} in INIT state", snapshot.snapshotId());
+                                    logger.warn("failed to clean up abandoned snapshot {} in INIT state", t, snapshot.snapshotId());
                                 }
                             });
                         } else if (snapshot.state() == State.SUCCESS && newMaster) {
@@ -607,7 +607,7 @@ public void onFailure(Throwable t) {
 
                 @Override
                 public void onFailure(String source, Throwable t) {
-                    logger.warn("failed to update snapshot state after node removal");
+                    logger.warn("failed to update snapshot state after node removal", t);
                 }
             });
         }
@@ -682,7 +682,7 @@ public void onFailure(String source, Throwable t) {
                 }
                 // Shard that we were waiting for went into unassigned state or disappeared - giving up
                 snapshotChanged = true;
-                logger.warn("failing snapshot of shard [{}] on unassigned shard [{}]", shardId, shardStatus.nodeId());
+                logger.warn("failing snapshot of shard [{}] on unassigned shard [{}]", null, shardId, shardStatus.nodeId());
                 shards.put(shardId, new ShardSnapshotStatus(shardStatus.nodeId(), State.FAILED, "shard is unassigned"));
             } else {
                 shards.put(shardId, shardStatus);
@@ -842,7 +842,7 @@ public ClusterState execute(ClusterState currentState) {
 
             @Override
             public void onFailure(String source, Throwable t) {
-                logger.warn("[{}][{}] failed to remove snapshot metadata", t, snapshotId);
+                logger.warn("[{}][{}] failed to remove snapshot metadata", t, source, snapshotId);
             }
 
             @Override
diff --git a/core/src/main/java/org/elasticsearch/transport/TransportService.java b/core/src/main/java/org/elasticsearch/transport/TransportService.java
index 14fc9029b006..9302d1b34f2f 100644
--- a/core/src/main/java/org/elasticsearch/transport/TransportService.java
+++ b/core/src/main/java/org/elasticsearch/transport/TransportService.java
@@ -428,7 +428,7 @@ private long newRequestId() {
             RequestHandlerRegistry replaced = requestHandlers.get(reg.getAction());
             requestHandlers = MapBuilder.newMapBuilder(requestHandlers).put(reg.getAction(), reg).immutableMap();
             if (replaced != null) {
-                logger.warn("registered two transport handlers for action {}, handlers: {}, {}", reg.getAction(), reg.getHandler(), replaced.getHandler());
+                logger.warn("registered two transport handlers for action {}, handlers: {}, {}", null, reg.getAction(), reg.getHandler(), replaced.getHandler());
             }
         }
     }
@@ -521,11 +521,12 @@ protected void checkForTimeout(long requestId) {
             TimeoutInfoHolder timeoutInfoHolder = timeoutInfoHandlers.remove(requestId);
             if (timeoutInfoHolder != null) {
                 long time = System.currentTimeMillis();
-                logger.warn("Received response for a request that has timed out, sent [{}ms] ago, timed out [{}ms] ago, action [{}], node [{}], id [{}]", time - timeoutInfoHolder.sentTime(), time - timeoutInfoHolder.timeoutTime(), timeoutInfoHolder.action(), timeoutInfoHolder.node(), requestId);
+                logger.warn("Received response for a request that has timed out, sent [{}ms] ago, timed out [{}ms] ago, action [{}], node [{}], id [{}]",
+                            null, time - timeoutInfoHolder.sentTime(), time - timeoutInfoHolder.timeoutTime(), timeoutInfoHolder.action(), timeoutInfoHolder.node(), requestId);
                 action = timeoutInfoHolder.action();
                 sourceNode = timeoutInfoHolder.node();
             } else {
-                logger.warn("Transport response handler not found of id [{}]", requestId);
+                logger.warn("Transport response handler not found of id [{}]", null, requestId);
                 action = null;
                 sourceNode = null;
             }
diff --git a/core/src/main/java/org/elasticsearch/transport/netty/NettyInternalESLogger.java b/core/src/main/java/org/elasticsearch/transport/netty/NettyInternalESLogger.java
index ed92aa261db2..b3da8a1532bf 100644
--- a/core/src/main/java/org/elasticsearch/transport/netty/NettyInternalESLogger.java
+++ b/core/src/main/java/org/elasticsearch/transport/netty/NettyInternalESLogger.java
@@ -75,7 +75,7 @@ public void info(String msg, Throwable cause) {
 
     @Override
     public void warn(String msg) {
-        logger.warn(msg);
+        logger.warn(msg, null);
     }
 
     @Override
@@ -85,7 +85,7 @@ public void warn(String msg, Throwable cause) {
 
     @Override
     public void error(String msg) {
-        logger.error(msg);
+        logger.error(msg, null);
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java b/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java
index ab39a35d2249..053558338f36 100644
--- a/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java
+++ b/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java
@@ -543,7 +543,7 @@ private BoundTransportAddress createBoundTransportAddress(String name, Settings
             // TODO: In case of DEFAULT_PROFILE we should probably fail here, as publish address does not match any bound address
             // In case of a custom profile, we might use the publish address of the default profile
             publishPort = boundAddresses.get(0).getPort();
-            logger.warn("Publish port not found by matching publish address [{}] to bound addresses [{}], falling back to port [{}] of first bound address", publishInetAddress, boundAddresses, publishPort);
+            logger.warn("Publish port not found by matching publish address [{}] to bound addresses [{}], falling back to port [{}] of first bound address", null, publishInetAddress, boundAddresses, publishPort);
         }
 
         final TransportAddress publishAddress = new InetSocketTransportAddress(new InetSocketAddress(publishInetAddress, publishPort));
@@ -1333,9 +1333,9 @@ public void operationComplete(ChannelFuture future) throws Exception {
         @Override
         public void onFailure(Throwable t) {
             if (lifecycle.stoppedOrClosed()) {
-                logger.trace("[{}] failed to send ping transport message", t);
+                logger.trace("failed to send ping transport message", t);
             } else {
-                logger.warn("[{}] failed to send ping transport message", t);
+                logger.warn("failed to send ping transport message", t);
             }
         }
     }
diff --git a/core/src/main/java/org/elasticsearch/tribe/TribeService.java b/core/src/main/java/org/elasticsearch/tribe/TribeService.java
index 87da13fad4a5..52a91b1c0568 100644
--- a/core/src/main/java/org/elasticsearch/tribe/TribeService.java
+++ b/core/src/main/java/org/elasticsearch/tribe/TribeService.java
@@ -181,7 +181,7 @@ protected void doStart() {
                     try {
                         otherNode.close();
                     } catch (Throwable t) {
-                        logger.warn("failed to close node {} on failed start", otherNode, t);
+                        logger.warn("failed to close node {} on failed start", t, otherNode);
                     }
                 }
                 if (e instanceof RuntimeException) {
diff --git a/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityIT.java b/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityIT.java
index b72c0998898b..b765060d0f5f 100644
--- a/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityIT.java
+++ b/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityIT.java
@@ -256,7 +256,7 @@ public void testAllVersionsTested() throws Exception {
 
         for (String index : indexes) {
             if (expectedVersions.remove(index) == false) {
-                logger.warn("Old indexes tests contain extra index: " + index);
+                logger.warn("Old indexes tests contain extra index: " + index, null);
             }
         }
         if (expectedVersions.isEmpty() == false) {
diff --git a/core/src/test/java/org/elasticsearch/bwcompat/RestoreBackwardsCompatIT.java b/core/src/test/java/org/elasticsearch/bwcompat/RestoreBackwardsCompatIT.java
index bccd4290d8e2..4939b0fecd6f 100644
--- a/core/src/test/java/org/elasticsearch/bwcompat/RestoreBackwardsCompatIT.java
+++ b/core/src/test/java/org/elasticsearch/bwcompat/RestoreBackwardsCompatIT.java
@@ -104,7 +104,7 @@ public void testRestoreOldSnapshots() throws Exception {
 
         for (String repoVersion : repoVersions) {
             if (expectedVersions.remove(repoVersion) == false) {
-                logger.warn("Old repositories tests contain extra repo: " + repoVersion);
+                logger.warn("Old repositories tests contain extra repo: " + repoVersion, null);
             }
         }
         if (expectedVersions.isEmpty() == false) {
diff --git a/core/src/test/java/org/elasticsearch/cluster/ClusterStateDiffIT.java b/core/src/test/java/org/elasticsearch/cluster/ClusterStateDiffIT.java
index 8d4540aad3b7..aba405a7bd48 100644
--- a/core/src/test/java/org/elasticsearch/cluster/ClusterStateDiffIT.java
+++ b/core/src/test/java/org/elasticsearch/cluster/ClusterStateDiffIT.java
@@ -156,7 +156,7 @@ public void testClusterStateDiffSerialization() throws Exception {
                 // however, serialized size should remain the same
                 assertThat(ClusterState.Builder.toBytes(clusterStateFromDiffs).length, equalTo(ClusterState.Builder.toBytes(clusterState).length));
             } catch (AssertionError error) {
-                logger.error("Cluster state:\n{}\nCluster state from diffs:\n{}", clusterState.toString(), clusterStateFromDiffs.toString());
+                logger.error("Cluster state:\n{}\nCluster state from diffs:\n{}", error, clusterState.toString(), clusterStateFromDiffs.toString());
                 throw error;
             }
         }
diff --git a/core/src/test/java/org/elasticsearch/common/logging/jdk/JDKESLoggerTests.java b/core/src/test/java/org/elasticsearch/common/logging/jdk/JDKESLoggerTests.java
index 92dd9ffc0120..8c8abee9551d 100644
--- a/core/src/test/java/org/elasticsearch/common/logging/jdk/JDKESLoggerTests.java
+++ b/core/src/test/java/org/elasticsearch/common/logging/jdk/JDKESLoggerTests.java
@@ -51,8 +51,8 @@ public void setUp() throws Exception {
     }
 
     public void testLocationInfoTest() {
-        esTestLogger.error("This is an error");
-        esTestLogger.warn("This is a warning");
+        esTestLogger.error("This is an error", null);
+        esTestLogger.warn("This is a warning", null);
         esTestLogger.info("This is an info");
         esTestLogger.debug("This is a debug");
         esTestLogger.trace("This is a trace");
diff --git a/core/src/test/java/org/elasticsearch/common/logging/log4j/Log4jESLoggerTests.java b/core/src/test/java/org/elasticsearch/common/logging/log4j/Log4jESLoggerTests.java
index 8f9c9009071f..42fe54dd943d 100644
--- a/core/src/test/java/org/elasticsearch/common/logging/log4j/Log4jESLoggerTests.java
+++ b/core/src/test/java/org/elasticsearch/common/logging/log4j/Log4jESLoggerTests.java
@@ -84,8 +84,8 @@ public void tearDown() throws Exception {
     }
 
     public void testLocationInfoTest() {
-        esTestLogger.error("This is an error");
-        esTestLogger.warn("This is a warning");
+        esTestLogger.error("This is an error", null);
+        esTestLogger.warn("This is a warning", null);
         esTestLogger.info("This is an info");
         esTestLogger.debug("This is a debug");
         esTestLogger.trace("This is a trace");
diff --git a/core/src/test/java/org/elasticsearch/gateway/RecoveryFromGatewayIT.java b/core/src/test/java/org/elasticsearch/gateway/RecoveryFromGatewayIT.java
index 01c76b465a97..1c596ea6b21e 100644
--- a/core/src/test/java/org/elasticsearch/gateway/RecoveryFromGatewayIT.java
+++ b/core/src/test/java/org/elasticsearch/gateway/RecoveryFromGatewayIT.java
@@ -373,7 +373,7 @@ public void testReusePeerRecovery() throws Exception {
             assertSyncIdsNotNull();
         }
 
-        logger.info("--> disabling allocation while the cluster is shut down", useSyncIds ? "" : " a second time");
+        logger.info("--> disabling allocation while the cluster is shut down" + (useSyncIds ? "" : " a second time"));
         // Disable allocations while we are closing nodes
         client().admin().cluster().prepareUpdateSettings()
                 .setTransientSettings(settingsBuilder()
diff --git a/core/src/test/java/org/elasticsearch/index/store/CorruptedFileIT.java b/core/src/test/java/org/elasticsearch/index/store/CorruptedFileIT.java
index 4858e0a6e3c2..33a1263b4ff6 100644
--- a/core/src/test/java/org/elasticsearch/index/store/CorruptedFileIT.java
+++ b/core/src/test/java/org/elasticsearch/index/store/CorruptedFileIT.java
@@ -205,7 +205,7 @@ public void afterIndexShardClosed(ShardId sid, @Nullable IndexShard indexShard,
                             out.flush();
                             CheckIndex.Status status = checkIndex.checkIndex();
                             if (!status.clean) {
-                                logger.warn("check index [failure]\n{}", new String(os.bytes().toBytes(), StandardCharsets.UTF_8));
+                                logger.warn("check index [failure]\n{}", null, new String(os.bytes().toBytes(), StandardCharsets.UTF_8));
                                 throw new IOException("index check failure");
                             }
                         }
diff --git a/core/src/test/java/org/elasticsearch/indices/template/SimpleIndexTemplateIT.java b/core/src/test/java/org/elasticsearch/indices/template/SimpleIndexTemplateIT.java
index b9da71d75aa3..27f7845c3f94 100644
--- a/core/src/test/java/org/elasticsearch/indices/template/SimpleIndexTemplateIT.java
+++ b/core/src/test/java/org/elasticsearch/indices/template/SimpleIndexTemplateIT.java
@@ -129,7 +129,7 @@ public void testSimpleIndexTemplateTests() throws Exception {
                 .addField("field1").addField("field2")
                 .execute().actionGet();
         if (searchResponse.getFailedShards() > 0) {
-            logger.warn("failed search " + Arrays.toString(searchResponse.getShardFailures()));
+            logger.warn("failed search " + Arrays.toString(searchResponse.getShardFailures()), null);
         }
         assertHitCount(searchResponse, 1);
         assertThat(searchResponse.getHits().getAt(0).field("field1").value().toString(), equalTo("value1"));
diff --git a/core/src/test/java/org/elasticsearch/percolator/ConcurrentPercolatorIT.java b/core/src/test/java/org/elasticsearch/percolator/ConcurrentPercolatorIT.java
index b11f24377add..09da10ba75a6 100644
--- a/core/src/test/java/org/elasticsearch/percolator/ConcurrentPercolatorIT.java
+++ b/core/src/test/java/org/elasticsearch/percolator/ConcurrentPercolatorIT.java
@@ -288,7 +288,7 @@ public void run() {
         }
 
         for (Throwable t : exceptionsHolder) {
-            logger.error("Unexpected exception {}", t.getMessage(), t);
+            logger.error("Unexpected exception", t);
         }
         assertThat(exceptionsHolder.isEmpty(), equalTo(true));
     }
diff --git a/core/src/test/java/org/elasticsearch/percolator/TTLPercolatorIT.java b/core/src/test/java/org/elasticsearch/percolator/TTLPercolatorIT.java
index 4b4d4a84237c..1f31382970d3 100644
--- a/core/src/test/java/org/elasticsearch/percolator/TTLPercolatorIT.java
+++ b/core/src/test/java/org/elasticsearch/percolator/TTLPercolatorIT.java
@@ -184,7 +184,7 @@ public void testEnsureTTLDoesNotCreateIndex() throws IOException, InterruptedExc
                         .endObject()
                 ).setTTL(randomIntBetween(1, 500)).execute().actionGet();
             } catch (MapperParsingException e) {
-                logger.info("failed indexing {}", i, e);
+                logger.info("failed indexing {}", e, i);
                 // if we are unlucky the TTL is so small that we see the expiry date is already in the past when
                 // we parse the doc ignore those...
                 assertThat(e.getCause(), Matchers.instanceOf(AlreadyExpiredException.class));
diff --git a/core/src/test/java/org/elasticsearch/plugins/PluginManagerCliTests.java b/core/src/test/java/org/elasticsearch/plugins/PluginManagerCliTests.java
index f16f9981d936..35399dfe07e0 100644
--- a/core/src/test/java/org/elasticsearch/plugins/PluginManagerCliTests.java
+++ b/core/src/test/java/org/elasticsearch/plugins/PluginManagerCliTests.java
@@ -58,7 +58,7 @@ public void testUrlSpacesInPath() throws MalformedURLException {
         CliToolTestCase.CaptureOutputTerminal terminal = new CliToolTestCase.CaptureOutputTerminal();
         Path tmpDir = createTempDir().resolve("foo deps");
         String finalDir = tmpDir.toAbsolutePath().toUri().toURL().toString();
-        logger.warn(finalDir);
+        logger.warn(finalDir, null);
         CliTool.ExitStatus execute = new PluginManagerCliParser(terminal).execute(args("install " + finalDir));
         assertThat(execute.status(), is(IO_ERROR.status()));
     }
diff --git a/core/src/test/java/org/elasticsearch/recovery/RelocationIT.java b/core/src/test/java/org/elasticsearch/recovery/RelocationIT.java
index 57b5e888ea92..22c6be1939ab 100644
--- a/core/src/test/java/org/elasticsearch/recovery/RelocationIT.java
+++ b/core/src/test/java/org/elasticsearch/recovery/RelocationIT.java
@@ -227,14 +227,14 @@ public void testRelocationWhileIndexingRandom() throws Exception {
                         for (SearchHit hit : hits.hits()) {
                             int id = Integer.parseInt(hit.id());
                             if (!set.remove(id)) {
-                                logger.error("Extra id [{}]", id);
+                                logger.error("Extra id [{}]", null, id);
                             }
                         }
                         set.forEach(new IntProcedure() {
 
                             @Override
                             public void apply(int value) {
-                                logger.error("Missing id [{}]", value);
+                                logger.error("Missing id [{}]", null, value);
                             }
 
                         });
diff --git a/core/src/test/java/org/elasticsearch/snapshots/DedicatedClusterSnapshotRestoreIT.java b/core/src/test/java/org/elasticsearch/snapshots/DedicatedClusterSnapshotRestoreIT.java
index f9392836d8b8..68447598c8bd 100644
--- a/core/src/test/java/org/elasticsearch/snapshots/DedicatedClusterSnapshotRestoreIT.java
+++ b/core/src/test/java/org/elasticsearch/snapshots/DedicatedClusterSnapshotRestoreIT.java
@@ -330,7 +330,7 @@ public void testSnapshotDuringNodeShutdown() throws Exception {
         logger.info("--> execution was blocked on node [{}], shutting it down", blockedNode);
         unblockNode(blockedNode);
 
-        logger.info("--> stopping node", blockedNode);
+        logger.info("--> stopping node {}", blockedNode);
         stopNode(blockedNode);
         logger.info("--> waiting for completion");
         SnapshotInfo snapshotInfo = waitForCompletion("test-repo", "test-snap", TimeValue.timeValueSeconds(60));
diff --git a/core/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java b/core/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java
index afbdf9d48d5d..4aa0ecc573ce 100644
--- a/core/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java
+++ b/core/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java
@@ -1450,7 +1450,7 @@ public void testSnapshotStatus() throws Exception {
             }
         }
 
-        logger.info("--> checking snapshot status for all currently running and snapshot with empty repository", blockedNode);
+        logger.info("--> checking snapshot status for all currently running and snapshot with empty repository; blockedNode {}", blockedNode);
         response = client.admin().cluster().prepareSnapshotStatus().execute().actionGet();
         assertThat(response.getSnapshots().size(), equalTo(1));
         snapshotStatus = response.getSnapshots().get(0);
@@ -1463,7 +1463,7 @@ public void testSnapshotStatus() throws Exception {
             }
         }
 
-        logger.info("--> checking that _current returns the currently running snapshot", blockedNode);
+        logger.info("--> checking that _current returns the currently running snapshot; blockedNode {}", blockedNode);
         GetSnapshotsResponse getResponse = client.admin().cluster().prepareGetSnapshots("test-repo").setCurrentSnapshot().execute().actionGet();
         assertThat(getResponse.getSnapshots().size(), equalTo(1));
         SnapshotInfo snapshotInfo = getResponse.getSnapshots().get(0);
@@ -1477,7 +1477,7 @@ public void testSnapshotStatus() throws Exception {
         logger.info("--> done");
 
 
-        logger.info("--> checking snapshot status again after snapshot is done", blockedNode);
+        logger.info("--> checking snapshot status again after snapshot is done; blockedNode {}", blockedNode);
         response = client.admin().cluster().prepareSnapshotStatus("test-repo").addSnapshots("test-snap").execute().actionGet();
         snapshotStatus = response.getSnapshots().get(0);
         assertThat(snapshotStatus.getIndices().size(), equalTo(1));
@@ -1488,11 +1488,11 @@ public void testSnapshotStatus() throws Exception {
         assertThat(indexStatus.getShardsStats().getDoneShards(), equalTo(snapshotInfo.successfulShards()));
         assertThat(indexStatus.getShards().size(), equalTo(snapshotInfo.totalShards()));
 
-        logger.info("--> checking snapshot status after it is done with empty repository", blockedNode);
+        logger.info("--> checking snapshot status after it is done with empty repository; blockedNode {}", blockedNode);
         response = client.admin().cluster().prepareSnapshotStatus().execute().actionGet();
         assertThat(response.getSnapshots().size(), equalTo(0));
 
-        logger.info("--> checking that _current no longer returns the snapshot", blockedNode);
+        logger.info("--> checking that _current no longer returns the snapshot; blockedNode {}", blockedNode);
         assertThat(client.admin().cluster().prepareGetSnapshots("test-repo").addSnapshots("_current").execute().actionGet().getSnapshots().isEmpty(), equalTo(true));
 
         try {
diff --git a/core/src/test/java/org/elasticsearch/update/UpdateIT.java b/core/src/test/java/org/elasticsearch/update/UpdateIT.java
index a789bb48774b..fd6c188883ed 100644
--- a/core/src/test/java/org/elasticsearch/update/UpdateIT.java
+++ b/core/src/test/java/org/elasticsearch/update/UpdateIT.java
@@ -966,7 +966,7 @@ public void run() {
                         logger.info("Client [{}] issued all [{}] requests.", Thread.currentThread().getName(), numberOfUpdatesPerThread);
                     } catch (InterruptedException e) {
                         // test infrastructure kills long-running tests by interrupting them, thus we handle this case separately
-                        logger.warn("Test was forcefully stopped. Client [{}] may still have outstanding requests.", Thread.currentThread().getName());
+                        logger.warn("Test was forcefully stopped. Client [{}] may still have outstanding requests.", e, Thread.currentThread().getName());
                         failures.add(e);
                         Thread.currentThread().interrupt();
                     } catch (Throwable e) {
@@ -1097,7 +1097,7 @@ public void run(){
                                 if (hasWaitedForNoNode) {
                                     throw nne;
                                 }
-                                logger.warn("Got NoNodeException waiting for 1 second for things to recover.");
+                                logger.warn("Got NoNodeException waiting for 1 second for things to recover.", nne);
                                 hasWaitedForNoNode = true;
                                 Thread.sleep(1000);
                             }
@@ -1114,7 +1114,7 @@ public void run(){
                                 if (hasWaitedForNoNode) {
                                     throw nne;
                                 }
-                                logger.warn("Got NoNodeException waiting for 1 second for things to recover.");
+                                logger.warn("Got NoNodeException waiting for 1 second for things to recover.", nne);
                                 hasWaitedForNoNode = true;
                                 Thread.sleep(1000); //Wait for no-node to clear
                             }
@@ -1204,7 +1204,7 @@ private void waitForOutstandingRequests(TimeValue timeOut, Semaphore requestsOut
                     }
                 }
                 expectedVersion -= totalFailures;
-                logger.error("Actual version [{}] Expected version [{}] Total failures [{}]", response.getVersion(), expectedVersion, totalFailures);
+                logger.error("Actual version [{}] Expected version [{}] Total failures [{}]", null, response.getVersion(), expectedVersion, totalFailures);
                 assertThat(response.getVersion(), equalTo((long) expectedVersion));
                 assertThat(response.getVersion() + totalFailures,
                         equalTo(
diff --git a/dev-tools/check-logger-params.py b/dev-tools/check-logger-params.py
new file mode 100644
index 000000000000..0198fb9f97ff
--- /dev/null
+++ b/dev-tools/check-logger-params.py
@@ -0,0 +1,58 @@
+import os
+import re
+
+# NOTE: this is only approximate, it gets fooled by nested expressions, by debug/info/trace taking the optional Throwable cause, etc.!
+
+reLoggerLine = re.compile(r'(logger.(?:error|warn|debug|info|trace)\s*)\((.*?)\)\s*;', re.DOTALL)
+
+def parseParams(s):
+  upto = 0
+  inQuote = False
+  params = []
+  lastStart = 0
+  while upto < len(s):
+    ch = s[upto]
+    upto += 1
+    if inQuote:
+      if ch == '"':
+        inQuote = False
+    elif ch == ',':
+      params.append(s[lastStart:upto])
+      lastStart = upto
+    elif ch == '"':
+      inQuote = True
+  if lastStart < upto:
+    params.append(s[lastStart:upto])
+  return params
+
+def getLineNumber(s, fragment):
+  # stupid slow but hopefully bug free approach:
+  loc = s.find(fragment)
+  if loc == -1:
+    raise RuntimeError('fragment "%s" does not occur in file' % repr(s))
+
+  upto = 0
+  for lineNumber, line in enumerate(s.splitlines()):
+    upto += len(line)+1
+    if upto > loc:
+      return lineNumber+1
+  return lineNumber+1
+    
+for root, dirs, files in os.walk("."):
+  for file in files:
+    if file.endswith('.java'):
+      fullPath = os.path.join(root, file)
+      s = open(fullPath).read()
+      for parts in reLoggerLine.findall(s):
+        params = parseParams(parts[1])
+
+        expectedParams = parts[1].count('{}')
+
+        if parts[0] in ('logger.error', 'logger.warn'):
+          # Cause is required arg:
+          expectedParams += 1
+
+        if len(params)-1 != expectedParams:
+          print('\n%s:%d: expected %d params but saw %d' % (fullPath, getLineNumber(s, '%s(%s);' % parts), expectedParams, len(params)-1))
+          print('  %s(%s);' % parts)
+
diff --git a/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/TransportDeleteByQueryAction.java b/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/TransportDeleteByQueryAction.java
index df57aca16688..cb1dbd567995 100644
--- a/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/TransportDeleteByQueryAction.java
+++ b/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/TransportDeleteByQueryAction.java
@@ -288,13 +288,13 @@ public void onResponse(ClearScrollResponse clearScrollResponse) {
 
                         @Override
                         public void onFailure(Throwable e) {
-                            logger.warn("unable to clear scroll id [{}]: {}", scrollId, e.getMessage());
+                            logger.warn("unable to clear scroll id [{}]", e, scrollId);
                         }
                     });
                 }
 
                 if (failure != null) {
-                    logger.trace("scrolling document(s) terminated with failures: {}", failure.getMessage());
+                    logger.trace("scrolling document(s) terminated with failures", failure);
                     listener.onFailure(failure);
                 } else {
                     logger.trace("scrolling document(s) terminated with success");
diff --git a/plugins/discovery-azure/src/main/java/org/elasticsearch/cloud/azure/management/AzureComputeServiceImpl.java b/plugins/discovery-azure/src/main/java/org/elasticsearch/cloud/azure/management/AzureComputeServiceImpl.java
index 26406e3811cc..801be411eeea 100644
--- a/plugins/discovery-azure/src/main/java/org/elasticsearch/cloud/azure/management/AzureComputeServiceImpl.java
+++ b/plugins/discovery-azure/src/main/java/org/elasticsearch/cloud/azure/management/AzureComputeServiceImpl.java
@@ -64,7 +64,7 @@ public AzureComputeServiceImpl(Settings settings) {
         try {
             tmpKeyStoreType = KeyStoreType.fromString(strKeyStoreType);
         } catch (Exception e) {
-            logger.warn("wrong value for [{}]: [{}]. falling back to [{}]...", KEYSTORE_TYPE,
+            logger.warn("wrong value for [{}]: [{}]. falling back to [{}]...", e, KEYSTORE_TYPE,
                     strKeyStoreType, KeyStoreType.pkcs12.name());
         }
         KeyStoreType keystoreType = tmpKeyStoreType;
@@ -75,7 +75,7 @@ public AzureComputeServiceImpl(Settings settings) {
             configuration = ManagementConfiguration.configure(new URI(Azure.ENDPOINT),
                     subscriptionId, keystorePath, keystorePassword, keystoreType);
         } catch (IOException|URISyntaxException e) {
-            logger.error("can not start azure client: {}", e.getMessage());
+            logger.error("can not start azure client", e);
             computeManagementClient = null;
             return;
         }
diff --git a/plugins/discovery-azure/src/main/java/org/elasticsearch/discovery/azure/AzureUnicastHostsProvider.java b/plugins/discovery-azure/src/main/java/org/elasticsearch/discovery/azure/AzureUnicastHostsProvider.java
index 9f58b0bbb18d..0fc1c4035d7c 100644
--- a/plugins/discovery-azure/src/main/java/org/elasticsearch/discovery/azure/AzureUnicastHostsProvider.java
+++ b/plugins/discovery-azure/src/main/java/org/elasticsearch/discovery/azure/AzureUnicastHostsProvider.java
@@ -120,7 +120,7 @@ public AzureUnicastHostsProvider(Settings settings, AzureComputeService azureCom
         String strHostType = settings.get(Discovery.HOST_TYPE, HostType.PRIVATE_IP.name()).toUpperCase(Locale.ROOT);
         HostType tmpHostType = HostType.fromString(strHostType);
         if (tmpHostType == null) {
-            logger.warn("wrong value for [{}]: [{}]. falling back to [{}]...", Discovery.HOST_TYPE,
+            logger.warn("wrong value for [{}]: [{}]. falling back to [{}]...", null, Discovery.HOST_TYPE,
                     strHostType, HostType.PRIVATE_IP.name().toLowerCase(Locale.ROOT));
             tmpHostType = HostType.PRIVATE_IP;
         }
@@ -135,7 +135,7 @@ public AzureUnicastHostsProvider(Settings settings, AzureComputeService azureCom
         String strDeployment = settings.get(Discovery.DEPLOYMENT_SLOT, Deployment.PRODUCTION.deployment);
         Deployment tmpDeployment = Deployment.fromString(strDeployment);
         if (tmpDeployment == null) {
-            logger.warn("wrong value for [{}]: [{}]. falling back to [{}]...", Discovery.DEPLOYMENT_SLOT, strDeployment,
+            logger.warn("wrong value for [{}]: [{}]. falling back to [{}]...", null, Discovery.DEPLOYMENT_SLOT, strDeployment,
                     Deployment.PRODUCTION.deployment);
             tmpDeployment = Deployment.PRODUCTION;
         }
@@ -170,7 +170,7 @@ public AzureUnicastHostsProvider(Settings settings, AzureComputeService azureCom
             return cachedDiscoNodes;
         } catch (AzureServiceRemoteException e) {
             // We got a remote exception
-            logger.warn("can not get list of azure nodes: [{}]. Returning empty list of nodes.", e.getMessage());
+            logger.warn("can not get list of azure nodes. Returning empty list of nodes.", e);
             logger.trace("AzureServiceRemoteException caught", e);
             return cachedDiscoNodes;
         }
@@ -243,13 +243,13 @@ public AzureUnicastHostsProvider(Settings settings, AzureComputeService azureCom
                         break;
                     default:
                         // This could never happen!
-                        logger.warn("undefined host_type [{}]. Please check your settings.", hostType);
+                        logger.warn("undefined host_type [{}]. Please check your settings.", null, hostType);
                         return cachedDiscoNodes;
                 }
 
                 if (networkAddress == null) {
                     // We have a bad parameter here or not enough information from azure
-                    logger.warn("no network address found. ignoring [{}]...", instance.getInstanceName());
+                    logger.warn("no network address found. ignoring [{}]...", null, instance.getInstanceName());
                     continue;
                 }
 
@@ -262,7 +262,7 @@ public AzureUnicastHostsProvider(Settings settings, AzureComputeService azureCom
                             version.minimumCompatibilityVersion()));
                     }
                 } catch (Exception e) {
-                    logger.warn("can not convert [{}] to transport address. skipping. [{}]", networkAddress, e.getMessage());
+                    logger.warn("can not convert [{}] to transport address. skipping.", e, networkAddress);
                 }
             }
         }
diff --git a/plugins/discovery-ec2/src/main/java/org/elasticsearch/cloud/aws/AwsEc2ServiceImpl.java b/plugins/discovery-ec2/src/main/java/org/elasticsearch/cloud/aws/AwsEc2ServiceImpl.java
index 76c3262db3fa..1dcef3b86d3d 100644
--- a/plugins/discovery-ec2/src/main/java/org/elasticsearch/cloud/aws/AwsEc2ServiceImpl.java
+++ b/plugins/discovery-ec2/src/main/java/org/elasticsearch/cloud/aws/AwsEc2ServiceImpl.java
@@ -102,7 +102,7 @@ public synchronized AmazonEC2 client() {
             try {
                 AwsSigner.configureSigner(awsSigner, clientConfiguration);
             } catch (IllegalArgumentException e) {
-                logger.warn("wrong signer set for [{}] or [{}]: [{}]",
+                logger.warn("wrong signer set for [{}] or [{}]: [{}]", e,
                         CLOUD_EC2.SIGNER, CLOUD_AWS.SIGNER, awsSigner);
             }
         }
diff --git a/plugins/discovery-ec2/src/main/java/org/elasticsearch/cloud/aws/AwsSigner.java b/plugins/discovery-ec2/src/main/java/org/elasticsearch/cloud/aws/AwsSigner.java
index 36eae9b58292..18a1fff49699 100644
--- a/plugins/discovery-ec2/src/main/java/org/elasticsearch/cloud/aws/AwsSigner.java
+++ b/plugins/discovery-ec2/src/main/java/org/elasticsearch/cloud/aws/AwsSigner.java
@@ -55,7 +55,7 @@ public static void configureSigner(String signer, ClientConfiguration configurat
         try {
             validateSignerType(signer);
         } catch (IllegalArgumentException e) {
-            logger.warn(e.getMessage());
+            logger.warn("failed to validate signer type", e);
         }
 
         configuration.setSignerOverride(signer);
diff --git a/plugins/discovery-ec2/src/main/java/org/elasticsearch/cloud/aws/node/Ec2CustomNodeAttributes.java b/plugins/discovery-ec2/src/main/java/org/elasticsearch/cloud/aws/node/Ec2CustomNodeAttributes.java
index fcac113ebccf..6c3753583840 100644
--- a/plugins/discovery-ec2/src/main/java/org/elasticsearch/cloud/aws/node/Ec2CustomNodeAttributes.java
+++ b/plugins/discovery-ec2/src/main/java/org/elasticsearch/cloud/aws/node/Ec2CustomNodeAttributes.java
@@ -62,7 +62,7 @@ public Ec2CustomNodeAttributes(Settings settings) {
 
             String metadataResult = urlReader.readLine();
             if (metadataResult == null || metadataResult.length() == 0) {
-                logger.error("no ec2 metadata returned from {}", url);
+                logger.error("no ec2 metadata returned from {}", null, url);
                 return null;
             }
             ec2Attributes.put("aws_availability_zone", metadataResult);
diff --git a/plugins/discovery-ec2/src/test/java/org/elasticsearch/discovery/ec2/Ec2DiscoveryTests.java b/plugins/discovery-ec2/src/test/java/org/elasticsearch/discovery/ec2/Ec2DiscoveryTests.java
index 6f88be2be5a0..bca7bcc3eda0 100644
--- a/plugins/discovery-ec2/src/test/java/org/elasticsearch/discovery/ec2/Ec2DiscoveryTests.java
+++ b/plugins/discovery-ec2/src/test/java/org/elasticsearch/discovery/ec2/Ec2DiscoveryTests.java
@@ -196,7 +196,7 @@ public void testFilterByTags() throws InterruptedException {
             tagsList.add(tags);
         }
 
-        logger.info("started [{}] instances with [{}] stage=prod tag");
+        logger.info("started [{}] instances with [{}] stage=prod tag", nodes, tagsList);
         List<DiscoveryNode> discoveryNodes = buildDynamicNodes(nodeSettings, nodes, tagsList);
         assertThat(discoveryNodes, hasSize(prodInstances));
     }
diff --git a/plugins/discovery-gce/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java b/plugins/discovery-gce/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java
index d8f6dd331b2f..c4f598ceab10 100644
--- a/plugins/discovery-gce/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java
+++ b/plugins/discovery-gce/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java
@@ -84,8 +84,7 @@ public InstanceList run() throws Exception {
                 }
                 return instanceList.getItems();
             } catch (PrivilegedActionException e) {
-                logger.warn("Problem fetching instance list for zone {}", zoneId);
-                logger.debug("Full exception:", e);
+                logger.warn("Problem fetching instance list for zone {}", e, zoneId);
                 return Collections.EMPTY_LIST;
             }
         }).reduce(new ArrayList<>(), (a, b) -> {
@@ -94,7 +93,7 @@ public InstanceList run() throws Exception {
         });
 
         if (instances.isEmpty()) {
-            logger.warn("disabling GCE discovery. Can not get list of nodes");
+            logger.warn("disabling GCE discovery. Can not get list of nodes", null);
         }
 
         return instances;
diff --git a/plugins/discovery-gce/src/main/java/org/elasticsearch/plugin/discovery/gce/GceDiscoveryPlugin.java b/plugins/discovery-gce/src/main/java/org/elasticsearch/plugin/discovery/gce/GceDiscoveryPlugin.java
index 5f01a98a5f23..4eab0434e0b7 100644
--- a/plugins/discovery-gce/src/main/java/org/elasticsearch/plugin/discovery/gce/GceDiscoveryPlugin.java
+++ b/plugins/discovery-gce/src/main/java/org/elasticsearch/plugin/discovery/gce/GceDiscoveryPlugin.java
@@ -135,7 +135,7 @@ public static boolean isDiscoveryAlive(Settings settings, ESLogger logger) {
 
     private static boolean checkProperty(String name, String value, ESLogger logger) {
         if (!Strings.hasText(value)) {
-            logger.warn("{} is not set.", name);
+            logger.warn("{} is not set.", null, name);
             return false;
         }
         return true;
@@ -143,7 +143,7 @@ private static boolean checkProperty(String name, String value, ESLogger logger)
 
     private static boolean checkProperty(String name, String[] values, ESLogger logger) {
         if (values == null || values.length == 0) {
-            logger.warn("{} is not set.", name);
+            logger.warn("{} is not set.", null, name);
             return false;
         }
         return true;
diff --git a/plugins/discovery-multicast/src/main/java/org/elasticsearch/plugin/discovery/multicast/MulticastChannel.java b/plugins/discovery-multicast/src/main/java/org/elasticsearch/plugin/discovery/multicast/MulticastChannel.java
index dee74b9ddcef..6e6d8912da40 100644
--- a/plugins/discovery-multicast/src/main/java/org/elasticsearch/plugin/discovery/multicast/MulticastChannel.java
+++ b/plugins/discovery-multicast/src/main/java/org/elasticsearch/plugin/discovery/multicast/MulticastChannel.java
@@ -365,7 +365,7 @@ public void run() {
                             } catch (Exception e) {
                                 if (running) {
                                     if (multicastSocket.isClosed()) {
-                                        logger.warn("multicast socket closed while running, restarting...");
+                                        logger.warn("multicast socket closed while running, restarting...", e);
                                         multicastSocket = buildMulticastSocket(config);
                                     } else {
                                         logger.warn("failed to receive packet, throttling...", e);
diff --git a/plugins/discovery-multicast/src/main/java/org/elasticsearch/plugin/discovery/multicast/MulticastZenPing.java b/plugins/discovery-multicast/src/main/java/org/elasticsearch/plugin/discovery/multicast/MulticastZenPing.java
index f28bc08e9a6b..ed028af37d68 100644
--- a/plugins/discovery-multicast/src/main/java/org/elasticsearch/plugin/discovery/multicast/MulticastZenPing.java
+++ b/plugins/discovery-multicast/src/main/java/org/elasticsearch/plugin/discovery/multicast/MulticastZenPing.java
@@ -299,7 +299,7 @@ private void sendPingRequest(int id) {
             if (logger.isDebugEnabled()) {
                 logger.debug("failed to send multicast ping request", e);
             } else {
-                logger.warn("failed to send multicast ping request: {}", ExceptionsHelper.detailedMessage(e));
+                logger.warn("failed to send multicast ping request", e);
             }
         }
     }
@@ -365,7 +365,7 @@ public void messageReceived(MulticastPingResponse request, TransportChannel chan
             }
             PingCollection responses = receivedResponses.get(request.id);
             if (responses == null) {
-                logger.warn("received ping response {} with no matching id [{}]", request.pingResponse, request.id);
+                logger.warn("received ping response {} with no matching id [{}]", null, request.pingResponse, request.id);
             } else {
                 responses.addPing(request.pingResponse);
             }
@@ -469,13 +469,13 @@ private void handleExternalPingRequest(Map<String, Object> externalPingData, XCo
 
             Map<String, Object> request = (Map<String, Object>) externalPingData.get("request");
             if (request == null) {
-                logger.warn("malformed external ping request, no 'request' element from {}, content {}", remoteAddress, externalPingData);
+                logger.warn("malformed external ping request, no 'request' element from {}, content {}", null, remoteAddress, externalPingData);
                 return;
             }
 
             final String requestClusterName = request.containsKey("cluster_name") ? request.get("cluster_name").toString() : request.containsKey("clusterName") ? request.get("clusterName").toString() : null;
             if (requestClusterName == null) {
-                logger.warn("malformed external ping request, missing 'cluster_name' element within request, from {}, content {}", remoteAddress, externalPingData);
+                logger.warn("malformed external ping request, missing 'cluster_name' element within request, from {}, content {}", null, remoteAddress, externalPingData);
                 return;
             }
 
@@ -539,7 +539,7 @@ private void handleNodePingRequest(int id, DiscoveryNode requestingNodeX, Cluste
             // don't connect between two client nodes, no need for that...
             if (!discoveryNodes.localNode().shouldConnectTo(requestingNode)) {
                 if (logger.isTraceEnabled()) {
-                    logger.trace("[{}] received ping_request from [{}], both are client nodes, ignoring", id, requestingNode, requestClusterName);
+                    logger.trace("[{}] received ping_request from [{}], cluster name [{}], both are client nodes, ignoring", id, requestingNode, requestClusterName);
                 }
                 return;
             }
diff --git a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/ExtendedStatsTests.java b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/ExtendedStatsTests.java
index b610f9648b5e..98c2ef714bbc 100644
--- a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/ExtendedStatsTests.java
+++ b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/ExtendedStatsTests.java
@@ -502,7 +502,7 @@ private void assertShardExecutionState(SearchResponse response, int expectedFail
         ShardSearchFailure[] failures = response.getShardFailures();
         if (failures.length != expectedFailures) {
             for (ShardSearchFailure failure : failures) {
-                logger.error("Shard Failure: {}", failure.reason(), failure.toString());
+                logger.error("Shard Failure: [{}]", failure.getCause(), failure);
             }
             fail("Unexpected shard failures!");
         }
@@ -514,4 +514,4 @@ private void checkUpperLowerBounds(ExtendedStats stats, double sigma) {
         assertThat(stats.getStdDeviationBound(ExtendedStats.Bounds.LOWER), equalTo(stats.getAvg() - (stats.getStdDeviation() * sigma)));
     }
 
-}
\ No newline at end of file
+}
diff --git a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SimpleSortTests.java b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SimpleSortTests.java
index 5a00bca9facc..c9b44693c145 100644
--- a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SimpleSortTests.java
+++ b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SimpleSortTests.java
@@ -921,9 +921,9 @@ public void testDocumentsWithNullValue() throws Exception {
                 .execute().actionGet();
 
         if (searchResponse.getFailedShards() > 0) {
-            logger.warn("Failed shards:");
+            logger.warn("Failed shards:", null);
             for (ShardSearchFailure shardSearchFailure : searchResponse.getShardFailures()) {
-                logger.warn("-> {}", shardSearchFailure);
+                logger.warn("-> {}", null, shardSearchFailure);
             }
         }
         assertThat(searchResponse.getFailedShards(), equalTo(0));
@@ -941,9 +941,9 @@ public void testDocumentsWithNullValue() throws Exception {
                 .execute().actionGet();
 
         if (searchResponse.getFailedShards() > 0) {
-            logger.warn("Failed shards:");
+            logger.warn("Failed shards:", null);
             for (ShardSearchFailure shardSearchFailure : searchResponse.getShardFailures()) {
-                logger.warn("-> {}", shardSearchFailure);
+                logger.warn("-> {}", null, shardSearchFailure);
             }
         }
         assertThat(searchResponse.getFailedShards(), equalTo(0));
diff --git a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/StatsTests.java b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/StatsTests.java
index f480ba4d2e01..65efbe4a7e71 100644
--- a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/StatsTests.java
+++ b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/StatsTests.java
@@ -404,10 +404,10 @@ private void assertShardExecutionState(SearchResponse response, int expectedFail
         ShardSearchFailure[] failures = response.getShardFailures();
         if (failures.length != expectedFailures) {
             for (ShardSearchFailure failure : failures) {
-                logger.error("Shard Failure: {}", failure.reason(), failure.toString());
+                logger.error("Shard Failure: [{}]", failure.getCause(), failure);
             }
             fail("Unexpected shard failures!");
         }
         assertThat("Not all shards are initialized", response.getSuccessfulShards(), equalTo(response.getTotalShards()));
     }
-}
\ No newline at end of file
+}
diff --git a/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/blobstore/AzureBlobContainer.java b/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/blobstore/AzureBlobContainer.java
index cf25e5d8b77a..38ef658bad22 100644
--- a/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/blobstore/AzureBlobContainer.java
+++ b/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/blobstore/AzureBlobContainer.java
@@ -65,7 +65,7 @@ public boolean blobExists(String blobName) {
         try {
             return blobStore.blobExists(blobStore.container(), buildKey(blobName));
         } catch (URISyntaxException | StorageException e) {
-            logger.warn("can not access [{}] in container {{}}: {}", blobName, blobStore.container(), e.getMessage());
+            logger.warn("can not access [{}] in container {{}}", e, blobName, blobStore.container());
         }
         return false;
     }
@@ -118,7 +118,7 @@ public void deleteBlob(String blobName) throws IOException {
         try {
             blobStore.deleteBlob(blobStore.container(), buildKey(blobName));
         } catch (URISyntaxException | StorageException e) {
-            logger.warn("can not access [{}] in container {{}}: {}", blobName, blobStore.container(), e.getMessage());
+            logger.warn("can not access [{}] in container {{}}", e, blobName, blobStore.container());
             throw new IOException(e);
         }
     }
@@ -129,7 +129,7 @@ public void deleteBlob(String blobName) throws IOException {
         try {
             return blobStore.listBlobsByPrefix(blobStore.container(), keyPath, prefix);
         } catch (URISyntaxException | StorageException e) {
-            logger.warn("can not access [{}] in container {{}}: {}", prefix, blobStore.container(), e.getMessage());
+            logger.warn("can not access [{}] in container {{}}", e, prefix, blobStore.container());
             throw new IOException(e);
         }
     }
@@ -144,10 +144,10 @@ public void move(String sourceBlobName, String targetBlobName) throws IOExceptio
 
             blobStore.moveBlob(blobStore.container(), source, target);
         } catch (URISyntaxException e) {
-            logger.warn("can not move blob [{}] to [{}] in container {{}}: {}", sourceBlobName, targetBlobName, blobStore.container(), e.getMessage());
+            logger.warn("can not move blob [{}] to [{}] in container {{}}", e, sourceBlobName, targetBlobName, blobStore.container());
             throw new IOException(e);
         } catch (StorageException e) {
-            logger.warn("can not move blob [{}] to [{}] in container {{}}: {}", sourceBlobName, targetBlobName, blobStore.container(), e.getMessage());
+            logger.warn("can not move blob [{}] to [{}] in container {{}}", e, sourceBlobName, targetBlobName, blobStore.container());
             throw new IOException(e);
         }
     }
diff --git a/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/blobstore/AzureBlobStore.java b/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/blobstore/AzureBlobStore.java
index 99a505c56665..6c398ecd2fab 100644
--- a/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/blobstore/AzureBlobStore.java
+++ b/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/blobstore/AzureBlobStore.java
@@ -94,7 +94,7 @@ public void delete(BlobPath path) {
         try {
             this.client.deleteFiles(this.accountName, this.locMode, container, keyPath);
         } catch (URISyntaxException | StorageException e) {
-            logger.warn("can not remove [{}] in container {{}}: {}", keyPath, container, e.getMessage());
+            logger.warn("can not remove [{}] in container {{}}", e, keyPath, container);
         }
     }
 
diff --git a/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/storage/AzureStorageServiceImpl.java b/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/storage/AzureStorageServiceImpl.java
index 56e75d7386c2..c52dfd4b69fb 100644
--- a/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/storage/AzureStorageServiceImpl.java
+++ b/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/storage/AzureStorageServiceImpl.java
@@ -78,7 +78,7 @@ void createClient(AzureStorageSettings azureStorageSettings) {
             // Register the client
             this.clients.put(azureStorageSettings.getAccount(), client);
         } catch (Exception e) {
-            logger.error("can not create azure storage client: {}", e.getMessage());
+            logger.error("can not create azure storage client", e);
         }
     }
     
@@ -125,7 +125,7 @@ public boolean doesContainerExist(String account, LocationMode mode, String cont
             CloudBlobContainer blob_container = client.getContainerReference(container);
             return blob_container.exists();
         } catch (Exception e) {
-            logger.error("can not access container [{}]", container);
+            logger.error("can not access container [{}]", e, container);
         }
         return false;
     }
@@ -153,7 +153,7 @@ public void createContainer(String account, LocationMode mode, String container)
             logger.trace("creating container [{}]", container);
             blob_container.createIfNotExists();
         } catch (IllegalArgumentException e) {
-            logger.trace("fails creating container [{}]", container, e.getMessage());
+            logger.trace("fails creating container [{}]", e, container);
             throw new RepositoryException(container, e.getMessage());
         }
     }
diff --git a/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/storage/AzureStorageSettings.java b/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/storage/AzureStorageSettings.java
index 7fd0312df29b..626be4a95736 100644
--- a/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/storage/AzureStorageSettings.java
+++ b/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/storage/AzureStorageSettings.java
@@ -77,7 +77,7 @@ public String toString() {
         String key = settings.get(Storage.KEY);
         if (account != null) {
             logger.warn("[{}] and [{}] have been deprecated. Use now [{}xxx.account] and [{}xxx.key] where xxx is any name",
-                    Storage.ACCOUNT, Storage.KEY, Storage.PREFIX, Storage.PREFIX);
+                    null, Storage.ACCOUNT, Storage.KEY, Storage.PREFIX, Storage.PREFIX);
             primaryStorage = new AzureStorageSettings(null, account, key);
         } else {
             Settings storageSettings = settings.getByPrefix(Storage.PREFIX);
@@ -93,7 +93,7 @@ public String toString() {
                             if (primaryStorage == null) {
                                 primaryStorage = current;
                             } else {
-                                logger.warn("default storage settings has already been defined. You can not define it to [{}]", storage.getKey());
+                                logger.warn("default storage settings has already been defined. You can not define it to [{}]", null, storage.getKey());
                                 secondaryStorage.put(storage.getKey(), current);
                             }
                         } else {
@@ -109,7 +109,7 @@ public String toString() {
                     if (secondaryStorage.size() > 1) {
                         logger.warn("no default storage settings has been defined. " +
                                 "Add \"default\": true to the settings you want to activate by default. " +
-                                "Forcing default to [{}].", fallback.getKey());
+                                "Forcing default to [{}].", null, fallback.getKey());
                     }
                     primaryStorage = fallback.getValue();
                     secondaryStorage.remove(fallback.getKey());
diff --git a/plugins/repository-azure/src/main/java/org/elasticsearch/repositories/azure/AzureRepository.java b/plugins/repository-azure/src/main/java/org/elasticsearch/repositories/azure/AzureRepository.java
index 829ccb7e95ec..eee0e6285bd5 100644
--- a/plugins/repository-azure/src/main/java/org/elasticsearch/repositories/azure/AzureRepository.java
+++ b/plugins/repository-azure/src/main/java/org/elasticsearch/repositories/azure/AzureRepository.java
@@ -91,7 +91,7 @@ public AzureRepository(RepositoryName name, RepositorySettings repositorySetting
                 settings.getAsBytesSize(Storage.CHUNK_SIZE, new ByteSizeValue(64, ByteSizeUnit.MB)));
 
         if (this.chunkSize.getMb() > 64) {
-            logger.warn("azure repository does not support yet size > 64mb. Fall back to 64mb.");
+            logger.warn("azure repository does not support yet size > 64mb. Fall back to 64mb.", null);
             this.chunkSize = new ByteSizeValue(64, ByteSizeUnit.MB);
         }
 
@@ -164,7 +164,7 @@ public void initializeSnapshot(SnapshotId snapshotId, List<String> indices, Meta
             }
             super.initializeSnapshot(snapshotId, indices, metaData);
         } catch (StorageException | URISyntaxException e) {
-            logger.warn("can not initialize container [{}]: [{}]", blobStore.container(), e.getMessage());
+            logger.warn("can not initialize container [{}]", e, blobStore.container());
             throw new SnapshotCreationException(snapshotId, e);
         }
     }
@@ -178,7 +178,7 @@ public String startVerification() {
                     blobStore.createContainer(blobStore.container());
                 }
             } catch (StorageException | URISyntaxException e) {
-                logger.warn("can not initialize container [{}]: [{}]", blobStore.container(), e.getMessage());
+                logger.warn("can not initialize container [{}]", e, blobStore.container());
                 throw new RepositoryVerificationException(repositoryName, "can not initialize container " + blobStore.container(), e);
             }
         }
diff --git a/plugins/repository-s3/src/main/java/org/elasticsearch/cloud/aws/AwsSigner.java b/plugins/repository-s3/src/main/java/org/elasticsearch/cloud/aws/AwsSigner.java
index c94491696c04..39d84640dd16 100644
--- a/plugins/repository-s3/src/main/java/org/elasticsearch/cloud/aws/AwsSigner.java
+++ b/plugins/repository-s3/src/main/java/org/elasticsearch/cloud/aws/AwsSigner.java
@@ -64,7 +64,7 @@ public static void configureSigner(String signer, ClientConfiguration configurat
         try {
             validateSignerType(signer, endpoint);
         } catch (IllegalArgumentException e) {
-            logger.warn(e.getMessage());
+            logger.warn("failed to validate signer type", e);
         }
 
         configuration.setSignerOverride(signer);
diff --git a/qa/evil-tests/src/test/java/org/elasticsearch/plugins/PluginManagerTests.java b/qa/evil-tests/src/test/java/org/elasticsearch/plugins/PluginManagerTests.java
index 0e7597e61e88..010588012951 100644
--- a/qa/evil-tests/src/test/java/org/elasticsearch/plugins/PluginManagerTests.java
+++ b/qa/evil-tests/src/test/java/org/elasticsearch/plugins/PluginManagerTests.java
@@ -571,12 +571,12 @@ private boolean isDownloadServiceWorking(String host, int port, String resource)
             String protocol = port == 443 ? "https" : "http";
             HttpResponse response = new HttpRequestBuilder(HttpClients.createDefault()).protocol(protocol).host(host).port(port).path(resource).execute();
             if (response.getStatusCode() != 200) {
-                logger.warn("[{}{}] download service is not working. Disabling current test.", host, resource);
+                logger.warn("[{}{}] download service is not working. Disabling current test.", null, host, resource);
                 return false;
             }
             return true;
         } catch (Throwable t) {
-            logger.warn("[{}{}] download service is not working. Disabling current test.", host, resource);
+            logger.warn("[{}{}] download service is not working. Disabling current test.", t, host, resource);
         }
         return false;
     }
diff --git a/test-framework/src/main/java/org/elasticsearch/test/ESIntegTestCase.java b/test-framework/src/main/java/org/elasticsearch/test/ESIntegTestCase.java
index 7506c52c7094..a2ee0938409b 100644
--- a/test-framework/src/main/java/org/elasticsearch/test/ESIntegTestCase.java
+++ b/test-framework/src/main/java/org/elasticsearch/test/ESIntegTestCase.java
@@ -882,7 +882,7 @@ public void assertResultsAndLogOnFailure(long expectedResults, SearchResponse se
                 sb.append("\n-> _index: [").append(hit.getIndex()).append("] type [").append(hit.getType())
                         .append("] id [").append(hit.id()).append("]");
             }
-            logger.warn(sb.toString());
+            logger.warn(sb.toString(), null);
             fail(failMsg);
         }
     }
@@ -1117,7 +1117,7 @@ protected void ensureClusterStateConsistency() throws IOException {
                         // Compare JSON serialization
                         assertNull("clusterstate JSON serialization does not match", differenceBetweenMapsIgnoringArrayOrder(masterStateMap, localStateMap));
                     } catch (AssertionError error) {
-                        logger.error("Cluster state from master:\n{}\nLocal cluster state:\n{}", masterClusterState.toString(), localClusterState.toString());
+                        logger.error("Cluster state from master:\n{}\nLocal cluster state:\n{}", error, masterClusterState.toString(), localClusterState.toString());
                         throw error;
                     }
                 }
@@ -1437,7 +1437,7 @@ public void indexRandom(boolean forceRefresh, boolean dummyDocuments, boolean ma
                 // see https://github.com/elasticsearch/elasticsearch/issues/8706
                 final DeleteResponse deleteResponse = client().prepareDelete(doc.v1(), RANDOM_BOGUS_TYPE, doc.v2()).get();
                 if (deleteResponse.isFound() == false) {
-                    logger.warn("failed to delete a dummy doc [{}][{}]", doc.v1(), doc.v2());
+                    logger.warn("failed to delete a dummy doc [{}][{}]", null, doc.v1(), doc.v2());
                 }
             }
         }
diff --git a/test-framework/src/main/java/org/elasticsearch/test/junit/rule/RepeatOnExceptionRule.java b/test-framework/src/main/java/org/elasticsearch/test/junit/rule/RepeatOnExceptionRule.java
index 7ded36f3809b..2cd06dff033a 100644
--- a/test-framework/src/main/java/org/elasticsearch/test/junit/rule/RepeatOnExceptionRule.java
+++ b/test-framework/src/main/java/org/elasticsearch/test/junit/rule/RepeatOnExceptionRule.java
@@ -71,7 +71,7 @@ public void evaluate() throws Throwable {
                         }
                     }
                 }
-                logger.error("Giving up after [{}] failures... marking test as failed", retryCount);
+                logger.error("Giving up after [{}] failures... marking test as failed", caughtThrowable, retryCount);
                 throw caughtThrowable;
             }
         };
diff --git a/test-framework/src/main/java/org/elasticsearch/test/store/MockFSDirectoryService.java b/test-framework/src/main/java/org/elasticsearch/test/store/MockFSDirectoryService.java
index 9c2b8612d511..551684595074 100644
--- a/test-framework/src/main/java/org/elasticsearch/test/store/MockFSDirectoryService.java
+++ b/test-framework/src/main/java/org/elasticsearch/test/store/MockFSDirectoryService.java
@@ -120,6 +120,7 @@ public static void checkIndex(ESLogger logger, Store store, ShardId shardId) {
                     if (!status.clean) {
                         ESTestCase.checkIndexFailed = true;
                         logger.warn("check index [failure] index files={}\n{}",
+                                null,
                                 Arrays.toString(dir.listAll()),
                                 new String(os.bytes().toBytes(), StandardCharsets.UTF_8));
                         throw new IOException("index check failure");
