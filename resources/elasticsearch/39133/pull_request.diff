diff --git a/server/src/main/java/org/elasticsearch/action/support/replication/ReplicationOperation.java b/server/src/main/java/org/elasticsearch/action/support/replication/ReplicationOperation.java
index 7fdb613c38bb..02945b07b2f3 100644
--- a/server/src/main/java/org/elasticsearch/action/support/replication/ReplicationOperation.java
+++ b/server/src/main/java/org/elasticsearch/action/support/replication/ReplicationOperation.java
@@ -104,6 +104,7 @@ public void execute() throws Exception {
         pendingActions.incrementAndGet(); // increase by 1 until we finish all primary coordination
         primaryResult = primary.perform(request);
         primary.updateLocalCheckpointForShard(primaryRouting.allocationId().getId(), primary.localCheckpoint());
+        primary.updateLocalCheckpointOfSafeCommitForShard(primaryRouting.allocationId().getId(), primary.localCheckpointOfSafeCommit());
         final ReplicaRequest replicaRequest = primaryResult.replicaRequest();
         if (replicaRequest != null) {
             if (logger.isTraceEnabled()) {
@@ -170,6 +171,7 @@ public void onResponse(ReplicaResponse response) {
                 try {
                     primary.updateLocalCheckpointForShard(shard.allocationId().getId(), response.localCheckpoint());
                     primary.updateGlobalCheckpointForShard(shard.allocationId().getId(), response.globalCheckpoint());
+                    primary.updateLocalCheckpointOfSafeCommitForShard(shard.allocationId().getId(), response.localCheckpointOfSafeCommit());
                 } catch (final AlreadyClosedException e) {
                     // okay, the index was deleted or this shard was never activated after a relocation; fall through and finish normally
                 } catch (final Exception e) {
@@ -334,6 +336,14 @@ private void finishAsFailed(Exception exception) {
          */
         void updateGlobalCheckpointForShard(String allocationId, long globalCheckpoint);
 
+        /**
+         * Update the local knowledge of the local checkpoint of the safe commit for the specified allocation ID.
+         *
+         * @param allocationId     the allocation ID to update the local checkpoint of the safe commit for
+         * @param localCheckpointOfSafeCommit the local checkpoint of the safe commit
+         */
+        void updateLocalCheckpointOfSafeCommitForShard(String allocationId, long localCheckpointOfSafeCommit);
+
         /**
          * Returns the local checkpoint on the primary shard.
          *
@@ -348,6 +358,13 @@ private void finishAsFailed(Exception exception) {
          */
         long globalCheckpoint();
 
+        /**
+         * Returns the local checkpoint of the safe commit on the primary shard.
+         *
+         * @return the local checkpoint of the safe commit
+         */
+        long localCheckpointOfSafeCommit();
+
         /**
          * Returns the maximum seq_no of updates (index operations overwrite Lucene) or deletes on the primary.
          * This value must be captured after the execution of a replication request on the primary is completed.
@@ -423,6 +440,12 @@ void performOn(ShardRouting replica, RequestT replicaRequest, long globalCheckpo
          **/
         long globalCheckpoint();
 
+        /**
+         * The local checkpoint of the safe commit for the shard copy.
+         *
+         * @return the local checkpoint of the safe commit
+         **/
+        long localCheckpointOfSafeCommit();
     }
 
     public static class RetryOnPrimaryException extends ElasticsearchException {
diff --git a/server/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java b/server/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java
index 3178dc5d937b..5c800f3dd261 100644
--- a/server/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java
+++ b/server/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java
@@ -23,6 +23,7 @@
 import org.apache.lucene.store.AlreadyClosedException;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.ExceptionsHelper;
+import org.elasticsearch.Version;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.ActionListenerResponseHandler;
 import org.elasticsearch.action.ActionResponse;
@@ -231,6 +232,13 @@ protected boolean resolveIndex() {
         return true;
     }
 
+    /**
+     * True if this action can be replicated even on closed indices.
+     */
+    protected boolean isReplicatedOnClosedIndices() {
+        return false;
+    }
+
     protected TransportRequestOptions transportOptions(Settings settings) {
         return TransportRequestOptions.EMPTY;
     }
@@ -618,7 +626,8 @@ public void onResponse(Releasable releasable) {
                 final ReplicaResult replicaResult = shardOperationOnReplica(request, replica);
                 releasable.close(); // release shard operation lock before responding to caller
                 final TransportReplicationAction.ReplicaResponse response =
-                        new ReplicaResponse(replica.getLocalCheckpoint(), replica.getGlobalCheckpoint());
+                        new ReplicaResponse(replica.getLocalCheckpoint(), replica.getGlobalCheckpoint(),
+                                            replica.getLocalCheckpointOfSafeCommit());
                 replicaResult.respond(new ResponseListener(response));
             } catch (final Exception e) {
                 Releasables.closeWhileHandlingException(releasable); // release shard operation lock before responding to caller
@@ -773,7 +782,7 @@ protected void doRun() {
                     retry(new IndexNotFoundException(concreteIndex));
                     return;
                 }
-                if (indexMetaData.getState() == IndexMetaData.State.CLOSE) {
+                if (isReplicatedOnClosedIndices() == false && indexMetaData.getState() == IndexMetaData.State.CLOSE) {
                     throw new IndexClosedException(indexMetaData.getIndex());
                 }
 
@@ -1045,6 +1054,11 @@ public void updateGlobalCheckpointForShard(final String allocationId, final long
             indexShard.updateGlobalCheckpointForShard(allocationId, globalCheckpoint);
         }
 
+        @Override
+        public void updateLocalCheckpointOfSafeCommitForShard(final String allocationId, final long localCheckpointOfSafeCommit) {
+            indexShard.updateLocalCheckpointOfSafeCommitForShard(allocationId, localCheckpointOfSafeCommit);
+        }
+
         @Override
         public long localCheckpoint() {
             return indexShard.getLocalCheckpoint();
@@ -1055,6 +1069,11 @@ public long globalCheckpoint() {
             return indexShard.getGlobalCheckpoint();
         }
 
+        @Override
+        public long localCheckpointOfSafeCommit() {
+            return indexShard.getLocalCheckpointOfSafeCommit();
+        }
+
         @Override
         public long maxSeqNoOfUpdatesOrDeletes() {
             return indexShard.getMaxSeqNoOfUpdatesOrDeletes();
@@ -1070,12 +1089,13 @@ public ReplicationGroup getReplicationGroup() {
     public static class ReplicaResponse extends ActionResponse implements ReplicationOperation.ReplicaResponse {
         private long localCheckpoint;
         private long globalCheckpoint;
+        private long localCheckpointOfSafeCommit;
 
         ReplicaResponse() {
 
         }
 
-        public ReplicaResponse(long localCheckpoint, long globalCheckpoint) {
+        public ReplicaResponse(long localCheckpoint, long globalCheckpoint, long localCheckpointOfSafeCommit) {
             /*
              * A replica should always know its own local checkpoints so this should always be a valid sequence number or the pre-6.0
              * checkpoint value when simulating responses to replication actions that pre-6.0 nodes are not aware of (e.g., the global
@@ -1084,6 +1104,7 @@ public ReplicaResponse(long localCheckpoint, long globalCheckpoint) {
             assert localCheckpoint != SequenceNumbers.UNASSIGNED_SEQ_NO;
             this.localCheckpoint = localCheckpoint;
             this.globalCheckpoint = globalCheckpoint;
+            this.localCheckpointOfSafeCommit = localCheckpointOfSafeCommit;
         }
 
         @Override
@@ -1091,6 +1112,11 @@ public void readFrom(StreamInput in) throws IOException {
             super.readFrom(in);
             localCheckpoint = in.readZLong();
             globalCheckpoint = in.readZLong();
+            if (in.getVersion().onOrAfter(Version.V_8_0_0)) { // TODO V_7_0_0 for backport
+                localCheckpointOfSafeCommit = in.readZLong();
+            } else {
+                localCheckpointOfSafeCommit = SequenceNumbers.UNASSIGNED_SEQ_NO;
+            }
         }
 
         @Override
@@ -1098,6 +1124,9 @@ public void writeTo(StreamOutput out) throws IOException {
             super.writeTo(out);
             out.writeZLong(localCheckpoint);
             out.writeZLong(globalCheckpoint);
+            if (out.getVersion().onOrAfter(Version.V_8_0_0)) { // TODO V_7_0_0 for backport
+                out.writeZLong(localCheckpointOfSafeCommit);
+            }
         }
 
         @Override
@@ -1110,18 +1139,24 @@ public long globalCheckpoint() {
             return globalCheckpoint;
         }
 
+        @Override
+        public long localCheckpointOfSafeCommit() {
+            return localCheckpointOfSafeCommit;
+        }
+
         @Override
         public boolean equals(Object o) {
             if (this == o) return true;
             if (o == null || getClass() != o.getClass()) return false;
             ReplicaResponse that = (ReplicaResponse) o;
             return localCheckpoint == that.localCheckpoint &&
-                globalCheckpoint == that.globalCheckpoint;
+                globalCheckpoint == that.globalCheckpoint &&
+                localCheckpointOfSafeCommit == that.localCheckpointOfSafeCommit;
         }
 
         @Override
         public int hashCode() {
-            return Objects.hash(localCheckpoint, globalCheckpoint);
+            return Objects.hash(localCheckpoint, globalCheckpoint, localCheckpointOfSafeCommit);
         }
     }
 
diff --git a/server/src/main/java/org/elasticsearch/index/IndexService.java b/server/src/main/java/org/elasticsearch/index/IndexService.java
index 9738cb034e88..a8007362aca2 100644
--- a/server/src/main/java/org/elasticsearch/index/IndexService.java
+++ b/server/src/main/java/org/elasticsearch/index/IndexService.java
@@ -26,6 +26,7 @@
 import org.apache.lucene.util.Accountable;
 import org.elasticsearch.Assertions;
 import org.elasticsearch.Version;
+import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.client.Client;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.routing.ShardRouting;
@@ -88,6 +89,7 @@
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
+import java.util.function.BiConsumer;
 import java.util.function.Consumer;
 import java.util.function.LongSupplier;
 import java.util.function.Supplier;
@@ -122,6 +124,7 @@
     private volatile AsyncTranslogFSync fsyncTask;
     private volatile AsyncGlobalCheckpointTask globalCheckpointTask;
     private volatile AsyncRetentionLeaseSyncTask retentionLeaseSyncTask;
+    private volatile AsyncPeerRecoveryRetentionLeaseRenewalTask peerRecoveryRetentionLeaseRenewalTask;
 
     // don't convert to Setting<> and register... we only set this in tests and register via a plugin
     private final String INDEX_TRANSLOG_RETENTION_CHECK_INTERVAL_SETTING = "index.translog.retention.check_interval";
@@ -199,6 +202,7 @@ public IndexService(
         this.trimTranslogTask = new AsyncTrimTranslogTask(this);
         this.globalCheckpointTask = new AsyncGlobalCheckpointTask(this);
         this.retentionLeaseSyncTask = new AsyncRetentionLeaseSyncTask(this);
+        this.peerRecoveryRetentionLeaseRenewalTask = new AsyncPeerRecoveryRetentionLeaseRenewalTask(this);
         rescheduleFsyncTask(indexSettings.getTranslogDurability());
     }
 
@@ -289,7 +293,8 @@ public synchronized void close(final String reason, boolean delete) throws IOExc
                         fsyncTask,
                         trimTranslogTask,
                         globalCheckpointTask,
-                        retentionLeaseSyncTask);
+                        retentionLeaseSyncTask,
+                        peerRecoveryRetentionLeaseRenewalTask);
             }
         }
     }
@@ -317,8 +322,10 @@ private long getAvgShardSizeInBytes() throws IOException {
     public synchronized IndexShard createShard(
             final ShardRouting routing,
             final Consumer<ShardId> globalCheckpointSyncer,
-            final RetentionLeaseSyncer retentionLeaseSyncer) throws IOException {
+            final RetentionLeaseSyncer retentionLeaseSyncer,
+            final BiConsumer<ShardId, ActionListener<Void>> peerRecoveryRetentionLeaseRenewer) throws IOException {
         Objects.requireNonNull(retentionLeaseSyncer);
+        Objects.requireNonNull(peerRecoveryRetentionLeaseRenewer);
         /*
          * TODO: we execute this in parallel but it's a synced method. Yet, we might
          * be able to serialize the execution via the cluster state in the future. for now we just
@@ -408,7 +415,8 @@ public synchronized IndexShard createShard(
                     indexingOperationListeners,
                     () -> globalCheckpointSyncer.accept(shardId),
                     retentionLeaseSyncer,
-                    circuitBreakerService);
+                    circuitBreakerService,
+                    listener -> peerRecoveryRetentionLeaseRenewer.accept(shardId, listener));
             eventListener.indexShardStateChanged(indexShard, null, indexShard.state(), "shard created");
             eventListener.afterIndexShardCreated(indexShard);
             shards = newMapBuilder(shards).put(shardId.id(), indexShard).immutableMap();
@@ -795,6 +803,10 @@ private void syncRetentionLeases() {
         }
     }
 
+    private void renewPeerRecoveryRetentionLeases() {
+        sync(IndexShard::renewPeerRecoveryRetentionLeases, "peer recovery retention leases");
+    }
+
     private void sync(final Consumer<IndexShard> sync, final String source) {
         for (final IndexShard shard : this.shards.values()) {
             if (shard.routingEntry().active() && shard.routingEntry().primary()) {
@@ -937,6 +949,15 @@ public String toString() {
                     Property.Dynamic,
                     Property.IndexScope);
 
+    // this setting is intentionally not registered, it is only used in tests
+    public static final Setting<TimeValue> RETENTION_LEASE_PEER_RECOVERY_SYNC_INTERVAL_SETTING =
+        Setting.timeSetting(
+            "index.soft_deletes.retention_lease.peer_recovery.sync_interval",
+            new TimeValue(5, TimeUnit.MINUTES),
+            new TimeValue(0, TimeUnit.MILLISECONDS),
+            Property.Dynamic,
+            Property.IndexScope);
+
     /**
      * Background task that syncs the global checkpoint to replicas.
      */
@@ -986,6 +1007,30 @@ public String toString() {
 
     }
 
+    final class AsyncPeerRecoveryRetentionLeaseRenewalTask extends BaseAsyncTask {
+
+        // TODO perhaps we can just piggyback on the synced flush that happens after 5 minutes of inactivity instead?
+
+        AsyncPeerRecoveryRetentionLeaseRenewalTask(final IndexService indexService) {
+            super(indexService, RETENTION_LEASE_PEER_RECOVERY_SYNC_INTERVAL_SETTING.get(indexService.getIndexSettings().getSettings()));
+        }
+
+        @Override
+        protected void runInternal() {
+            indexService.renewPeerRecoveryRetentionLeases();
+        }
+
+        @Override
+        protected String getThreadPool() {
+            return ThreadPool.Names.MANAGEMENT;
+        }
+
+        @Override
+        public String toString() {
+            return "peer_recovery_retention_lease_sync";
+        }
+    }
+
     AsyncRefreshTask getRefreshTask() { // for tests
         return refreshTask;
     }
diff --git a/server/src/main/java/org/elasticsearch/index/engine/Engine.java b/server/src/main/java/org/elasticsearch/index/engine/Engine.java
index 55b1ce6e6992..c3779c22b2bc 100644
--- a/server/src/main/java/org/elasticsearch/index/engine/Engine.java
+++ b/server/src/main/java/org/elasticsearch/index/engine/Engine.java
@@ -264,6 +264,8 @@ protected final DocsStats docsStats(IndexReader indexReader) {
         return new DocsStats(numDocs, numDeletedDocs, sizeInBytes);
     }
 
+    public abstract long getLocalCheckpointOfSafeCommit();
+
     /**
      * Performs the pre-closing checks on the {@link Engine}.
      *
@@ -766,7 +768,7 @@ public abstract int estimateNumberOfHistoryOperations(String source,
                                                                 MapperService mapperService, long startingSeqNo) throws IOException;
 
     /**
-     * Checks if this engine has every operations since  {@code startingSeqNo}(inclusive) in its translog
+     * Checks if this engine has every operations since  {@code startingSeqNo}(inclusive) in its history (either Lucene or translog)
      */
     public abstract boolean hasCompleteOperationHistory(String source, MapperService mapperService, long startingSeqNo) throws IOException;
 
diff --git a/server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java b/server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
index 7bf6f5ce3f18..e15e3dedf9ae 100644
--- a/server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
+++ b/server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
@@ -497,11 +497,16 @@ public void syncTranslog() throws IOException {
     }
 
     /**
-     * Creates a new history snapshot for reading operations since the provided seqno from the translog.
+     * Creates a new history snapshot for reading operations since the provided seqno.
+     * The returned snapshot can be retrieved from either Lucene index or translog files.
      */
     @Override
     public Translog.Snapshot readHistoryOperations(String source, MapperService mapperService, long startingSeqNo) throws IOException {
-        return getTranslog().newSnapshotFromMinSeqNo(startingSeqNo);
+        if (engineConfig.getIndexSettings().isSoftDeleteEnabled()) {
+            return newChangesSnapshot(source, mapperService, Math.max(0, startingSeqNo), Long.MAX_VALUE, false);
+        } else {
+            return getTranslog().newSnapshotFromMinSeqNo(startingSeqNo);
+        }
     }
 
     /**
@@ -547,6 +552,11 @@ public long getWritingBytes() {
         return indexWriter.getFlushingBytes() + versionMap.getRefreshingBytes();
     }
 
+    @Override
+    public long getLocalCheckpointOfSafeCommit() {
+        return softDeletesPolicy.getLocalCheckpointOfSafeCommit();
+    }
+
     /**
      * Reads the current stored translog ID from the last commit data.
      */
@@ -2555,17 +2565,21 @@ long getNumDocUpdates() {
 
     @Override
     public boolean hasCompleteOperationHistory(String source, MapperService mapperService, long startingSeqNo) throws IOException {
-        final long currentLocalCheckpoint = getLocalCheckpointTracker().getCheckpoint();
-        final LocalCheckpointTracker tracker = new LocalCheckpointTracker(startingSeqNo, startingSeqNo - 1);
-        try (Translog.Snapshot snapshot = getTranslog().newSnapshotFromMinSeqNo(startingSeqNo)) {
-            Translog.Operation operation;
-            while ((operation = snapshot.next()) != null) {
-                if (operation.seqNo() != SequenceNumbers.UNASSIGNED_SEQ_NO) {
-                    tracker.markSeqNoAsCompleted(operation.seqNo());
+        if (engineConfig.getIndexSettings().isSoftDeleteEnabled()) {
+            return getMinRetainedSeqNo() <= startingSeqNo;
+        } else {
+            final long currentLocalCheckpoint = getLocalCheckpointTracker().getCheckpoint();
+            final LocalCheckpointTracker tracker = new LocalCheckpointTracker(startingSeqNo, startingSeqNo - 1);
+            try (Translog.Snapshot snapshot = getTranslog().newSnapshotFromMinSeqNo(startingSeqNo)) {
+                Translog.Operation operation;
+                while ((operation = snapshot.next()) != null) {
+                    if (operation.seqNo() != SequenceNumbers.UNASSIGNED_SEQ_NO) {
+                        tracker.markSeqNoAsCompleted(operation.seqNo());
+                    }
                 }
             }
+            return tracker.getCheckpoint() >= currentLocalCheckpoint;
         }
-        return tracker.getCheckpoint() >= currentLocalCheckpoint;
     }
 
     /**
@@ -2580,15 +2594,7 @@ public final long getMinRetainedSeqNo() {
     @Override
     public Closeable acquireRetentionLock() {
         if (softDeleteEnabled) {
-            final Releasable softDeletesRetentionLock = softDeletesPolicy.acquireRetentionLock();
-            final Closeable translogRetentionLock;
-            try {
-                translogRetentionLock = translog.acquireRetentionLock();
-            } catch (Exception e) {
-                softDeletesRetentionLock.close();
-                throw e;
-            }
-            return () -> IOUtils.close(translogRetentionLock, softDeletesRetentionLock);
+            return softDeletesPolicy.acquireRetentionLock();
         } else {
             return translog.acquireRetentionLock();
         }
diff --git a/server/src/main/java/org/elasticsearch/index/engine/ReadOnlyEngine.java b/server/src/main/java/org/elasticsearch/index/engine/ReadOnlyEngine.java
index 14336e66ca4f..f9fd0ef8e21f 100644
--- a/server/src/main/java/org/elasticsearch/index/engine/ReadOnlyEngine.java
+++ b/server/src/main/java/org/elasticsearch/index/engine/ReadOnlyEngine.java
@@ -449,6 +449,11 @@ public DocsStats docStats() {
         return docsStats;
     }
 
+    @Override
+    public long getLocalCheckpointOfSafeCommit() {
+        return seqNoStats.getMaxSeqNo();
+    }
+
     @Override
     public void updateMaxUnsafeAutoIdTimestamp(long newTimestamp) {
 
diff --git a/server/src/main/java/org/elasticsearch/index/engine/SoftDeletesPolicy.java b/server/src/main/java/org/elasticsearch/index/engine/SoftDeletesPolicy.java
index 4c9ee0be92f4..8529eb9a8b2f 100644
--- a/server/src/main/java/org/elasticsearch/index/engine/SoftDeletesPolicy.java
+++ b/server/src/main/java/org/elasticsearch/index/engine/SoftDeletesPolicy.java
@@ -38,7 +38,7 @@
  */
 final class SoftDeletesPolicy {
     private final LongSupplier globalCheckpointSupplier;
-    private long localCheckpointOfSafeCommit;
+    private volatile long localCheckpointOfSafeCommit;
     // This lock count is used to prevent `minRetainedSeqNo` from advancing.
     private int retentionLockCount;
     // The extra number of operations before the global checkpoint are retained
@@ -80,6 +80,10 @@ synchronized void setLocalCheckpointOfSafeCommit(long newCheckpoint) {
         this.localCheckpointOfSafeCommit = newCheckpoint;
     }
 
+    long getLocalCheckpointOfSafeCommit() {
+        return localCheckpointOfSafeCommit;
+    }
+
     /**
      * Acquires a lock on soft-deleted documents to prevent them from cleaning up in merge processes. This is necessary to
      * make sure that all operations that are being retained will be retained until the lock is released.
diff --git a/server/src/main/java/org/elasticsearch/index/seqno/GlobalCheckpointSyncAction.java b/server/src/main/java/org/elasticsearch/index/seqno/GlobalCheckpointSyncAction.java
index 9b55cff8cff9..070924de1458 100644
--- a/server/src/main/java/org/elasticsearch/index/seqno/GlobalCheckpointSyncAction.java
+++ b/server/src/main/java/org/elasticsearch/index/seqno/GlobalCheckpointSyncAction.java
@@ -112,7 +112,7 @@ protected void sendReplicaRequest(
             super.sendReplicaRequest(replicaRequest, node, listener);
         } else {
             final long pre60NodeCheckpoint = SequenceNumbers.PRE_60_NODE_CHECKPOINT;
-            listener.onResponse(new ReplicaResponse(pre60NodeCheckpoint, pre60NodeCheckpoint));
+            listener.onResponse(new ReplicaResponse(pre60NodeCheckpoint, pre60NodeCheckpoint, SequenceNumbers.UNASSIGNED_SEQ_NO));
         }
     }
 
diff --git a/server/src/main/java/org/elasticsearch/index/seqno/PeerRecoveryRetentionLeaseRenewalAction.java b/server/src/main/java/org/elasticsearch/index/seqno/PeerRecoveryRetentionLeaseRenewalAction.java
new file mode 100644
index 000000000000..69025f591dc5
--- /dev/null
+++ b/server/src/main/java/org/elasticsearch/index/seqno/PeerRecoveryRetentionLeaseRenewalAction.java
@@ -0,0 +1,96 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.elasticsearch.index.seqno;
+
+import org.elasticsearch.action.ActionListener;
+import org.elasticsearch.action.support.ActionFilters;
+import org.elasticsearch.action.support.replication.ReplicationRequest;
+import org.elasticsearch.action.support.replication.ReplicationResponse;
+import org.elasticsearch.action.support.replication.TransportReplicationAction;
+import org.elasticsearch.cluster.action.shard.ShardStateAction;
+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;
+import org.elasticsearch.cluster.service.ClusterService;
+import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.index.seqno.PeerRecoveryRetentionLeaseRenewalAction.Request;
+import org.elasticsearch.index.shard.IndexShard;
+import org.elasticsearch.index.shard.ShardId;
+import org.elasticsearch.indices.IndicesService;
+import org.elasticsearch.threadpool.ThreadPool;
+import org.elasticsearch.threadpool.ThreadPool.Names;
+import org.elasticsearch.transport.TransportService;
+
+/**
+ * Background action to renew retention leases held to ensure that enough history is retained to perform a peer recovery if needed. This
+ * action renews the leases for each copy of the shard, advancing the corresponding sequence number, and thereby releases any operations
+ * that are now contained in a safe commit on every copy since they are no longer needed.
+ */
+public class PeerRecoveryRetentionLeaseRenewalAction extends TransportReplicationAction<Request, Request, ReplicationResponse> {
+
+    public static final String ACTION_NAME = "indices:admin/seq_no/peer_recovery_retention_lease_renewal";
+
+    @Inject
+    public PeerRecoveryRetentionLeaseRenewalAction(
+        final Settings settings,
+        final TransportService transportService,
+        final ClusterService clusterService,
+        final IndicesService indicesService,
+        final ThreadPool threadPool,
+        final ShardStateAction shardStateAction,
+        final ActionFilters actionFilters,
+        final IndexNameExpressionResolver indexNameExpressionResolver) {
+
+        super(settings, ACTION_NAME, transportService, clusterService, indicesService, threadPool, shardStateAction, actionFilters,
+            indexNameExpressionResolver, Request::new, Request::new, Names.MANAGEMENT);
+    }
+
+    @Override
+    protected ReplicationResponse newResponseInstance() {
+        return new ReplicationResponse();
+    }
+
+    @Override
+    protected PrimaryResult<Request, ReplicationResponse> shardOperationOnPrimary(Request shardRequest, IndexShard primary) {
+        primary.renewPeerRecoveryRetentionLeaseForPrimary();
+        return new PrimaryResult<>(shardRequest, new ReplicationResponse());
+    }
+
+    @Override
+    protected ReplicaResult shardOperationOnReplica(Request shardRequest, IndexShard replica) {
+        return new ReplicaResult();
+    }
+
+    public void renewPeerRecoveryRetentionLease(ShardId shardId, ActionListener<Void> listener) {
+        execute(new Request(shardId), ActionListener.wrap(v -> listener.onResponse(null), listener::onFailure));
+    }
+
+    static final class Request extends ReplicationRequest<Request> {
+        Request() {
+        }
+
+        Request(ShardId shardId) {
+            super(shardId);
+        }
+
+        @Override
+        public String toString() {
+            return "request for update of local checkpoint of safe commit for " + shardId;
+        }
+    }
+}
diff --git a/server/src/main/java/org/elasticsearch/index/seqno/ReplicationTracker.java b/server/src/main/java/org/elasticsearch/index/seqno/ReplicationTracker.java
index 61beddb776c9..5757635e297b 100644
--- a/server/src/main/java/org/elasticsearch/index/seqno/ReplicationTracker.java
+++ b/server/src/main/java/org/elasticsearch/index/seqno/ReplicationTracker.java
@@ -43,7 +43,6 @@
 import java.io.IOException;
 import java.nio.file.Path;
 import java.util.Collection;
-import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
@@ -60,6 +59,10 @@
 import java.util.stream.LongStream;
 import java.util.stream.Stream;
 
+import static java.lang.Math.max;
+import static java.util.Collections.singletonList;
+import static org.elasticsearch.action.ActionListener.wrap;
+
 /**
  * This class is responsible for tracking the replication group with its progress and safety markers (local and global checkpoints).
  *
@@ -180,6 +183,11 @@
      */
     private RetentionLeases retentionLeases = RetentionLeases.EMPTY;
 
+    /**
+     * The version in which this index was created
+     */
+    private final Version indexCreatedVersion;
+
     /**
      * Get all retention leases tracked on this shard.
      *
@@ -189,6 +197,16 @@ public RetentionLeases getRetentionLeases() {
         return getRetentionLeases(false).v2();
     }
 
+    public static final String PEER_RECOVERY_RETENTION_LEASE_SOURCE = "peer recovery";
+
+    static String getPeerRecoveryRetentionLeaseId(String nodeId) {
+        return "peer_recovery/" + nodeId;
+    }
+
+    public static String getPeerRecoveryRetentionLeaseId(ShardRouting shardRouting) {
+        return getPeerRecoveryRetentionLeaseId(shardRouting.currentNodeId());
+    }
+
     /**
      * If the expire leases parameter is false, gets all retention leases tracked on this shard and otherwise first calculates
      * expiration of existing retention leases, and then gets all non-expired retention leases tracked on this shard. Note that only the
@@ -205,18 +223,28 @@ public RetentionLeases getRetentionLeases() {
         // the primary calculates the non-expired retention leases and syncs them to replicas
         final long currentTimeMillis = currentTimeMillisSupplier.getAsLong();
         final long retentionLeaseMillis = indexSettings.getRetentionLeaseMillis();
+        final Set<String> leaseIdsForCurrentPeers
+            = routingTable.assignedShards().stream().map(ReplicationTracker::getPeerRecoveryRetentionLeaseId).collect(Collectors.toSet());
         final Map<Boolean, List<RetentionLease>> partitionByExpiration = retentionLeases
                 .leases()
                 .stream()
-                .collect(Collectors.groupingBy(lease -> currentTimeMillis - lease.timestamp() > retentionLeaseMillis));
-        if (partitionByExpiration.get(true) == null) {
-            // early out as no retention leases have expired
-            return Tuple.tuple(false, retentionLeases);
-        }
-        final Collection<RetentionLease> nonExpiredLeases =
-                partitionByExpiration.get(false) != null ? partitionByExpiration.get(false) : Collections.emptyList();
-        retentionLeases = new RetentionLeases(operationPrimaryTerm, retentionLeases.version() + 1, nonExpiredLeases);
-        return Tuple.tuple(true, retentionLeases);
+                .collect(Collectors.groupingBy(lease -> {
+                    if (lease.source().equals(PEER_RECOVERY_RETENTION_LEASE_SOURCE)) {
+                        if (leaseIdsForCurrentPeers.contains(lease.id())) {
+                            return false;
+                        }
+                        if (routingTable.allShardsStarted()) {
+                            return true;
+                        }
+                    }
+                    return currentTimeMillis - lease.timestamp() > retentionLeaseMillis;
+                }));
+        final Collection<RetentionLease> nonExpiredLeases = partitionByExpiration.get(false);
+        retentionLeases = new RetentionLeases(operationPrimaryTerm, retentionLeases.version() + 1, nonExpiredLeases.stream()
+                .map(lease -> leaseIdsForCurrentPeers.contains(lease.id()) ?
+                    new RetentionLease(lease.id(), lease.retainingSequenceNumber(), currentTimeMillis, lease.source()) : lease)
+                .collect(Collectors.toList()));
+        return Tuple.tuple(partitionByExpiration.containsKey(true), retentionLeases);
     }
 
     /**
@@ -238,21 +266,38 @@ public RetentionLease addRetentionLease(
         final RetentionLease retentionLease;
         final RetentionLeases currentRetentionLeases;
         synchronized (this) {
-            assert primaryMode;
-            if (retentionLeases.contains(id)) {
-                throw new RetentionLeaseAlreadyExistsException(id);
-            }
-            retentionLease = new RetentionLease(id, retainingSequenceNumber, currentTimeMillisSupplier.getAsLong(), source);
-            retentionLeases = new RetentionLeases(
-                    operationPrimaryTerm,
-                    retentionLeases.version() + 1,
-                    Stream.concat(retentionLeases.leases().stream(), Stream.of(retentionLease)).collect(Collectors.toList()));
-            currentRetentionLeases = retentionLeases;
+            retentionLease = innerAddRetentionLease(id, retainingSequenceNumber, source);
+            currentRetentionLeases = this.retentionLeases;
         }
         onSyncRetentionLeases.accept(currentRetentionLeases, listener);
         return retentionLease;
     }
 
+    /**
+     * Adds a new retention lease, but does not synchronise it with the rest of the replication group.
+     *
+     * @param id                      the identifier of the retention lease
+     * @param retainingSequenceNumber the retaining sequence number
+     * @param source                  the source of the retention lease
+     * @return the new retention lease
+     * @throws IllegalArgumentException if the specified retention lease already exists
+     */
+    private RetentionLease innerAddRetentionLease(String id, long retainingSequenceNumber, String source) {
+        assert Thread.holdsLock(this);
+        assert primaryMode : id + "/" + retainingSequenceNumber + "/" + source;
+        if (retentionLeases.contains(id)) {
+            throw new RetentionLeaseAlreadyExistsException(id);
+        }
+        // should we abort if we have already discarded operations >= retainingSequenceNumber?
+        final RetentionLease retentionLease
+            = new RetentionLease(id, retainingSequenceNumber, currentTimeMillisSupplier.getAsLong(), source);
+        retentionLeases = new RetentionLeases(
+            operationPrimaryTerm,
+            retentionLeases.version() + 1,
+            Stream.concat(retentionLeases.leases().stream(), Stream.of(retentionLease)).collect(Collectors.toList()));
+        return retentionLease;
+    }
+
     /**
      * Renews an existing retention lease.
      *
@@ -321,6 +366,42 @@ public synchronized void updateRetentionLeasesOnReplica(final RetentionLeases re
         }
     }
 
+    public synchronized void renewPeerRecoveryRetentionLease(ShardRouting shardRouting, long localCheckpointOfSafeCommit) {
+        assert primaryMode;
+        final String leaseId = getPeerRecoveryRetentionLeaseId(shardRouting);
+        final RetentionLease retentionLease = retentionLeases.get(leaseId);
+        if (retentionLease == null) {
+            assert routingTable.activeShards().contains(shardRouting) == false : "no retention lease found for current " + shardRouting;
+            logger.debug("attempted to renew peer recovery retention lease for unknown {}", shardRouting);
+        } else if (retentionLease.retainingSequenceNumber() < localCheckpointOfSafeCommit + 1) {
+            renewRetentionLease(leaseId, localCheckpointOfSafeCommit + 1, PEER_RECOVERY_RETENTION_LEASE_SOURCE);
+        }
+    }
+
+    public void addPeerRecoveryRetentionLease(String nodeId, long startingSeqNo, ActionListener<Void> listener) {
+        addRetentionLease(getPeerRecoveryRetentionLeaseId(nodeId), max(0L, startingSeqNo),
+            PEER_RECOVERY_RETENTION_LEASE_SOURCE, wrap(r -> listener.onResponse(null), listener::onFailure));
+    }
+
+    public synchronized boolean peerRetentionLeasesNeedRenewal(long localCheckpointOfSafeCommit) {
+        assert primaryMode;
+        final RetentionLeases retentionLeases = getRetentionLeases();
+        return routingTable.activeShards().stream().anyMatch(
+            shardRouting -> {
+                final RetentionLease retentionLease = retentionLeases.get(getPeerRecoveryRetentionLeaseId(shardRouting));
+                if (retentionLease == null) {
+                    /*
+                     * We got here via a rolling upgrade from an older version that doesn't create peer recovery retention leases for every
+                     * shard copy. These missing leases are created lazily if they're found to be missing during a
+                     * TransportReplicationAction, such as the peer recovery retention lease sync, so let's trigger a sync.
+                     */
+                    assert indexCreatedVersion.before(Version.V_8_0_0) : indexCreatedVersion; // TODO V_7_1_0 in backport
+                    return true;
+                }
+                return retentionLease.retainingSequenceNumber() < localCheckpointOfSafeCommit + 1;
+            });
+    }
+
     /**
      * Loads the latest retention leases from their dedicated state file.
      *
@@ -358,6 +439,57 @@ public void persistRetentionLeases(final Path path) throws WriteStateException {
         }
     }
 
+    public synchronized void updatePeerRecoveryRetentionLeasesFromCheckpointState() {
+        assert primaryMode;
+
+        for (final Map.Entry<String, CheckpointState> entry : checkpoints.entrySet()) {
+            final ShardRouting shardRouting = routingTable.getByAllocationId(entry.getKey());
+            final CheckpointState cps = entry.getValue();
+            if (cps.tracked) {
+                if (getRetentionLeases().contains(getPeerRecoveryRetentionLeaseId(shardRouting))) {
+                    renewRetentionLease(
+                        getPeerRecoveryRetentionLeaseId(shardRouting),
+                        cps.localCheckpointOfSafeCommit + 1,
+                        PEER_RECOVERY_RETENTION_LEASE_SOURCE);
+                } else {
+                    assert indexCreatedVersion.before(Version.V_8_0_0) : indexCreatedVersion; // TODO V_7_1_0 in backport
+                }
+            }
+        }
+    }
+
+    public void addMissingPeerRecoveryRetentionLease(String allocationId, long startingSeqNo) {
+        final RetentionLeases updatedLeases;
+        synchronized (this) {
+            final ShardRouting replicaShardRouting = routingTable.getByAllocationId(allocationId);
+            if (replicaShardRouting == null) {
+                return;
+            }
+
+            if (retentionLeases.get(ReplicationTracker.getPeerRecoveryRetentionLeaseId(replicaShardRouting)) != null) {
+                return;
+            }
+
+            /*
+             * We got here via a rolling upgrade from an older version that doesn't create peer recovery retention leases for every shard
+             * copy. But the replica we're dealing with now has been upgraded and is retaining history while we asynchronously make it a
+             * retention lease.
+             */
+            assert indexCreatedVersion.before(Version.V_8_0_0) : indexCreatedVersion; // TODO V_7_1_0 in backport
+            try {
+                innerAddRetentionLease(getPeerRecoveryRetentionLeaseId(replicaShardRouting.currentNodeId()), startingSeqNo,
+                    PEER_RECOVERY_RETENTION_LEASE_SOURCE);
+                updatedLeases = retentionLeases;
+            } catch (RetentionLeaseAlreadyExistsException e) {
+                assert false : e;
+                logger.debug("BWC peer recovery retention lease created concurrently", e);
+                return;
+            }
+        }
+        onSyncRetentionLeases.accept(updatedLeases, ActionListener.wrap(() -> {
+        }));
+    }
+
     public boolean assertRetentionLeasesPersisted(final Path path) throws IOException {
         assert RetentionLeases.FORMAT.loadLatestState(logger, NamedXContentRegistry.EMPTY, path) != null;
         return true;
@@ -375,6 +507,12 @@ public boolean assertRetentionLeasesPersisted(final Path path) throws IOExceptio
          * the tracker is in primary mode and received from the primary if in replica mode.
          */
         long globalCheckpoint;
+
+        /**
+         * The last local-checkpoint-of-safe-commit that we have for this shard
+         */
+        long localCheckpointOfSafeCommit;
+
         /**
          * whether this shard is treated as in-sync and thus contributes to the global checkpoint calculation
          */
@@ -385,9 +523,11 @@ public boolean assertRetentionLeasesPersisted(final Path path) throws IOExceptio
          */
         boolean tracked;
 
-        public CheckpointState(long localCheckpoint, long globalCheckpoint, boolean inSync, boolean tracked) {
+        public CheckpointState(long localCheckpoint, long globalCheckpoint, long localCheckpointOfSafeCommit,
+                               boolean inSync, boolean tracked) {
             this.localCheckpoint = localCheckpoint;
             this.globalCheckpoint = globalCheckpoint;
+            this.localCheckpointOfSafeCommit = localCheckpointOfSafeCommit;
             this.inSync = inSync;
             this.tracked = tracked;
         }
@@ -395,6 +535,11 @@ public CheckpointState(long localCheckpoint, long globalCheckpoint, boolean inSy
         public CheckpointState(StreamInput in) throws IOException {
             this.localCheckpoint = in.readZLong();
             this.globalCheckpoint = in.readZLong();
+            if (in.getVersion().onOrAfter(Version.V_8_0_0)) {
+                this.localCheckpointOfSafeCommit = in.readZLong();
+            } else {
+                this.localCheckpointOfSafeCommit = SequenceNumbers.UNASSIGNED_SEQ_NO;
+            }
             this.inSync = in.readBoolean();
             this.tracked = in.readBoolean();
         }
@@ -403,6 +548,9 @@ public CheckpointState(StreamInput in) throws IOException {
         public void writeTo(StreamOutput out) throws IOException {
             out.writeZLong(localCheckpoint);
             out.writeZLong(globalCheckpoint);
+            if (out.getVersion().onOrAfter(Version.V_8_0_0)) {
+                out.writeZLong(this.localCheckpointOfSafeCommit);
+            }
             out.writeBoolean(inSync);
             out.writeBoolean(tracked);
         }
@@ -411,7 +559,7 @@ public void writeTo(StreamOutput out) throws IOException {
          * Returns a full copy of this object
          */
         public CheckpointState copy() {
-            return new CheckpointState(localCheckpoint, globalCheckpoint, inSync, tracked);
+            return new CheckpointState(localCheckpoint, globalCheckpoint, localCheckpointOfSafeCommit, inSync, tracked);
         }
 
         public long getLocalCheckpoint() {
@@ -422,11 +570,16 @@ public long getGlobalCheckpoint() {
             return globalCheckpoint;
         }
 
+        public long getLocalCheckpointOfSafeCommit() {
+            return localCheckpointOfSafeCommit;
+        }
+
         @Override
         public String toString() {
             return "LocalCheckpointState{" +
                 "localCheckpoint=" + localCheckpoint +
                 ", globalCheckpoint=" + globalCheckpoint +
+                ", localCheckpointOfSafeCommit=" + localCheckpointOfSafeCommit +
                 ", inSync=" + inSync +
                 ", tracked=" + tracked +
                 '}';
@@ -441,6 +594,7 @@ public boolean equals(Object o) {
 
             if (localCheckpoint != that.localCheckpoint) return false;
             if (globalCheckpoint != that.globalCheckpoint) return false;
+            if (localCheckpointOfSafeCommit != that.localCheckpointOfSafeCommit) return false;
             if (inSync != that.inSync) return false;
             return tracked == that.tracked;
         }
@@ -449,6 +603,7 @@ public boolean equals(Object o) {
         public int hashCode() {
             int result = Long.hashCode(localCheckpoint);
             result = 31 * result + Long.hashCode(globalCheckpoint);
+            result = 31 * result + Long.hashCode(localCheckpointOfSafeCommit);
             result = 31 * result + Boolean.hashCode(inSync);
             result = 31 * result + Boolean.hashCode(tracked);
             return result;
@@ -593,6 +748,18 @@ private boolean invariant() {
             assert checkpoints.get(aId) != null : "aId [" + aId + "] is pending in sync but isn't tracked";
         }
 
+        if (primaryMode && indexCreatedVersion.onOrAfter(Version.V_8_0_0)) { // TODO V_7_1_0 after backporting
+            for (final ShardRouting shardRouting : routingTable.assignedShards()) {
+                assert checkpoints.get(shardRouting.allocationId().getId()).tracked == false
+                    || retentionLeases.contains(getPeerRecoveryRetentionLeaseId(shardRouting)) :
+                    "no retention lease for tracked shard " + shardRouting + " in " + retentionLeases;
+                assert shardRouting.relocating() == false
+                    || checkpoints.get(shardRouting.allocationId().getRelocationId()).tracked == false
+                    || retentionLeases.contains(getPeerRecoveryRetentionLeaseId(shardRouting.getTargetRelocatingShard())) :
+                    "no retention lease for relocation target " + shardRouting + " in " + retentionLeases;
+            }
+        }
+
         return true;
     }
 
@@ -630,7 +797,8 @@ public ReplicationTracker(
             final long globalCheckpoint,
             final LongConsumer onGlobalCheckpointUpdated,
             final LongSupplier currentTimeMillisSupplier,
-            final BiConsumer<RetentionLeases, ActionListener<ReplicationResponse>> onSyncRetentionLeases) {
+            final BiConsumer<RetentionLeases, ActionListener<ReplicationResponse>> onSyncRetentionLeases,
+            final Version indexCreatedVersion) {
         super(shardId, indexSettings);
         assert globalCheckpoint >= SequenceNumbers.UNASSIGNED_SEQ_NO : "illegal initial global checkpoint: " + globalCheckpoint;
         this.shardAllocationId = allocationId;
@@ -639,13 +807,16 @@ public ReplicationTracker(
         this.handoffInProgress = false;
         this.appliedClusterStateVersion = -1L;
         this.checkpoints = new HashMap<>(1 + indexSettings.getNumberOfReplicas());
-        checkpoints.put(allocationId, new CheckpointState(SequenceNumbers.UNASSIGNED_SEQ_NO, globalCheckpoint, false, false));
+        checkpoints.put(allocationId,
+            new CheckpointState(SequenceNumbers.UNASSIGNED_SEQ_NO, globalCheckpoint, SequenceNumbers.UNASSIGNED_SEQ_NO, false, false));
         this.onGlobalCheckpointUpdated = Objects.requireNonNull(onGlobalCheckpointUpdated);
         this.currentTimeMillisSupplier = Objects.requireNonNull(currentTimeMillisSupplier);
         this.onSyncRetentionLeases = Objects.requireNonNull(onSyncRetentionLeases);
         this.pendingInSync = new HashSet<>();
         this.routingTable = null;
         this.replicationGroup = null;
+        assert Version.V_EMPTY.equals(indexCreatedVersion) == false;
+        this.indexCreatedVersion = indexCreatedVersion;
         assert invariant();
     }
 
@@ -736,19 +907,60 @@ private void updateGlobalCheckpoint(final String allocationId, final long global
         }
     }
 
+    public synchronized void updateLocalCheckpointOfSafeCommitForShard(String allocationId, long localCheckpointOfSafeCommit) {
+        assert primaryMode;
+        assert handoffInProgress == false;
+        assert invariant();
+
+        final CheckpointState cps = checkpoints.get(allocationId);
+        assert !this.shardAllocationId.equals(allocationId) || cps != null;
+        if (cps != null && localCheckpointOfSafeCommit > cps.localCheckpointOfSafeCommit) {
+            long previousValue = cps.localCheckpointOfSafeCommit;
+            cps.localCheckpointOfSafeCommit = localCheckpointOfSafeCommit;
+            logger.trace(
+                "updated local knowledge for [{}] on the primary of the local checkpoint of the safe commit from [{}] to [{}]",
+                allocationId,
+                previousValue,
+                localCheckpointOfSafeCommit);
+        }
+        assert invariant();
+    }
+
     /**
      * Initializes the global checkpoint tracker in primary mode (see {@link #primaryMode}. Called on primary activation or promotion.
      */
-    public synchronized void activatePrimaryMode(final long localCheckpoint) {
+    public synchronized void activatePrimaryMode(final long localCheckpoint, final long localCheckpointOfSafeCommit) {
         assert invariant();
         assert primaryMode == false;
         assert checkpoints.get(shardAllocationId) != null && checkpoints.get(shardAllocationId).inSync &&
             checkpoints.get(shardAllocationId).localCheckpoint == SequenceNumbers.UNASSIGNED_SEQ_NO :
             "expected " + shardAllocationId + " to have initialized entry in " + checkpoints + " when activating primary";
-        assert localCheckpoint >= SequenceNumbers.NO_OPS_PERFORMED;
+        assert localCheckpointOfSafeCommit >= SequenceNumbers.NO_OPS_PERFORMED : localCheckpointOfSafeCommit;
+        assert localCheckpoint >= localCheckpointOfSafeCommit : localCheckpoint + " < " + localCheckpointOfSafeCommit;
         primaryMode = true;
         updateLocalCheckpoint(shardAllocationId, checkpoints.get(shardAllocationId), localCheckpoint);
         updateGlobalCheckpointOnPrimary();
+
+        final ShardRouting primaryShard = routingTable.primaryShard();
+        final String leaseId = getPeerRecoveryRetentionLeaseId(primaryShard);
+        if (retentionLeases.get(leaseId) == null) {
+            /*
+             * We might have got here here via a rolling upgrade from an older version that doesn't create peer recovery retention leases
+             * for every shard copy. The missing leases are created in a more relaxed fashion, and offer weaker guarantees.
+             */
+            if (indexCreatedVersion.onOrAfter(Version.V_8_0_0)) { // TODO V_7_1_0 in backport
+                // We are starting up the whole replication group from scratch: if we were not (i.e. this is a replica promotion) then
+                // this copy must already be in-sync and active and therefore holds a retention lease for itself.
+                assert routingTable.activeShards().equals(singletonList(primaryShard)) : routingTable.activeShards();
+                assert primaryShard.allocationId().getId().equals(shardAllocationId)
+                    : routingTable.activeShards() + " vs " + shardAllocationId;
+                assert replicationGroup.getReplicationTargets().equals(singletonList(primaryShard));
+
+                // Safe to call innerAddRetentionLease() without a subsequent sync since there are no other members of this replication gp.
+                innerAddRetentionLease(leaseId, max(0L, localCheckpointOfSafeCommit + 1), PEER_RECOVERY_RETENTION_LEASE_SOURCE);
+            }
+        }
+
         assert invariant();
     }
 
@@ -785,7 +997,8 @@ public synchronized void updateFromMaster(final long applyingClusterStateVersion
                         final long localCheckpoint = pre60AllocationIds.contains(initializingId) ?
                             SequenceNumbers.PRE_60_NODE_CHECKPOINT : SequenceNumbers.UNASSIGNED_SEQ_NO;
                         final long globalCheckpoint = localCheckpoint;
-                        checkpoints.put(initializingId, new CheckpointState(localCheckpoint, globalCheckpoint, inSync, inSync));
+                        checkpoints.put(initializingId,
+                            new CheckpointState(localCheckpoint, globalCheckpoint, SequenceNumbers.UNASSIGNED_SEQ_NO, inSync, inSync));
                     }
                 }
                 if (removedEntries) {
@@ -797,7 +1010,8 @@ public synchronized void updateFromMaster(final long applyingClusterStateVersion
                         final long localCheckpoint = pre60AllocationIds.contains(initializingId) ?
                             SequenceNumbers.PRE_60_NODE_CHECKPOINT : SequenceNumbers.UNASSIGNED_SEQ_NO;
                         final long globalCheckpoint = localCheckpoint;
-                        checkpoints.put(initializingId, new CheckpointState(localCheckpoint, globalCheckpoint, false, false));
+                        checkpoints.put(initializingId,
+                            new CheckpointState(localCheckpoint, globalCheckpoint, SequenceNumbers.UNASSIGNED_SEQ_NO, false, false));
                     }
                 }
                 for (String inSyncId : inSyncAllocationIds) {
@@ -810,7 +1024,8 @@ public synchronized void updateFromMaster(final long applyingClusterStateVersion
                         final long localCheckpoint = pre60AllocationIds.contains(inSyncId) ?
                             SequenceNumbers.PRE_60_NODE_CHECKPOINT : SequenceNumbers.UNASSIGNED_SEQ_NO;
                         final long globalCheckpoint = localCheckpoint;
-                        checkpoints.put(inSyncId, new CheckpointState(localCheckpoint, globalCheckpoint, true, true));
+                        checkpoints.put(inSyncId,
+                            new CheckpointState(localCheckpoint, globalCheckpoint, SequenceNumbers.UNASSIGNED_SEQ_NO, true, true));
                     }
                 }
             }
diff --git a/server/src/main/java/org/elasticsearch/index/seqno/RetentionLease.java b/server/src/main/java/org/elasticsearch/index/seqno/RetentionLease.java
index e6d6ed3fe825..035f2a8b97af 100644
--- a/server/src/main/java/org/elasticsearch/index/seqno/RetentionLease.java
+++ b/server/src/main/java/org/elasticsearch/index/seqno/RetentionLease.java
@@ -211,4 +211,7 @@ public String toString() {
                 '}';
     }
 
+    public boolean isNotPeerRecoveryRetentionLease() {
+        return ReplicationTracker.PEER_RECOVERY_RETENTION_LEASE_SOURCE.equals(source) == false;
+    }
 }
diff --git a/server/src/main/java/org/elasticsearch/index/seqno/RetentionLeaseSyncAction.java b/server/src/main/java/org/elasticsearch/index/seqno/RetentionLeaseSyncAction.java
index d4845d92a3a6..5fb8569dd605 100644
--- a/server/src/main/java/org/elasticsearch/index/seqno/RetentionLeaseSyncAction.java
+++ b/server/src/main/java/org/elasticsearch/index/seqno/RetentionLeaseSyncAction.java
@@ -122,6 +122,16 @@ public void sync(
         }
     }
 
+    @Override
+    protected boolean resolveIndex() {
+        return false;
+    }
+
+    @Override
+    protected boolean isReplicatedOnClosedIndices() {
+        return true;
+    }
+
     @Override
     protected WritePrimaryResult<Request, Response> shardOperationOnPrimary(
             final Request request,
diff --git a/server/src/main/java/org/elasticsearch/index/seqno/RetentionLeaseSyncer.java b/server/src/main/java/org/elasticsearch/index/seqno/RetentionLeaseSyncer.java
index 927d2ec49996..7de6bad3f110 100644
--- a/server/src/main/java/org/elasticsearch/index/seqno/RetentionLeaseSyncer.java
+++ b/server/src/main/java/org/elasticsearch/index/seqno/RetentionLeaseSyncer.java
@@ -44,7 +44,7 @@
     RetentionLeaseSyncer EMPTY = new RetentionLeaseSyncer() {
         @Override
         public void sync(final ShardId shardId, final RetentionLeases retentionLeases, final ActionListener<ReplicationResponse> listener) {
-
+            listener.onResponse(new ReplicationResponse());
         }
 
         @Override
diff --git a/server/src/main/java/org/elasticsearch/index/seqno/RetentionLeases.java b/server/src/main/java/org/elasticsearch/index/seqno/RetentionLeases.java
index 3bad88728250..b13419d34601 100644
--- a/server/src/main/java/org/elasticsearch/index/seqno/RetentionLeases.java
+++ b/server/src/main/java/org/elasticsearch/index/seqno/RetentionLeases.java
@@ -38,6 +38,8 @@
 import java.util.function.Function;
 import java.util.stream.Collectors;
 
+import static org.elasticsearch.index.seqno.ReplicationTracker.PEER_RECOVERY_RETENTION_LEASE_SOURCE;
+
 /**
  * Represents a versioned collection of retention leases. We version the collection of retention leases to ensure that sync requests that
  * arrive out of order on the replica, using the version to ensure that older sync requests are rejected.
@@ -260,13 +262,18 @@ public String toString() {
     }
 
     /**
-     * A utility method to convert a retention lease collection to a map from retention lease ID to retention lease.
+     * A utility method to convert a retention lease collection to a map from retention lease ID to retention lease and exclude
+     * the automatically-added peer-recovery retention leases
      *
      * @param retentionLeases the retention lease collection
      * @return the map from retention lease ID to retention lease
      */
-    static Map<String, RetentionLease> toMap(final RetentionLeases retentionLeases) {
-        return retentionLeases.leases;
+    static Map<String, RetentionLease> toMapExcludingPeerRecoveryRetentionLeases(final RetentionLeases retentionLeases) {
+        return retentionLeases.leases.values().stream().filter(l -> PEER_RECOVERY_RETENTION_LEASE_SOURCE.equals(l.source()) == false)
+            .collect(Collectors.toMap(RetentionLease::id, Function.identity(),
+                (o1, o2) -> {
+                    throw new AssertionError("unexpectedly merging " + o1 + " and " + o2);
+                },
+                LinkedHashMap::new));
     }
-
 }
diff --git a/server/src/main/java/org/elasticsearch/index/shard/IndexShard.java b/server/src/main/java/org/elasticsearch/index/shard/IndexShard.java
index 99dab5a0f391..10d9f562759d 100644
--- a/server/src/main/java/org/elasticsearch/index/shard/IndexShard.java
+++ b/server/src/main/java/org/elasticsearch/index/shard/IndexShard.java
@@ -41,6 +41,7 @@
 import org.elasticsearch.action.admin.indices.flush.FlushRequest;
 import org.elasticsearch.action.admin.indices.forcemerge.ForceMergeRequest;
 import org.elasticsearch.action.admin.indices.upgrade.post.UpgradeRequest;
+import org.elasticsearch.action.support.PlainActionFuture;
 import org.elasticsearch.action.support.replication.ReplicationResponse;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MappingMetaData;
@@ -140,6 +141,7 @@
 import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.search.suggest.completion.CompletionStats;
 import org.elasticsearch.threadpool.ThreadPool;
+import org.elasticsearch.threadpool.ThreadPool.Names;
 
 import java.io.Closeable;
 import java.io.IOException;
@@ -157,6 +159,7 @@
 import java.util.Set;
 import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
 import java.util.concurrent.atomic.AtomicBoolean;
@@ -217,6 +220,8 @@ Runnable getGlobalCheckpointSyncer() {
 
     private final RetentionLeaseSyncer retentionLeaseSyncer;
 
+    private final Consumer<ActionListener<Void>> peerRecoveryRetentionLeaseRenewer;
+
     @Nullable
     private RecoveryState recoveryState;
 
@@ -275,7 +280,8 @@ public IndexShard(
             final List<IndexingOperationListener> listeners,
             final Runnable globalCheckpointSyncer,
             final RetentionLeaseSyncer retentionLeaseSyncer,
-            final CircuitBreakerService circuitBreakerService) throws IOException {
+            final CircuitBreakerService circuitBreakerService,
+            final Consumer<ActionListener<Void>> peerRecoveryRetentionLeaseRenewer) throws IOException {
         super(shardRouting.shardId(), indexSettings);
         assert shardRouting.initializing();
         this.shardRouting = shardRouting;
@@ -327,8 +333,10 @@ public IndexShard(
                         UNASSIGNED_SEQ_NO,
                         globalCheckpointListeners::globalCheckpointUpdated,
                         threadPool::absoluteTimeInMillis,
-                        (retentionLeases, listener) -> retentionLeaseSyncer.sync(shardId, retentionLeases, listener));
+                        (retentionLeases, listener) -> retentionLeaseSyncer.sync(shardId, retentionLeases, listener),
+                        IndexMetaData.SETTING_INDEX_VERSION_CREATED.get(indexSettings.getSettings()));
         this.replicationTracker = replicationTracker;
+        this.peerRecoveryRetentionLeaseRenewer = peerRecoveryRetentionLeaseRenewer;
 
         // the query cache is a node-level thing, however we want the most popular filters
         // to be computed on a per-shard basis
@@ -478,7 +486,8 @@ public void updateShardState(final ShardRouting newRouting,
                 if (newPrimaryTerm == pendingPrimaryTerm) {
                     if (currentRouting.initializing() && currentRouting.isRelocationTarget() == false && newRouting.active()) {
                         // the master started a recovering primary, activate primary mode.
-                        replicationTracker.activatePrimaryMode(getLocalCheckpoint());
+                        replicationTracker.activatePrimaryMode(getLocalCheckpoint(), getLocalCheckpointOfSafeCommit());
+                        asyncEnsurePeerRecoveryRetentionLeaseForPrimary();
                     }
                 } else {
                     assert currentRouting.primary() == false : "term is only increased as part of primary promotion";
@@ -520,7 +529,8 @@ public void updateShardState(final ShardRouting newRouting,
                                 ", current routing: " + currentRouting + ", new routing: " + newRouting;
                             assert getOperationPrimaryTerm() == newPrimaryTerm;
                             try {
-                                replicationTracker.activatePrimaryMode(getLocalCheckpoint());
+                                replicationTracker.activatePrimaryMode(getLocalCheckpoint(), getLocalCheckpointOfSafeCommit());
+                                asyncEnsurePeerRecoveryRetentionLeaseForPrimary();
                                 /*
                                  * If this shard was serving as a replica shard when another shard was promoted to primary then
                                  * its Lucene index was reset during the primary term transition. In particular, the Lucene index
@@ -592,6 +602,28 @@ public void onFailure(Exception e) {
         }
     }
 
+    private void asyncEnsurePeerRecoveryRetentionLeaseForPrimary() {
+        if (replicationTracker.getRetentionLeases()
+            .get(ReplicationTracker.getPeerRecoveryRetentionLeaseId(routingEntry())) == null) {
+            /*
+             * We got here via a rolling upgrade from an older version that doesn't create peer recovery retention leases for every shard
+             * copy, so there isn't yet one for this primary. We offer relaxed guarantees in this case, so create one asynchronously once
+             * the shard is fully started.
+             */
+            assertIndexCreatedBeforePeerRecoveryRetentionLeases();
+            threadPool.generic().execute(() -> {
+                synchronized (mutex) {
+                    // wait for the shard to be started
+                }
+                runUnderPrimaryPermit(
+                    () -> replicationTracker.addPeerRecoveryRetentionLease(shardRouting.currentNodeId(),
+                        getLocalCheckpointOfSafeCommit(), ActionListener.wrap(() -> { })),
+                    e -> logger.debug("failed to lazily create peer recovery retention lease for primary", e),
+                    Names.SAME, "");
+            });
+        }
+    }
+
     /**
      * Marks the shard as recovering based on a recovery state, fails with exception is recovering is not allowed to be set.
      */
@@ -1883,6 +1915,31 @@ public void updateGlobalCheckpointForShard(final String allocationId, final long
         replicationTracker.updateGlobalCheckpointForShard(allocationId, globalCheckpoint);
     }
 
+    /**
+     * Update the local knowledge of the local checkpoint of the safe commit for the specified allocation ID.
+     *
+     * @param allocationId                the allocation ID to update the local checkpoint of the safe commit for
+     * @param localCheckpointOfSafeCommit the local checkpoint of the safe commit
+     */
+    public void updateLocalCheckpointOfSafeCommitForShard(final String allocationId, final long localCheckpointOfSafeCommit) {
+        assert assertPrimaryMode();
+        verifyNotClosed();
+        replicationTracker.updateLocalCheckpointOfSafeCommitForShard(allocationId, localCheckpointOfSafeCommit);
+
+        if (indexCreatedBeforePeerRecoveryRetentionLeases()) {
+            /*
+             * We might have got here via a rolling upgrade from an older version that doesn't create peer recovery retention leases for
+             * every shard copy. We create them lazily in this case and offer relaxed guarantees about history retention.  If the lease does
+             * not currently exist, create one using the given LCPoSC as a starting point for retention. This might be too low (other shards
+             * are no longer retaining this history) or too high (the replica in question already discarded too much history to satisfy the
+             * other leases) but this will eventually be resolved.
+             */
+            replicationTracker.addMissingPeerRecoveryRetentionLease(allocationId, localCheckpointOfSafeCommit + 1);
+        } else {
+            assert localCheckpointOfSafeCommit != UNASSIGNED_SEQ_NO;
+        }
+    }
+
     /**
      * Add a global checkpoint listener. If the global checkpoint is equal to or above the global checkpoint the listener is waiting for,
      * then the listener will be notified immediately via an executor (so possibly not on the current thread). If the specified timeout
@@ -1918,10 +1975,10 @@ public RetentionLeases getRetentionLeases() {
     }
 
     /**
-     * If the expire leases parameter is false, gets all retention leases tracked on this shard and otherwise first calculates
-     * expiration of existing retention leases, and then gets all non-expired retention leases tracked on this shard. Note that only the
-     * primary shard calculates which leases are expired, and if any have expired, syncs the retention leases to any replicas. If the
-     * expire leases parameter is true, this replication tracker must be in primary mode.
+     * If the expire leases parameter is false, gets all retention leases tracked on this shard and otherwise first calculates expiration of
+     * existing retention leases, renews all peer-recovery retention leases for active shard copies, and then gets all non-expired retention
+     * leases tracked on this shard. Note that only the primary shard calculates which leases are expired, and if any have expired, syncs
+     * the retention leases to any replicas. If the expire leases parameter is true, this replication tracker must be in primary mode.
      *
      * @return a tuple indicating whether or not any retention leases were expired, and the non-expired retention leases
      */
@@ -2061,6 +2118,28 @@ public void syncRetentionLeases() {
         }
     }
 
+    public Future<Void> foregroundSyncRetentionLeases() {
+        // TODO merge this with syncRetentionLeases, allowing to wait until completion of a backgroundSync too.
+        assert assertPrimaryMode();
+        verifyNotClosed();
+        final Tuple<Boolean, RetentionLeases> retentionLeases = getRetentionLeases(true);
+        logger.trace("foreground syncing retention leases [{}] after expiration check", retentionLeases.v2());
+        final PlainActionFuture<Void> future = new PlainActionFuture<>();
+        retentionLeaseSyncer.sync(
+            shardId,
+            retentionLeases.v2(),
+            ActionListener.wrap(
+                r -> future.onResponse(null),
+                e -> {
+                    logger.warn(new ParameterizedMessage(
+                            "failed to sync retention leases [{}] after expiration check",
+                            retentionLeases),
+                        e);
+                    future.onFailure(e);
+                }));
+        return future;
+    }
+
     /**
      * Called when the recovery process for a shard has opened the engine on the target shard. Ensures that the right data structures
      * have been set up locally to track local checkpoint information for the shard and that the shard is added to the replication group.
@@ -2202,6 +2281,7 @@ public void activateWithPrimaryContext(final ReplicationTracker.PrimaryContext p
             getLocalCheckpoint() == primaryContext.getCheckpointStates().get(routingEntry().allocationId().getId()).getLocalCheckpoint();
         synchronized (mutex) {
             replicationTracker.activateWithPrimaryContext(primaryContext); // make changes to primaryMode flag only under mutex
+            asyncEnsurePeerRecoveryRetentionLeaseForPrimary();
             if (getMaxSeqNoOfUpdatesOrDeletes() == UNASSIGNED_SEQ_NO) {
                 // If the old primary was on an old version that did not replicate the msu,
                 // we need to bootstrap it manually from its local history.
@@ -2428,6 +2508,59 @@ public boolean isRelocatedPrimary() {
         return replicationTracker.isRelocated();
     }
 
+    public void addPeerRecoveryRetentionLease(String nodeId, long startingSeqNo, ActionListener<Void> listener) {
+        assert assertPrimaryMode();
+        replicationTracker.addPeerRecoveryRetentionLease(nodeId, startingSeqNo, listener);
+    }
+
+    public void renewPeerRecoveryRetentionLeaseForReplica(ShardRouting shardRouting, long localCheckpointOfSafeCommit) {
+        assert shardRouting.primary() == false : shardRouting;
+        runUnderPrimaryPermit(() -> replicationTracker.renewPeerRecoveryRetentionLease(shardRouting, localCheckpointOfSafeCommit),
+            e -> logger.debug(new ParameterizedMessage("exception renewing peer-recovery retention lease for {}", shardRouting), e),
+            Names.SAME, Tuple.tuple(shardRouting, localCheckpointOfSafeCommit));
+    }
+
+    public void renewPeerRecoveryRetentionLeaseForPrimary() {
+        assert assertPrimaryMode();
+        // already running under primary permit
+        assert indexShardOperationPermits.getActiveOperationsCount() != 0 : "no operation permit for " + routingEntry();
+        replicationTracker.renewPeerRecoveryRetentionLease(routingEntry(), getLocalCheckpointOfSafeCommit());
+    }
+
+    public Future<Void> renewPeerRecoveryRetentionLeases() {
+        assert assertPrimaryMode();
+        final PlainActionFuture<Void> plainActionFuture = new PlainActionFuture<>();
+        if (replicationTracker.peerRetentionLeasesNeedRenewal(getLocalCheckpointOfSafeCommit())) {
+            peerRecoveryRetentionLeaseRenewer.accept(ActionListener.wrap(v -> {
+                runUnderPrimaryPermit(replicationTracker::updatePeerRecoveryRetentionLeasesFromCheckpointState,
+                    e -> logger.debug("exception updating peer-recovery retention leases", e), Names.SAME, "");
+                plainActionFuture.onResponse(null);
+            }, plainActionFuture::onFailure));
+        } else {
+            plainActionFuture.onResponse(null);
+        }
+        return plainActionFuture;
+    }
+
+    public long getLocalCheckpointOfSafeCommit() {
+        final Engine engine = getEngineOrNull();
+        if (engine == null) {
+            throw new ElasticsearchException("minimum sequence number for peer recovery is unavailable");
+        }
+        return engine.getLocalCheckpointOfSafeCommit();
+    }
+
+    private boolean assertIndexCreatedBeforePeerRecoveryRetentionLeases() {
+        assert indexCreatedBeforePeerRecoveryRetentionLeases()
+            : IndexMetaData.SETTING_INDEX_VERSION_CREATED.get(indexSettings.getSettings());
+        return true;
+    }
+
+    private boolean indexCreatedBeforePeerRecoveryRetentionLeases() {
+        return IndexMetaData.SETTING_INDEX_VERSION_CREATED.get(indexSettings.getSettings()).before(Version.V_8_0_0);
+        // TODO V_7_0_0 on backport
+    }
+
     class ShardEventListener implements Engine.EventListener {
         private final CopyOnWriteArrayList<Consumer<ShardFailure>> delegates = new CopyOnWriteArrayList<>();
 
diff --git a/server/src/main/java/org/elasticsearch/indices/IndicesService.java b/server/src/main/java/org/elasticsearch/indices/IndicesService.java
index 4a12bdae6b9e..5f919b5e5909 100644
--- a/server/src/main/java/org/elasticsearch/indices/IndicesService.java
+++ b/server/src/main/java/org/elasticsearch/indices/IndicesService.java
@@ -30,6 +30,7 @@
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.ResourceAlreadyExistsException;
 import org.elasticsearch.Version;
+import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.admin.indices.stats.CommonStats;
 import org.elasticsearch.action.admin.indices.stats.CommonStatsFlags;
 import org.elasticsearch.action.admin.indices.stats.CommonStatsFlags.Flag;
@@ -144,6 +145,7 @@
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
+import java.util.function.BiConsumer;
 import java.util.function.Consumer;
 import java.util.function.Function;
 import java.util.function.LongSupplier;
@@ -635,11 +637,13 @@ public IndexShard createShard(
             final RepositoriesService repositoriesService,
             final Consumer<IndexShard.ShardFailure> onShardFailure,
             final Consumer<ShardId> globalCheckpointSyncer,
-            final RetentionLeaseSyncer retentionLeaseSyncer) throws IOException {
+            final RetentionLeaseSyncer retentionLeaseSyncer,
+            final BiConsumer<ShardId, ActionListener<Void>> peerRecoveryRetentionLeaseRenewer) throws IOException {
         Objects.requireNonNull(retentionLeaseSyncer);
         ensureChangesAllowed();
         IndexService indexService = indexService(shardRouting.index());
-        IndexShard indexShard = indexService.createShard(shardRouting, globalCheckpointSyncer, retentionLeaseSyncer);
+        IndexShard indexShard = indexService.createShard(shardRouting, globalCheckpointSyncer, retentionLeaseSyncer,
+            peerRecoveryRetentionLeaseRenewer);
         indexShard.addShardFailureCallback(onShardFailure);
         indexShard.startRecovery(recoveryState, recoveryTargetService, recoveryListener, repositoriesService,
             (type, mapping) -> {
diff --git a/server/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java b/server/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java
index 821e095fc20b..f87215e9c642 100644
--- a/server/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java
+++ b/server/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java
@@ -56,6 +56,7 @@
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.IndexSettings;
 import org.elasticsearch.index.seqno.GlobalCheckpointSyncAction;
+import org.elasticsearch.index.seqno.PeerRecoveryRetentionLeaseRenewalAction;
 import org.elasticsearch.index.seqno.ReplicationTracker;
 import org.elasticsearch.index.seqno.RetentionLeaseBackgroundSyncAction;
 import org.elasticsearch.index.seqno.RetentionLeaseSyncAction;
@@ -128,6 +129,7 @@
     private final PrimaryReplicaSyncer primaryReplicaSyncer;
     private final Consumer<ShardId> globalCheckpointSyncer;
     private final RetentionLeaseSyncer retentionLeaseSyncer;
+    private final BiConsumer<ShardId, ActionListener<Void>> peerRecoveryRetentionLeaseRenewer;
 
     @Inject
     public IndicesClusterStateService(
@@ -146,7 +148,8 @@ public IndicesClusterStateService(
             final PrimaryReplicaSyncer primaryReplicaSyncer,
             final GlobalCheckpointSyncAction globalCheckpointSyncAction,
             final RetentionLeaseSyncAction retentionLeaseSyncAction,
-            final RetentionLeaseBackgroundSyncAction retentionLeaseBackgroundSyncAction) {
+            final RetentionLeaseBackgroundSyncAction retentionLeaseBackgroundSyncAction,
+            final PeerRecoveryRetentionLeaseRenewalAction peerRecoveryRetentionLeaseRenewalAction) {
         this(
                 settings,
                 (AllocatedIndices<? extends Shard, ? extends AllocatedIndex<? extends Shard>>) indicesService,
@@ -175,7 +178,7 @@ public void sync(
                     public void backgroundSync(final ShardId shardId, final RetentionLeases retentionLeases) {
                         Objects.requireNonNull(retentionLeaseBackgroundSyncAction).backgroundSync(shardId, retentionLeases);
                     }
-                });
+                }, peerRecoveryRetentionLeaseRenewalAction::renewPeerRecoveryRetentionLease);
     }
 
     // for tests
@@ -194,7 +197,8 @@ public void backgroundSync(final ShardId shardId, final RetentionLeases retentio
             final SnapshotShardsService snapshotShardsService,
             final PrimaryReplicaSyncer primaryReplicaSyncer,
             final Consumer<ShardId> globalCheckpointSyncer,
-            final RetentionLeaseSyncer retentionLeaseSyncer) {
+            final RetentionLeaseSyncer retentionLeaseSyncer,
+            final BiConsumer<ShardId, ActionListener<Void>> peerRecoveryRetentionLeaseRenewer) {
         this.settings = settings;
         this.buildInIndexListener =
                 Arrays.asList(
@@ -214,6 +218,7 @@ public void backgroundSync(final ShardId shardId, final RetentionLeases retentio
         this.globalCheckpointSyncer = globalCheckpointSyncer;
         this.retentionLeaseSyncer = Objects.requireNonNull(retentionLeaseSyncer);
         this.sendRefreshMapping = settings.getAsBoolean("indices.cluster.send_refresh_mapping", true);
+        this.peerRecoveryRetentionLeaseRenewer = peerRecoveryRetentionLeaseRenewer;
     }
 
     @Override
@@ -611,7 +616,8 @@ private void createShard(DiscoveryNodes nodes, RoutingTable routingTable, ShardR
                     repositoriesService,
                     failedShardHandler,
                     globalCheckpointSyncer,
-                    retentionLeaseSyncer);
+                    retentionLeaseSyncer,
+                    peerRecoveryRetentionLeaseRenewer);
         } catch (Exception e) {
             failAndRemoveShard(shardRouting, true, "failed to create shard", e, state);
         }
@@ -916,6 +922,7 @@ U createIndex(IndexMetaData indexMetaData,
          * @param onShardFailure         a callback when this shard fails
          * @param globalCheckpointSyncer a callback when this shard syncs the global checkpoint
          * @param retentionLeaseSyncer   a callback when this shard syncs retention leases
+         * @param peerRecoveryRetentionLeaseRenewer a callback when this shard renews peer recovery retention leases for each copy
          * @return a new shard
          * @throws IOException if an I/O exception occurs when creating the shard
          */
@@ -927,7 +934,8 @@ T createShard(
                 RepositoriesService repositoriesService,
                 Consumer<IndexShard.ShardFailure> onShardFailure,
                 Consumer<ShardId> globalCheckpointSyncer,
-                RetentionLeaseSyncer retentionLeaseSyncer) throws IOException;
+                RetentionLeaseSyncer retentionLeaseSyncer,
+                BiConsumer<ShardId, ActionListener<Void>> peerRecoveryRetentionLeaseRenewer) throws IOException;
 
         /**
          * Returns shard for the specified id if it exists otherwise returns <code>null</code>.
diff --git a/server/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java b/server/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java
index 971f705b3958..9d27a08af95a 100644
--- a/server/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java
+++ b/server/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java
@@ -29,6 +29,7 @@
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.RateLimiter;
 import org.apache.lucene.util.ArrayUtil;
+import org.apache.lucene.util.SetOnce;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.Version;
 import org.elasticsearch.action.ActionListener;
@@ -50,6 +51,8 @@
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.engine.RecoveryEngineException;
 import org.elasticsearch.index.seqno.LocalCheckpointTracker;
+import org.elasticsearch.index.seqno.RetentionLease;
+import org.elasticsearch.index.seqno.RetentionLeaseAlreadyExistsException;
 import org.elasticsearch.index.seqno.RetentionLeases;
 import org.elasticsearch.index.seqno.SequenceNumbers;
 import org.elasticsearch.index.shard.IndexShard;
@@ -78,6 +81,7 @@
 import java.util.function.Supplier;
 import java.util.stream.StreamSupport;
 
+import static org.elasticsearch.index.seqno.ReplicationTracker.getPeerRecoveryRetentionLeaseId;
 import static org.elasticsearch.index.seqno.SequenceNumbers.NO_OPS_PERFORMED;
 
 /**
@@ -144,27 +148,43 @@ public void recoverToTarget(ActionListener<RecoveryResponse> listener) {
             final Consumer<Exception> onFailure = e ->
                 IOUtils.closeWhileHandlingException(releaseResources, () -> wrappedListener.onFailure(e));
 
+            final SetOnce<RetentionLease> retentionLease = new SetOnce<>();
             runUnderPrimaryPermit(() -> {
                 final IndexShardRoutingTable routingTable = shard.getReplicationGroup().getRoutingTable();
-                ShardRouting targetShardRouting = routingTable.getByAllocationId(request.targetAllocationId());
+                final ShardRouting targetShardRouting = routingTable.getByAllocationId(request.targetAllocationId());
                 if (targetShardRouting == null) {
                     logger.debug("delaying recovery of {} as it is not listed as assigned to target node {}", request.shardId(),
                         request.targetNode());
                     throw new DelayRecoveryException("source node does not have the shard listed in its state as allocated on the node");
                 }
-                assert targetShardRouting.initializing() : "expected recovery target to be initializing but was " + targetShardRouting;
+                assert targetShardRouting.initializing()
+                    : "expected recovery target to be initializing but was " + targetShardRouting;
+                retentionLease.set(shard.getRetentionLeases().get(getPeerRecoveryRetentionLeaseId(targetShardRouting)));
             }, shardId + " validating recovery target ["+ request.targetAllocationId() + "] registered ",
                 shard, cancellableThreads, logger);
-            final Closeable retentionLock = shard.acquireRetentionLock();
+
+            final Closeable retentionLock = retentionLease.get() == null ? () -> {} : shard.acquireRetentionLock();
             resources.add(retentionLock);
             final long startingSeqNo;
+
             final boolean isSequenceNumberBasedRecovery = request.startingSeqNo() != SequenceNumbers.UNASSIGNED_SEQ_NO &&
-                isTargetSameHistory() && shard.hasCompleteHistoryOperations("peer-recovery", request.startingSeqNo());
+                isTargetSameHistory() && shard.hasCompleteHistoryOperations("peer-recovery", request.startingSeqNo())
+                && (shard.indexSettings().isSoftDeleteEnabled() == false || retentionLease.get() != null);
+
             final SendFileResult sendFileResult;
+            final StepListener<Void> addPeerRecoveryRetentionLeaseStep = new StepListener<>();
+            final long requiredSeqNoRangeStart;
             if (isSequenceNumberBasedRecovery) {
                 logger.trace("performing sequence numbers based recovery. starting at [{}]", request.startingSeqNo());
                 startingSeqNo = request.startingSeqNo();
+                requiredSeqNoRangeStart = startingSeqNo;
                 sendFileResult = SendFileResult.EMPTY;
+
+                if (shard.indexSettings().isSoftDeleteEnabled()) {
+                    assert retentionLease.get() != null;
+                    assert retentionLease.get().retainingSequenceNumber() <= request.startingSeqNo()
+                        : retentionLease.get() + " vs " + request.startingSeqNo();
+                }
             } else {
                 final Engine.IndexCommitRef phase1Snapshot;
                 try {
@@ -172,9 +192,15 @@ public void recoverToTarget(ActionListener<RecoveryResponse> listener) {
                 } catch (final Exception e) {
                     throw new RecoveryEngineException(shard.shardId(), 1, "snapshot failed", e);
                 }
-                // We need to set this to 0 to create a translog roughly according to the retention policy on the target. Note that it will
-                // still filter out legacy operations without seqNo.
-                startingSeqNo = 0;
+
+                // We must have everything above the local checkpoint in the commit
+                requiredSeqNoRangeStart
+                    = Long.parseLong(phase1Snapshot.getIndexCommit().getUserData().get(SequenceNumbers.LOCAL_CHECKPOINT_KEY)) + 1;
+                // If soft-deletes enabled, we need to transfer only operations after the local_checkpoint of the commit to have
+                // the same history on the target. However, with translog, we need to set this to 0 to create a translog roughly
+                // according to the retention policy on the target. Note that it will still filter out legacy operations without seqNo.
+                startingSeqNo = shard.indexSettings().isSoftDeleteEnabled() ? requiredSeqNoRangeStart : 0;
+
                 try {
                     final int estimateNumOps = shard.estimateNumberOfHistoryOperations("peer-recovery", startingSeqNo);
                     sendFileResult = phase1(phase1Snapshot.getIndexCommit(), () -> estimateNumOps);
@@ -190,10 +216,35 @@ public void recoverToTarget(ActionListener<RecoveryResponse> listener) {
             }
             assert startingSeqNo >= 0 : "startingSeqNo must be non negative. got: " + startingSeqNo;
 
+            if (retentionLease.get() == null) {
+                assert isSequenceNumberBasedRecovery == false;
+                runUnderPrimaryPermit(() -> {
+                    try {
+                        shard.addPeerRecoveryRetentionLease(request.targetNode().getId(), startingSeqNo, addPeerRecoveryRetentionLeaseStep);
+                    } catch (RetentionLeaseAlreadyExistsException e) {
+                        logger.debug("peer-recovery retention lease somehow exists now", e);
+                        addPeerRecoveryRetentionLeaseStep.onFailure(e);
+                    }
+                }, shardId + " adding peer-recovery retention lease for " + request.targetNode(), shard, cancellableThreads, logger);
+            } else {
+                assert retentionLease.get().retainingSequenceNumber() <= requiredSeqNoRangeStart
+                    : shard.shardId() + ": seqno " + startingSeqNo + " should be retained by " + retentionLease.get();
+                // The target shard has a lease (and it is now in the routing table so its lease will not expire)
+                addPeerRecoveryRetentionLeaseStep.onResponse(null);
+            }
+
+            addPeerRecoveryRetentionLeaseStep.whenComplete(r -> {
+                // we can release the retention lock here because the retention lease now reatils the required operations.
+                retentionLock.close();
+            }, onFailure);
+
             final StepListener<TimeValue> prepareEngineStep = new StepListener<>();
-            // For a sequence based recovery, the target can keep its local translog
-            prepareTargetForTranslog(isSequenceNumberBasedRecovery == false,
-                shard.estimateNumberOfHistoryOperations("peer-recovery", startingSeqNo), prepareEngineStep);
+            addPeerRecoveryRetentionLeaseStep.whenComplete(r -> {
+                // For a sequence based recovery, the target can keep its local translog
+                prepareTargetForTranslog(isSequenceNumberBasedRecovery == false,
+                    shard.estimateNumberOfHistoryOperations("peer-recovery", startingSeqNo), prepareEngineStep);
+            }, onFailure);
+
             final StepListener<SendSnapshotResult> sendSnapshotStep = new StepListener<>();
             prepareEngineStep.whenComplete(prepareEngineTime -> {
                 /*
@@ -212,8 +263,6 @@ public void recoverToTarget(ActionListener<RecoveryResponse> listener) {
                 }
                 final Translog.Snapshot phase2Snapshot = shard.getHistoryOperations("peer-recovery", startingSeqNo);
                 resources.add(phase2Snapshot);
-                // we can release the retention lock here because the snapshot itself will retain the required operations.
-                retentionLock.close();
                 // we have to capture the max_seen_auto_id_timestamp and the max_seq_no_of_updates to make sure that these values
                 // are at least as high as the corresponding values on the primary when any of these operations were executed on it.
                 final long maxSeenAutoIdTimestamp = shard.getMaxSeenAutoIdTimestamp();
diff --git a/server/src/test/java/org/elasticsearch/action/admin/indices/close/TransportVerifyShardBeforeCloseActionTests.java b/server/src/test/java/org/elasticsearch/action/admin/indices/close/TransportVerifyShardBeforeCloseActionTests.java
index 687b01680704..0463a38c73a7 100644
--- a/server/src/test/java/org/elasticsearch/action/admin/indices/close/TransportVerifyShardBeforeCloseActionTests.java
+++ b/server/src/test/java/org/elasticsearch/action/admin/indices/close/TransportVerifyShardBeforeCloseActionTests.java
@@ -238,7 +238,7 @@ public void testUnavailableShardsMarkedAsStale() throws Exception {
                 String allocationId = ((ConcreteShardRequest) capturedRequest.request).getTargetAllocationID();
                 assertFalse(unavailableShards.stream().anyMatch(shardRouting -> shardRouting.allocationId().getId().equals(allocationId)));
                 assertTrue(inSyncAllocationIds.stream().anyMatch(inSyncAllocationId -> inSyncAllocationId.equals(allocationId)));
-                transport.handleResponse(capturedRequest.requestId, new TransportReplicationAction.ReplicaResponse(0L, 0L));
+                transport.handleResponse(capturedRequest.requestId, new TransportReplicationAction.ReplicaResponse(0L, 0L, 0L));
 
             } else {
                 fail("Test does not support action " + capturedRequest.action);
@@ -288,6 +288,10 @@ public void updateLocalCheckpointForShard(String allocationId, long checkpoint)
                         public void updateGlobalCheckpointForShard(String allocationId, long globalCheckpoint) {
                         }
 
+                        @Override
+                        public void updateLocalCheckpointOfSafeCommitForShard(String allocationId, long localCheckpointOfSafeCommit) {
+                        }
+
                         @Override
                         public long localCheckpoint() {
                             return 0;
@@ -298,6 +302,11 @@ public long globalCheckpoint() {
                             return 0;
                         }
 
+                        @Override
+                        public long localCheckpointOfSafeCommit() {
+                            return 0;
+                        }
+
                         @Override
                         public long maxSeqNoOfUpdatesOrDeletes() {
                             return 0;
diff --git a/server/src/test/java/org/elasticsearch/action/support/replication/ReplicationOperationTests.java b/server/src/test/java/org/elasticsearch/action/support/replication/ReplicationOperationTests.java
index 02988e7981a2..34965ba97937 100644
--- a/server/src/test/java/org/elasticsearch/action/support/replication/ReplicationOperationTests.java
+++ b/server/src/test/java/org/elasticsearch/action/support/replication/ReplicationOperationTests.java
@@ -461,16 +461,19 @@ public String toString() {
         final ShardRouting routing;
         final long localCheckpoint;
         final long globalCheckpoint;
+        final long localCheckpointOfSafeCommit;
         final long maxSeqNoOfUpdatesOrDeletes;
         final Supplier<ReplicationGroup> replicationGroupSupplier;
         final Map<String, Long> knownLocalCheckpoints = new HashMap<>();
         final Map<String, Long> knownGlobalCheckpoints = new HashMap<>();
+        final Map<String, Long> knownLocalCheckpointsOfSafeCommits = new HashMap<>(); // TODO assert things about this
 
         TestPrimary(ShardRouting routing, Supplier<ReplicationGroup> replicationGroupSupplier) {
             this.routing = routing;
             this.replicationGroupSupplier = replicationGroupSupplier;
             this.localCheckpoint = random().nextLong();
             this.globalCheckpoint = randomNonNegativeLong();
+            this.localCheckpointOfSafeCommit = randomNonNegativeLong();
             this.maxSeqNoOfUpdatesOrDeletes = randomNonNegativeLong();
         }
 
@@ -525,6 +528,11 @@ public void updateGlobalCheckpointForShard(String allocationId, long globalCheck
             knownGlobalCheckpoints.put(allocationId, globalCheckpoint);
         }
 
+        @Override
+        public void updateLocalCheckpointOfSafeCommitForShard(String allocationId, long localCheckpointOfSafeCommit) {
+            knownLocalCheckpointsOfSafeCommits.put(allocationId, localCheckpointOfSafeCommit);
+        }
+
         @Override
         public long localCheckpoint() {
             return localCheckpoint;
@@ -535,6 +543,11 @@ public long globalCheckpoint() {
             return globalCheckpoint;
         }
 
+        @Override
+        public long localCheckpointOfSafeCommit() {
+            return localCheckpointOfSafeCommit;
+        }
+
         @Override
         public long maxSeqNoOfUpdatesOrDeletes() {
             return maxSeqNoOfUpdatesOrDeletes;
@@ -550,10 +563,12 @@ public ReplicationGroup getReplicationGroup() {
     static class ReplicaResponse implements ReplicationOperation.ReplicaResponse {
         final long localCheckpoint;
         final long globalCheckpoint;
+        final long localCheckpointOfSafeCommit;
 
-        ReplicaResponse(long localCheckpoint, long globalCheckpoint) {
+        ReplicaResponse(long localCheckpoint, long globalCheckpoint, long localCheckpointOfSafeCommit) {
             this.localCheckpoint = localCheckpoint;
             this.globalCheckpoint = globalCheckpoint;
+            this.localCheckpointOfSafeCommit = localCheckpointOfSafeCommit;
         }
 
         @Override
@@ -566,6 +581,11 @@ public long globalCheckpoint() {
             return globalCheckpoint;
         }
 
+        @Override
+        public long localCheckpointOfSafeCommit() {
+            return localCheckpointOfSafeCommit;
+        }
+
     }
 
     static class TestReplicaProxy implements ReplicationOperation.Replicas<Request> {
@@ -578,6 +598,8 @@ public long globalCheckpoint() {
 
         final Map<String, Long> generatedGlobalCheckpoints = ConcurrentCollections.newConcurrentMap();
 
+        final Map<String, Long> generatedLocalCheckpointsOfSafeCommits = ConcurrentCollections.newConcurrentMap();
+
         final Set<String> markedAsStaleCopies = ConcurrentCollections.newConcurrentSet();
 
         final long primaryTerm;
@@ -604,10 +626,13 @@ public void performOn(
             } else {
                 final long generatedLocalCheckpoint = random().nextLong();
                 final long generatedGlobalCheckpoint = random().nextLong();
+                final long generatedLocalCheckpointOfSafeCommit = random().nextLong();
                 final String allocationId = replica.allocationId().getId();
                 assertNull(generatedLocalCheckpoints.put(allocationId, generatedLocalCheckpoint));
                 assertNull(generatedGlobalCheckpoints.put(allocationId, generatedGlobalCheckpoint));
-                listener.onResponse(new ReplicaResponse(generatedLocalCheckpoint, generatedGlobalCheckpoint));
+                assertNull(generatedLocalCheckpointsOfSafeCommits.put(allocationId, generatedLocalCheckpointOfSafeCommit));
+                listener.onResponse(
+                    new ReplicaResponse(generatedLocalCheckpoint, generatedGlobalCheckpoint, generatedLocalCheckpointOfSafeCommit));
             }
         }
 
diff --git a/server/src/test/java/org/elasticsearch/action/support/replication/TransportReplicationActionTests.java b/server/src/test/java/org/elasticsearch/action/support/replication/TransportReplicationActionTests.java
index ffc9c2bf70a8..fcfdeeabb023 100644
--- a/server/src/test/java/org/elasticsearch/action/support/replication/TransportReplicationActionTests.java
+++ b/server/src/test/java/org/elasticsearch/action/support/replication/TransportReplicationActionTests.java
@@ -729,7 +729,7 @@ public void testReplicaProxy() throws InterruptedException, ExecutionException {
         assertThat(captures, arrayWithSize(1));
         if (randomBoolean()) {
             final TransportReplicationAction.ReplicaResponse response =
-                    new TransportReplicationAction.ReplicaResponse(randomLong(), randomLong());
+                    new TransportReplicationAction.ReplicaResponse(randomLong(), randomLong(), randomLong());
             transport.handleResponse(captures[0].requestId, response);
             assertTrue(listener.isDone());
             assertThat(listener.get(), equalTo(response));
diff --git a/server/src/test/java/org/elasticsearch/action/support/replication/TransportWriteActionTests.java b/server/src/test/java/org/elasticsearch/action/support/replication/TransportWriteActionTests.java
index f540374a56c2..4ae591541347 100644
--- a/server/src/test/java/org/elasticsearch/action/support/replication/TransportWriteActionTests.java
+++ b/server/src/test/java/org/elasticsearch/action/support/replication/TransportWriteActionTests.java
@@ -296,7 +296,7 @@ public void testReplicaProxy() throws InterruptedException, ExecutionException {
         assertThat(captures, arrayWithSize(1));
         if (randomBoolean()) {
             final TransportReplicationAction.ReplicaResponse response =
-                    new TransportReplicationAction.ReplicaResponse(randomLong(), randomLong());
+                    new TransportReplicationAction.ReplicaResponse(randomLong(), randomLong(), randomLong());
             transport.handleResponse(captures[0].requestId, response);
             assertTrue(listener.isDone());
             assertThat(listener.get(), equalTo(response));
diff --git a/server/src/test/java/org/elasticsearch/gateway/RecoveryFromGatewayIT.java b/server/src/test/java/org/elasticsearch/gateway/RecoveryFromGatewayIT.java
index 3ea0663d7d4c..49df07d55c61 100644
--- a/server/src/test/java/org/elasticsearch/gateway/RecoveryFromGatewayIT.java
+++ b/server/src/test/java/org/elasticsearch/gateway/RecoveryFromGatewayIT.java
@@ -75,6 +75,7 @@
 import static org.elasticsearch.gateway.GatewayService.RECOVER_AFTER_NODES_SETTING;
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
 import static org.elasticsearch.index.query.QueryBuilders.termQuery;
+import static org.elasticsearch.index.seqno.ReplicationTracker.PEER_RECOVERY_RETENTION_LEASE_SOURCE;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
 import static org.hamcrest.Matchers.equalTo;
@@ -467,11 +468,28 @@ public Settings onNodeStopped(String nodeName) throws Exception {
                     .put(IndexSettings.INDEX_TRANSLOG_RETENTION_AGE_SETTING.getKey(), "-1")
                     .put(IndexSettings.INDEX_TRANSLOG_RETENTION_SIZE_SETTING.getKey(), "-1")
                     .put(IndexSettings.INDEX_SOFT_DELETES_RETENTION_OPERATIONS_SETTING.getKey(), 0)
+                    .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 0)
                 ).get();
                 client(primaryNode).admin().indices().prepareFlush("test").setForce(true).get();
                 if (softDeleteEnabled) { // We need an extra flush to advance the min_retained_seqno of the SoftDeletesPolicy
                     client(primaryNode).admin().indices().prepareFlush("test").setForce(true).get();
+                    // expire retention lease for replica; since number_of_replicas is 0 it is no longer needed
+                    internalCluster().getInstance(IndicesService.class, primaryNode).indexServiceSafe(resolveIndex("test", primaryNode))
+                        .forEach(is -> {
+                            try {
+                                is.renewPeerRecoveryRetentionLeases().get();
+                                is.foregroundSyncRetentionLeases().get();
+                                assertThat(is.getRetentionLeases().leases().stream()
+                                    .filter(l -> PEER_RECOVERY_RETENTION_LEASE_SOURCE.equals(l.source())).count(), equalTo(1L));
+                                assertEquals(is.getMinRetainedSeqNo(), is.getLocalCheckpointOfSafeCommit() + 1);
+                            } catch (Exception e) {
+                                throw new AssertionError(e);
+                            }
+                        });
                 }
+                client(primaryNode).admin().indices().prepareUpdateSettings("test").setSettings(Settings.builder()
+                    .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)
+                ).get();
                 return super.onNodeStopped(nodeName);
             }
         });
diff --git a/server/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java b/server/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
index cfdf820ceb59..97c8cf0e61e5 100644
--- a/server/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
+++ b/server/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
@@ -170,10 +170,12 @@
 
 import static java.util.Collections.emptyMap;
 import static java.util.Collections.shuffle;
+import static org.elasticsearch.action.ActionListener.wrap;
 import static org.elasticsearch.index.engine.Engine.Operation.Origin.LOCAL_TRANSLOG_RECOVERY;
 import static org.elasticsearch.index.engine.Engine.Operation.Origin.PEER_RECOVERY;
 import static org.elasticsearch.index.engine.Engine.Operation.Origin.PRIMARY;
 import static org.elasticsearch.index.engine.Engine.Operation.Origin.REPLICA;
+import static org.elasticsearch.index.seqno.SequenceNumbers.NO_OPS_PERFORMED;
 import static org.elasticsearch.index.seqno.SequenceNumbers.UNASSIGNED_PRIMARY_TERM;
 import static org.elasticsearch.index.seqno.SequenceNumbers.UNASSIGNED_SEQ_NO;
 import static org.elasticsearch.index.translog.TranslogDeletionPolicies.createTranslogDeletionPolicy;
@@ -2300,9 +2302,13 @@ public void testSeqNoAndCheckpoints() throws IOException {
                 TestShardRouting.newShardRouting(shardId, "node2", false, ShardRoutingState.STARTED);
             ReplicationTracker gcpTracker = (ReplicationTracker) initialEngine.config().getGlobalCheckpointSupplier();
             gcpTracker.updateFromMaster(1L, new HashSet<>(Arrays.asList(primary.allocationId().getId(),
+                replica.allocationId().getId())),
+                new IndexShardRoutingTable.Builder(shardId).addShard(primary).build(), Collections.emptySet());
+            gcpTracker.activatePrimaryMode(primarySeqNo, NO_OPS_PERFORMED);
+            gcpTracker.addPeerRecoveryRetentionLease("node2", 0, wrap(() -> {}));
+            gcpTracker.updateFromMaster(2L, new HashSet<>(Arrays.asList(primary.allocationId().getId(),
                 replica.allocationId().getId())),
                 new IndexShardRoutingTable.Builder(shardId).addShard(primary).addShard(replica).build(), Collections.emptySet());
-            gcpTracker.activatePrimaryMode(primarySeqNo);
             for (int op = 0; op < opCount; op++) {
                 final String id;
                 // mostly index, sometimes delete
diff --git a/server/src/test/java/org/elasticsearch/index/engine/NoOpEngineTests.java b/server/src/test/java/org/elasticsearch/index/engine/NoOpEngineTests.java
index 3a857a204684..13bd647f0d63 100644
--- a/server/src/test/java/org/elasticsearch/index/engine/NoOpEngineTests.java
+++ b/server/src/test/java/org/elasticsearch/index/engine/NoOpEngineTests.java
@@ -76,7 +76,7 @@ public void testNoopAfterRegularEngine() throws IOException {
             null, true, ShardRoutingState.STARTED, allocationId);
         IndexShardRoutingTable table = new IndexShardRoutingTable.Builder(shardId).addShard(routing).build();
         tracker.updateFromMaster(1L, Collections.singleton(allocationId.getId()), table, Collections.emptySet());
-        tracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED);
+        tracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED, SequenceNumbers.NO_OPS_PERFORMED);
         for (int i = 0; i < docs; i++) {
             ParsedDocument doc = testParsedDocument("" + i, null, testDocumentWithTextField(), B_1, null);
             engine.index(indexForDoc(doc));
diff --git a/server/src/test/java/org/elasticsearch/index/replication/RecoveryDuringReplicationTests.java b/server/src/test/java/org/elasticsearch/index/replication/RecoveryDuringReplicationTests.java
index d8a7827a8cb4..3ee9a8fda17e 100644
--- a/server/src/test/java/org/elasticsearch/index/replication/RecoveryDuringReplicationTests.java
+++ b/server/src/test/java/org/elasticsearch/index/replication/RecoveryDuringReplicationTests.java
@@ -59,6 +59,8 @@
 import org.elasticsearch.indices.recovery.RecoveryState;
 import org.elasticsearch.indices.recovery.RecoveryTarget;
 import org.elasticsearch.test.junit.annotations.TestLogging;
+import org.elasticsearch.threadpool.ThreadPool.Names;
+import org.junit.Assert;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -74,6 +76,8 @@
 import java.util.concurrent.atomic.AtomicReference;
 import java.util.stream.Collectors;
 
+import static org.elasticsearch.action.ActionListener.wrap;
+import static org.elasticsearch.index.seqno.ReplicationTracker.getPeerRecoveryRetentionLeaseId;
 import static org.hamcrest.Matchers.anyOf;
 import static org.hamcrest.Matchers.empty;
 import static org.hamcrest.Matchers.equalTo;
@@ -257,6 +261,7 @@ public void testRecoveryAfterPrimaryPromotion() throws Exception {
             }
 
             shards.promoteReplicaToPrimary(newPrimary).get();
+            shards.removeReplica(oldPrimary);
 
             // check that local checkpoint of new primary is properly tracked after primary promotion
             assertThat(newPrimary.getLocalCheckpoint(), equalTo(totalDocs - 1L));
@@ -289,6 +294,11 @@ public void testRecoveryAfterPrimaryPromotion() throws Exception {
                 });
                 newPrimary.flush(new FlushRequest().force(true));
                 if (replica.indexSettings().isSoftDeleteEnabled()) {
+                    replica.flush(new FlushRequest().force(true));
+                    newPrimary.removeRetentionLease(getPeerRecoveryRetentionLeaseId(oldPrimary.routingEntry()), wrap(() -> {}));
+                    newPrimary.runUnderPrimaryPermit(
+                        newPrimary::renewPeerRecoveryRetentionLeaseForPrimary, Assert::assertNull, Names.SAME, "");
+                    newPrimary.renewPeerRecoveryRetentionLeaseForReplica(replica.routingEntry(), replica.getLocalCheckpointOfSafeCommit());
                     // We need an extra flush to advance the min_retained_seqno on the new primary so ops-based won't happen.
                     // The min_retained_seqno only advances when a merge asks for the retention query.
                     newPrimary.flush(new FlushRequest().force(true));
diff --git a/server/src/test/java/org/elasticsearch/index/replication/RetentionLeasesReplicationTests.java b/server/src/test/java/org/elasticsearch/index/replication/RetentionLeasesReplicationTests.java
index ce3986f0a251..dd556156c9a9 100644
--- a/server/src/test/java/org/elasticsearch/index/replication/RetentionLeasesReplicationTests.java
+++ b/server/src/test/java/org/elasticsearch/index/replication/RetentionLeasesReplicationTests.java
@@ -35,6 +35,7 @@
 import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.CountDownLatch;
+import java.util.stream.Collectors;
 
 import static org.hamcrest.Matchers.containsInAnyOrder;
 import static org.hamcrest.Matchers.equalTo;
@@ -44,7 +45,8 @@
 
     public void testSimpleSyncRetentionLeases() throws Exception {
         Settings settings = Settings.builder().put(IndexSettings.INDEX_SOFT_DELETES_SETTING.getKey(), true).build();
-        try (ReplicationGroup group = createGroup(between(0, 2), settings)) {
+        final int numberOfReplicas = between(0, 2);
+        try (ReplicationGroup group = createGroup(numberOfReplicas, settings)) {
             group.startAll();
             List<RetentionLease> leases = new ArrayList<>();
             int iterations = between(1, 100);
@@ -61,9 +63,10 @@ public void testSimpleSyncRetentionLeases() throws Exception {
                 }
             }
             RetentionLeases leasesOnPrimary = group.getPrimary().getRetentionLeases();
-            assertThat(leasesOnPrimary.version(), equalTo((long) iterations));
+            assertThat(leasesOnPrimary.version(), equalTo(iterations + numberOfReplicas + 1L));
             assertThat(leasesOnPrimary.primaryTerm(), equalTo(group.getPrimary().getOperationPrimaryTerm()));
-            assertThat(leasesOnPrimary.leases(), containsInAnyOrder(leases.toArray(new RetentionLease[0])));
+            assertThat(leasesOnPrimary.leases().stream().filter(RetentionLease::isNotPeerRecoveryRetentionLease)
+                .collect(Collectors.toList()), containsInAnyOrder(leases.toArray(new RetentionLease[0])));
             latch.await();
             for (IndexShard replica : group.getReplicas()) {
                 assertThat(replica.getRetentionLeases(), equalTo(leasesOnPrimary));
diff --git a/server/src/test/java/org/elasticsearch/index/seqno/ReplicationTrackerRetentionLeaseTests.java b/server/src/test/java/org/elasticsearch/index/seqno/ReplicationTrackerRetentionLeaseTests.java
index 178df2eac899..a69df31c6f3e 100644
--- a/server/src/test/java/org/elasticsearch/index/seqno/ReplicationTrackerRetentionLeaseTests.java
+++ b/server/src/test/java/org/elasticsearch/index/seqno/ReplicationTrackerRetentionLeaseTests.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index.seqno;
 
+import org.elasticsearch.Version;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.cluster.routing.AllocationId;
 import org.elasticsearch.common.collect.Tuple;
@@ -42,8 +43,10 @@
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicLong;
 import java.util.concurrent.atomic.AtomicReference;
+import java.util.function.Function;
 import java.util.stream.Collectors;
 
+import static org.elasticsearch.index.seqno.ReplicationTracker.getPeerRecoveryRetentionLeaseId;
 import static org.elasticsearch.index.seqno.SequenceNumbers.UNASSIGNED_SEQ_NO;
 import static org.hamcrest.Matchers.contains;
 import static org.hamcrest.Matchers.containsString;
@@ -66,13 +69,14 @@ public void testAddOrRenewRetentionLease() {
                 UNASSIGNED_SEQ_NO,
                 value -> {},
                 () -> 0L,
-                (leases, listener) -> {});
+                (leases, listener) -> {},
+                Version.CURRENT);
         replicationTracker.updateFromMaster(
                 randomNonNegativeLong(),
                 Collections.singleton(allocationId.getId()),
                 routingTable(Collections.emptySet(), allocationId),
                 Collections.emptySet());
-        replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED);
+        replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED, SequenceNumbers.NO_OPS_PERFORMED);
         final int length = randomIntBetween(0, 8);
         final long[] minimumRetainingSequenceNumbers = new long[length];
         for (int i = 0; i < length; i++) {
@@ -83,7 +87,7 @@ public void testAddOrRenewRetentionLease() {
             minimumRetainingSequenceNumbers[i] = randomLongBetween(SequenceNumbers.NO_OPS_PERFORMED, Long.MAX_VALUE);
             replicationTracker.addRetentionLease(
                     Integer.toString(i), minimumRetainingSequenceNumbers[i], "test-" + i, ActionListener.wrap(() -> {}));
-            assertRetentionLeases(replicationTracker, i + 1, minimumRetainingSequenceNumbers, primaryTerm, 1 + i, true, false);
+            assertRetentionLeases(replicationTracker, i + 1, minimumRetainingSequenceNumbers, primaryTerm, 2 + i, true, false);
         }
 
         for (int i = 0; i < length; i++) {
@@ -93,7 +97,7 @@ public void testAddOrRenewRetentionLease() {
             }
             minimumRetainingSequenceNumbers[i] = randomLongBetween(minimumRetainingSequenceNumbers[i], Long.MAX_VALUE);
             replicationTracker.renewRetentionLease(Integer.toString(i), minimumRetainingSequenceNumbers[i], "test-" + i);
-            assertRetentionLeases(replicationTracker, length, minimumRetainingSequenceNumbers, primaryTerm, 1 + length + i, true, false);
+            assertRetentionLeases(replicationTracker, length, minimumRetainingSequenceNumbers, primaryTerm, 2 + length + i, true, false);
         }
     }
 
@@ -108,13 +112,14 @@ public void testAddDuplicateRetentionLease() {
                 UNASSIGNED_SEQ_NO,
                 value -> {},
                 () -> 0L,
-                (leases, listener) -> {});
+                (leases, listener) -> {},
+                Version.CURRENT);
         replicationTracker.updateFromMaster(
                 randomNonNegativeLong(),
                 Collections.singleton(allocationId.getId()),
                 routingTable(Collections.emptySet(), allocationId),
                 Collections.emptySet());
-        replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED);
+        replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED, SequenceNumbers.NO_OPS_PERFORMED);
         final String id = randomAlphaOfLength(8);
         final long retainingSequenceNumber = randomNonNegativeLong();
         final String source = randomAlphaOfLength(8);
@@ -137,13 +142,14 @@ public void testRenewNotFoundRetentionLease() {
                 UNASSIGNED_SEQ_NO,
                 value -> {},
                 () -> 0L,
-                (leases, listener) -> {});
+                (leases, listener) -> {},
+                Version.CURRENT);
         replicationTracker.updateFromMaster(
                 randomNonNegativeLong(),
                 Collections.singleton(allocationId.getId()),
                 routingTable(Collections.emptySet(), allocationId),
                 Collections.emptySet());
-        replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED);
+        replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED, SequenceNumbers.NO_OPS_PERFORMED);
         final String id = randomAlphaOfLength(8);
         final RetentionLeaseNotFoundException e = expectThrows(
                 RetentionLeaseNotFoundException.class,
@@ -173,14 +179,15 @@ public void testAddRetentionLeaseCausesRetentionLeaseSync() {
                                     .stream()
                                     .collect(Collectors.toMap(RetentionLease::id, RetentionLease::retainingSequenceNumber)),
                             equalTo(retainingSequenceNumbers));
-                });
+                }, Version.CURRENT);
         reference.set(replicationTracker);
         replicationTracker.updateFromMaster(
                 randomNonNegativeLong(),
                 Collections.singleton(allocationId.getId()),
                 routingTable(Collections.emptySet(), allocationId),
                 Collections.emptySet());
-        replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED);
+        replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED, SequenceNumbers.NO_OPS_PERFORMED);
+        retainingSequenceNumbers.put(getPeerRecoveryRetentionLeaseId(nodeIdFromAllocationId(allocationId)), 0L);
 
         final int length = randomIntBetween(0, 8);
         for (int i = 0; i < length; i++) {
@@ -209,13 +216,14 @@ public void testRemoveRetentionLease() {
                 UNASSIGNED_SEQ_NO,
                 value -> {},
                 () -> 0L,
-                (leases, listener) -> {});
+                (leases, listener) -> {},
+                Version.CURRENT);
         replicationTracker.updateFromMaster(
                 randomNonNegativeLong(),
                 Collections.singleton(allocationId.getId()),
                 routingTable(Collections.emptySet(), allocationId),
                 Collections.emptySet());
-        replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED);
+        replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED, SequenceNumbers.NO_OPS_PERFORMED);
         final int length = randomIntBetween(0, 8);
         final long[] minimumRetainingSequenceNumbers = new long[length];
         for (int i = 0; i < length; i++) {
@@ -243,7 +251,7 @@ public void testRemoveRetentionLease() {
                     length - i - 1,
                     minimumRetainingSequenceNumbers,
                     primaryTerm,
-                    1 + length + i,
+                    2 + length + i,
                     true,
                     false);
         }
@@ -260,13 +268,14 @@ public void testRemoveNotFound() {
                 UNASSIGNED_SEQ_NO,
                 value -> {},
                 () -> 0L,
-                (leases, listener) -> {});
+                (leases, listener) -> {},
+                Version.CURRENT);
         replicationTracker.updateFromMaster(
                 randomNonNegativeLong(),
                 Collections.singleton(allocationId.getId()),
                 routingTable(Collections.emptySet(), allocationId),
                 Collections.emptySet());
-        replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED);
+        replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED, SequenceNumbers.NO_OPS_PERFORMED);
         final String id = randomAlphaOfLength(8);
         final RetentionLeaseNotFoundException e = expectThrows(
                 RetentionLeaseNotFoundException.class,
@@ -296,14 +305,15 @@ public void testRemoveRetentionLeaseCausesRetentionLeaseSync() {
                                     .stream()
                                     .collect(Collectors.toMap(RetentionLease::id, RetentionLease::retainingSequenceNumber)),
                             equalTo(retainingSequenceNumbers));
-                });
+                }, Version.CURRENT);
         reference.set(replicationTracker);
         replicationTracker.updateFromMaster(
                 randomNonNegativeLong(),
                 Collections.singleton(allocationId.getId()),
                 routingTable(Collections.emptySet(), allocationId),
                 Collections.emptySet());
-        replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED);
+        replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED, SequenceNumbers.NO_OPS_PERFORMED);
+        retainingSequenceNumbers.put(getPeerRecoveryRetentionLeaseId(nodeIdFromAllocationId(allocationId)), 0L);
 
         final int length = randomIntBetween(0, 8);
         for (int i = 0; i < length; i++) {
@@ -349,14 +359,15 @@ private void runExpirationTest(final boolean primaryMode) {
                 UNASSIGNED_SEQ_NO,
                 value -> {},
                 currentTimeMillis::get,
-                (leases, listener) -> {});
+                (leases, listener) -> {},
+                Version.CURRENT);
         replicationTracker.updateFromMaster(
                 randomNonNegativeLong(),
                 Collections.singleton(allocationId.getId()),
                 routingTable(Collections.emptySet(), allocationId),
                 Collections.emptySet());
         if (primaryMode) {
-            replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED);
+            replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED, SequenceNumbers.NO_OPS_PERFORMED);
         }
         final long[] retainingSequenceNumbers = new long[1];
         retainingSequenceNumbers[0] = randomLongBetween(0, Long.MAX_VALUE);
@@ -372,11 +383,12 @@ private void runExpirationTest(final boolean primaryMode) {
 
         {
             final RetentionLeases retentionLeases = replicationTracker.getRetentionLeases();
-            assertThat(retentionLeases.version(), equalTo(1L));
-            assertThat(retentionLeases.leases(), hasSize(1));
-            final RetentionLease retentionLease = retentionLeases.leases().iterator().next();
+            final long expectedVersion = primaryMode ? 2L : 1L;
+            assertThat(retentionLeases.version(), equalTo(expectedVersion));
+            assertThat(retentionLeases.leases(), hasSize(primaryMode ? 2 : 1));
+            final RetentionLease retentionLease = retentionLeases.get("0");
             assertThat(retentionLease.timestamp(), equalTo(currentTimeMillis.get()));
-            assertRetentionLeases(replicationTracker, 1, retainingSequenceNumbers, primaryTerm, 1, primaryMode, false);
+            assertRetentionLeases(replicationTracker, 1, retainingSequenceNumbers, primaryTerm, expectedVersion, primaryMode, false);
         }
 
         // renew the lease
@@ -394,18 +406,19 @@ private void runExpirationTest(final boolean primaryMode) {
 
         {
             final RetentionLeases retentionLeases = replicationTracker.getRetentionLeases();
-            assertThat(retentionLeases.version(), equalTo(2L));
-            assertThat(retentionLeases.leases(), hasSize(1));
-            final RetentionLease retentionLease = retentionLeases.leases().iterator().next();
+            final long expectedVersion = primaryMode ? 3L : 2L;
+            assertThat(retentionLeases.version(), equalTo(expectedVersion));
+            assertThat(retentionLeases.leases(), hasSize(primaryMode ? 2 : 1));
+            final RetentionLease retentionLease = retentionLeases.get("0");
             assertThat(retentionLease.timestamp(), equalTo(currentTimeMillis.get()));
-            assertRetentionLeases(replicationTracker, 1, retainingSequenceNumbers, primaryTerm, 2, primaryMode, false);
+            assertRetentionLeases(replicationTracker, 1, retainingSequenceNumbers, primaryTerm, expectedVersion, primaryMode, false);
         }
 
         // now force the lease to expire
         currentTimeMillis.set(currentTimeMillis.get() + randomLongBetween(retentionLeaseMillis, Long.MAX_VALUE - currentTimeMillis.get()));
         if (primaryMode) {
-            assertRetentionLeases(replicationTracker, 1, retainingSequenceNumbers, primaryTerm, 2, true, false);
-            assertRetentionLeases(replicationTracker, 0, new long[0], primaryTerm, 3, true, true);
+            assertRetentionLeases(replicationTracker, 1, retainingSequenceNumbers, primaryTerm, 3, true, false);
+            assertRetentionLeases(replicationTracker, 0, new long[0], primaryTerm, 4, true, true);
         } else {
             // leases do not expire on replicas until synced from the primary
             assertRetentionLeases(replicationTracker, 1, retainingSequenceNumbers, primaryTerm, 2, false, false);
@@ -422,7 +435,8 @@ public void testReplicaIgnoresOlderRetentionLeasesVersion() {
                 UNASSIGNED_SEQ_NO,
                 value -> {},
                 () -> 0L,
-                (leases, listener) -> {});
+                (leases, listener) -> {},
+                Version.CURRENT);
         replicationTracker.updateFromMaster(
                 randomNonNegativeLong(),
                 Collections.singleton(allocationId.getId()),
@@ -476,13 +490,14 @@ public void testLoadAndPersistRetentionLeases() throws IOException {
                 UNASSIGNED_SEQ_NO,
                 value -> {},
                 () -> 0L,
-                (leases, listener) -> {});
+                (leases, listener) -> {},
+                Version.CURRENT);
         replicationTracker.updateFromMaster(
                 randomNonNegativeLong(),
                 Collections.singleton(allocationId.getId()),
                 routingTable(Collections.emptySet(), allocationId),
                 Collections.emptySet());
-        replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED);
+        replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED, SequenceNumbers.NO_OPS_PERFORMED);
         final int length = randomIntBetween(0, 8);
         for (int i = 0; i < length; i++) {
             if (rarely() && primaryTerm < Long.MAX_VALUE) {
@@ -516,13 +531,14 @@ public void testPersistRetentionLeasesUnderConcurrency() throws IOException {
                 UNASSIGNED_SEQ_NO,
                 value -> {},
                 () -> 0L,
-                (leases, listener) -> {});
+                (leases, listener) -> {},
+                Version.CURRENT);
         replicationTracker.updateFromMaster(
                 randomNonNegativeLong(),
                 Collections.singleton(allocationId.getId()),
                 routingTable(Collections.emptySet(), allocationId),
                 Collections.emptySet());
-        replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED);
+        replicationTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED, SequenceNumbers.NO_OPS_PERFORMED);
         final int length = randomIntBetween(0, 8);
         for (int i = 0; i < length; i++) {
             if (rarely() && primaryTerm < Long.MAX_VALUE) {
@@ -593,11 +609,8 @@ private void assertRetentionLeases(
         }
         assertThat(retentionLeases.primaryTerm(), equalTo(primaryTerm));
         assertThat(retentionLeases.version(), equalTo(version));
-        final Map<String, RetentionLease> idToRetentionLease = new HashMap<>();
-        for (final RetentionLease retentionLease : retentionLeases.leases()) {
-            idToRetentionLease.put(retentionLease.id(), retentionLease);
-        }
-
+        final Map<String, RetentionLease> idToRetentionLease = retentionLeases.leases().stream()
+            .filter(RetentionLease::isNotPeerRecoveryRetentionLease).collect(Collectors.toMap(RetentionLease::id, Function.identity()));
         assertThat(idToRetentionLease.entrySet(), hasSize(size));
         for (int i = 0; i < size; i++) {
             assertThat(idToRetentionLease.keySet(), hasItem(Integer.toString(i)));
@@ -606,5 +619,4 @@ private void assertRetentionLeases(
             assertThat(retentionLease.source(), equalTo("test-" + i));
         }
     }
-
 }
diff --git a/server/src/test/java/org/elasticsearch/index/seqno/ReplicationTrackerTestCase.java b/server/src/test/java/org/elasticsearch/index/seqno/ReplicationTrackerTestCase.java
index 5165f2e8dc9e..734041928ccc 100644
--- a/server/src/test/java/org/elasticsearch/index/seqno/ReplicationTrackerTestCase.java
+++ b/server/src/test/java/org/elasticsearch/index/seqno/ReplicationTrackerTestCase.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index.seqno;
 
+import org.elasticsearch.Version;
 import org.elasticsearch.cluster.routing.AllocationId;
 import org.elasticsearch.cluster.routing.IndexShardRoutingTable;
 import org.elasticsearch.cluster.routing.ShardRouting;
@@ -49,13 +50,18 @@ ReplicationTracker newTracker(
                 UNASSIGNED_SEQ_NO,
                 updatedGlobalCheckpoint,
                 currentTimeMillisSupplier,
-                (leases, listener) -> {});
+                (leases, listener) -> {},
+                Version.CURRENT);
+    }
+
+    static String nodeIdFromAllocationId(final AllocationId allocationId) {
+        return "n-" + allocationId.getId().substring(0, 8);
     }
 
     static IndexShardRoutingTable routingTable(final Set<AllocationId> initializingIds, final AllocationId primaryId) {
         final ShardId shardId = new ShardId("test", "_na_", 0);
-        final ShardRouting primaryShard =
-                TestShardRouting.newShardRouting(shardId, randomAlphaOfLength(10), null, true, ShardRoutingState.STARTED, primaryId);
+        final ShardRouting primaryShard = TestShardRouting.newShardRouting(
+            shardId, nodeIdFromAllocationId(primaryId), null, true, ShardRoutingState.STARTED, primaryId);
         return routingTable(initializingIds, primaryShard);
     }
 
@@ -65,7 +71,7 @@ static IndexShardRoutingTable routingTable(final Set<AllocationId> initializingI
         final IndexShardRoutingTable.Builder builder = new IndexShardRoutingTable.Builder(shardId);
         for (final AllocationId initializingId : initializingIds) {
             builder.addShard(TestShardRouting.newShardRouting(
-                    shardId, randomAlphaOfLength(10), null, false, ShardRoutingState.INITIALIZING, initializingId));
+                    shardId, nodeIdFromAllocationId(initializingId), null, false, ShardRoutingState.INITIALIZING, initializingId));
         }
 
         builder.addShard(primaryShard);
diff --git a/server/src/test/java/org/elasticsearch/index/seqno/ReplicationTrackerTests.java b/server/src/test/java/org/elasticsearch/index/seqno/ReplicationTrackerTests.java
index 037d2130b5c7..322cb60467bb 100644
--- a/server/src/test/java/org/elasticsearch/index/seqno/ReplicationTrackerTests.java
+++ b/server/src/test/java/org/elasticsearch/index/seqno/ReplicationTrackerTests.java
@@ -19,6 +19,9 @@
 
 package org.elasticsearch.index.seqno;
 
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.elasticsearch.Version;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.support.replication.ReplicationResponse;
 import org.elasticsearch.cluster.routing.AllocationId;
@@ -64,6 +67,8 @@
 import static org.hamcrest.Matchers.not;
 
 public class ReplicationTrackerTests extends ReplicationTrackerTestCase {
+
+    private static final Logger logger = LogManager.getLogger(ReplicationTrackerTests.class);
     
     public void testEmptyShards() {
         final ReplicationTracker tracker = newTracker(AllocationId.newInitializing());
@@ -121,7 +126,7 @@ public void testGlobalCheckpointUpdate() {
         });
 
         tracker.updateFromMaster(initialClusterStateVersion, ids(active), routingTable(initializing, primaryId), emptySet());
-        tracker.activatePrimaryMode(NO_OPS_PERFORMED);
+        tracker.activatePrimaryMode(NO_OPS_PERFORMED, NO_OPS_PERFORMED);
         assertThat(tracker.getReplicationGroup().getReplicationTargets().size(), equalTo(1));
         initializing.forEach(aId -> markAsTrackingAndInSyncQuietly(tracker, aId.getId(), NO_OPS_PERFORMED));
         assertThat(tracker.getReplicationGroup().getReplicationTargets().size(), equalTo(1 + initializing.size()));
@@ -149,6 +154,7 @@ public void testGlobalCheckpointUpdate() {
         newInitializing.add(extraId);
         tracker.updateFromMaster(initialClusterStateVersion + 1, ids(active), routingTable(newInitializing, primaryId), emptySet());
 
+        addPeerRecoveryRetentionLease(tracker, extraId);
         tracker.initiateTracking(extraId.getId());
 
         // now notify for the new id
@@ -189,7 +195,8 @@ public void testMarkAllocationIdAsInSync() throws BrokenBarrierException, Interr
         final ReplicationTracker tracker = newTracker(primaryId);
         tracker.updateFromMaster(initialClusterStateVersion, ids(active), routingTable(initializing, primaryId), emptySet());
         final long localCheckpoint = randomLongBetween(0, Long.MAX_VALUE - 1);
-        tracker.activatePrimaryMode(localCheckpoint);
+        tracker.activatePrimaryMode(localCheckpoint, NO_OPS_PERFORMED);
+        addPeerRecoveryRetentionLease(tracker, replicaId);
         tracker.initiateTracking(replicaId.getId());
         final CyclicBarrier barrier = new CyclicBarrier(2);
         final Thread thread = new Thread(() -> {
@@ -230,7 +237,7 @@ public void testMissingActiveIdsPreventAdvance() {
         AllocationId primaryId = active.keySet().iterator().next();
         final ReplicationTracker tracker = newTracker(primaryId);
         tracker.updateFromMaster(randomNonNegativeLong(), ids(active.keySet()), routingTable(initializing.keySet(), primaryId), emptySet());
-        tracker.activatePrimaryMode(NO_OPS_PERFORMED);
+        tracker.activatePrimaryMode(NO_OPS_PERFORMED, NO_OPS_PERFORMED);
         randomSubsetOf(initializing.keySet()).forEach(k -> markAsTrackingAndInSyncQuietly(tracker, k.getId(), NO_OPS_PERFORMED));
         final AllocationId missingActiveID = randomFrom(active.keySet());
         assigned
@@ -257,7 +264,7 @@ public void testMissingInSyncIdsPreventAdvance() {
         AllocationId primaryId = active.keySet().iterator().next();
         final ReplicationTracker tracker = newTracker(primaryId);
         tracker.updateFromMaster(randomNonNegativeLong(), ids(active.keySet()), routingTable(initializing.keySet(), primaryId), emptySet());
-        tracker.activatePrimaryMode(NO_OPS_PERFORMED);
+        tracker.activatePrimaryMode(NO_OPS_PERFORMED, NO_OPS_PERFORMED);
         randomSubsetOf(randomIntBetween(1, initializing.size() - 1),
             initializing.keySet()).forEach(aId -> markAsTrackingAndInSyncQuietly(tracker, aId.getId(), NO_OPS_PERFORMED));
 
@@ -279,7 +286,7 @@ public void testInSyncIdsAreIgnoredIfNotValidatedByMaster() {
         final AllocationId primaryId = active.keySet().iterator().next();
         final ReplicationTracker tracker = newTracker(primaryId);
         tracker.updateFromMaster(randomNonNegativeLong(), ids(active.keySet()), routingTable(initializing.keySet(), primaryId), emptySet());
-        tracker.activatePrimaryMode(NO_OPS_PERFORMED);
+        tracker.activatePrimaryMode(NO_OPS_PERFORMED, NO_OPS_PERFORMED);
         initializing.keySet().forEach(k -> markAsTrackingAndInSyncQuietly(tracker, k.getId(), NO_OPS_PERFORMED));
         nonApproved.keySet().forEach(k ->
             expectThrows(IllegalStateException.class, () -> markAsTrackingAndInSyncQuietly(tracker, k.getId(), NO_OPS_PERFORMED)));
@@ -314,7 +321,7 @@ public void testInSyncIdsAreRemovedIfNotValidatedByMaster() {
         }
         final ReplicationTracker tracker = newTracker(primaryId);
         tracker.updateFromMaster(initialClusterStateVersion, ids(active), routingTable(initializing, primaryId), emptySet());
-        tracker.activatePrimaryMode(NO_OPS_PERFORMED);
+        tracker.activatePrimaryMode(NO_OPS_PERFORMED, NO_OPS_PERFORMED);
         if (randomBoolean()) {
             initializingToStay.keySet().forEach(k -> markAsTrackingAndInSyncQuietly(tracker, k.getId(), NO_OPS_PERFORMED));
         } else {
@@ -358,7 +365,8 @@ public void testWaitForAllocationIdToBeInSync() throws Exception {
         final long clusterStateVersion = randomNonNegativeLong();
         tracker.updateFromMaster(clusterStateVersion, Collections.singleton(inSyncAllocationId.getId()),
             routingTable(Collections.singleton(trackingAllocationId), inSyncAllocationId), emptySet());
-        tracker.activatePrimaryMode(globalCheckpoint);
+        tracker.activatePrimaryMode(globalCheckpoint, NO_OPS_PERFORMED);
+        addPeerRecoveryRetentionLease(tracker, trackingAllocationId);
         final Thread thread = new Thread(() -> {
             try {
                 // synchronize starting with the test thread
@@ -422,7 +430,8 @@ public void testWaitForAllocationIdToBeInSyncCanBeInterrupted() throws BrokenBar
         final ReplicationTracker tracker = newTracker(inSyncAllocationId);
         tracker.updateFromMaster(randomNonNegativeLong(), Collections.singleton(inSyncAllocationId.getId()),
             routingTable(Collections.singleton(trackingAllocationId), inSyncAllocationId), emptySet());
-        tracker.activatePrimaryMode(globalCheckpoint);
+        tracker.activatePrimaryMode(globalCheckpoint, NO_OPS_PERFORMED);
+        addPeerRecoveryRetentionLease(tracker, trackingAllocationId);
         final Thread thread = new Thread(() -> {
             try {
                 // synchronize starting with the test thread
@@ -471,7 +480,7 @@ public void testUpdateAllocationIdsFromMaster() throws Exception {
         IndexShardRoutingTable routingTable = routingTable(initializingIds, primaryId);
         final ReplicationTracker tracker = newTracker(primaryId);
         tracker.updateFromMaster(initialClusterStateVersion, ids(activeAllocationIds), routingTable, emptySet());
-        tracker.activatePrimaryMode(NO_OPS_PERFORMED);
+        tracker.activatePrimaryMode(NO_OPS_PERFORMED, NO_OPS_PERFORMED);
         assertThat(tracker.getReplicationGroup().getInSyncAllocationIds(), equalTo(ids(activeAllocationIds)));
         assertThat(tracker.getReplicationGroup().getRoutingTable(), equalTo(routingTable));
 
@@ -567,6 +576,7 @@ public void testUpdateAllocationIdsFromMaster() throws Exception {
                 ids(newActiveAllocationIds),
                 routingTable(newInitializingAllocationIds, primaryId),
                 emptySet());
+        addPeerRecoveryRetentionLease(tracker, newSyncingAllocationId);
         final CyclicBarrier barrier = new CyclicBarrier(2);
         final Thread thread = new Thread(() -> {
             try {
@@ -615,7 +625,7 @@ public void testUpdateAllocationIdsFromMaster() throws Exception {
      * allocation ID to the in-sync set and removing it from pending, the local checkpoint update that freed the thread waiting for the
      * local checkpoint to advance could miss updating the global checkpoint in a race if the waiting thread did not add the allocation
      * ID to the in-sync set and remove it from the pending set before the local checkpoint updating thread executed the global checkpoint
-     * update. This test fails without an additional call to {@link ReplicationTracker#updateGlobalCheckpointOnPrimary()} after
+     * update. This test fails without an additional call to {@code ReplicationTracker#updateGlobalCheckpointOnPrimary()} after
      * removing the allocation ID from the pending set in {@link ReplicationTracker#markAllocationIdAsInSync(String, long)} (even if a
      * call is added after notifying all waiters in {@link ReplicationTracker#updateLocalCheckpoint(String, long)}).
      *
@@ -635,7 +645,8 @@ public void testRaceUpdatingGlobalCheckpoint() throws InterruptedException, Brok
                 Collections.singleton(active.getId()),
                 routingTable(Collections.singleton(initializing), active),
                 emptySet());
-        tracker.activatePrimaryMode(activeLocalCheckpoint);
+        tracker.activatePrimaryMode(activeLocalCheckpoint, NO_OPS_PERFORMED);
+        addPeerRecoveryRetentionLease(tracker, initializing);
         final int nextActiveLocalCheckpoint = randomIntBetween(activeLocalCheckpoint + 1, Integer.MAX_VALUE);
         final Thread activeThread = new Thread(() -> {
             try {
@@ -689,17 +700,19 @@ public void testPrimaryContextHandoff() throws IOException {
         final long globalCheckpoint = UNASSIGNED_SEQ_NO;
         final BiConsumer<RetentionLeases, ActionListener<ReplicationResponse>> onNewRetentionLease =
                 (leases, listener) -> {};
-        ReplicationTracker oldPrimary = new ReplicationTracker(
-                shardId, aId.getId(), indexSettings, primaryTerm, globalCheckpoint, onUpdate, () -> 0L, onNewRetentionLease);
-        ReplicationTracker newPrimary = new ReplicationTracker(
-                shardId, aId.getRelocationId(), indexSettings, primaryTerm, globalCheckpoint, onUpdate, () -> 0L, onNewRetentionLease);
+        ReplicationTracker oldPrimary = new ReplicationTracker(shardId,
+            aId.getId(), indexSettings, primaryTerm, globalCheckpoint, onUpdate, () -> 0L, onNewRetentionLease, Version.CURRENT);
+        ReplicationTracker newPrimary = new ReplicationTracker(shardId,
+            aId.getRelocationId(), indexSettings, primaryTerm, globalCheckpoint, onUpdate, () -> 0L, onNewRetentionLease, Version.CURRENT);
 
         Set<String> allocationIds = new HashSet<>(Arrays.asList(oldPrimary.shardAllocationId, newPrimary.shardAllocationId));
 
         clusterState.apply(oldPrimary);
         clusterState.apply(newPrimary);
 
-        activatePrimary(oldPrimary);
+        oldPrimary.activatePrimaryMode(randomIntBetween(Math.toIntExact(NO_OPS_PERFORMED), 10), NO_OPS_PERFORMED);
+        addPeerRecoveryRetentionLease(oldPrimary, newPrimary.shardAllocationId);
+        newPrimary.updateRetentionLeasesOnReplica(oldPrimary.getRetentionLeases());
 
         final int numUpdates = randomInt(10);
         for (int i = 0; i < numUpdates; i++) {
@@ -712,7 +725,8 @@ public void testPrimaryContextHandoff() throws IOException {
                 randomLocalCheckpointUpdate(oldPrimary);
             }
             if (randomBoolean()) {
-                randomMarkInSync(oldPrimary);
+                randomMarkInSync(oldPrimary, newPrimary);
+                newPrimary.updateRetentionLeasesOnReplica(oldPrimary.getRetentionLeases());
             }
         }
 
@@ -744,7 +758,7 @@ public void testPrimaryContextHandoff() throws IOException {
                 randomLocalCheckpointUpdate(oldPrimary);
             }
             if (randomBoolean()) {
-                randomMarkInSync(oldPrimary);
+                randomMarkInSync(oldPrimary, newPrimary);
             }
 
             // do another handoff
@@ -836,7 +850,7 @@ public void testIllegalStateExceptionIfUnknownAllocationId() {
         final ReplicationTracker tracker = newTracker(active);
         tracker.updateFromMaster(randomNonNegativeLong(), Collections.singleton(active.getId()),
             routingTable(Collections.singleton(initializing), active), emptySet());
-        tracker.activatePrimaryMode(NO_OPS_PERFORMED);
+        tracker.activatePrimaryMode(NO_OPS_PERFORMED, NO_OPS_PERFORMED);
 
         expectThrows(IllegalStateException.class, () -> tracker.initiateTracking(randomAlphaOfLength(10)));
         expectThrows(IllegalStateException.class, () -> tracker.markAllocationIdAsInSync(randomAlphaOfLength(10), randomNonNegativeLong()));
@@ -882,7 +896,10 @@ private static FakeClusterState initialState() {
         final ShardId shardId = new ShardId("test", "_na_", 0);
         final ShardRouting primaryShard =
                 TestShardRouting.newShardRouting(
-                        shardId, randomAlphaOfLength(10), randomAlphaOfLength(10), true, ShardRoutingState.RELOCATING, relocatingId);
+                    shardId,
+                    nodeIdFromAllocationId(relocatingId),
+                    nodeIdFromAllocationId(AllocationId.newInitializing(relocatingId.getRelocationId())),
+                    true, ShardRoutingState.RELOCATING, relocatingId);
 
         return new FakeClusterState(
                 initialClusterStateVersion,
@@ -890,20 +907,17 @@ private static FakeClusterState initialState() {
                 routingTable(initializingAllocationIds, primaryShard));
     }
 
-    private static void activatePrimary(ReplicationTracker gcp) {
-        gcp.activatePrimaryMode(randomIntBetween(Math.toIntExact(NO_OPS_PERFORMED), 10));
-    }
-
     private static void randomLocalCheckpointUpdate(ReplicationTracker gcp) {
         String allocationId = randomFrom(gcp.checkpoints.keySet());
         long currentLocalCheckpoint = gcp.checkpoints.get(allocationId).getLocalCheckpoint();
         gcp.updateLocalCheckpoint(allocationId, Math.max(SequenceNumbers.NO_OPS_PERFORMED, currentLocalCheckpoint + randomInt(5)));
     }
 
-    private static void randomMarkInSync(ReplicationTracker gcp) {
-        String allocationId = randomFrom(gcp.checkpoints.keySet());
-        long newLocalCheckpoint = Math.max(NO_OPS_PERFORMED, gcp.getGlobalCheckpoint() + randomInt(5));
-        markAsTrackingAndInSyncQuietly(gcp, allocationId, newLocalCheckpoint);
+    private static void randomMarkInSync(ReplicationTracker oldTracker, ReplicationTracker newTracker) {
+        String allocationId = randomFrom(oldTracker.checkpoints.keySet());
+        long newLocalCheckpoint = Math.max(NO_OPS_PERFORMED, oldTracker.getGlobalCheckpoint() + randomInt(5));
+        markAsTrackingAndInSyncQuietly(oldTracker, allocationId, newLocalCheckpoint);
+        newTracker.updateRetentionLeasesOnReplica(oldTracker.getRetentionLeases());
     }
 
     private static FakeClusterState randomUpdateClusterState(Set<String> allocationIds, FakeClusterState clusterState) {
@@ -914,11 +928,14 @@ private static FakeClusterState randomUpdateClusterState(Set<String> allocationI
         final Set<AllocationId> inSyncIdsToRemove = new HashSet<>(
             exclude(randomSubsetOf(randomInt(clusterState.inSyncIds.size()), clusterState.inSyncIds), allocationIds));
         final Set<AllocationId> remainingInSyncIds = Sets.difference(clusterState.inSyncIds, inSyncIdsToRemove);
+        final Set<AllocationId> initializingIdsExceptRelocationTargets = exclude(clusterState.initializingIds(),
+            clusterState.routingTable.activeShards().stream().filter(ShardRouting::relocating)
+                .map(s -> s.allocationId().getRelocationId()).collect(Collectors.toSet()));
         return new FakeClusterState(
                 clusterState.version + randomIntBetween(1, 5),
                 remainingInSyncIds.isEmpty() ? clusterState.inSyncIds : remainingInSyncIds,
                 routingTable(
-                        Sets.difference(Sets.union(clusterState.initializingIds(), initializingIdsToAdd), initializingIdsToRemove),
+                        Sets.difference(Sets.union(initializingIdsExceptRelocationTargets, initializingIdsToAdd), initializingIdsToRemove),
                         clusterState.routingTable.primaryShard()));
     }
 
@@ -951,6 +968,7 @@ private static FakeClusterState randomUpdateClusterState(Set<String> allocationI
     private static void markAsTrackingAndInSyncQuietly(
         final ReplicationTracker tracker, final String allocationId, final long localCheckpoint) {
         try {
+            addPeerRecoveryRetentionLease(tracker, allocationId);
             tracker.initiateTracking(allocationId);
             tracker.markAllocationIdAsInSync(allocationId, localCheckpoint);
         } catch (final InterruptedException e) {
@@ -958,4 +976,14 @@ private static void markAsTrackingAndInSyncQuietly(
         }
     }
 
+    private static void addPeerRecoveryRetentionLease(final ReplicationTracker tracker, final AllocationId allocationId) {
+        final String nodeId = nodeIdFromAllocationId(allocationId);
+        if (tracker.getRetentionLeases().contains(ReplicationTracker.getPeerRecoveryRetentionLeaseId(nodeId)) == false) {
+            tracker.addPeerRecoveryRetentionLease(nodeId, 0, ActionListener.wrap(() -> { }));
+        }
+    }
+
+    private static void addPeerRecoveryRetentionLease(final ReplicationTracker tracker, final String allocationId) {
+        addPeerRecoveryRetentionLease(tracker, AllocationId.newInitializing(allocationId));
+    }
 }
diff --git a/server/src/test/java/org/elasticsearch/index/seqno/RetentionLeaseActionsTests.java b/server/src/test/java/org/elasticsearch/index/seqno/RetentionLeaseActionsTests.java
index bff449332128..434c37212fe1 100644
--- a/server/src/test/java/org/elasticsearch/index/seqno/RetentionLeaseActionsTests.java
+++ b/server/src/test/java/org/elasticsearch/index/seqno/RetentionLeaseActionsTests.java
@@ -36,17 +36,25 @@
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 import java.util.function.BiConsumer;
+import java.util.stream.Collectors;
 
 import static org.elasticsearch.index.seqno.RetentionLeaseActions.RETAIN_ALL;
 import static org.hamcrest.Matchers.arrayWithSize;
+import static org.hamcrest.Matchers.containsInAnyOrder;
 import static org.hamcrest.Matchers.containsString;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.greaterThan;
 import static org.hamcrest.Matchers.hasSize;
 import static org.hamcrest.Matchers.hasToString;
+import static org.hamcrest.Matchers.contains;
 
 public class RetentionLeaseActionsTests extends ESSingleNodeTestCase {
 
+    private String getPeerRecoveryRetentionLeaseId() {
+        return ReplicationTracker.getPeerRecoveryRetentionLeaseId(
+            client().admin().cluster().prepareState().get().getState().nodes().getLocalNodeId());
+    }
+
     public void testAddAction() {
         final Settings settings = Settings.builder()
                 .put("index.number_of_shards", 1)
@@ -73,8 +81,13 @@ public void testAddAction() {
         assertNotNull(stats.getShards());
         assertThat(stats.getShards(), arrayWithSize(1));
         assertNotNull(stats.getShards()[0].getRetentionLeaseStats());
-        assertThat(stats.getShards()[0].getRetentionLeaseStats().retentionLeases().leases(), hasSize(1));
-        final RetentionLease retentionLease = stats.getShards()[0].getRetentionLeaseStats().retentionLeases().leases().iterator().next();
+
+        final RetentionLeases retentionLeases = stats.getShards()[0].getRetentionLeaseStats().retentionLeases();
+        assertThat(retentionLeases.leases(), hasSize(2));
+        assertThat(retentionLeases.leases().stream().map(RetentionLease::id).collect(Collectors.toList()),
+            containsInAnyOrder(id, getPeerRecoveryRetentionLeaseId()));
+
+        final RetentionLease retentionLease = retentionLeases.get(id);
         assertThat(retentionLease.id(), equalTo(id));
         assertThat(retentionLease.retainingSequenceNumber(), equalTo(retainingSequenceNumber == RETAIN_ALL ? 0L : retainingSequenceNumber));
         assertThat(retentionLease.source(), equalTo(source));
@@ -160,9 +173,13 @@ public void testRenewAction() throws InterruptedException {
         assertNotNull(initialStats.getShards());
         assertThat(initialStats.getShards(), arrayWithSize(1));
         assertNotNull(initialStats.getShards()[0].getRetentionLeaseStats());
-        assertThat(initialStats.getShards()[0].getRetentionLeaseStats().retentionLeases().leases(), hasSize(1));
-        final RetentionLease initialRetentionLease =
-                initialStats.getShards()[0].getRetentionLeaseStats().retentionLeases().leases().iterator().next();
+
+        final RetentionLeases initialRetentionLeases = initialStats.getShards()[0].getRetentionLeaseStats().retentionLeases();
+        assertThat(initialRetentionLeases.leases(), hasSize(2));
+        assertThat(initialRetentionLeases.leases().stream().map(RetentionLease::id).collect(Collectors.toList()),
+            containsInAnyOrder(id, getPeerRecoveryRetentionLeaseId()));
+
+        final RetentionLease initialRetentionLease = initialRetentionLeases.get(id);
 
         final long nextRetainingSequenceNumber =
                 retainingSequenceNumber == RETAIN_ALL && randomBoolean() ? RETAIN_ALL
@@ -195,9 +212,11 @@ public void testRenewAction() throws InterruptedException {
         assertNotNull(renewedStats.getShards());
         assertThat(renewedStats.getShards(), arrayWithSize(1));
         assertNotNull(renewedStats.getShards()[0].getRetentionLeaseStats());
-        assertThat(renewedStats.getShards()[0].getRetentionLeaseStats().retentionLeases().leases(), hasSize(1));
-        final RetentionLease renewedRetentionLease =
-                renewedStats.getShards()[0].getRetentionLeaseStats().retentionLeases().leases().iterator().next();
+        final RetentionLeases renewedRetentionLeases = renewedStats.getShards()[0].getRetentionLeaseStats().retentionLeases();
+        assertThat(renewedRetentionLeases.leases(), hasSize(2));
+        assertThat(renewedRetentionLeases.leases().stream().map(RetentionLease::id).collect(Collectors.toList()),
+            containsInAnyOrder(id, getPeerRecoveryRetentionLeaseId()));
+        final RetentionLease renewedRetentionLease = renewedRetentionLeases.get(id);
         assertThat(renewedRetentionLease.id(), equalTo(id));
         assertThat(
                 renewedRetentionLease.retainingSequenceNumber(),
@@ -265,7 +284,10 @@ public void testRemoveAction() {
         assertNotNull(stats.getShards());
         assertThat(stats.getShards(), arrayWithSize(1));
         assertNotNull(stats.getShards()[0].getRetentionLeaseStats());
-        assertThat(stats.getShards()[0].getRetentionLeaseStats().retentionLeases().leases(), hasSize(0));
+        final RetentionLeases retentionLeases = stats.getShards()[0].getRetentionLeaseStats().retentionLeases();
+        assertThat(retentionLeases.leases(), hasSize(1));
+        assertThat(retentionLeases.leases().stream().map(RetentionLease::id).collect(Collectors.toList()),
+            contains(getPeerRecoveryRetentionLeaseId()));
     }
 
     public void testRemoveNotFound() {
@@ -328,8 +350,13 @@ public void onFailure(final Exception e) {
         assertNotNull(stats.getShards());
         assertThat(stats.getShards(), arrayWithSize(1));
         assertNotNull(stats.getShards()[0].getRetentionLeaseStats());
-        assertThat(stats.getShards()[0].getRetentionLeaseStats().retentionLeases().leases(), hasSize(1));
-        final RetentionLease retentionLease = stats.getShards()[0].getRetentionLeaseStats().retentionLeases().leases().iterator().next();
+
+        final RetentionLeases retentionLeases = stats.getShards()[0].getRetentionLeaseStats().retentionLeases();
+        assertThat(retentionLeases.leases(), hasSize(2));
+        assertThat(retentionLeases.leases().stream().map(RetentionLease::id).collect(Collectors.toList()),
+            containsInAnyOrder(id, getPeerRecoveryRetentionLeaseId()));
+
+        final RetentionLease retentionLease = retentionLeases.get(id);
         assertThat(retentionLease.id(), equalTo(id));
         assertThat(retentionLease.retainingSequenceNumber(), equalTo(retainingSequenceNumber == RETAIN_ALL ? 0L : retainingSequenceNumber));
         assertThat(retentionLease.source(), equalTo(source));
@@ -378,9 +405,13 @@ public void testRenewUnderBlock() throws InterruptedException {
         assertNotNull(initialStats.getShards());
         assertThat(initialStats.getShards(), arrayWithSize(1));
         assertNotNull(initialStats.getShards()[0].getRetentionLeaseStats());
-        assertThat(initialStats.getShards()[0].getRetentionLeaseStats().retentionLeases().leases(), hasSize(1));
-        final RetentionLease initialRetentionLease =
-                initialStats.getShards()[0].getRetentionLeaseStats().retentionLeases().leases().iterator().next();
+
+        final RetentionLeases initialRetentionLeases = initialStats.getShards()[0].getRetentionLeaseStats().retentionLeases();
+        assertThat(initialRetentionLeases.leases(), hasSize(2));
+        assertThat(initialRetentionLeases.leases().stream().map(RetentionLease::id).collect(Collectors.toList()),
+            containsInAnyOrder(id, getPeerRecoveryRetentionLeaseId()));
+
+        final RetentionLease initialRetentionLease = initialRetentionLeases.get(id);
 
         final long nextRetainingSequenceNumber =
                 retainingSequenceNumber == RETAIN_ALL && randomBoolean() ? RETAIN_ALL
@@ -427,9 +458,11 @@ public void onFailure(final Exception e) {
         assertNotNull(renewedStats.getShards());
         assertThat(renewedStats.getShards(), arrayWithSize(1));
         assertNotNull(renewedStats.getShards()[0].getRetentionLeaseStats());
-        assertThat(renewedStats.getShards()[0].getRetentionLeaseStats().retentionLeases().leases(), hasSize(1));
-        final RetentionLease renewedRetentionLease =
-                renewedStats.getShards()[0].getRetentionLeaseStats().retentionLeases().leases().iterator().next();
+        final RetentionLeases renewedRetentionLeases = renewedStats.getShards()[0].getRetentionLeaseStats().retentionLeases();
+        assertThat(renewedRetentionLeases.leases(), hasSize(2));
+        assertThat(renewedRetentionLeases.leases().stream().map(RetentionLease::id).collect(Collectors.toList()),
+            containsInAnyOrder(id, getPeerRecoveryRetentionLeaseId()));
+        final RetentionLease renewedRetentionLease = renewedRetentionLeases.get(id);
         assertThat(renewedRetentionLease.id(), equalTo(id));
         assertThat(
                 renewedRetentionLease.retainingSequenceNumber(),
@@ -484,7 +517,10 @@ public void onFailure(final Exception e) {
         assertNotNull(stats.getShards());
         assertThat(stats.getShards(), arrayWithSize(1));
         assertNotNull(stats.getShards()[0].getRetentionLeaseStats());
-        assertThat(stats.getShards()[0].getRetentionLeaseStats().retentionLeases().leases(), hasSize(0));
+        final RetentionLeases retentionLeases = stats.getShards()[0].getRetentionLeaseStats().retentionLeases();
+        assertThat(retentionLeases.leases(), hasSize(1));
+        assertThat(retentionLeases.leases().stream().map(RetentionLease::id).collect(Collectors.toList()),
+            contains(getPeerRecoveryRetentionLeaseId()));
     }
 
     /*
diff --git a/server/src/test/java/org/elasticsearch/index/seqno/RetentionLeaseIT.java b/server/src/test/java/org/elasticsearch/index/seqno/RetentionLeaseIT.java
index 4839844781e1..53f98334258e 100644
--- a/server/src/test/java/org/elasticsearch/index/seqno/RetentionLeaseIT.java
+++ b/server/src/test/java/org/elasticsearch/index/seqno/RetentionLeaseIT.java
@@ -57,12 +57,14 @@
 import java.util.stream.Collectors;
 import java.util.stream.Stream;
 
+import static org.elasticsearch.index.seqno.RetentionLeases.toMapExcludingPeerRecoveryRetentionLeases;
 import static org.elasticsearch.indices.recovery.RecoverySettings.INDICES_RECOVERY_RETRY_DELAY_NETWORK_SETTING;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
 import static org.hamcrest.Matchers.anyOf;
 import static org.hamcrest.Matchers.contains;
 import static org.hamcrest.Matchers.empty;
 import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.hasItem;
 
 @ESIntegTestCase.ClusterScope(scope = ESIntegTestCase.Scope.TEST)
 public class RetentionLeaseIT extends ESIntegTestCase  {
@@ -115,7 +117,7 @@ public void testRetentionLeasesSyncedOnAdd() throws Exception {
             retentionLock.close();
 
             // check retention leases have been written on the primary
-            assertThat(currentRetentionLeases, equalTo(RetentionLeases.toMap(primary.loadRetentionLeases())));
+            assertThat(currentRetentionLeases, equalTo(toMapExcludingPeerRecoveryRetentionLeases(primary.loadRetentionLeases())));
 
             // check current retention leases have been synced to all replicas
             for (final ShardRouting replicaShard : clusterService().state().routingTable().index("index").shard(0).replicaShards()) {
@@ -124,11 +126,10 @@ public void testRetentionLeasesSyncedOnAdd() throws Exception {
                 final IndexShard replica = internalCluster()
                         .getInstance(IndicesService.class, replicaShardNodeName)
                         .getShardOrNull(new ShardId(resolveIndex("index"), 0));
-                final Map<String, RetentionLease> retentionLeasesOnReplica = RetentionLeases.toMap(replica.getRetentionLeases());
-                assertThat(retentionLeasesOnReplica, equalTo(currentRetentionLeases));
+                assertThat(toMapExcludingPeerRecoveryRetentionLeases(replica.getRetentionLeases()), equalTo(currentRetentionLeases));
 
                 // check retention leases have been written on the replica
-                assertThat(currentRetentionLeases, equalTo(RetentionLeases.toMap(replica.loadRetentionLeases())));
+                assertThat(currentRetentionLeases, equalTo(toMapExcludingPeerRecoveryRetentionLeases(replica.loadRetentionLeases())));
             }
         }
     }
@@ -173,7 +174,7 @@ public void testRetentionLeaseSyncedOnRemove() throws Exception {
             retentionLock.close();
 
             // check retention leases have been written on the primary
-            assertThat(currentRetentionLeases, equalTo(RetentionLeases.toMap(primary.loadRetentionLeases())));
+            assertThat(currentRetentionLeases, equalTo(toMapExcludingPeerRecoveryRetentionLeases(primary.loadRetentionLeases())));
 
             // check current retention leases have been synced to all replicas
             for (final ShardRouting replicaShard : clusterService().state().routingTable().index("index").shard(0).replicaShards()) {
@@ -182,11 +183,10 @@ public void testRetentionLeaseSyncedOnRemove() throws Exception {
                 final IndexShard replica = internalCluster()
                         .getInstance(IndicesService.class, replicaShardNodeName)
                         .getShardOrNull(new ShardId(resolveIndex("index"), 0));
-                final Map<String, RetentionLease> retentionLeasesOnReplica = RetentionLeases.toMap(replica.getRetentionLeases());
-                assertThat(retentionLeasesOnReplica, equalTo(currentRetentionLeases));
+                assertThat(toMapExcludingPeerRecoveryRetentionLeases(replica.getRetentionLeases()), equalTo(currentRetentionLeases));
 
                 // check retention leases have been written on the replica
-                assertThat(currentRetentionLeases, equalTo(RetentionLeases.toMap(replica.loadRetentionLeases())));
+                assertThat(currentRetentionLeases, equalTo(toMapExcludingPeerRecoveryRetentionLeases(replica.loadRetentionLeases())));
             }
         }
     }
@@ -239,7 +239,8 @@ public void testRetentionLeasesSyncOnExpiration() throws Exception {
                 final IndexShard replica = internalCluster()
                         .getInstance(IndicesService.class, replicaShardNodeName)
                         .getShardOrNull(new ShardId(resolveIndex("index"), 0));
-                assertThat(replica.getRetentionLeases().leases(), anyOf(empty(), contains(currentRetentionLease)));
+                assertThat(toMapExcludingPeerRecoveryRetentionLeases(replica.getRetentionLeases()).keySet(),
+                    anyOf(empty(), contains(currentRetentionLease.id())));
             }
 
             // update the index for retention leases to short a long time, to force expiration
@@ -256,7 +257,7 @@ public void testRetentionLeasesSyncOnExpiration() throws Exception {
             // sleep long enough that the current retention lease has expired
             final long later = System.nanoTime();
             Thread.sleep(Math.max(0, retentionLeaseTimeToLive.millis() - TimeUnit.NANOSECONDS.toMillis(later - now)));
-            assertBusy(() -> assertThat(primary.getRetentionLeases().leases(), empty()));
+            assertBusy(() -> assertThat(toMapExcludingPeerRecoveryRetentionLeases(primary.getRetentionLeases()).entrySet(), empty()));
 
             // now that all retention leases are expired should have been synced to all replicas
             assertBusy(() -> {
@@ -266,7 +267,7 @@ public void testRetentionLeasesSyncOnExpiration() throws Exception {
                     final IndexShard replica = internalCluster()
                             .getInstance(IndicesService.class, replicaShardNodeName)
                             .getShardOrNull(new ShardId(resolveIndex("index"), 0));
-                    assertThat(replica.getRetentionLeases().leases(), empty());
+                    assertThat(toMapExcludingPeerRecoveryRetentionLeases(replica.getRetentionLeases()).entrySet(), empty());
                 }
             });
         }
@@ -427,11 +428,10 @@ public void testRetentionLeasesSyncOnRecovery() throws Exception {
             final IndexShard replica = internalCluster()
                     .getInstance(IndicesService.class, replicaShardNodeName)
                     .getShardOrNull(new ShardId(resolveIndex("index"), 0));
-            final Map<String, RetentionLease> retentionLeasesOnReplica = RetentionLeases.toMap(replica.getRetentionLeases());
-            assertThat(retentionLeasesOnReplica, equalTo(currentRetentionLeases));
+            assertThat(toMapExcludingPeerRecoveryRetentionLeases(replica.getRetentionLeases()), equalTo(currentRetentionLeases));
 
             // check retention leases have been written on the replica; see RecoveryTarget#finalizeRecovery
-            assertThat(currentRetentionLeases, equalTo(RetentionLeases.toMap(replica.loadRetentionLeases())));
+            assertThat(currentRetentionLeases, equalTo(toMapExcludingPeerRecoveryRetentionLeases(replica.loadRetentionLeases())));
         }
     }
 
@@ -469,7 +469,7 @@ public void testCanRenewRetentionLeaseUnderBlock() throws InterruptedException {
                          * way for the current retention leases to end up written to disk so we assume that if they are written to disk, it
                          * implies that the background sync was able to execute under a block.
                          */
-                        assertBusy(() -> assertThat(primary.loadRetentionLeases().leases(), contains(retentionLease.get())));
+                        assertBusy(() -> assertThat(primary.loadRetentionLeases().leases(), hasItem(retentionLease.get())));
                     } catch (final Exception e) {
                         fail(e.toString());
                     }
@@ -588,7 +588,7 @@ public void testCanRenewRetentionLeaseWithoutWaitingForShards() throws Interrupt
                          * way for the current retention leases to end up written to disk so we assume that if they are written to disk, it
                          * implies that the background sync was able to execute despite wait for shards being set on the index.
                          */
-                        assertBusy(() -> assertThat(primary.loadRetentionLeases().leases(), contains(retentionLease.get())));
+                        assertBusy(() -> assertThat(primary.loadRetentionLeases().leases(), hasItem(retentionLease.get())));
                     } catch (final Exception e) {
                         fail(e.toString());
                     }
diff --git a/server/src/test/java/org/elasticsearch/index/seqno/RetentionLeaseStatsTests.java b/server/src/test/java/org/elasticsearch/index/seqno/RetentionLeaseStatsTests.java
index adacf6539a80..81bcfff284a7 100644
--- a/server/src/test/java/org/elasticsearch/index/seqno/RetentionLeaseStatsTests.java
+++ b/server/src/test/java/org/elasticsearch/index/seqno/RetentionLeaseStatsTests.java
@@ -33,6 +33,7 @@
 import java.util.Map;
 import java.util.concurrent.CountDownLatch;
 
+import static org.elasticsearch.index.seqno.RetentionLeases.toMapExcludingPeerRecoveryRetentionLeases;
 import static org.hamcrest.Matchers.arrayWithSize;
 import static org.hamcrest.Matchers.equalTo;
 
@@ -63,7 +64,6 @@ public void testRetentionLeaseStats() throws InterruptedException {
         final IndicesStatsResponse indicesStats = client().admin().indices().prepareStats("index").execute().actionGet();
         assertThat(indicesStats.getShards(), arrayWithSize(1));
         final RetentionLeaseStats retentionLeaseStats = indicesStats.getShards()[0].getRetentionLeaseStats();
-        assertThat(RetentionLeases.toMap(retentionLeaseStats.retentionLeases()), equalTo(currentRetentionLeases));
+        assertThat(toMapExcludingPeerRecoveryRetentionLeases(retentionLeaseStats.retentionLeases()), equalTo(currentRetentionLeases));
     }
-
 }
diff --git a/server/src/test/java/org/elasticsearch/index/shard/IndexShardIT.java b/server/src/test/java/org/elasticsearch/index/shard/IndexShardIT.java
index 78d442891153..0f57f589aa38 100644
--- a/server/src/test/java/org/elasticsearch/index/shard/IndexShardIT.java
+++ b/server/src/test/java/org/elasticsearch/index/shard/IndexShardIT.java
@@ -669,7 +669,8 @@ public static final IndexShard newIndexShard(
                 Arrays.asList(listeners),
                 () -> {},
                 RetentionLeaseSyncer.EMPTY,
-                cbs);
+                cbs,
+                l -> {});
     }
 
     private static ShardRouting getInitializingShardRouting(ShardRouting existingShardRouting) {
diff --git a/server/src/test/java/org/elasticsearch/index/shard/IndexShardRetentionLeaseTests.java b/server/src/test/java/org/elasticsearch/index/shard/IndexShardRetentionLeaseTests.java
index 974e060bf252..a6a5007bea75 100644
--- a/server/src/test/java/org/elasticsearch/index/shard/IndexShardRetentionLeaseTests.java
+++ b/server/src/test/java/org/elasticsearch/index/shard/IndexShardRetentionLeaseTests.java
@@ -27,6 +27,7 @@
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.index.IndexSettings;
 import org.elasticsearch.index.engine.InternalEngineFactory;
+import org.elasticsearch.index.seqno.ReplicationTracker;
 import org.elasticsearch.index.seqno.RetentionLease;
 import org.elasticsearch.index.seqno.RetentionLeaseStats;
 import org.elasticsearch.index.seqno.RetentionLeases;
@@ -35,12 +36,14 @@
 import org.elasticsearch.threadpool.ThreadPool;
 
 import java.io.IOException;
-import java.util.Collections;
+import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicLong;
 
+import static org.elasticsearch.index.seqno.ReplicationTracker.PEER_RECOVERY_RETENTION_LEASE_SOURCE;
+import static org.elasticsearch.index.seqno.ReplicationTracker.getPeerRecoveryRetentionLeaseId;
 import static org.hamcrest.Matchers.contains;
 import static org.hamcrest.Matchers.empty;
 import static org.hamcrest.Matchers.equalTo;
@@ -73,7 +76,7 @@ public void testAddOrRenewRetentionLease() throws IOException {
                 indexShard.addRetentionLease(
                         Integer.toString(i), minimumRetainingSequenceNumbers[i], "test-" + i, ActionListener.wrap(() -> {}));
                 assertRetentionLeases(
-                        indexShard, i + 1, minimumRetainingSequenceNumbers, primaryTerm, 1 + i, true, false);
+                        indexShard, i + 1, minimumRetainingSequenceNumbers, primaryTerm, 2 + i, true, false);
             }
 
             for (int i = 0; i < length; i++) {
@@ -84,7 +87,7 @@ public void testAddOrRenewRetentionLease() throws IOException {
                         length,
                         minimumRetainingSequenceNumbers,
                         primaryTerm,
-                        1 + length + i,
+                        2 + length + i,
                         true,
                         false);
             }
@@ -105,7 +108,7 @@ public void testRemoveRetentionLease() throws IOException {
                 indexShard.addRetentionLease(
                         Integer.toString(i), minimumRetainingSequenceNumbers[i], "test-" + i, ActionListener.wrap(() -> {}));
                 assertRetentionLeases(
-                        indexShard, i + 1, minimumRetainingSequenceNumbers, primaryTerm, 1 + i, true, false);
+                        indexShard, i + 1, minimumRetainingSequenceNumbers, primaryTerm, 2 + i, true, false);
             }
 
             for (int i = 0; i < length; i++) {
@@ -115,7 +118,7 @@ public void testRemoveRetentionLease() throws IOException {
                         length - i - 1,
                         minimumRetainingSequenceNumbers,
                         primaryTerm,
-                        1 + length + i,
+                        2 + length + i,
                         true,
                         false);
             }
@@ -132,6 +135,11 @@ public void testExpirationOnReplica() throws IOException {
         runExpirationTest(false);
     }
 
+    private RetentionLease peerRecoveryRetentionLease(IndexShard indexShard) {
+        return new RetentionLease(
+            getPeerRecoveryRetentionLeaseId(indexShard.routingEntry()), 0, currentTimeMillis.get(), PEER_RECOVERY_RETENTION_LEASE_SOURCE);
+    }
+
     private void runExpirationTest(final boolean primary) throws IOException {
         final long retentionLeaseMillis = randomLongBetween(1, TimeValue.timeValueHours(12).millis());
         final Settings settings = Settings
@@ -147,23 +155,29 @@ private void runExpirationTest(final boolean primary) throws IOException {
         try {
             final long[] retainingSequenceNumbers = new long[1];
             retainingSequenceNumbers[0] = randomLongBetween(0, Long.MAX_VALUE);
+            final long initialVersion;
             if (primary) {
                 indexShard.addRetentionLease("0", retainingSequenceNumbers[0], "test-0", ActionListener.wrap(() -> {}));
+                initialVersion = 2;
             } else {
+                assertRetentionLeases(indexShard, 0, new long[0], primaryTerm, 2, false, false);
+                initialVersion = 3;
                 final RetentionLeases retentionLeases = new RetentionLeases(
                         primaryTerm,
-                        1,
-                        Collections.singleton(new RetentionLease("0", retainingSequenceNumbers[0], currentTimeMillis.get(), "test-0")));
+                        initialVersion,
+                        Arrays.asList(peerRecoveryRetentionLease(indexShard), // add a fake peer-recovery retention lease for this shard
+                            new RetentionLease("0", retainingSequenceNumbers[0], currentTimeMillis.get(), "test-0")));
                 indexShard.updateRetentionLeasesOnReplica(retentionLeases);
             }
 
             {
                 final RetentionLeases retentionLeases = indexShard.getEngine().config().retentionLeasesSupplier().get();
-                assertThat(retentionLeases.version(), equalTo(1L));
-                assertThat(retentionLeases.leases(), hasSize(1));
-                final RetentionLease retentionLease = retentionLeases.leases().iterator().next();
+                assertThat(retentionLeases.version(), equalTo(initialVersion));
+                assertThat(retentionLeases.leases(), hasSize(2));
+                logger.info("retentionLeases = {}", retentionLeases);
+                final RetentionLease retentionLease = retentionLeases.get("0");
                 assertThat(retentionLease.timestamp(), equalTo(currentTimeMillis.get()));
-                assertRetentionLeases(indexShard, 1, retainingSequenceNumbers, primaryTerm, 1, primary, false);
+                assertRetentionLeases(indexShard, 1, retainingSequenceNumbers, primaryTerm, initialVersion, primary, false);
             }
 
             // renew the lease
@@ -174,28 +188,29 @@ private void runExpirationTest(final boolean primary) throws IOException {
             } else {
                 final RetentionLeases retentionLeases = new RetentionLeases(
                         primaryTerm,
-                        2,
-                        Collections.singleton(new RetentionLease("0", retainingSequenceNumbers[0], currentTimeMillis.get(), "test-0")));
+                        initialVersion + 1,
+                        Arrays.asList(peerRecoveryRetentionLease(indexShard), // add a fake peer-recovery retention lease for this shard
+                            new RetentionLease("0", retainingSequenceNumbers[0], currentTimeMillis.get(), "test-0")));
                 indexShard.updateRetentionLeasesOnReplica(retentionLeases);
             }
 
             {
                 final RetentionLeases retentionLeases = indexShard.getEngine().config().retentionLeasesSupplier().get();
-                assertThat(retentionLeases.version(), equalTo(2L));
-                assertThat(retentionLeases.leases(), hasSize(1));
-                final RetentionLease retentionLease = retentionLeases.leases().iterator().next();
+                assertThat(retentionLeases.version(), equalTo(initialVersion + 1));
+                assertThat(retentionLeases.leases(), hasSize(2));
+                final RetentionLease retentionLease = retentionLeases.get("0");
                 assertThat(retentionLease.timestamp(), equalTo(currentTimeMillis.get()));
-                assertRetentionLeases(indexShard, 1, retainingSequenceNumbers, primaryTerm, 2, primary, false);
+                assertRetentionLeases(indexShard, 1, retainingSequenceNumbers, primaryTerm, initialVersion + 1, primary, false);
             }
 
             // now force the lease to expire
             currentTimeMillis.set(
                     currentTimeMillis.get() + randomLongBetween(retentionLeaseMillis, Long.MAX_VALUE - currentTimeMillis.get()));
             if (primary) {
-                assertRetentionLeases(indexShard, 1, retainingSequenceNumbers, primaryTerm, 2, true, false);
-                assertRetentionLeases(indexShard, 0, new long[0], primaryTerm, 3, true, true);
+                assertRetentionLeases(indexShard, 1, retainingSequenceNumbers, primaryTerm, initialVersion + 1, true, false);
+                assertRetentionLeases(indexShard, 0, new long[0], primaryTerm, initialVersion + 2, true, true);
             } else {
-                assertRetentionLeases(indexShard, 1, retainingSequenceNumbers, primaryTerm, 2, false, false);
+                assertRetentionLeases(indexShard, 1, retainingSequenceNumbers, primaryTerm, initialVersion + 1, false, false);
             }
         } finally {
             closeShards(indexShard);
@@ -233,8 +248,8 @@ public void testPersistence() throws IOException {
                 assertThat(writtenRetentionLeases.version(), equalTo(0L));
                 assertThat(writtenRetentionLeases.leases(), empty());
             } else {
-                assertThat(writtenRetentionLeases.version(), equalTo((long) length));
-                assertThat(retentionLeases.leases(), contains(retentionLeases.leases().toArray(new RetentionLease[0])));
+                assertThat(writtenRetentionLeases.version(), equalTo(length + 1L));
+                assertThat(writtenRetentionLeases.leases(), contains(retentionLeases.leases().toArray(new RetentionLease[0])));
             }
 
             // when we recover, we should recover the retention leases
@@ -248,7 +263,7 @@ public void testPersistence() throws IOException {
                     assertThat(recoveredRetentionLeases.version(), equalTo(0L));
                     assertThat(recoveredRetentionLeases.leases(), empty());
                 } else {
-                    assertThat(recoveredRetentionLeases.version(), equalTo((long) length));
+                    assertThat(recoveredRetentionLeases.version(), equalTo(length + 1L));
                     assertThat(
                             recoveredRetentionLeases.leases(),
                             contains(retentionLeases.leases().toArray(new RetentionLease[0])));
@@ -265,8 +280,10 @@ public void testPersistence() throws IOException {
             try {
                 recoverShardFromStore(forceRecoveredShard);
                 final RetentionLeases recoveredRetentionLeases = forceRecoveredShard.getEngine().config().retentionLeasesSupplier().get();
-                assertThat(recoveredRetentionLeases.leases(), empty());
-                assertThat(recoveredRetentionLeases.version(), equalTo(0L));
+                assertThat(recoveredRetentionLeases.version(), equalTo(1L));
+                assertThat(recoveredRetentionLeases.leases(), hasSize(1));
+                assertThat(recoveredRetentionLeases.leases().iterator().next().id(),
+                    equalTo(ReplicationTracker.getPeerRecoveryRetentionLeaseId(indexShard.shardRouting)));
             } finally {
                 closeShards(forceRecoveredShard);
             }
@@ -291,8 +308,8 @@ public void testRetentionLeaseStats() throws IOException {
                     stats.retentionLeases(),
                     length,
                     minimumRetainingSequenceNumbers,
-                    length == 0 ? RetentionLeases.EMPTY.primaryTerm() : indexShard.getOperationPrimaryTerm(),
-                    length);
+                    indexShard.getOperationPrimaryTerm(),
+                    length + 1);
         } finally {
             closeShards(indexShard);
         }
@@ -355,7 +372,9 @@ private void assertRetentionLeases(
         assertThat(retentionLeases.version(), equalTo(version));
         final Map<String, RetentionLease> idToRetentionLease = new HashMap<>();
         for (final RetentionLease retentionLease : retentionLeases.leases()) {
-            idToRetentionLease.put(retentionLease.id(), retentionLease);
+            if (PEER_RECOVERY_RETENTION_LEASE_SOURCE.equals(retentionLease.source()) == false) {
+                idToRetentionLease.put(retentionLease.id(), retentionLease);
+            }
         }
 
         assertThat(idToRetentionLease.entrySet(), hasSize(size));
diff --git a/server/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java b/server/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
index 8e25f85ce5c9..62f76b55a3e0 100644
--- a/server/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
+++ b/server/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
@@ -84,7 +84,6 @@
 import org.elasticsearch.index.engine.Engine.DeleteResult;
 import org.elasticsearch.index.engine.EngineException;
 import org.elasticsearch.index.engine.EngineTestCase;
-import org.elasticsearch.index.engine.InternalEngine;
 import org.elasticsearch.index.engine.InternalEngineFactory;
 import org.elasticsearch.index.engine.Segment;
 import org.elasticsearch.index.engine.SegmentsStats;
@@ -101,6 +100,8 @@
 import org.elasticsearch.index.mapper.SourceToParse;
 import org.elasticsearch.index.mapper.Uid;
 import org.elasticsearch.index.mapper.VersionFieldMapper;
+import org.elasticsearch.index.seqno.ReplicationTracker;
+import org.elasticsearch.index.seqno.RetentionLease;
 import org.elasticsearch.index.seqno.RetentionLeaseSyncer;
 import org.elasticsearch.index.seqno.RetentionLeases;
 import org.elasticsearch.index.seqno.SeqNoStats;
@@ -125,6 +126,8 @@
 import org.elasticsearch.test.FieldMaskingReader;
 import org.elasticsearch.test.VersionUtils;
 import org.elasticsearch.threadpool.ThreadPool;
+import org.elasticsearch.threadpool.ThreadPool.Names;
+import org.junit.Assert;
 
 import java.io.IOException;
 import java.nio.charset.Charset;
@@ -2797,6 +2800,29 @@ public void testDocStats() throws Exception {
             flushRequest.waitIfOngoing(false);
             indexShard.flush(flushRequest);
 
+            if (indexShard.indexSettings.isSoftDeleteEnabled()) {
+                // We still retain the deletes because of the peer-recovery retention lease - need to update the lease and flush again
+                if (indexShard.routingEntry().primary()) {
+                    indexShard.runUnderPrimaryPermit(
+                        indexShard::renewPeerRecoveryRetentionLeaseForPrimary, Assert::assertNull, Names.SAME, "");
+                } else {
+                    final RetentionLeases retentionLeases = indexShard.getRetentionLeases();
+                    final long localCheckpointOfSafeCommit = indexShard.getLocalCheckpointOfSafeCommit();
+                    indexShard.updateRetentionLeasesOnReplica(new RetentionLeases(retentionLeases.primaryTerm(),
+                        retentionLeases.version() + 1,
+                        retentionLeases.leases().stream().map(l -> {
+                            assertEquals(ReplicationTracker.PEER_RECOVERY_RETENTION_LEASE_SOURCE, l.source());
+                            assertThat(l.retainingSequenceNumber(), lessThanOrEqualTo(localCheckpointOfSafeCommit + 1));
+                            return new RetentionLease(l.id(), localCheckpointOfSafeCommit + 1, l.timestamp(), l.source());
+                        }).collect(Collectors.toList())));
+                    indexShard.updateGlobalCheckpointOnReplica(indexShard.getLocalCheckpoint(), "test");
+                }
+                final FlushRequest flushRequest2 = new FlushRequest();
+                flushRequest2.force(true);
+                flushRequest2.waitIfOngoing(true);
+                indexShard.flush(flushRequest2);
+            }
+
             if (randomBoolean()) {
                 indexShard.refresh("test");
             }
@@ -3350,7 +3376,7 @@ public void testSegmentMemoryTrackedInBreaker() throws Exception {
         indexDoc(primary, "_doc", "4", "{\"foo\": \"potato\"}");
         indexDoc(primary, "_doc", "5", "{\"foo\": \"potato\"}");
         // Forces a refresh with the INTERNAL scope
-        ((InternalEngine) primary.getEngine()).writeIndexingBuffer();
+        primary.getEngine().writeIndexingBuffer();
 
         ss = primary.segmentStats(randomBoolean(), randomBoolean());
         breaker = primary.circuitBreakerService.getBreaker(CircuitBreaker.ACCOUNTING);
@@ -3366,6 +3392,8 @@ public void testSegmentMemoryTrackedInBreaker() throws Exception {
         if (IndexSettings.INDEX_SOFT_DELETES_SETTING.get(settings)) {
             primary.sync();
             flushShard(primary);
+            primary.runUnderPrimaryPermit(primary::renewPeerRecoveryRetentionLeaseForPrimary, Assert::assertNull, Names.SAME, "");
+            flushShard(primary, true); // force since the last flush didn't discard the retained ops; TODO should an unforced flush work?
         }
         primary.refresh("force refresh");
 
@@ -3716,7 +3744,7 @@ public void testTypelessDelete() throws IOException {
         IndexMetaData metaData = IndexMetaData.builder("index")
                 .putMapping("some_type", "{ \"properties\": {}}")
                 .settings(settings)
-                .build();
+                .primaryTerm(0, 1).build();
         IndexShard shard = newShard(new ShardId(metaData.getIndex(), 0), true, "n1", metaData, null);
         recoverShardFromStore(shard);
         Engine.IndexResult indexResult = indexDoc(shard, "some_type", "id", "{}");
diff --git a/server/src/test/java/org/elasticsearch/index/shard/PrimaryReplicaSyncerTests.java b/server/src/test/java/org/elasticsearch/index/shard/PrimaryReplicaSyncerTests.java
index 85e381b176cc..d074ef337583 100644
--- a/server/src/test/java/org/elasticsearch/index/shard/PrimaryReplicaSyncerTests.java
+++ b/server/src/test/java/org/elasticsearch/index/shard/PrimaryReplicaSyncerTests.java
@@ -115,10 +115,16 @@ public void testSyncerSendsOffCorrectDocuments() throws Exception {
             assertThat(resyncRequest.getMaxSeenAutoIdTimestampOnPrimary(), equalTo(shard.getMaxSeenAutoIdTimestamp()));
         }
         if (syncNeeded && globalCheckPoint < numDocs - 1) {
-            int skippedOps = Math.toIntExact(globalCheckPoint + 1); // everything up to global checkpoint included
-            assertThat(resyncTask.getSkippedOperations(), equalTo(skippedOps));
-            assertThat(resyncTask.getResyncedOperations(), equalTo(numDocs - skippedOps));
-            assertThat(resyncTask.getTotalOperations(), equalTo(globalCheckPoint == numDocs - 1 ? 0 : numDocs));
+            if (shard.indexSettings.isSoftDeleteEnabled()) {
+                assertThat(resyncTask.getSkippedOperations(), equalTo(0));
+                assertThat(resyncTask.getResyncedOperations(), equalTo(resyncTask.getTotalOperations()));
+                assertThat(resyncTask.getTotalOperations(), equalTo(Math.toIntExact(numDocs - 1 - globalCheckPoint)));
+            } else {
+                int skippedOps = Math.toIntExact(globalCheckPoint + 1); // everything up to global checkpoint included
+                assertThat(resyncTask.getSkippedOperations(), equalTo(skippedOps));
+                assertThat(resyncTask.getResyncedOperations(), equalTo(numDocs - skippedOps));
+                assertThat(resyncTask.getTotalOperations(), equalTo(globalCheckPoint == numDocs - 1 ? 0 : numDocs));
+            }
         } else {
             assertThat(resyncTask.getSkippedOperations(), equalTo(0));
             assertThat(resyncTask.getResyncedOperations(), equalTo(0));
diff --git a/server/src/test/java/org/elasticsearch/indices/IndicesLifecycleListenerSingleNodeTests.java b/server/src/test/java/org/elasticsearch/indices/IndicesLifecycleListenerSingleNodeTests.java
index 122d74121a71..67e04bc5088c 100644
--- a/server/src/test/java/org/elasticsearch/indices/IndicesLifecycleListenerSingleNodeTests.java
+++ b/server/src/test/java/org/elasticsearch/indices/IndicesLifecycleListenerSingleNodeTests.java
@@ -131,7 +131,7 @@ public void afterIndexRemoved(Index index, IndexSettings indexSettings, IndexRem
             newRouting = newRouting.moveToUnassigned(unassignedInfo)
                 .updateUnassigned(unassignedInfo, RecoverySource.EmptyStoreRecoverySource.INSTANCE);
             newRouting = ShardRoutingHelper.initialize(newRouting, nodeId);
-            IndexShard shard = index.createShard(newRouting, s -> {}, RetentionLeaseSyncer.EMPTY);
+            IndexShard shard = index.createShard(newRouting, s -> {}, RetentionLeaseSyncer.EMPTY, (s, l) -> {});
             IndexShardTestCase.updateRoutingEntry(shard, newRouting);
             assertEquals(5, counter.get());
             final DiscoveryNode localNode = new DiscoveryNode("foo", buildNewFakeTransportAddress(),
diff --git a/server/src/test/java/org/elasticsearch/indices/cluster/AbstractIndicesClusterStateServiceTestCase.java b/server/src/test/java/org/elasticsearch/indices/cluster/AbstractIndicesClusterStateServiceTestCase.java
index 9b6cae43081a..f5c4a0fa2b50 100644
--- a/server/src/test/java/org/elasticsearch/indices/cluster/AbstractIndicesClusterStateServiceTestCase.java
+++ b/server/src/test/java/org/elasticsearch/indices/cluster/AbstractIndicesClusterStateServiceTestCase.java
@@ -235,7 +235,8 @@ public MockIndexShard createShard(
                 final RepositoriesService repositoriesService,
                 final Consumer<IndexShard.ShardFailure> onShardFailure,
                 final Consumer<ShardId> globalCheckpointSyncer,
-                final RetentionLeaseSyncer retentionLeaseSyncer) throws IOException {
+                final RetentionLeaseSyncer retentionLeaseSyncer,
+                final BiConsumer<ShardId, ActionListener<Void>> peerRecoveryRetentionLeaseRenewer) throws IOException {
             failRandomly();
             MockIndexService indexService = indexService(recoveryState.getShardId().getIndex());
             MockIndexShard indexShard = indexService.createShard(shardRouting);
diff --git a/server/src/test/java/org/elasticsearch/indices/cluster/IndicesClusterStateServiceRandomUpdatesTests.java b/server/src/test/java/org/elasticsearch/indices/cluster/IndicesClusterStateServiceRandomUpdatesTests.java
index 9fd7f24db024..b723023a1323 100644
--- a/server/src/test/java/org/elasticsearch/indices/cluster/IndicesClusterStateServiceRandomUpdatesTests.java
+++ b/server/src/test/java/org/elasticsearch/indices/cluster/IndicesClusterStateServiceRandomUpdatesTests.java
@@ -482,7 +482,8 @@ private IndicesClusterStateService createIndicesClusterStateService(DiscoveryNod
                 null,
                 primaryReplicaSyncer,
                 s -> {},
-                RetentionLeaseSyncer.EMPTY);
+                RetentionLeaseSyncer.EMPTY,
+                (s, l) -> {});
     }
 
     private class RecordingIndicesService extends MockIndicesService {
diff --git a/server/src/test/java/org/elasticsearch/indices/recovery/IndexRecoveryIT.java b/server/src/test/java/org/elasticsearch/indices/recovery/IndexRecoveryIT.java
index 82d6c38becae..6db7087fad3b 100644
--- a/server/src/test/java/org/elasticsearch/indices/recovery/IndexRecoveryIT.java
+++ b/server/src/test/java/org/elasticsearch/indices/recovery/IndexRecoveryIT.java
@@ -47,6 +47,8 @@
 import org.elasticsearch.common.xcontent.XContentType;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.recovery.RecoveryStats;
+import org.elasticsearch.index.shard.IndexShard;
+import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.index.store.Store;
 import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.indices.recovery.RecoveryState.Stage;
@@ -81,7 +83,11 @@
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.function.Consumer;
+import java.util.function.Function;
+import java.util.stream.Collectors;
+import java.util.stream.StreamSupport;
 
+import static java.util.Objects.requireNonNull;
 import static org.elasticsearch.node.RecoverySettingsChunkSizePlugin.CHUNK_SIZE_SETTING;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
@@ -813,7 +819,7 @@ public void sendRequest(Transport.Connection connection, long requestId, String
         }
     }
 
-    @TestLogging("org.elasticsearch.indices.recovery:TRACE")
+    @TestLogging("org.elasticsearch.indices.recovery:TRACE,org.elasticsearch.index.seqno:TRACE")
     public void testHistoryRetention() throws Exception {
         internalCluster().startNodes(3);
 
@@ -838,9 +844,7 @@ public void testHistoryRetention() throws Exception {
         internalCluster().stopRandomNode(s -> true);
 
         final long desyncNanoTime = System.nanoTime();
-        while (System.nanoTime() <= desyncNanoTime) {
-            // time passes
-        }
+        assertBusy(() -> assertThat(System.nanoTime(), greaterThan(desyncNanoTime))); // time passes
 
         final int numNewDocs = scaledRandomIntBetween(25, 250);
         for (int i = 0; i < numNewDocs; i++) {
@@ -862,5 +866,23 @@ public void testHistoryRetention() throws Exception {
         assertThat(recoveryStates, hasSize(1));
         assertThat(recoveryStates.get(0).getIndex().totalFileCount(), is(0));
         assertThat(recoveryStates.get(0).getTranslog().recoveredOperations(), greaterThan(0));
+
+        final Map<Boolean, IndexShard> indexShardsByPrimary
+            = StreamSupport.stream(internalCluster().getInstances(IndicesService.class).spliterator(), false)
+            .map(is -> is.getShardOrNull(new ShardId(resolveIndex("test"), 0)))
+            .collect(Collectors.toMap(is -> is.routingEntry().primary(), Function.identity(),
+                (o1, o2) -> {
+                    throw new AssertionError("should not need to combine " + o1 + " with " + o2);
+                }));
+
+        final IndexShard primary = requireNonNull(indexShardsByPrimary.get(true));
+        assertThat(client().admin().indices().prepareFlush().setForce(true).get().getFailedShards(), equalTo(0)); // make a safe commit
+        primary.getRetentionLeases(true); // happens periodically, expires leases for unassigned shards
+        primary.renewPeerRecoveryRetentionLeases().get(); // happens periodically, advances retention leases according to last safe commit
+        assertThat(primary.getMinRetainedSeqNo(), equalTo(primary.seqNoStats().getMaxSeqNo() + 1));
+
+        primary.foregroundSyncRetentionLeases().get(); // happens periodically, pushes updated retention leases to replica
+        final IndexShard replica = requireNonNull(indexShardsByPrimary.get(false));
+        assertThat(replica.getMinRetainedSeqNo(), equalTo(replica.seqNoStats().getMaxSeqNo() + 1));
     }
 }
diff --git a/server/src/test/java/org/elasticsearch/indices/recovery/RecoveryTests.java b/server/src/test/java/org/elasticsearch/indices/recovery/RecoveryTests.java
index 2761333ef562..48061b11d58c 100644
--- a/server/src/test/java/org/elasticsearch/indices/recovery/RecoveryTests.java
+++ b/server/src/test/java/org/elasticsearch/indices/recovery/RecoveryTests.java
@@ -68,7 +68,8 @@ public void testTranslogHistoryTransferred() throws Exception {
             shards.addReplica();
             shards.startAll();
             final IndexShard replica = shards.getReplicas().get(0);
-            assertThat(getTranslog(replica).totalOperations(), equalTo(docs + moreDocs));
+            boolean softDeletesEnabled = replica.indexSettings().isSoftDeleteEnabled();
+            assertThat(getTranslog(replica).totalOperations(), equalTo(softDeletesEnabled ? moreDocs : docs + moreDocs));
             shards.assertAllEqual(docs + moreDocs);
         }
     }
@@ -281,7 +282,8 @@ public void testDifferentHistoryUUIDDisablesOPsRecovery() throws Exception {
             shards.recoverReplica(newReplica);
             // file based recovery should be made
             assertThat(newReplica.recoveryState().getIndex().fileDetails(), not(empty()));
-            assertThat(getTranslog(newReplica).totalOperations(), equalTo(numDocs));
+            boolean softDeletesEnabled = replica.indexSettings().isSoftDeleteEnabled();
+            assertThat(getTranslog(newReplica).totalOperations(), equalTo(softDeletesEnabled ? nonFlushedDocs : numDocs));
 
             // history uuid was restored
             assertThat(newReplica.getHistoryUUID(), equalTo(historyUUID));
@@ -385,7 +387,8 @@ public void testShouldFlushAfterPeerRecovery() throws Exception {
             shards.recoverReplica(replica);
             // Make sure the flushing will eventually be completed (eg. `shouldPeriodicallyFlush` is false)
             assertBusy(() -> assertThat(getEngine(replica).shouldPeriodicallyFlush(), equalTo(false)));
-            assertThat(getTranslog(replica).totalOperations(), equalTo(numDocs));
+            boolean softDeletesEnabled = replica.indexSettings().isSoftDeleteEnabled();
+            assertThat(getTranslog(replica).totalOperations(), equalTo(softDeletesEnabled ? 0 : numDocs));
             shards.assertAllEqual(numDocs);
         }
     }
diff --git a/server/src/test/java/org/elasticsearch/indices/stats/IndexStatsIT.java b/server/src/test/java/org/elasticsearch/indices/stats/IndexStatsIT.java
index 5fb67a64d9db..c3e2848d3631 100644
--- a/server/src/test/java/org/elasticsearch/indices/stats/IndexStatsIT.java
+++ b/server/src/test/java/org/elasticsearch/indices/stats/IndexStatsIT.java
@@ -1057,6 +1057,16 @@ public void testFilterCacheStats() throws Exception {
         if (IndexSettings.INDEX_SOFT_DELETES_SETTING.get(settings)) {
             persistGlobalCheckpoint("index");
             flush("index");
+            internalCluster().renewAndSyncPeerRecoveryRetentionLeases(resolveIndex("index"));
+            for (String node : internalCluster().nodesInclude("index")) {
+                final IndicesService indexServices = internalCluster().getInstance(IndicesService.class, node);
+                for (IndexService indexService : indexServices) {
+                    for (IndexShard indexShard : indexService) {
+                        assertFalse(indexShard.routingEntry().toString(),
+                            indexShard.hasCompleteHistoryOperations("test", indexShard.getLocalCheckpointOfSafeCommit()));
+                    }
+                }
+            }
         }
         ForceMergeResponse forceMergeResponse =
             client().admin().indices().prepareForceMerge("index").setFlush(true).setMaxNumSegments(1).get();
diff --git a/server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java b/server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java
index 9c1d256b552b..1da75c0f8446 100644
--- a/server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java
+++ b/server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java
@@ -97,6 +97,7 @@
 import org.elasticsearch.gateway.TransportNodesListGatewayStartedShards;
 import org.elasticsearch.index.analysis.AnalysisRegistry;
 import org.elasticsearch.index.seqno.GlobalCheckpointSyncAction;
+import org.elasticsearch.index.seqno.PeerRecoveryRetentionLeaseRenewalAction;
 import org.elasticsearch.index.seqno.RetentionLeaseBackgroundSyncAction;
 import org.elasticsearch.index.seqno.RetentionLeaseSyncAction;
 import org.elasticsearch.index.shard.PrimaryReplicaSyncer;
@@ -911,7 +912,9 @@ protected void assertSnapshotOrGenericThread() {
                             threadPool,
                             shardStateAction,
                             actionFilters,
-                            indexNameExpressionResolver));
+                            indexNameExpressionResolver),
+                new PeerRecoveryRetentionLeaseRenewalAction(settings, transportService, clusterService, indicesService, threadPool,
+                    shardStateAction, actionFilters, indexNameExpressionResolver));
             Map<Action, TransportAction> actions = new HashMap<>();
             actions.put(CreateIndexAction.INSTANCE,
                 new TransportCreateIndexAction(
diff --git a/test/framework/src/main/java/org/elasticsearch/index/engine/EngineTestCase.java b/test/framework/src/main/java/org/elasticsearch/index/engine/EngineTestCase.java
index a483e79467b9..efd53ca6c80a 100644
--- a/test/framework/src/main/java/org/elasticsearch/index/engine/EngineTestCase.java
+++ b/test/framework/src/main/java/org/elasticsearch/index/engine/EngineTestCase.java
@@ -663,7 +663,8 @@ public EngineConfig config(
                     SequenceNumbers.NO_OPS_PERFORMED,
                     update -> {},
                     () -> 0L,
-                    (leases, listener) -> {});
+                    (leases, listener) -> {},
+                    Version.CURRENT);
             globalCheckpointSupplier = replicationTracker;
             retentionLeasesSupplier = replicationTracker::getRetentionLeases;
         } else {
diff --git a/test/framework/src/main/java/org/elasticsearch/index/replication/ESIndexLevelReplicationTestCase.java b/test/framework/src/main/java/org/elasticsearch/index/replication/ESIndexLevelReplicationTestCase.java
index d6d160f01ac8..82cc12de960f 100644
--- a/test/framework/src/main/java/org/elasticsearch/index/replication/ESIndexLevelReplicationTestCase.java
+++ b/test/framework/src/main/java/org/elasticsearch/index/replication/ESIndexLevelReplicationTestCase.java
@@ -287,6 +287,7 @@ public synchronized int startReplicas(int numOfReplicasToStart) throws IOExcepti
 
         public void startPrimary() throws IOException {
             recoverPrimary(primary);
+            computeReplicationTargets();
             HashSet<String> activeIds = new HashSet<>();
             activeIds.addAll(activeIds());
             activeIds.add(primary.routingEntry().allocationId().getId());
@@ -662,6 +663,11 @@ public void updateGlobalCheckpointForShard(String allocationId, long globalCheck
                 getPrimaryShard().updateGlobalCheckpointForShard(allocationId, globalCheckpoint);
             }
 
+            @Override
+            public void updateLocalCheckpointOfSafeCommitForShard(String allocationId, long localCheckpointOfSafeCommit) {
+                getPrimaryShard().updateLocalCheckpointOfSafeCommitForShard(allocationId, localCheckpointOfSafeCommit);
+            }
+
             @Override
             public long localCheckpoint() {
                 return getPrimaryShard().getLocalCheckpoint();
@@ -672,6 +678,11 @@ public long globalCheckpoint() {
                 return getPrimaryShard().getGlobalCheckpoint();
             }
 
+            @Override
+            public long localCheckpointOfSafeCommit() {
+                return getPrimaryShard().getLocalCheckpointOfSafeCommit();
+            }
+
             @Override
             public long maxSeqNoOfUpdatesOrDeletes() {
                 return getPrimaryShard().getMaxSeqNoOfUpdatesOrDeletes();
@@ -704,7 +715,8 @@ public void onResponse(Releasable releasable) {
                                 try {
                                     performOnReplica(request, replica);
                                     releasable.close();
-                                    listener.onResponse(new ReplicaResponse(replica.getLocalCheckpoint(), replica.getGlobalCheckpoint()));
+                                    listener.onResponse(new ReplicaResponse(replica.getLocalCheckpoint(), replica.getGlobalCheckpoint(),
+                                                                            replica.getLocalCheckpointOfSafeCommit()));
                                 } catch (final Exception e) {
                                     Releasables.closeWhileHandlingException(releasable);
                                     listener.onFailure(e);
diff --git a/test/framework/src/main/java/org/elasticsearch/index/shard/IndexShardTestCase.java b/test/framework/src/main/java/org/elasticsearch/index/shard/IndexShardTestCase.java
index 5b5ff8de01d0..5e3e1a4f76a0 100644
--- a/test/framework/src/main/java/org/elasticsearch/index/shard/IndexShardTestCase.java
+++ b/test/framework/src/main/java/org/elasticsearch/index/shard/IndexShardTestCase.java
@@ -344,6 +344,7 @@ protected IndexShard newShard(ShardRouting routing, IndexMetaData indexMetaData,
      * @param storeProvider                 an optional custom store provider to use. If null a default file based store will be created
      * @param indexSearcherWrapper          an optional wrapper to be used during searchers
      * @param globalCheckpointSyncer        callback for syncing global checkpoints
+     * @param retentionLeaseSyncer          callback for syncing retention leases
      * @param indexEventListener            index event listener
      * @param listeners                     an optional set of listeners to add to the shard
      */
@@ -390,7 +391,8 @@ protected IndexShard newShard(ShardRouting routing, ShardPath shardPath, IndexMe
                     Arrays.asList(listeners),
                     globalCheckpointSyncer,
                     retentionLeaseSyncer,
-                    breakerService);
+                    breakerService,
+                    l -> {});
             indexShard.addShardFailureCallback(DEFAULT_SHARD_FAILURE_HANDLER);
             success = true;
         } finally {
@@ -442,7 +444,7 @@ protected IndexShard reinitShard(IndexShard current, ShardRouting routing, Engin
                 engineFactory,
                 current.getGlobalCheckpointSyncer(),
                 current.getRetentionLeaseSyncer(),
-            EMPTY_EVENT_LISTENER, listeners);
+                EMPTY_EVENT_LISTENER, listeners);
     }
 
     /**
diff --git a/test/framework/src/main/java/org/elasticsearch/test/ESIntegTestCase.java b/test/framework/src/main/java/org/elasticsearch/test/ESIntegTestCase.java
index d657952260e8..eab6bbd1291c 100644
--- a/test/framework/src/main/java/org/elasticsearch/test/ESIntegTestCase.java
+++ b/test/framework/src/main/java/org/elasticsearch/test/ESIntegTestCase.java
@@ -2306,7 +2306,11 @@ private static boolean isSuiteScopedTest(Class<?> clazz) {
     }
 
     public static Index resolveIndex(String index) {
-        GetIndexResponse getIndexResponse = client().admin().indices().prepareGetIndex().setIndices(index).get();
+        return resolveIndex(index, null);
+    }
+
+    public static Index resolveIndex(String index, String viaNode) {
+        GetIndexResponse getIndexResponse = client(viaNode).admin().indices().prepareGetIndex().setIndices(index).get();
         assertTrue("index " + index + " not found", getIndexResponse.getSettings().containsKey(index));
         String uuid = getIndexResponse.getSettings().get(index).get(IndexMetaData.SETTING_INDEX_UUID);
         return new Index(index, uuid);
diff --git a/test/framework/src/main/java/org/elasticsearch/test/InternalTestCluster.java b/test/framework/src/main/java/org/elasticsearch/test/InternalTestCluster.java
index c3f5762fbe37..74608a20ca6d 100644
--- a/test/framework/src/main/java/org/elasticsearch/test/InternalTestCluster.java
+++ b/test/framework/src/main/java/org/elasticsearch/test/InternalTestCluster.java
@@ -135,6 +135,7 @@
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
+import java.util.function.Consumer;
 import java.util.function.Function;
 import java.util.function.Predicate;
 import java.util.stream.Collectors;
@@ -148,8 +149,8 @@
 import static org.elasticsearch.common.unit.TimeValue.timeValueSeconds;
 import static org.elasticsearch.discovery.DiscoveryModule.DISCOVERY_TYPE_SETTING;
 import static org.elasticsearch.discovery.DiscoveryModule.ZEN2_DISCOVERY_TYPE;
-import static org.elasticsearch.node.Node.INITIAL_STATE_TIMEOUT_SETTING;
 import static org.elasticsearch.discovery.FileBasedSeedHostsProvider.UNICAST_HOSTS_FILE;
+import static org.elasticsearch.node.Node.INITIAL_STATE_TIMEOUT_SETTING;
 import static org.elasticsearch.test.ESTestCase.assertBusy;
 import static org.elasticsearch.test.ESTestCase.awaitBusy;
 import static org.elasticsearch.test.ESTestCase.getTestTransportType;
@@ -827,6 +828,37 @@ public synchronized void close() throws IOException {
 
     private static final int REMOVED_MINIMUM_MASTER_NODES = Integer.MAX_VALUE;
 
+    /**
+     * Renews the peer recovery retention leases for the given indices (updating each lease to the local checkpoint of the safe commit)
+     * and pushes the updated leases out to all the replicas.
+     */
+    public void renewAndSyncPeerRecoveryRetentionLeases(Index... indices) {
+        final List<IndexShard> indexShards = new ArrayList<>();
+        for (final IndicesService indicesService : getInstances(IndicesService.class)) {
+            for (final Index index : indices) {
+                final IndexService indexService = indicesService.indexService(index);
+                if (indexService != null) {
+                    for (IndexShard indexShard : indexService) {
+                        if (indexShard.routingEntry().primary()) {
+                            indexShards.add(indexShard);
+                        }
+                    }
+                }
+            }
+        }
+
+        final Consumer<Future<Void>> futureConsumer = f -> {
+            try {
+                f.get();
+            } catch (Exception e) {
+                throw new AssertionError(e);
+            }
+        };
+
+        indexShards.stream().map(IndexShard::renewPeerRecoveryRetentionLeases).forEach(futureConsumer);
+        indexShards.stream().map(IndexShard::foregroundSyncRetentionLeases).forEach(futureConsumer);
+    }
+
     private final class NodeAndClient implements Closeable {
         private MockNode node;
         private final Settings originalNodeSettings;
diff --git a/x-pack/plugin/ccr/src/test/java/org/elasticsearch/xpack/ccr/CcrRetentionLeaseIT.java b/x-pack/plugin/ccr/src/test/java/org/elasticsearch/xpack/ccr/CcrRetentionLeaseIT.java
index eb15cef3b1c5..40fe8c4e2510 100644
--- a/x-pack/plugin/ccr/src/test/java/org/elasticsearch/xpack/ccr/CcrRetentionLeaseIT.java
+++ b/x-pack/plugin/ccr/src/test/java/org/elasticsearch/xpack/ccr/CcrRetentionLeaseIT.java
@@ -72,6 +72,7 @@
 import java.util.Set;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
+import java.util.function.Supplier;
 import java.util.stream.Collectors;
 import java.util.stream.IntStream;
 import java.util.stream.Stream;
@@ -189,10 +190,15 @@ public void testRetentionLeaseIsTakenAtTheStartOfRecovery() throws Exception {
             assertThat(stats.getShards(), arrayWithSize(numberOfShards * (1 + numberOfReplicas)));
             final List<ShardStats> shardsStats = getShardsStats(stats);
             for (int i = 0; i < numberOfShards * (1 + numberOfReplicas); i++) {
-                final RetentionLeases currentRetentionLeases = shardsStats.get(i).getRetentionLeaseStats().retentionLeases();
-                assertThat(currentRetentionLeases.leases(), hasSize(1));
-                final RetentionLease retentionLease =
-                        currentRetentionLeases.leases().iterator().next();
+                final List<RetentionLease> ccrLeases
+                    = shardsStats.get(i).getRetentionLeaseStats().retentionLeases()
+                    .leases().stream().filter(RetentionLease::isNotPeerRecoveryRetentionLease)
+                    .collect(Collectors.toList());
+                assertThat(ccrLeases, hasSize(1));
+                final ClusterStateResponse followerIndexClusterState =
+                        followerClient().admin().cluster().prepareState().clear().setMetaData(true).setIndices(followerIndex).get();
+                final String followerUUID = followerIndexClusterState.getState().metaData().index(followerIndex).getIndexUUID();
+                final RetentionLease retentionLease = ccrLeases.iterator().next();
                 assertThat(retentionLease.id(), equalTo(getRetentionLeaseId(followerIndex, leaderIndex)));
             }
         });
@@ -304,7 +310,7 @@ public void testRetentionLeasesAreNotBeingRenewedAfterRecoveryCompletes() throws
         final String leaderUUID = leaderIndexClusterState.getState().metaData().index(leaderIndex).getIndexUUID();
 
         // sample the leases after recovery
-        final List<RetentionLeases> retentionLeases = new ArrayList<>();
+        final List<Supplier<RetentionLease>> retentionLeases = new ArrayList<>();
         assertBusy(() -> {
             retentionLeases.clear();
             final IndicesStatsResponse stats =
@@ -313,20 +319,23 @@ public void testRetentionLeasesAreNotBeingRenewedAfterRecoveryCompletes() throws
             assertThat(stats.getShards(), arrayWithSize(numberOfShards * (1 + numberOfReplicas)));
             final List<ShardStats> shardsStats = getShardsStats(stats);
             for (int i = 0; i < numberOfShards * (1 + numberOfReplicas); i++) {
-                final RetentionLeases currentRetentionLeases = shardsStats.get(i).getRetentionLeaseStats().retentionLeases();
-                assertThat(currentRetentionLeases.leases(), hasSize(1));
+                final List<RetentionLease> ccrLeases
+                    = shardsStats.get(i).getRetentionLeaseStats().retentionLeases()
+                    .leases().stream().filter(RetentionLease::isNotPeerRecoveryRetentionLease)
+                    .collect(Collectors.toList());
+                assertThat(ccrLeases, hasSize(1));
                 final ClusterStateResponse followerIndexClusterState =
                         followerClient().admin().cluster().prepareState().clear().setMetaData(true).setIndices(followerIndex).get();
                 final String followerUUID = followerIndexClusterState.getState().metaData().index(followerIndex).getIndexUUID();
-                final RetentionLease retentionLease =
-                        currentRetentionLeases.leases().iterator().next();
+                final RetentionLease retentionLease = ccrLeases.iterator().next();
+                assertThat(retentionLease.id(), equalTo(getRetentionLeaseId(followerIndex, followerUUID, leaderIndex, leaderUUID)));
                 final String expectedRetentionLeaseId = retentionLeaseId(
                         getFollowerCluster().getClusterName(),
                         new Index(followerIndex, followerUUID),
                         getLeaderCluster().getClusterName(),
                         new Index(leaderIndex, leaderUUID));
                 assertThat(retentionLease.id(), equalTo(expectedRetentionLeaseId));
-                retentionLeases.add(currentRetentionLeases);
+                retentionLeases.add(() -> retentionLease);
             }
         });
 
@@ -348,19 +357,18 @@ public void testRetentionLeasesAreNotBeingRenewedAfterRecoveryCompletes() throws
             assertThat(stats.getShards(), arrayWithSize(numberOfShards * (1 + numberOfReplicas)));
             final List<ShardStats> shardsStats = getShardsStats(stats);
             for (int i = 0; i < numberOfShards * (1 + numberOfReplicas); i++) {
-                if (shardsStats.get(i).getShardRouting().primary() == false) {
-                    continue;
-                }
-                final RetentionLeases currentRetentionLeases = shardsStats.get(i).getRetentionLeaseStats().retentionLeases();
-                assertThat(currentRetentionLeases.leases(), hasSize(1));
+                final List<RetentionLease> ccrLeases
+                    = shardsStats.get(i).getRetentionLeaseStats().retentionLeases()
+                    .leases().stream().filter(RetentionLease::isNotPeerRecoveryRetentionLease)
+                    .collect(Collectors.toList());
+                assertThat(ccrLeases, hasSize(1));
                 final ClusterStateResponse followerIndexClusterState =
                         followerClient().admin().cluster().prepareState().clear().setMetaData(true).setIndices(followerIndex).get();
                 final String followerUUID = followerIndexClusterState.getState().metaData().index(followerIndex).getIndexUUID();
-                final RetentionLease retentionLease =
-                        currentRetentionLeases.leases().iterator().next();
+                final RetentionLease retentionLease = ccrLeases.iterator().next();
                 assertThat(retentionLease.id(), equalTo(getRetentionLeaseId(followerIndex, followerUUID, leaderIndex, leaderUUID)));
                 // we assert that retention leases are being renewed by an increase in the timestamp
-                assertThat(retentionLease.timestamp(), equalTo(retentionLeases.get(i).leases().iterator().next().timestamp()));
+                assertThat(retentionLease.timestamp(), equalTo(retentionLeases.get(i).get().timestamp()));
             }
         });
 
@@ -390,9 +398,11 @@ public void testUnfollowRemovesRetentionLeases() throws Exception {
                 leaderClient().admin().indices().stats(new IndicesStatsRequest().clear().indices(leaderIndex)).actionGet();
         final List<ShardStats> shardsStats = getShardsStats(stats);
         for (final ShardStats shardStats : shardsStats) {
-            assertThat(shardStats.getRetentionLeaseStats().retentionLeases().leases(), hasSize(1));
+            final Collection<RetentionLease> ccrLeases = shardStats.getRetentionLeaseStats().retentionLeases().leases()
+                .stream().filter(RetentionLease::isNotPeerRecoveryRetentionLease).collect(Collectors.toList());
+            assertThat(ccrLeases, hasSize(1));
             assertThat(
-                    shardStats.getRetentionLeaseStats().retentionLeases().leases().iterator().next().id(),
+                    ccrLeases.iterator().next().id(),
                     equalTo(retentionLeaseId));
         }
 
@@ -452,7 +462,9 @@ public void testUnfollowRemovesRetentionLeases() throws Exception {
                     leaderClient().admin().indices().stats(new IndicesStatsRequest().clear().indices(leaderIndex)).actionGet();
             final List<ShardStats> afterUnfollowShardsStats = getShardsStats(afterUnfollowStats);
             for (final ShardStats shardStats : afterUnfollowShardsStats) {
-                assertThat(shardStats.getRetentionLeaseStats().retentionLeases().leases(), empty());
+                final Collection<RetentionLease> ccrLeases = shardStats.getRetentionLeaseStats().retentionLeases().leases()
+                    .stream().filter(RetentionLease::isNotPeerRecoveryRetentionLease).collect(Collectors.toList());
+                assertThat(ccrLeases, empty());
             }
         } finally {
             for (final ObjectCursor<DiscoveryNode> senderNode : followerClusterState.getState().nodes().getDataNodes().values()) {
@@ -604,10 +616,12 @@ public void testRetentionLeaseAdvancesWhileFollowing() throws Exception {
             assertThat(stats.getShards(), arrayWithSize(numberOfShards * (1 + numberOfReplicas)));
             final List<ShardStats> shardsStats = getShardsStats(stats);
             for (int i = 0; i < numberOfShards * (1 + numberOfReplicas); i++) {
-                final RetentionLeases currentRetentionLeases = shardsStats.get(i).getRetentionLeaseStats().retentionLeases();
-                assertThat(currentRetentionLeases.leases(), hasSize(1));
-                final RetentionLease retentionLease =
-                        currentRetentionLeases.leases().iterator().next();
+                final List<RetentionLease> ccrLeases
+                    = shardsStats.get(i).getRetentionLeaseStats().retentionLeases()
+                    .leases().stream().filter(RetentionLease::isNotPeerRecoveryRetentionLease)
+                    .collect(Collectors.toList());
+                assertThat(ccrLeases, hasSize(1));
+                final RetentionLease retentionLease = ccrLeases.iterator().next();
                 assertThat(retentionLease.id(), equalTo(getRetentionLeaseId(followerIndex, leaderIndex)));
                 // we assert that retention leases are being advanced
                 assertThat(
@@ -670,12 +684,14 @@ public void testRetentionLeaseRenewalIsCancelledWhenFollowingIsPaused() throws E
             final List<ShardStats> shardsStats = getShardsStats(stats);
             for (int i = 0; i < numberOfShards * (1 + numberOfReplicas); i++) {
                 final RetentionLeases currentRetentionLeases = shardsStats.get(i).getRetentionLeaseStats().retentionLeases();
-                assertThat(currentRetentionLeases.leases(), hasSize(1));
+                final List<RetentionLease> ccrLeases
+                        = currentRetentionLeases.leases().stream().filter(RetentionLease::isNotPeerRecoveryRetentionLease)
+                        .collect(Collectors.toList());
+                assertThat(ccrLeases, hasSize(1));
                 final ClusterStateResponse followerIndexClusterState =
                         followerClient().admin().cluster().prepareState().clear().setMetaData(true).setIndices(followerIndex).get();
                 final String followerUUID = followerIndexClusterState.getState().metaData().index(followerIndex).getIndexUUID();
-                final RetentionLease retentionLease =
-                        currentRetentionLeases.leases().iterator().next();
+                final RetentionLease retentionLease = ccrLeases.iterator().next();
                 final String expectedRetentionLeaseId = retentionLeaseId(
                         getFollowerCluster().getClusterName(),
                         new Index(followerIndex, followerUUID),
@@ -707,16 +723,18 @@ public void testRetentionLeaseRenewalIsCancelledWhenFollowingIsPaused() throws E
                 if (shardsStats.get(i).getShardRouting().primary() == false) {
                     continue;
                 }
-                final RetentionLeases currentRetentionLeases = shardsStats.get(i).getRetentionLeaseStats().retentionLeases();
-                assertThat(currentRetentionLeases.leases(), hasSize(1));
+                final List<RetentionLease> ccrLeases
+                        = shardsStats.get(i).getRetentionLeaseStats().retentionLeases()
+                        .leases().stream().filter(RetentionLease::isNotPeerRecoveryRetentionLease)
+                        .collect(Collectors.toList());
+                assertThat(ccrLeases, hasSize(1));
                 final ClusterStateResponse followerIndexClusterState =
                         followerClient().admin().cluster().prepareState().clear().setMetaData(true).setIndices(followerIndex).get();
                 final String followerUUID = followerIndexClusterState.getState().metaData().index(followerIndex).getIndexUUID();
-                final RetentionLease retentionLease =
-                        currentRetentionLeases.leases().iterator().next();
+                final RetentionLease retentionLease = ccrLeases.iterator().next();
                 assertThat(retentionLease.id(), equalTo(getRetentionLeaseId(followerIndex, followerUUID, leaderIndex, leaderUUID)));
-                // we assert that retention leases are not being renewed by an unchanged timestamp
-                assertThat(retentionLease.timestamp(), equalTo(retentionLeases.get(i).leases().iterator().next().timestamp()));
+                // we assert that retentxion leases are not being renewed by an unchanged timestamp
+                assertThat(retentionLease.timestamp(), equalTo(retentionLeases.get(i).get(retentionLease.id()).timestamp()));
             }
         });
     }
@@ -915,7 +933,9 @@ public void onResponseReceived(
                     leaderClient().admin().indices().stats(new IndicesStatsRequest().clear().indices(leaderIndex)).actionGet();
             final List<ShardStats> afterUnfollowShardsStats = getShardsStats(afterUnfollowStats);
             for (final ShardStats shardStats : afterUnfollowShardsStats) {
-                assertThat(shardStats.getRetentionLeaseStats().retentionLeases().leases(), empty());
+                final Collection<RetentionLease> ccrLeases = shardStats.getRetentionLeaseStats().retentionLeases().leases()
+                    .stream().filter(RetentionLease::isNotPeerRecoveryRetentionLease).collect(Collectors.toList());
+                assertThat(ccrLeases, empty());
             }
         } finally {
             for (final ObjectCursor<DiscoveryNode> senderNode : followerClusterState.getState().nodes().getDataNodes().values()) {
@@ -984,9 +1004,11 @@ private void assertRetentionLeaseRenewal(
             final List<ShardStats> shardsStats = getShardsStats(stats);
             for (int i = 0; i < numberOfShards * (1 + numberOfReplicas); i++) {
                 final RetentionLeases currentRetentionLeases = shardsStats.get(i).getRetentionLeaseStats().retentionLeases();
-                assertThat(currentRetentionLeases.leases(), hasSize(1));
-                final RetentionLease retentionLease =
-                        currentRetentionLeases.leases().iterator().next();
+                final List<RetentionLease> ccrLeases
+                    = currentRetentionLeases.leases().stream().filter(RetentionLease::isNotPeerRecoveryRetentionLease)
+                    .collect(Collectors.toList());
+                assertThat(ccrLeases, hasSize(1));
+                final RetentionLease retentionLease = ccrLeases.iterator().next();
                 assertThat(retentionLease.id(), equalTo(getRetentionLeaseId(followerIndex, leaderIndex)));
                 retentionLeases.add(currentRetentionLeases);
             }
@@ -1000,10 +1022,12 @@ private void assertRetentionLeaseRenewal(
             assertThat(stats.getShards(), arrayWithSize(numberOfShards * (1 + numberOfReplicas)));
             final List<ShardStats> shardsStats = getShardsStats(stats);
             for (int i = 0; i < numberOfShards * (1 + numberOfReplicas); i++) {
-                final RetentionLeases currentRetentionLeases = shardsStats.get(i).getRetentionLeaseStats().retentionLeases();
-                assertThat(currentRetentionLeases.leases(), hasSize(1));
-                final RetentionLease retentionLease =
-                        currentRetentionLeases.leases().iterator().next();
+                final List<RetentionLease> ccrLeases
+                    = shardsStats.get(i).getRetentionLeaseStats().retentionLeases()
+                    .leases().stream().filter(RetentionLease::isNotPeerRecoveryRetentionLease)
+                    .collect(Collectors.toList());
+                assertThat(ccrLeases, hasSize(1));
+                final RetentionLease retentionLease = ccrLeases.iterator().next();
                 assertThat(retentionLease.id(), equalTo(getRetentionLeaseId(followerIndex, leaderIndex)));
                 // we assert that retention leases are being renewed by an increase in the timestamp
                 assertThat(retentionLease.timestamp(), greaterThan(retentionLeases.get(i).leases().iterator().next().timestamp()));
diff --git a/x-pack/plugin/ccr/src/test/java/org/elasticsearch/xpack/ccr/IndexFollowingIT.java b/x-pack/plugin/ccr/src/test/java/org/elasticsearch/xpack/ccr/IndexFollowingIT.java
index 52202982701c..5821eb38de5a 100644
--- a/x-pack/plugin/ccr/src/test/java/org/elasticsearch/xpack/ccr/IndexFollowingIT.java
+++ b/x-pack/plugin/ccr/src/test/java/org/elasticsearch/xpack/ccr/IndexFollowingIT.java
@@ -1088,6 +1088,8 @@ private void runFallBehindTest(
         leaderClient().prepareDelete("index1", "doc", "1").get();
         leaderClient().admin().indices().refresh(new RefreshRequest("index1")).actionGet();
         leaderClient().admin().indices().flush(new FlushRequest("index1").force(true)).actionGet();
+        getLeaderCluster().renewAndSyncPeerRecoveryRetentionLeases(resolveLeaderIndex("index1"));
+
         ForceMergeRequest forceMergeRequest = new ForceMergeRequest("index1");
         forceMergeRequest.maxNumSegments(1);
         leaderClient().admin().indices().forceMerge(forceMergeRequest).actionGet();
diff --git a/x-pack/plugin/ccr/src/test/java/org/elasticsearch/xpack/ccr/action/ShardChangesTests.java b/x-pack/plugin/ccr/src/test/java/org/elasticsearch/xpack/ccr/action/ShardChangesTests.java
index f42a50b91ff0..0bbd54ab5519 100644
--- a/x-pack/plugin/ccr/src/test/java/org/elasticsearch/xpack/ccr/action/ShardChangesTests.java
+++ b/x-pack/plugin/ccr/src/test/java/org/elasticsearch/xpack/ccr/action/ShardChangesTests.java
@@ -16,11 +16,16 @@
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentType;
 import org.elasticsearch.index.engine.Engine;
+import org.elasticsearch.index.shard.IndexShard;
+import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.index.translog.Translog;
+import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.ESSingleNodeTestCase;
+import org.elasticsearch.threadpool.ThreadPool.Names;
 import org.elasticsearch.xpack.ccr.Ccr;
 import org.elasticsearch.xpack.ccr.LocalStateCcr;
+import org.junit.Assert;
 
 import java.util.Collection;
 import java.util.Collections;
@@ -110,6 +115,10 @@ public void testMissingOperations() throws Exception {
             client().prepareDelete("index", "_doc", "1").get();
             client().admin().indices().flush(new FlushRequest("index").force(true)).actionGet();
         }
+
+        final IndexShard primary = getInstanceFromNode(IndicesService.class).getShardOrNull(new ShardId(resolveIndex("index"), 0));
+        primary.runUnderPrimaryPermit(primary::renewPeerRecoveryRetentionLeaseForPrimary, Assert::assertNull, Names.SAME, "");
+
         client().admin().indices().refresh(new RefreshRequest("index")).actionGet();
         ForceMergeRequest forceMergeRequest = new ForceMergeRequest("index");
         forceMergeRequest.maxNumSegments(1);
@@ -117,7 +126,7 @@ public void testMissingOperations() throws Exception {
 
         ShardStats shardStats = client().admin().indices().prepareStats("index").get().getIndex("index").getShards()[0];
         String historyUUID = shardStats.getCommitStats().getUserData().get(Engine.HISTORY_UUID_KEY);
-        ShardChangesAction.Request request =  new ShardChangesAction.Request(shardStats.getShardRouting().shardId(), historyUUID);
+        ShardChangesAction.Request request = new ShardChangesAction.Request(shardStats.getShardRouting().shardId(), historyUUID);
         request.setFromSeqNo(0L);
         request.setMaxOperationCount(1);
 
