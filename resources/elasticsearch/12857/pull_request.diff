diff --git a/core/src/main/java/org/elasticsearch/index/engine/CreateContextIndexSearcherService.java b/core/src/main/java/org/elasticsearch/index/engine/CreateContextIndexSearcherService.java
new file mode 100644
index 000000000000..1bb26f07fbc1
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/engine/CreateContextIndexSearcherService.java
@@ -0,0 +1,46 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.engine;
+
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.search.IndexSearcher;
+import org.elasticsearch.index.engine.Engine.Searcher;
+
+/**
+ * The service is responsible for two things:
+ * 1) Create a new ContextIndexSearcher instance for each shard level operation (search, get, field stats etc.)
+ * 2) Optionally wrapping the {@link DirectoryReader} and {@link IndexSearcher} of a {@link Searcher} via the
+ * configured {@link IndexSearcherWrapper} instance. This allows custom functionally to be added the {@link Searcher}
+ * before being used to do an operation (search, get, field stats etc.)
+ */
+// TODO: This needs extension point is a bit hacky now, because the IndexSearch from the engine can only be wrapped once,
+// if we allowed the IndexSearcher to be wrapped multiple times then a custom IndexSearcherWrapper needs have good
+// control over its location in the wrapping chain
+public interface CreateContextIndexSearcherService {
+
+    /**
+     * If there are configured {@link IndexSearcherWrapper} instances, the {@link IndexSearcher} of the provided engine searcher
+     * gets wrapped and a new {@link Searcher} instances is returned, otherwise the provided {@link Searcher} is returned.
+     *
+     * This is invoked each time a {@link Searcher} is requested to do an operation. (for example search)
+     */
+    Searcher wrap(EngineConfig engineConfig, final Searcher originalEngineSearcher) throws EngineException;
+
+}
diff --git a/core/src/main/java/org/elasticsearch/index/engine/IndexSearcherWrappingService.java b/core/src/main/java/org/elasticsearch/index/engine/DefaultCreateContextIndexSearcherService.java
similarity index 60%
rename from core/src/main/java/org/elasticsearch/index/engine/IndexSearcherWrappingService.java
rename to core/src/main/java/org/elasticsearch/index/engine/DefaultCreateContextIndexSearcherService.java
index a0ea90e024e0..6e3ca6c1cf22 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/IndexSearcherWrappingService.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/DefaultCreateContextIndexSearcherService.java
@@ -20,34 +20,28 @@
 package org.elasticsearch.index.engine;
 
 import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.search.IndexSearcher;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.index.engine.Engine.Searcher;
+import org.elasticsearch.search.internal.ContextIndexSearcher;
 
 import java.util.Set;
 
-/**
- * Service responsible for wrapping the {@link DirectoryReader} and {@link IndexSearcher} of a {@link Searcher} via the
- * configured {@link IndexSearcherWrapper} instance. This allows custom functionally to be added the {@link Searcher}
- * before being used to do an operation (search, get, field stats etc.)
- */
-// TODO: This needs extension point is a bit hacky now, because the IndexSearch from the engine can only be wrapped once,
-// if we allowed the IndexSearcher to be wrapped multiple times then a custom IndexSearcherWrapper needs have good
-// control over its location in the wrapping chain
-public final class IndexSearcherWrappingService {
+public class DefaultCreateContextIndexSearcherService implements CreateContextIndexSearcherService {
 
     private final IndexSearcherWrapper wrapper;
 
     // for unit tests:
-    IndexSearcherWrappingService() {
+    DefaultCreateContextIndexSearcherService() {
         this.wrapper = null;
     }
 
     @Inject
     // Use a Set parameter here, because constructor parameter can't be optional
     // and I prefer to keep the `wrapper` field final.
-    public IndexSearcherWrappingService(Set<IndexSearcherWrapper> wrappers) {
+    public DefaultCreateContextIndexSearcherService(Set<IndexSearcherWrapper> wrappers) {
         if (wrappers.size() > 1) {
             throw new IllegalStateException("wrapping of the index searcher by more than one wrappers is forbidden, found the following wrappers [" + wrappers + "]");
         }
@@ -64,31 +58,36 @@ public IndexSearcherWrappingService(Set<IndexSearcherWrapper> wrappers) {
      *
      * This is invoked each time a {@link Searcher} is requested to do an operation. (for example search)
      */
-    public Searcher wrap(EngineConfig engineConfig, final Searcher engineSearcher) throws EngineException {
+    public Searcher wrap(EngineConfig engineConfig, final Searcher originalEngineSearcher) throws EngineException {
         if (wrapper == null) {
-            return engineSearcher;
+            ContextIndexSearcher indexSearcher = createContextIndexSearcher(engineConfig, originalEngineSearcher, originalEngineSearcher.reader());
+            return wrapEngineSearcher(engineConfig, indexSearcher, originalEngineSearcher);
         }
 
-        DirectoryReader reader = wrapper.wrap((DirectoryReader) engineSearcher.reader());
-        IndexSearcher innerIndexSearcher = new IndexSearcher(reader);
-        innerIndexSearcher.setQueryCache(engineConfig.getQueryCache());
-        innerIndexSearcher.setQueryCachingPolicy(engineConfig.getQueryCachingPolicy());
-        innerIndexSearcher.setSimilarity(engineConfig.getSimilarity());
+        DirectoryReader reader = wrapper.wrap((DirectoryReader) originalEngineSearcher.reader());
+        ContextIndexSearcher innerIndexSearcher = createContextIndexSearcher(engineConfig, originalEngineSearcher, reader);
         // TODO: Right now IndexSearcher isn't wrapper friendly, when it becomes wrapper friendly we should revise this extension point
         // For example if IndexSearcher#rewrite() is overwritten than also IndexSearcher#createNormalizedWeight needs to be overwritten
         // This needs to be fixed before we can allow the IndexSearcher from Engine to be wrapped multiple times
-        IndexSearcher indexSearcher = wrapper.wrap(innerIndexSearcher);
-        if (reader == engineSearcher.reader() && indexSearcher == innerIndexSearcher) {
-            return engineSearcher;
-        } else {
-            return new Engine.Searcher(engineSearcher.source(), indexSearcher) {
+        ContextIndexSearcher indexSearcher = wrapper.wrap(innerIndexSearcher, engineConfig);
+        return wrapEngineSearcher(engineConfig, indexSearcher, originalEngineSearcher);
+    }
 
-                @Override
-                public void close() throws ElasticsearchException {
-                    engineSearcher.close();
-                }
-            };
-        }
+    protected Searcher wrapEngineSearcher(EngineConfig engineConfig, ContextIndexSearcher indexSearcher, final Searcher originalEngineSearcher) {
+        return new Searcher(originalEngineSearcher.source(), indexSearcher) {
+
+            @Override
+            public void close() throws ElasticsearchException {
+                originalEngineSearcher.close();
+            }
+        };
+    }
+
+    private ContextIndexSearcher createContextIndexSearcher(EngineConfig engineConfig, Searcher engineSearcher, IndexReader reader) {
+        return new ContextIndexSearcher(
+                reader, engineSearcher.searcher().getSimilarity(true),
+                engineConfig.getQueryCache(), engineConfig.getQueryCachingPolicy()
+        );
     }
 
 }
diff --git a/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java b/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java
index 91725899c17c..bac2b9e239a7 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java
@@ -77,7 +77,7 @@
     private final boolean forceNewTranslog;
     private final QueryCache queryCache;
     private final QueryCachingPolicy queryCachingPolicy;
-    private final IndexSearcherWrappingService wrappingService;
+    private final CreateContextIndexSearcherService wrappingService;
 
     /**
      * Index setting for index concurrency / number of threadstates in the indexwriter.
@@ -144,7 +144,7 @@ public EngineConfig(ShardId shardId, ThreadPool threadPool, ShardIndexingService
                         Settings indexSettings, IndicesWarmer warmer, Store store, SnapshotDeletionPolicy deletionPolicy,
                         MergePolicy mergePolicy, MergeSchedulerConfig mergeSchedulerConfig, Analyzer analyzer,
                         Similarity similarity, CodecService codecService, Engine.FailedEngineListener failedEngineListener,
-                        TranslogRecoveryPerformer translogRecoveryPerformer, QueryCache queryCache, QueryCachingPolicy queryCachingPolicy, IndexSearcherWrappingService wrappingService, TranslogConfig translogConfig) {
+                        TranslogRecoveryPerformer translogRecoveryPerformer, QueryCache queryCache, QueryCachingPolicy queryCachingPolicy, CreateContextIndexSearcherService wrappingService, TranslogConfig translogConfig) {
         this.shardId = shardId;
         this.indexSettings = indexSettings;
         this.threadPool = threadPool;
@@ -423,7 +423,7 @@ public QueryCachingPolicy getQueryCachingPolicy() {
         return queryCachingPolicy;
     }
 
-    public IndexSearcherWrappingService getWrappingService() {
+    public CreateContextIndexSearcherService getWrappingService() {
         return wrappingService;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/index/engine/IndexSearcherWrapper.java b/core/src/main/java/org/elasticsearch/index/engine/IndexSearcherWrapper.java
index c8a75f447b7d..da36050de85f 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/IndexSearcherWrapper.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/IndexSearcherWrapper.java
@@ -21,6 +21,7 @@
 
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.search.IndexSearcher;
+import org.elasticsearch.search.internal.ContextIndexSearcher;
 
 /**
  * Extension point to add custom functionality at request time to the {@link DirectoryReader}
@@ -36,10 +37,11 @@
     DirectoryReader wrap(DirectoryReader reader);
 
     /**
-     * @param searcher The provided index searcher to be wrapped to add custom functionality
+     * @param searcher      The provided index searcher to be wrapped to add custom functionality
+     * @param engineConfig  The engine config to get the query cache and query cache policy from
      * @return a new index searcher wrapping the provided index searcher or if no wrapping was performed
      *         the provided index searcher
      */
-    IndexSearcher wrap(IndexSearcher searcher) throws EngineException;
+    ContextIndexSearcher wrap(ContextIndexSearcher searcher, EngineConfig engineConfig) throws EngineException;
 
 }
diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
index bb681586781a..e3f3ba3fd99d 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
@@ -168,7 +168,7 @@
     protected volatile IndexShardState state;
     protected final AtomicReference<Engine> currentEngineReference = new AtomicReference<>();
     protected final EngineFactory engineFactory;
-    private final IndexSearcherWrappingService wrappingService;
+    private final CreateContextIndexSearcherService createContextIndexSearcherService;
 
     @Nullable
     private RecoveryState recoveryState;
@@ -198,13 +198,13 @@ public IndexShard(ShardId shardId, IndexSettingsService indexSettingsService, In
                       IndicesQueryCache indicesQueryCache, ShardPercolateService shardPercolateService, CodecService codecService,
                       ShardTermVectorsService termVectorsService, IndexFieldDataService indexFieldDataService, IndexService indexService,
                       @Nullable IndicesWarmer warmer, SnapshotDeletionPolicy deletionPolicy, SimilarityService similarityService, EngineFactory factory,
-                      ClusterService clusterService, ShardPath path, BigArrays bigArrays, IndexSearcherWrappingService wrappingService) {
+                      ClusterService clusterService, ShardPath path, BigArrays bigArrays, CreateContextIndexSearcherService createContextIndexSearcherService) {
         super(shardId, indexSettingsService.getSettings());
         this.codecService = codecService;
         this.warmer = warmer;
         this.deletionPolicy = deletionPolicy;
         this.similarityService = similarityService;
-        this.wrappingService = wrappingService;
+        this.createContextIndexSearcherService = createContextIndexSearcherService;
         Preconditions.checkNotNull(store, "Store must be provided to the index shard");
         Preconditions.checkNotNull(deletionPolicy, "Snapshot deletion policy must be provided to the index shard");
         this.engineFactory = factory;
@@ -1361,7 +1361,7 @@ protected void operationProcessed() {
         };
         return new EngineConfig(shardId,
                 threadPool, indexingService, indexSettingsService.indexSettings(), warmer, store, deletionPolicy, mergePolicyConfig.getMergePolicy(), mergeSchedulerConfig,
-                mapperService.indexAnalyzer(), similarityService.similarity(), codecService, failedEngineListener, translogRecoveryPerformer, indexCache.query(), cachingPolicy, wrappingService, translogConfig);
+                mapperService.indexAnalyzer(), similarityService.similarity(), codecService, failedEngineListener, translogRecoveryPerformer, indexCache.query(), cachingPolicy, createContextIndexSearcherService, translogConfig);
     }
 
     private static class IndexShardOperationCounter extends AbstractRefCounted {
@@ -1429,4 +1429,7 @@ public void sync(Translog.Location location) {
         }
     }
 
+    public CreateContextIndexSearcherService getCreateContextIndexSearcherService() {
+        return createContextIndexSearcherService;
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardModule.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardModule.java
index 28a59734dac2..b40a659a0c16 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardModule.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardModule.java
@@ -24,11 +24,7 @@
 import org.elasticsearch.common.inject.AbstractModule;
 import org.elasticsearch.common.inject.multibindings.Multibinder;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.cache.query.index.IndexQueryCache;
-import org.elasticsearch.index.engine.IndexSearcherWrapper;
-import org.elasticsearch.index.engine.IndexSearcherWrappingService;
-import org.elasticsearch.index.engine.EngineFactory;
-import org.elasticsearch.index.engine.InternalEngineFactory;
+import org.elasticsearch.index.engine.*;
 import org.elasticsearch.index.percolator.stats.ShardPercolateService;
 import org.elasticsearch.index.termvectors.ShardTermVectorsService;
 import org.elasticsearch.index.translog.TranslogService;
@@ -41,6 +37,7 @@
 public class IndexShardModule extends AbstractModule {
 
     public static final String ENGINE_FACTORY = "index.engine.factory";
+    public static final String WRAPPING_SERVICE_CLASS = "index.index_seache_.wrapping_class";
 
     private final ShardId shardId;
     private final Settings settings;
@@ -80,8 +77,13 @@ protected void configure() {
         bind(StoreRecoveryService.class).asEagerSingleton();
         bind(ShardPercolateService.class).asEagerSingleton();
         bind(ShardTermVectorsService.class).asEagerSingleton();
-        bind(IndexSearcherWrappingService.class).asEagerSingleton();
-        // this injects an empty set in IndexSearcherWrappingService, otherwise guice can't construct IndexSearcherWrappingService
+        Class<? extends CreateContextIndexSearcherService> wrappingServiceClass = DefaultCreateContextIndexSearcherService.class;
+        String customWrappingServiceClass = settings.get(WRAPPING_SERVICE_CLASS);
+        if (customWrappingServiceClass != null) {
+            wrappingServiceClass = Classes.loadClass(getClass().getClassLoader(), customWrappingServiceClass);
+        }
+        bind(CreateContextIndexSearcherService.class).to(wrappingServiceClass);
+        // this injects an empty set in CreateContextIndexSearcherService, otherwise guice can't construct CreateContextIndexSearcherService
         Multibinder<IndexSearcherWrapper> multibinder
                 = Multibinder.newSetBinder(binder(), IndexSearcherWrapper.class);
     }
diff --git a/core/src/main/java/org/elasticsearch/index/shard/ShadowIndexShard.java b/core/src/main/java/org/elasticsearch/index/shard/ShadowIndexShard.java
index 9e8776d1b1e9..3bc97a56278f 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/ShadowIndexShard.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/ShadowIndexShard.java
@@ -28,7 +28,7 @@
 import org.elasticsearch.index.cache.IndexCache;
 import org.elasticsearch.index.codec.CodecService;
 import org.elasticsearch.index.deletionpolicy.SnapshotDeletionPolicy;
-import org.elasticsearch.index.engine.IndexSearcherWrappingService;
+import org.elasticsearch.index.engine.CreateContextIndexSearcherService;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.engine.EngineConfig;
 import org.elasticsearch.index.engine.EngineFactory;
@@ -67,7 +67,7 @@ public ShadowIndexShard(ShardId shardId, IndexSettingsService indexSettingsServi
                             IndexService indexService, @Nullable IndicesWarmer warmer,
                             SnapshotDeletionPolicy deletionPolicy, SimilarityService similarityService,
                             EngineFactory factory, ClusterService clusterService,
-                            ShardPath path, BigArrays bigArrays, IndexSearcherWrappingService wrappingService) throws IOException {
+                            ShardPath path, BigArrays bigArrays, CreateContextIndexSearcherService wrappingService) throws IOException {
         super(shardId, indexSettingsService, indicesLifecycle, store, storeRecoveryService,
                 threadPool, mapperService, queryParserService, indexCache, indexAliasesService,
                 indicesQueryCache, shardPercolateService, codecService,
diff --git a/core/src/main/java/org/elasticsearch/percolator/PercolateContext.java b/core/src/main/java/org/elasticsearch/percolator/PercolateContext.java
index bf3b060db12d..69fe187dcf2a 100644
--- a/core/src/main/java/org/elasticsearch/percolator/PercolateContext.java
+++ b/core/src/main/java/org/elasticsearch/percolator/PercolateContext.java
@@ -32,8 +32,10 @@
 import org.elasticsearch.action.percolate.PercolateShardRequest;
 import org.elasticsearch.action.search.SearchType;
 import org.elasticsearch.cache.recycler.PageCacheRecycler;
-import org.elasticsearch.client.Client;
-import org.elasticsearch.common.*;
+import org.elasticsearch.common.HasContext;
+import org.elasticsearch.common.HasContextAndHeaders;
+import org.elasticsearch.common.HasHeaders;
+import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.lease.Releasables;
 import org.elasticsearch.common.text.StringText;
@@ -64,11 +66,7 @@
 import org.elasticsearch.search.fetch.script.ScriptFieldsContext;
 import org.elasticsearch.search.fetch.source.FetchSourceContext;
 import org.elasticsearch.search.highlight.SearchContextHighlight;
-import org.elasticsearch.search.internal.ContextIndexSearcher;
-import org.elasticsearch.search.internal.InternalSearchHit;
-import org.elasticsearch.search.internal.InternalSearchHitField;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.search.internal.ShardSearchRequest;
+import org.elasticsearch.search.internal.*;
 import org.elasticsearch.search.lookup.LeafSearchLookup;
 import org.elasticsearch.search.lookup.SearchLookup;
 import org.elasticsearch.search.query.QuerySearchResult;
@@ -133,7 +131,8 @@ public PercolateContext(PercolateShardRequest request, SearchShardTarget searchS
         this.bigArrays = bigArrays.withCircuitBreaking();
         this.querySearchResult = new QuerySearchResult(0, searchShardTarget);
         this.engineSearcher = indexShard.acquireSearcher("percolate");
-        this.searcher = new ContextIndexSearcher(this, engineSearcher);
+        this.searcher = (ContextIndexSearcher) engineSearcher.searcher();
+        this.searcher.setSearchContext(this);
         this.scriptService = scriptService;
         this.numberOfShards = request.getNumberOfShards();
         this.aliasFilter = aliasFilter;
diff --git a/core/src/main/java/org/elasticsearch/search/SearchService.java b/core/src/main/java/org/elasticsearch/search/SearchService.java
index 4beacda97f13..03a3707b7386 100644
--- a/core/src/main/java/org/elasticsearch/search/SearchService.java
+++ b/core/src/main/java/org/elasticsearch/search/SearchService.java
@@ -26,7 +26,6 @@
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.NumericDocValues;
-import org.apache.lucene.search.QueryCachingPolicy;
 import org.apache.lucene.search.TopDocs;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.ElasticsearchParseException;
@@ -54,7 +53,6 @@
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.IndexService;
-import org.elasticsearch.index.cache.IndexCache;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.fielddata.FieldDataType;
 import org.elasticsearch.index.fielddata.IndexFieldData;
@@ -82,7 +80,6 @@
 import org.elasticsearch.script.ScriptService;
 import org.elasticsearch.script.Template;
 import org.elasticsearch.script.mustache.MustacheScriptEngineService;
-import org.elasticsearch.search.dfs.CachedDfSource;
 import org.elasticsearch.search.dfs.DfsPhase;
 import org.elasticsearch.search.dfs.DfsSearchResult;
 import org.elasticsearch.search.fetch.*;
@@ -414,10 +411,7 @@ public QuerySearchResult executeQueryPhase(QuerySearchRequest request) {
         contextProcessing(context);
         IndexShard indexShard = context.indexShard();
         try {
-            final IndexCache indexCache = indexShard.indexService().cache();
-            final QueryCachingPolicy cachingPolicy = indexShard.getQueryCachingPolicy();
-            context.searcher().dfSource(new CachedDfSource(context.searcher().getIndexReader(), request.dfs(), context.similarityService().similarity(),
-                    indexCache.query(), cachingPolicy));
+            context.searcher().setDfSource(request.dfs());
         } catch (Throwable e) {
             processFailure(context, e);
             cleanContext(context);
@@ -489,11 +483,7 @@ public QueryFetchSearchResult executeFetchPhase(QuerySearchRequest request) {
         final SearchContext context = findContext(request.id());
         contextProcessing(context);
         try {
-            final IndexShard indexShard = context.indexShard();
-            final IndexCache indexCache = indexShard.indexService().cache();
-            final QueryCachingPolicy cachingPolicy = indexShard.getQueryCachingPolicy();
-            context.searcher().dfSource(new CachedDfSource(context.searcher().getIndexReader(), request.dfs(), context.similarityService().similarity(),
-                    indexCache.query(), cachingPolicy));
+            context.searcher().setDfSource(request.dfs());
         } catch (Throwable e) {
             freeContext(context.id());
             cleanContext(context);
@@ -637,7 +627,12 @@ final SearchContext createContext(ShardSearchRequest request, @Nullable Engine.S
 
         SearchShardTarget shardTarget = new SearchShardTarget(clusterService.localNode().id(), request.index(), request.shardId());
 
-        Engine.Searcher engineSearcher = searcher == null ? indexShard.acquireSearcher("search") : searcher;
+        final Engine.Searcher engineSearcher;
+        if (searcher == null) {
+            engineSearcher = indexShard.acquireSearcher("search");
+        } else {
+            engineSearcher = indexShard.getCreateContextIndexSearcherService().wrap(indexShard.engine().config(), searcher);
+        }
 
         SearchContext context = new DefaultSearchContext(idGenerator.incrementAndGet(), request, shardTarget, engineSearcher, indexService, indexShard, scriptService, pageCacheRecycler, bigArrays, threadPool.estimatedTimeInMillisCounter(), parseFieldMatcher, defaultSearchTimeout);
         SearchContext.setCurrent(context);
diff --git a/core/src/main/java/org/elasticsearch/search/dfs/CachedDfSource.java b/core/src/main/java/org/elasticsearch/search/dfs/CachedDfSource.java
deleted file mode 100644
index dbd66ab81dbe..000000000000
--- a/core/src/main/java/org/elasticsearch/search/dfs/CachedDfSource.java
+++ /dev/null
@@ -1,97 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.search.dfs;
-
-import org.apache.lucene.document.Document;
-import org.apache.lucene.index.*;
-import org.apache.lucene.search.*;
-import org.apache.lucene.search.similarities.Similarity;
-
-import java.io.IOException;
-import java.util.List;
-
-/**
- *
- */
-public class CachedDfSource extends IndexSearcher {
-
-    private final AggregatedDfs aggregatedDfs;
-
-    private final int maxDoc;
-
-    public CachedDfSource(IndexReader reader, AggregatedDfs aggregatedDfs, Similarity similarity,
-            QueryCache queryCache, QueryCachingPolicy queryCachingPolicy) throws IOException {
-        super(reader);
-        this.aggregatedDfs = aggregatedDfs;
-        setSimilarity(similarity);
-        setQueryCache(queryCache);
-        setQueryCachingPolicy(queryCachingPolicy);
-        if (aggregatedDfs.maxDoc() > Integer.MAX_VALUE) {
-            maxDoc = Integer.MAX_VALUE;
-        } else {
-            maxDoc = (int) aggregatedDfs.maxDoc();
-        }
-    }
-
-
-    @Override
-    public TermStatistics termStatistics(Term term, TermContext context) throws IOException {
-        TermStatistics termStatistics = aggregatedDfs.termStatistics().get(term);
-        if (termStatistics == null) {
-            // we don't have stats for this - this might be a must_not clauses etc. that doesn't allow extract terms on the query
-           return super.termStatistics(term, context);
-        }
-        return termStatistics;
-    }
-
-    @Override
-    public CollectionStatistics collectionStatistics(String field) throws IOException {
-        CollectionStatistics collectionStatistics = aggregatedDfs.fieldStatistics().get(field);
-        if (collectionStatistics == null) {
-            // we don't have stats for this - this might be a must_not clauses etc. that doesn't allow extract terms on the query
-           return super.collectionStatistics(field);
-        }
-        return collectionStatistics;
-    }
-    
-    public int maxDoc() {
-        return this.maxDoc;
-    }
-
-    @Override
-    public Document doc(int i) {
-        throw new UnsupportedOperationException();
-    }
-
-    @Override
-    public void doc(int docID, StoredFieldVisitor fieldVisitor) throws IOException {
-        throw new UnsupportedOperationException();
-    }
-
-    @Override
-    public Explanation explain(Weight weight, int doc) {
-        throw new UnsupportedOperationException();
-    }
-
-    @Override
-    protected void search(List<LeafReaderContext> leaves, Weight weight, Collector collector) throws IOException {
-        throw new UnsupportedOperationException();
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/search/internal/ContextIndexSearcher.java b/core/src/main/java/org/elasticsearch/search/internal/ContextIndexSearcher.java
index dd7489cc7a54..1819b5a72a32 100644
--- a/core/src/main/java/org/elasticsearch/search/internal/ContextIndexSearcher.java
+++ b/core/src/main/java/org/elasticsearch/search/internal/ContextIndexSearcher.java
@@ -19,24 +19,20 @@
 
 package org.elasticsearch.search.internal;
 
+import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.TermContext;
 import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Collector;
-import org.apache.lucene.search.Explanation;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.MultiCollector;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TimeLimitingCollector;
-import org.apache.lucene.search.Weight;
+import org.apache.lucene.search.*;
+import org.apache.lucene.search.similarities.Similarity;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.common.lease.Releasable;
 import org.elasticsearch.common.lucene.Lucene;
 import org.elasticsearch.common.lucene.MinimumScoreCollector;
 import org.elasticsearch.common.lucene.search.FilteredCollector;
-import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.search.SearchService;
-import org.elasticsearch.search.dfs.CachedDfSource;
+import org.elasticsearch.search.dfs.AggregatedDfs;
 import org.elasticsearch.search.internal.SearchContext.Lifetime;
 
 import java.io.IOException;
@@ -50,42 +46,66 @@
  */
 public class ContextIndexSearcher extends IndexSearcher implements Releasable {
 
-    public static enum Stage {
+    public enum Stage {
         NA,
         MAIN_QUERY
     }
 
-    /** The wrapped {@link IndexSearcher}. The reason why we sometimes prefer delegating to this searcher instead of <tt>super</tt> is that
-     *  this instance may have more assertions, for example if it comes from MockInternalEngine which wraps the IndexSearcher into an
-     *  AssertingIndexSearcher. */
-    private final IndexSearcher in;
+    private SearchContext searchContext;
+    private AggregatedDfs aggregatedDfs;
+    private Map<Class<?>, Collector> queryCollectors;
+    private Stage currentState = Stage.NA;
 
-    private final SearchContext searchContext;
+    private QueryCache queryCache;
+    private QueryCachingPolicy queryCachingPolicy;
 
-    private CachedDfSource dfSource;
+    // for testing:
+    public ContextIndexSearcher(IndexReader r) {
+        super(r);
+    }
 
-    private Map<Class<?>, Collector> queryCollectors;
+    public ContextIndexSearcher(IndexReader reader, Similarity similarity, QueryCache queryCache, QueryCachingPolicy queryCachingPolicy) {
+        super(reader);
+        setSimilarity(similarity);
+        setQueryCache(queryCache);
+        setQueryCachingPolicy(queryCachingPolicy);
+    }
 
-    private Stage currentState = Stage.NA;
+    @Override
+    public void close() {
+    }
 
-    public ContextIndexSearcher(SearchContext searchContext, Engine.Searcher searcher) {
-        super(searcher.reader());
-        in = searcher.searcher();
+    public void setDfSource(AggregatedDfs aggregatedDfs) {
+        this.aggregatedDfs = aggregatedDfs;
+    }
+
+    public void setSearchContext(SearchContext searchContext) {
         this.searchContext = searchContext;
-        setSimilarity(searcher.searcher().getSimilarity(true));
     }
 
     @Override
-    public void close() {
+    public void setQueryCache(QueryCache queryCache) {
+        this.queryCache = queryCache;
+        super.setQueryCache(queryCache);
     }
 
-    public void dfSource(CachedDfSource dfSource) {
-        this.dfSource = dfSource;
+    public QueryCache getQueryCache() {
+        return queryCache;
+    }
+
+    @Override
+    public void setQueryCachingPolicy(QueryCachingPolicy queryCachingPolicy) {
+        this.queryCachingPolicy = queryCachingPolicy;
+        super.setQueryCachingPolicy(queryCachingPolicy);
+    }
+
+    public QueryCachingPolicy getQueryCachingPolicy() {
+        return queryCachingPolicy;
     }
 
     /**
      * Adds a query level collector that runs at {@link Stage#MAIN_QUERY}. Note, supports
-     * {@link org.elasticsearch.common.lucene.search.XCollector} allowing for a callback
+     * {@link Collector} allowing for a callback
      * when collection is done.
      */
     public Map<Class<?>, Collector> queryCollectors() {
@@ -106,38 +126,36 @@ public void finishStage(Stage stage) {
 
     @Override
     public Query rewrite(Query original) throws IOException {
-        if (original == searchContext.query() || original == searchContext.parsedQuery().query()) {
+        if (searchContext != null && (original == searchContext.query() || original == searchContext.parsedQuery().query())) {
             // optimize in case its the top level search query and we already rewrote it...
             if (searchContext.queryRewritten()) {
                 return searchContext.query();
             }
-            Query rewriteQuery = in.rewrite(original);
+            Query rewriteQuery = super.rewrite(original);
             searchContext.updateRewriteQuery(rewriteQuery);
             return rewriteQuery;
         } else {
-            return in.rewrite(original);
+            return super.rewrite(original);
         }
     }
 
     @Override
     public Weight createNormalizedWeight(Query query, boolean needsScores) throws IOException {
-        // TODO: needsScores
-        // can we avoid dfs stuff here if we dont need scores?
         try {
-            // if its the main query, use we have dfs data, only then do it
-            if (dfSource != null && (query == searchContext.query() || query == searchContext.parsedQuery().query())) {
-                return dfSource.createNormalizedWeight(query, needsScores);
-            }
-            return in.createNormalizedWeight(query, needsScores);
+            return super.createNormalizedWeight(query, needsScores);
         } catch (Throwable t) {
             searchContext.clearReleasables(Lifetime.COLLECTION);
             throw ExceptionsHelper.convertToElastic(t);
         }
     }
 
-
     @Override
     public void search(Query query, Collector collector) throws IOException {
+        if (searchContext == null) {
+            super.search(query, collector);
+            return;
+        }
+
         // Wrap the caller's collector with various wrappers e.g. those used to siphon
         // matches off for aggregation or to impose a time-limit on collection.
         final boolean timeoutSet = searchContext.timeoutInMillis() != SearchService.NO_TIMEOUT.millis();
@@ -176,6 +194,11 @@ public void search(Query query, Collector collector) throws IOException {
 
     @Override
     public void search(List<LeafReaderContext> leaves, Weight weight, Collector collector) throws IOException {
+        if (searchContext == null) {
+            super.search(leaves, weight, collector);
+            return;
+        }
+
         final boolean timeoutSet = searchContext.timeoutInMillis() != SearchService.NO_TIMEOUT.millis();
         final boolean terminateAfterSet = searchContext.terminateAfter() != SearchContext.DEFAULT_TERMINATE_AFTER;
         try {
@@ -202,6 +225,10 @@ public void search(List<LeafReaderContext> leaves, Weight weight, Collector coll
 
     @Override
     public Explanation explain(Query query, int doc) throws IOException {
+        if (searchContext == null) {
+            return super.explain(query, doc);
+        }
+
         try {
             if (searchContext.aliasFilter() == null) {
                 return super.explain(query, doc);
@@ -214,4 +241,32 @@ public Explanation explain(Query query, int doc) throws IOException {
             searchContext.clearReleasables(Lifetime.COLLECTION);
         }
     }
+
+    @Override
+    public TermStatistics termStatistics(Term term, TermContext context) throws IOException {
+        if (searchContext == null || aggregatedDfs == null) {
+            return super.termStatistics(term, context);
+        }
+
+        TermStatistics termStatistics = aggregatedDfs.termStatistics().get(term);
+        if (termStatistics == null) {
+            // we don't have stats for this - this might be a must_not clauses etc. that doesn't allow extract terms on the query
+            return super.termStatistics(term, context);
+        }
+        return termStatistics;
+    }
+
+    @Override
+    public CollectionStatistics collectionStatistics(String field) throws IOException {
+        if (searchContext == null || aggregatedDfs == null) {
+            return super.collectionStatistics(field);
+        }
+
+        CollectionStatistics collectionStatistics = aggregatedDfs.fieldStatistics().get(field);
+        if (collectionStatistics == null) {
+            // we don't have stats for this - this might be a must_not clauses etc. that doesn't allow extract terms on the query
+            return super.collectionStatistics(field);
+        }
+        return collectionStatistics;
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/search/internal/DefaultSearchContext.java b/core/src/main/java/org/elasticsearch/search/internal/DefaultSearchContext.java
index f420986272d3..1103b8f72803 100644
--- a/core/src/main/java/org/elasticsearch/search/internal/DefaultSearchContext.java
+++ b/core/src/main/java/org/elasticsearch/search/internal/DefaultSearchContext.java
@@ -149,7 +149,8 @@ public DefaultSearchContext(long id, ShardSearchRequest request, SearchShardTarg
         this.fetchResult = new FetchSearchResult(id, shardTarget);
         this.indexShard = indexShard;
         this.indexService = indexService;
-        this.searcher = new ContextIndexSearcher(this, engineSearcher);
+        this.searcher = (ContextIndexSearcher) engineSearcher.searcher();
+        this.searcher.setSearchContext(this);
         this.timeEstimateCounter = timeEstimateCounter;
         this.timeoutInMillis = timeout.millis();
     }
diff --git a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
index bad431f67e57..57623576a555 100644
--- a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
+++ b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
@@ -79,6 +79,7 @@
 import org.elasticsearch.index.translog.Translog;
 import org.elasticsearch.index.translog.TranslogConfig;
 import org.elasticsearch.index.translog.TranslogTests;
+import org.elasticsearch.search.internal.ContextIndexSearcher;
 import org.elasticsearch.test.DummyShardLock;
 import org.elasticsearch.test.ESTestCase;
 import org.elasticsearch.threadpool.ThreadPool;
@@ -256,7 +257,7 @@ public EngineConfig config(Settings indexSettings, Store store, Path translogPat
             public void onFailedEngine(ShardId shardId, String reason, @Nullable Throwable t) {
                 // we don't need to notify anybody in this test
             }
-        }, new TranslogHandler(shardId.index().getName()), IndexSearcher.getDefaultQueryCache(), IndexSearcher.getDefaultQueryCachingPolicy(), new IndexSearcherWrappingService(new HashSet<>(Arrays.asList(wrappers))), translogConfig);
+        }, new TranslogHandler(shardId.index().getName()), IndexSearcher.getDefaultQueryCache(), IndexSearcher.getDefaultQueryCachingPolicy(), new DefaultCreateContextIndexSearcherService(new HashSet<>(Arrays.asList(wrappers))), translogConfig);
         try {
             config.setCreate(Lucene.indexExists(store.directory()) == false);
         } catch (IOException e) {
@@ -510,7 +511,7 @@ public DirectoryReader wrap(DirectoryReader reader) {
             }
 
             @Override
-            public IndexSearcher wrap(IndexSearcher searcher) throws EngineException {
+            public ContextIndexSearcher wrap(ContextIndexSearcher searcher, EngineConfig engineConfig) throws EngineException {
                 counter.incrementAndGet();
                 return searcher;
             }
@@ -2017,7 +2018,7 @@ public void testRecoverFromForeignTranslog() throws IOException {
         EngineConfig brokenConfig = new EngineConfig(shardId, threadPool, config.getIndexingService(), config.getIndexSettings()
                 , null, store, createSnapshotDeletionPolicy(), newMergePolicy(), config.getMergeSchedulerConfig(),
                 config.getAnalyzer(), config.getSimilarity(), new CodecService(shardId.index()), config.getFailedEngineListener()
-        , config.getTranslogRecoveryPerformer(), IndexSearcher.getDefaultQueryCache(), IndexSearcher.getDefaultQueryCachingPolicy(), new IndexSearcherWrappingService(), translogConfig);
+        , config.getTranslogRecoveryPerformer(), IndexSearcher.getDefaultQueryCache(), IndexSearcher.getDefaultQueryCachingPolicy(), new DefaultCreateContextIndexSearcherService(), translogConfig);
 
         try {
             new InternalEngine(brokenConfig, false);
diff --git a/core/src/test/java/org/elasticsearch/index/engine/ShadowEngineTests.java b/core/src/test/java/org/elasticsearch/index/engine/ShadowEngineTests.java
index 7b45a3b90cd6..5fe77e29bf6e 100644
--- a/core/src/test/java/org/elasticsearch/index/engine/ShadowEngineTests.java
+++ b/core/src/test/java/org/elasticsearch/index/engine/ShadowEngineTests.java
@@ -226,7 +226,7 @@ public EngineConfig config(Settings indexSettings, Store store, Path translogPat
             @Override
             public void onFailedEngine(ShardId shardId, String reason, @Nullable Throwable t) {
                 // we don't need to notify anybody in this test
-        }}, null, IndexSearcher.getDefaultQueryCache(), IndexSearcher.getDefaultQueryCachingPolicy(), new IndexSearcherWrappingService(), translogConfig);
+        }}, null, IndexSearcher.getDefaultQueryCache(), IndexSearcher.getDefaultQueryCachingPolicy(), new DefaultCreateContextIndexSearcherService(), translogConfig);
         try {
             config.setCreate(Lucene.indexExists(store.directory()) == false);
         } catch (IOException e) {
diff --git a/core/src/test/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQueryTests.java b/core/src/test/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQueryTests.java
index 2a74fb986e23..9ca72f953d8e 100644
--- a/core/src/test/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQueryTests.java
+++ b/core/src/test/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQueryTests.java
@@ -20,33 +20,18 @@
 
 import com.carrotsearch.hppc.IntHashSet;
 import com.carrotsearch.hppc.ObjectObjectHashMap;
-
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.PostingsEnum;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.SlowCompositeReaderWrapper;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryUtils;
-import org.apache.lucene.search.QueryWrapperFilter;
-import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.index.*;
+import org.apache.lucene.search.*;
 import org.apache.lucene.search.join.BitDocIdSetFilter;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
 import org.elasticsearch.common.lease.Releasables;
 import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
 import org.elasticsearch.index.mapper.Uid;
 import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
@@ -65,11 +50,7 @@
 import java.util.Random;
 import java.util.TreeSet;
 
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.filteredQuery;
-import static org.elasticsearch.index.query.QueryBuilders.hasChildQuery;
-import static org.elasticsearch.index.query.QueryBuilders.notQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
+import static org.elasticsearch.index.query.QueryBuilders.*;
 import static org.hamcrest.Matchers.equalTo;
 
 public class ChildrenConstantScoreQueryTests extends AbstractChildTestCase {
@@ -118,10 +99,8 @@ public void testSimple() throws Exception {
         }
 
         IndexReader indexReader = DirectoryReader.open(indexWriter.w, false);
-        IndexSearcher searcher = new IndexSearcher(indexReader);
-        ((TestSearchContext) SearchContext.current()).setSearcher(new ContextIndexSearcher(
-                SearchContext.current(), new Engine.Searcher(ChildrenConstantScoreQueryTests.class.getSimpleName(), searcher)
-        ));
+        ContextIndexSearcher searcher = new ContextIndexSearcher(indexReader);
+        ((TestSearchContext) SearchContext.current()).setSearcher(searcher);
 
         TermQuery childQuery = new TermQuery(new Term("field1", "value" + (1 + random().nextInt(3))));
         BitDocIdSetFilter parentFilter = wrapWithBitSetFilter(new QueryWrapperFilter(new TermQuery(new Term(TypeFieldMapper.NAME, "parent"))));
@@ -210,11 +189,8 @@ public void testRandom() throws Exception {
 
         indexWriter.commit();
         IndexReader indexReader = DirectoryReader.open(directory);
-        IndexSearcher searcher = new IndexSearcher(indexReader);
-        Engine.Searcher engineSearcher = new Engine.Searcher(
-                ChildrenConstantScoreQueryTests.class.getSimpleName(), searcher
-        );
-        ((TestSearchContext) SearchContext.current()).setSearcher(new ContextIndexSearcher(SearchContext.current(), engineSearcher));
+        ContextIndexSearcher searcher = new ContextIndexSearcher(indexReader);
+        ((TestSearchContext) SearchContext.current()).setSearcher(searcher);
 
         int max = numUniqueChildValues / 4;
         for (int i = 0; i < max; i++) {
@@ -239,11 +215,8 @@ public void testRandom() throws Exception {
 
                 indexReader.close();
                 indexReader = DirectoryReader.open(indexWriter.w, true);
-                searcher = new IndexSearcher(indexReader);
-                engineSearcher = new Engine.Searcher(
-                        ChildrenConstantScoreQueryTests.class.getSimpleName(), searcher
-                );
-                ((TestSearchContext) SearchContext.current()).setSearcher(new ContextIndexSearcher(SearchContext.current(), engineSearcher));
+                searcher = new ContextIndexSearcher(indexReader);
+                ((TestSearchContext) SearchContext.current()).setSearcher(searcher);
             }
 
             String childValue = childValues[random().nextInt(numUniqueChildValues)];
@@ -263,7 +236,7 @@ public void testRandom() throws Exception {
             Query query = parseQuery(queryBuilder);
 
             BitSetCollector collector = new BitSetCollector(indexReader.maxDoc());
-            searcher.search(query, collector);
+            SearchContext.current().searcher().search(query, collector);
             FixedBitSet actualResult = collector.getResult();
 
             FixedBitSet expectedResult = new FixedBitSet(indexReader.maxDoc());
@@ -286,7 +259,7 @@ public void testRandom() throws Exception {
                 }
             }
 
-            assertBitSet(actualResult, expectedResult, searcher);
+            assertBitSet(actualResult, expectedResult, SearchContext.current().searcher());
         }
 
         indexWriter.close();
diff --git a/core/src/test/java/org/elasticsearch/index/search/child/ChildrenQueryTests.java b/core/src/test/java/org/elasticsearch/index/search/child/ChildrenQueryTests.java
index 9e70f667502e..2424a905606f 100644
--- a/core/src/test/java/org/elasticsearch/index/search/child/ChildrenQueryTests.java
+++ b/core/src/test/java/org/elasticsearch/index/search/child/ChildrenQueryTests.java
@@ -22,41 +22,19 @@
 import com.carrotsearch.hppc.IntHashSet;
 import com.carrotsearch.hppc.ObjectObjectHashMap;
 import com.carrotsearch.randomizedtesting.generators.RandomInts;
-
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.DoubleField;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.PostingsEnum;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.SlowCompositeReaderWrapper;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.LeafCollector;
-import org.apache.lucene.search.MultiCollector;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryUtils;
-import org.apache.lucene.search.QueryWrapperFilter;
-import org.apache.lucene.search.ScoreDoc;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.search.TopDocs;
-import org.apache.lucene.search.TopScoreDocCollector;
+import org.apache.lucene.index.*;
+import org.apache.lucene.search.*;
 import org.apache.lucene.search.join.BitDocIdSetFilter;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
 import org.elasticsearch.common.lease.Releasables;
 import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
 import org.elasticsearch.index.mapper.Uid;
 import org.elasticsearch.index.mapper.internal.IdFieldMapper;
@@ -73,19 +51,9 @@
 import org.junit.Test;
 
 import java.io.IOException;
-import java.util.Locale;
-import java.util.Map;
-import java.util.NavigableMap;
-import java.util.Random;
-import java.util.TreeMap;
-
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.filteredQuery;
-import static org.elasticsearch.index.query.QueryBuilders.functionScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.hasChildQuery;
-import static org.elasticsearch.index.query.QueryBuilders.notQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
-import static org.elasticsearch.index.query.QueryBuilders.typeQuery;
+import java.util.*;
+
+import static org.elasticsearch.index.query.QueryBuilders.*;
 import static org.hamcrest.Matchers.is;
 import static org.hamcrest.Matchers.lessThanOrEqualTo;
 
@@ -191,11 +159,8 @@ public void testRandom() throws Exception {
         indexWriter.commit();
 
         IndexReader indexReader = DirectoryReader.open(directory);
-        IndexSearcher searcher = new IndexSearcher(indexReader);
-        Engine.Searcher engineSearcher = new Engine.Searcher(
-                ChildrenQueryTests.class.getSimpleName(), searcher
-        );
-        ((TestSearchContext) SearchContext.current()).setSearcher(new ContextIndexSearcher(SearchContext.current(), engineSearcher));
+        ContextIndexSearcher searcher = new ContextIndexSearcher(indexReader);
+        ((TestSearchContext) SearchContext.current()).setSearcher(searcher);
 
         int max = numUniqueChildValues / 4;
         for (int i = 0; i < max; i++) {
@@ -220,11 +185,8 @@ public void testRandom() throws Exception {
 
                 indexReader.close();
                 indexReader = DirectoryReader.open(indexWriter.w, true);
-                searcher = new IndexSearcher(indexReader);
-                engineSearcher = new Engine.Searcher(
-                        ChildrenConstantScoreQueryTests.class.getSimpleName(), searcher
-                );
-                ((TestSearchContext) SearchContext.current()).setSearcher(new ContextIndexSearcher(SearchContext.current(), engineSearcher));
+                searcher = new ContextIndexSearcher(indexReader);
+                ((TestSearchContext) SearchContext.current()).setSearcher(searcher);
             }
 
             String childValue = childValues[random().nextInt(numUniqueChildValues)];
@@ -380,12 +342,10 @@ private void assertScoreType(ScoreType scoreType) throws IOException {
 
         writer.commit();
 
-        IndexReader reader = DirectoryReader.open(writer, true);
-        IndexSearcher searcher = new IndexSearcher(reader);
-
         // setup to read the parent/child map
-        Engine.Searcher engineSearcher = new Engine.Searcher(ChildrenQueryTests.class.getSimpleName(), searcher);
-        ((TestSearchContext)context).setSearcher(new ContextIndexSearcher(context, engineSearcher));
+        IndexReader reader = DirectoryReader.open(writer, true);
+        ContextIndexSearcher searcher = new ContextIndexSearcher(reader);
+        ((TestSearchContext) SearchContext.current()).setSearcher(searcher);
 
         // child query that returns the score as the value of "childScore" for each child document, with the parent's score determined by the score type
         QueryBuilder childQueryBuilder = functionScoreQuery(typeQuery("child")).add(new FieldValueFactorFunctionBuilder(CHILD_SCORE_NAME));
diff --git a/core/src/test/java/org/elasticsearch/index/search/child/ParentConstantScoreQueryTests.java b/core/src/test/java/org/elasticsearch/index/search/child/ParentConstantScoreQueryTests.java
index ac5c3a46eceb..9f0339d8647d 100644
--- a/core/src/test/java/org/elasticsearch/index/search/child/ParentConstantScoreQueryTests.java
+++ b/core/src/test/java/org/elasticsearch/index/search/child/ParentConstantScoreQueryTests.java
@@ -20,22 +20,11 @@
 
 import com.carrotsearch.hppc.IntIntHashMap;
 import com.carrotsearch.hppc.ObjectObjectHashMap;
-
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.PostingsEnum;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.SlowCompositeReaderWrapper;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.index.*;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.QueryUtils;
 import org.apache.lucene.search.QueryWrapperFilter;
@@ -45,7 +34,6 @@
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
 import org.elasticsearch.common.lease.Releasables;
-import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
 import org.elasticsearch.index.mapper.Uid;
 import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
@@ -64,11 +52,7 @@
 import java.util.Random;
 import java.util.TreeSet;
 
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.filteredQuery;
-import static org.elasticsearch.index.query.QueryBuilders.hasParentQuery;
-import static org.elasticsearch.index.query.QueryBuilders.notQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
+import static org.elasticsearch.index.query.QueryBuilders.*;
 
 /**
  */
@@ -169,11 +153,8 @@ public void testRandom() throws Exception {
         indexWriter.commit();
 
         IndexReader indexReader = DirectoryReader.open(directory);
-        IndexSearcher searcher = new IndexSearcher(indexReader);
-        Engine.Searcher engineSearcher = new Engine.Searcher(
-                ParentConstantScoreQuery.class.getSimpleName(), searcher
-        );
-        ((TestSearchContext) SearchContext.current()).setSearcher(new ContextIndexSearcher(SearchContext.current(), engineSearcher));
+        ContextIndexSearcher searcher = new ContextIndexSearcher(indexReader);
+        ((TestSearchContext) SearchContext.current()).setSearcher(searcher);
 
         int max = numUniqueParentValues / 4;
         for (int i = 0; i < max; i++) {
@@ -196,11 +177,8 @@ public void testRandom() throws Exception {
 
                 indexReader.close();
                 indexReader = DirectoryReader.open(indexWriter.w, true);
-                searcher = new IndexSearcher(indexReader);
-                engineSearcher = new Engine.Searcher(
-                        ParentConstantScoreQueryTests.class.getSimpleName(), searcher
-                );
-                ((TestSearchContext) SearchContext.current()).setSearcher(new ContextIndexSearcher(SearchContext.current(), engineSearcher));
+                searcher = new ContextIndexSearcher(indexReader);
+                ((TestSearchContext) SearchContext.current()).setSearcher(searcher);
             }
 
             String parentValue = parentValues[random().nextInt(numUniqueParentValues)];
diff --git a/core/src/test/java/org/elasticsearch/index/search/child/ParentQueryTests.java b/core/src/test/java/org/elasticsearch/index/search/child/ParentQueryTests.java
index 836ddf3b6a8b..7cb2689d42fe 100644
--- a/core/src/test/java/org/elasticsearch/index/search/child/ParentQueryTests.java
+++ b/core/src/test/java/org/elasticsearch/index/search/child/ParentQueryTests.java
@@ -21,36 +21,17 @@
 import com.carrotsearch.hppc.FloatArrayList;
 import com.carrotsearch.hppc.IntIntHashMap;
 import com.carrotsearch.hppc.ObjectObjectHashMap;
-
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.PostingsEnum;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.SlowCompositeReaderWrapper;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.LeafCollector;
-import org.apache.lucene.search.MultiCollector;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryUtils;
-import org.apache.lucene.search.QueryWrapperFilter;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.search.TopScoreDocCollector;
+import org.apache.lucene.index.*;
+import org.apache.lucene.search.*;
 import org.apache.lucene.search.join.BitDocIdSetFilter;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
 import org.elasticsearch.common.lease.Releasables;
-import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
 import org.elasticsearch.index.mapper.Uid;
 import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
@@ -70,11 +51,7 @@
 import java.util.Random;
 import java.util.TreeMap;
 
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.filteredQuery;
-import static org.elasticsearch.index.query.QueryBuilders.hasParentQuery;
-import static org.elasticsearch.index.query.QueryBuilders.notQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
+import static org.elasticsearch.index.query.QueryBuilders.*;
 
 public class ParentQueryTests extends AbstractChildTestCase {
 
@@ -171,11 +148,8 @@ public void testRandom() throws Exception {
         indexWriter.commit();
 
         IndexReader indexReader = DirectoryReader.open(directory);
-        IndexSearcher searcher = new IndexSearcher(indexReader);
-        Engine.Searcher engineSearcher = new Engine.Searcher(
-                ParentQueryTests.class.getSimpleName(), searcher
-        );
-        ((TestSearchContext) SearchContext.current()).setSearcher(new ContextIndexSearcher(SearchContext.current(), engineSearcher));
+        ContextIndexSearcher searcher = new ContextIndexSearcher(indexReader);
+        ((TestSearchContext) SearchContext.current()).setSearcher(searcher);
 
         int max = numUniqueParentValues / 4;
         for (int i = 0; i < max; i++) {
@@ -198,11 +172,8 @@ public void testRandom() throws Exception {
 
                 indexReader.close();
                 indexReader = DirectoryReader.open(indexWriter.w, true);
-                searcher = new IndexSearcher(indexReader);
-                engineSearcher = new Engine.Searcher(
-                        ParentConstantScoreQueryTests.class.getSimpleName(), searcher
-                );
-                ((TestSearchContext) SearchContext.current()).setSearcher(new ContextIndexSearcher(SearchContext.current(), engineSearcher));
+                searcher = new ContextIndexSearcher(indexReader);
+                ((TestSearchContext) SearchContext.current()).setSearcher(searcher);
             }
 
             String parentValue = parentValues[random().nextInt(numUniqueParentValues)];
diff --git a/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java b/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java
index 065732ed8a48..d9db4d3e2aa2 100644
--- a/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java
+++ b/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java
@@ -103,6 +103,7 @@
 import org.elasticsearch.test.cache.recycler.MockBigArrays;
 import org.elasticsearch.test.cache.recycler.MockPageCacheRecycler;
 import org.elasticsearch.test.disruption.ServiceDisruptionScheme;
+import org.elasticsearch.test.engine.AssertingCreateContextIndexSearcherService;
 import org.elasticsearch.test.engine.MockEngineFactory;
 import org.elasticsearch.test.search.MockSearchService;
 import org.elasticsearch.test.store.MockFSIndexStore;
@@ -395,6 +396,7 @@ private static Settings getRandomNodeSettings(long seed) {
             builder.put(PageCacheRecyclerModule.CACHE_IMPL, MockPageCacheRecycler.class.getName());
             builder.put(BigArraysModule.IMPL, MockBigArrays.class.getName());
             builder.put(SearchModule.SEARCH_SERVICE_IMPL, MockSearchService.class.getName());
+            builder.put(IndexShardModule.WRAPPING_SERVICE_CLASS, AssertingCreateContextIndexSearcherService.class.getName());
         }
         if (isLocalTransportConfigured()) {
             builder.extendArray("plugin.types", AssertingLocalTransport.Plugin.class.getName());
diff --git a/core/src/test/java/org/elasticsearch/test/TestSearchContext.java b/core/src/test/java/org/elasticsearch/test/TestSearchContext.java
index 44004fe6f48f..d5d295137a10 100644
--- a/core/src/test/java/org/elasticsearch/test/TestSearchContext.java
+++ b/core/src/test/java/org/elasticsearch/test/TestSearchContext.java
@@ -20,6 +20,7 @@
 
 import com.carrotsearch.hppc.ObjectObjectAssociativeContainer;
 
+import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.ScoreDoc;
diff --git a/core/src/test/java/org/elasticsearch/test/engine/AssertingContextIndexSearcher.java b/core/src/test/java/org/elasticsearch/test/engine/AssertingContextIndexSearcher.java
new file mode 100644
index 000000000000..38305b3c97d2
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/test/engine/AssertingContextIndexSearcher.java
@@ -0,0 +1,288 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.test.engine;
+
+import com.carrotsearch.randomizedtesting.generators.RandomInts;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.PostingsEnum;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.*;
+import org.apache.lucene.util.Bits;
+import org.elasticsearch.search.internal.ContextIndexSearcher;
+
+import java.io.IOException;
+import java.util.List;
+import java.util.Random;
+import java.util.Set;
+
+/**
+ * Helper class that adds some extra checks to ensure correct
+ * usage of {@code ContextIndexSearcher} and {@code Weight}.
+ */
+// Modified fork of Lucene's AssertingIndexSearcher that adds extra checks for ContextIndexSearcher
+public class AssertingContextIndexSearcher extends ContextIndexSearcher {
+
+    final Random random;
+
+    public AssertingContextIndexSearcher(Random random, ContextIndexSearcher indexSearcher) {
+        super(indexSearcher.getIndexReader(), indexSearcher.getSimilarity(true), indexSearcher.getQueryCache(), indexSearcher.getQueryCachingPolicy());
+        this.random = new Random(random.nextLong());
+    }
+
+    /** Ensures, that the returned {@code Weight} is not normalized again, which may produce wrong scores. */
+    @Override
+    public Weight createNormalizedWeight(Query query, boolean needsScores) throws IOException {
+        final Weight w = super.createNormalizedWeight(query, needsScores);
+        return new AssertingWeight(random, w) {
+
+            @Override
+            public void normalize(float norm, float topLevelBoost) {
+                throw new IllegalStateException("Weight already normalized.");
+            }
+
+            @Override
+            public float getValueForNormalization() {
+                throw new IllegalStateException("Weight already normalized.");
+            }
+
+        };
+    }
+
+    @Override
+    public Weight createWeight(Query query, boolean needsScores) throws IOException {
+        // this adds assertions to the inner weights/scorers too
+        return new AssertingWeight(random, super.createWeight(query, needsScores));
+    }
+
+    @Override
+    public Query rewrite(Query original) throws IOException {
+        // TODO: use the more sophisticated QueryUtils.check sometimes!
+        QueryUtils.check(original);
+        Query rewritten = super.rewrite(original);
+        QueryUtils.check(rewritten);
+        return rewritten;
+    }
+
+    @Override
+    public void search(List<LeafReaderContext> leaves, Weight weight, Collector collector) throws IOException {
+        // TODO: shouldn't we AssertingCollector.wrap(collector) here?
+        super.search(leaves, AssertingWeight.wrap(random, weight), AssertingCollector.wrap(random, collector));
+    }
+
+    @Override
+    public String toString() {
+        return "AssertingIndexSearcher(" + super.toString() + ")";
+    }
+
+    // Also copied from Lucene:
+    // TODO: make these classes in Lucene public
+    static class AssertingWeight extends Weight {
+
+        static Weight wrap(Random random, Weight other) {
+            return other instanceof AssertingWeight ? other : new AssertingWeight(random, other);
+        }
+
+        final Random random;
+        final Weight in;
+
+        AssertingWeight(Random random, Weight in) {
+            super(in.getQuery());
+            this.random = random;
+            this.in = in;
+        }
+
+        @Override
+        public void extractTerms(Set<Term> terms) {
+            in.extractTerms(terms);
+        }
+
+        @Override
+        public Explanation explain(LeafReaderContext context, int doc) throws IOException {
+            return in.explain(context, doc);
+        }
+
+        @Override
+        public float getValueForNormalization() throws IOException {
+            return in.getValueForNormalization();
+        }
+
+        @Override
+        public void normalize(float norm, float topLevelBoost) {
+            in.normalize(norm, topLevelBoost);
+        }
+
+        @Override
+        public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+            final Scorer inScorer = in.scorer(context, acceptDocs);
+            assert inScorer == null || inScorer.docID() == -1;
+            return AssertingScorer.wrap(new Random(random.nextLong()), inScorer);
+        }
+
+        @Override
+        public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {
+            BulkScorer inScorer = in.bulkScorer(context, acceptDocs);
+            if (inScorer == null) {
+                return null;
+            }
+
+            return AssertingBulkScorer.wrap(new Random(random.nextLong()), inScorer, context.reader().maxDoc());
+        }
+
+    }
+
+    static final class AssertingBulkScorer extends BulkScorer {
+
+        public static BulkScorer wrap(Random random, BulkScorer other, int maxDoc) {
+            if (other == null || other instanceof AssertingBulkScorer) {
+                return other;
+            }
+            return new AssertingBulkScorer(random, other, maxDoc);
+        }
+
+        final Random random;
+        final BulkScorer in;
+        final int maxDoc;
+        int max = 0;
+
+        private AssertingBulkScorer(Random random, BulkScorer in, int maxDoc) {
+            this.random = random;
+            this.in = in;
+            this.maxDoc = maxDoc;
+        }
+
+        public BulkScorer getIn() {
+            return in;
+        }
+
+        @Override
+        public long cost() {
+            return in.cost();
+        }
+
+        @Override
+        public void score(LeafCollector collector) throws IOException {
+            assert max == 0;
+            collector = new AssertingLeafCollector(random, collector, 0, PostingsEnum.NO_MORE_DOCS);
+            if (random.nextBoolean()) {
+                try {
+                    final int next = score(collector, 0, PostingsEnum.NO_MORE_DOCS);
+                    assert next == DocIdSetIterator.NO_MORE_DOCS;
+                } catch (UnsupportedOperationException e) {
+                    in.score(collector);
+                }
+            } else {
+                in.score(collector);
+            }
+        }
+
+        @Override
+        public int score(LeafCollector collector, int min, final int max) throws IOException {
+            assert min >= this.max: "Scoring backward: min=" + min + " while previous max was max=" + this.max;
+            assert min <= max : "max must be greater than min, got min=" + min + ", and max=" + max;
+            this.max = max;
+            collector = new AssertingLeafCollector(random, collector, min, max);
+            final int next = in.score(collector, min, max);
+            assert next >= max;
+            if (max >= maxDoc || next >= maxDoc) {
+                assert next == DocIdSetIterator.NO_MORE_DOCS;
+                return DocIdSetIterator.NO_MORE_DOCS;
+            } else {
+                return RandomInts.randomIntBetween(random, max, next);
+            }
+        }
+
+        @Override
+        public String toString() {
+            return "AssertingBulkScorer(" + in + ")";
+        }
+
+    }
+
+    static class AssertingCollector extends FilterCollector {
+
+        private final Random random;
+        private int maxDoc = -1;
+
+        /** Wrap the given collector in order to add assertions. */
+        public static Collector wrap(Random random, Collector in) {
+            if (in instanceof AssertingCollector) {
+                return in;
+            }
+            return new AssertingCollector(random, in);
+        }
+
+        private AssertingCollector(Random random, Collector in) {
+            super(in);
+            this.random = random;
+        }
+
+        @Override
+        public LeafCollector getLeafCollector(LeafReaderContext context) throws IOException {
+            final LeafCollector in = super.getLeafCollector(context);
+            final int docBase = context.docBase;
+            return new AssertingLeafCollector(random, in, 0, DocIdSetIterator.NO_MORE_DOCS) {
+                @Override
+                public void collect(int doc) throws IOException {
+                    // check that documents are scored in order globally,
+                    // not only per segment
+                    assert docBase + doc >= maxDoc : "collection is not in order: current doc="
+                            + (docBase + doc) + " while " + maxDoc + " has already been collected";
+                    super.collect(doc);
+                    maxDoc = docBase + doc;
+                }
+            };
+        }
+
+    }
+
+    static class AssertingLeafCollector extends FilterLeafCollector {
+
+        private final Random random;
+        private final int min;
+        private final int max;
+
+        private Scorer scorer;
+        private int lastCollected = -1;
+
+        AssertingLeafCollector(Random random, LeafCollector collector, int min, int max) {
+            super(collector);
+            this.random = random;
+            this.min = min;
+            this.max = max;
+        }
+
+        @Override
+        public void setScorer(Scorer scorer) throws IOException {
+            this.scorer = scorer;
+            super.setScorer(AssertingScorer.wrap(random, scorer));
+        }
+
+        @Override
+        public void collect(int doc) throws IOException {
+            assert doc > lastCollected : "Out of order : " + lastCollected + " " + doc;
+            assert doc >= min : "Out of range: " + doc + " < " + min;
+            assert doc < max : "Out of range: " + doc + " >= " + max;
+            assert scorer.docID() == doc : "Collected: " + doc + " but scorer: " + scorer.docID();
+            in.collect(doc);
+            lastCollected = doc;
+        }
+
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/test/engine/AssertingCreateContextIndexSearcherService.java b/core/src/test/java/org/elasticsearch/test/engine/AssertingCreateContextIndexSearcherService.java
new file mode 100644
index 000000000000..27996fdc872e
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/test/engine/AssertingCreateContextIndexSearcherService.java
@@ -0,0 +1,56 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.test.engine;
+
+import org.elasticsearch.ElasticsearchException;
+import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.index.engine.*;
+import org.elasticsearch.index.settings.IndexSettings;
+import org.elasticsearch.search.internal.ContextIndexSearcher;
+import org.elasticsearch.test.ESIntegTestCase;
+
+import java.util.Random;
+import java.util.Set;
+
+public class AssertingCreateContextIndexSearcherService extends DefaultCreateContextIndexSearcherService {
+
+    private final Random random;
+
+    @Inject
+    public AssertingCreateContextIndexSearcherService(@IndexSettings Settings indexSettings, Set<IndexSearcherWrapper> wrappers) {
+        super(wrappers);
+        final long seed = indexSettings.getAsLong(ESIntegTestCase.SETTING_INDEX_SEED, 0l);
+        this.random = new Random(seed);
+    }
+
+    @Override
+    protected Engine.Searcher wrapEngineSearcher(EngineConfig engineConfig, final ContextIndexSearcher indexSearcher, final Engine.Searcher originalEngineSearcher) {
+        final Engine.Searcher newEngineSearcher = super.wrapEngineSearcher(engineConfig, indexSearcher, originalEngineSearcher);
+        AssertingContextIndexSearcher assertingIndexSearcher = new AssertingContextIndexSearcher(random, indexSearcher);
+        return new Engine.Searcher(newEngineSearcher.source(), assertingIndexSearcher) {
+
+            @Override
+            public void close() throws ElasticsearchException {
+                newEngineSearcher.close();
+            }
+        };
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/test/engine/MockEngineSupport.java b/core/src/test/java/org/elasticsearch/test/engine/MockEngineSupport.java
index 78b0439c5933..1d27b58fb3c1 100644
--- a/core/src/test/java/org/elasticsearch/test/engine/MockEngineSupport.java
+++ b/core/src/test/java/org/elasticsearch/test/engine/MockEngineSupport.java
@@ -22,7 +22,6 @@
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.FilterDirectoryReader;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.search.AssertingIndexSearcher;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.QueryCache;
 import org.apache.lucene.search.QueryCachingPolicy;
@@ -126,19 +125,20 @@ public CloseAction flushOrClose(Engine engine, CloseAction originalAction) throw
         }
     }
 
-    public AssertingIndexSearcher newSearcher(String source, IndexSearcher searcher, SearcherManager manager) throws EngineException {
+    public IndexSearcher newSearcher(String source, IndexSearcher searcher, SearcherManager manager) throws EngineException {
         IndexReader reader = searcher.getIndexReader();
-        IndexReader wrappedReader = reader;
         assert reader != null;
         if (reader instanceof DirectoryReader && mockContext.wrapReader) {
-            wrappedReader = wrapReader((DirectoryReader) reader);
+            DirectoryReader wrappedReader = wrapReader((DirectoryReader) reader);
+            // No need to wrap in AssertingIndexSearcher, this is already done in AssertingCreateContextIndexSearcherService
+            IndexSearcher indexSearcher =  new IndexSearcher(wrappedReader);
+            indexSearcher.setSimilarity(searcher.getSimilarity(true));
+            indexSearcher.setQueryCache(filterCache);
+            indexSearcher.setQueryCachingPolicy(filterCachingPolicy);
+            return indexSearcher;
+        } else {
+            return searcher;
         }
-        // this executes basic query checks and asserts that weights are normalized only once etc.
-        final AssertingIndexSearcher assertingIndexSearcher = new AssertingIndexSearcher(mockContext.random, wrappedReader);
-        assertingIndexSearcher.setSimilarity(searcher.getSimilarity(true));
-        assertingIndexSearcher.setQueryCache(filterCache);
-        assertingIndexSearcher.setQueryCachingPolicy(filterCachingPolicy);
-        return assertingIndexSearcher;
     }
 
     private DirectoryReader wrapReader(DirectoryReader reader) {
@@ -186,8 +186,7 @@ public Object getCombinedCoreAndDeletesKey() {
     }
 
     public Engine.Searcher wrapSearcher(String source, Engine.Searcher engineSearcher, IndexSearcher searcher, SearcherManager manager) {
-        final AssertingIndexSearcher assertingIndexSearcher = newSearcher(source, searcher, manager);
-        assertingIndexSearcher.setSimilarity(searcher.getSimilarity(true));
+        final IndexSearcher assertingIndexSearcher = newSearcher(source, searcher, manager);
         // pass the original searcher to the super.newSearcher() method to make sure this is the searcher that will
         // be released later on. If we wrap an index reader here must not pass the wrapped version to the manager
         // on release otherwise the reader will be closed too early. - good news, stuff will fail all over the place if we don't get this right here
